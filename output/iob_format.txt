nist	O
2019	O
speaker	B
recognition	O
evaluation	B
plan	I
august	O
16	O
,	O
2019	O
1	O
introduction	O
the	O
2019	O
speaker	B
recognition	O
evaluation	B
(	O
sre19	O
)	O
is	O
the	O
next	O
in	O
an	O
ongoing	O
series	O
of	O
speaker	B
recognition	O
evaluations	O
conducted	O
by	O
the	O
us	O
national	O
institute	O
of	O
standards	O
and	O
technology	O
(	O
nist	O
)	O
since	O
1996	O
.	O
the	O
objectives	O
of	O
the	O
evaluation	B
series	O
are	O
(	O
1	O
)	O
for	O
nist	O
to	O
effectively	O
measure	O
system	O
-	O
calibrated	O
performance	O
of	O
the	O
current	O
state	O
of	O
technology	O
,	O
(	O
2	O
)	O
to	O
provide	O
a	O
common	O
test	B
bed	O
that	O
enables	O
the	O
research	B
community	O
to	O
explore	O
promising	O
new	O
ideas	O
in	O
speaker	B
recognition	O
,	O
and	O
(	O
3	O
)	O
to	O
support	O
the	O
community	O
in	O
their	O
devel-	O
opment	O
of	O
advanced	O
technology	O
incorporating	O
these	O
ideas	O
.	O
the	O
evaluations	O
are	O
intended	O
to	O
be	O
of	O
interest	O
to	O
all	O
researchers	O
working	O
on	O
the	O
general	O
problem	O
of	O
text	O
-	O
independent	O
speaker	B
recognition	O
.	O
to	O
this	O
end	O
,	O
the	O
evaluations	O
are	O
designed	O
to	O
focus	O
on	O
core	O
technology	O
issues	O
and	O
to	O
be	O
simple	O
and	O
accessible	O
to	O
those	O
wishing	O
to	O
participate	O
.	O
sre19	O
will	O
consist	O
of	O
two	O
separate	O
activities	O
:	O
1	O
)	O
a	O
leaderboard	O
-	O
style	O
challenge	B
using	O
conversational	O
tele-	O
phone	O
speech	O
(	O
cts	O
)	O
extracted	O
from	O
the	O
unexposed	O
portions	O
of	O
the	O
call	O
my	O
net	O
2	O
(	O
cmn2	O
)	O
corpus	B
,	O
and	O
2	O
)	O
a	O
regular	O
evaluation	B
using	O
audio	O
-	O
visual	O
(	O
av	O
)	O
material	O
extracted	O
from	O
the	O
unexposed	O
portions	O
of	O
the	O
video	O
annotation	O
for	O
speech	O
technology	O
(	O
vast	O
)	O
corpus	B
.	O
this	O
document	O
describes	O
the	O
task	O
,	O
the	O
performance	O
met-	O
ric	O
,	O
data	B
,	O
and	O
the	O
evaluation	B
protocol	O
as	O
well	O
as	O
rules	O
/	O
requirements	O
for	O
the	O
regular	O
evaluation	B
(	O
referred	O
to	O
as	O
sre19	O
hereafter	O
)	O
.	O
the	O
evaluation	B
plan	I
for	O
the	O
sre19	O
cts	O
challenge	B
can	O
be	O
found	O
on	O
the	O
sre19	O
website1	O
.	O
note	O
that	O
in	O
order	B
to	O
participate	O
in	O
the	O
regular	O
evaluation	B
(	O
i.e.	O
,	O
part	O
2	O
)	O
,	O
one	O
must	O
ﬁrst	O
complete	O
part	O
1	O
.	O
the	O
sre19	O
will	O
be	O
organized	O
in	O
a	O
similar	O
manner	O
to	O
the	O
sre18	O
,	O
except	O
that	O
for	O
this	O
year	O
’s	O
evaluation	B
only	O
the	O
open	O
training	O
condition	B
will	O
be	O
offered	O
(	O
see	O
section	O
2.2	O
)	O
.	O
moreover	O
,	O
in	O
addition	O
to	O
the	O
regular	O
audio	O
-	O
only	O
track	O
,	O
the	O
sre19	O
will	O
also	O
introduce	O
audio	O
-	O
visual	O
and	O
visual	O
-	O
only	O
tracks	B
.	O
system	O
submission	O
is	O
required	O
for	O
the	O
audio	O
and	O
audio	O
-	O
visual	O
tracks	B
,	O
and	O
optional	O
for	O
the	O
visual	O
track	O
.	O
table	O
1	O
summarizes	O
the	O
tracks	B
for	O
the	O
sre19	O
.	O
track	O
input	B
core	O
audio	O
audio	O
from	O
video	O
yes	O
audio	O
-	O
visual	O
audio	O
and	O
frames	O
from	O
video	O
yes	O
visual	O
frames	O
from	O
video	O
no	O
table	O
1	O
:	O
the	O
sre19	O
tracks	B
participation	O
in	O
the	O
sre19	O
is	O
open	O
to	O
all	O
who	O
ﬁnd	O
the	O
evaluation	B
of	O
interest	O
and	O
are	O
able	O
to	O
comply	O
with	O
the	O
evaluation	B
rules	O
set	B
forth	O
in	O
this	O
plan	O
.	O
although	O
there	O
is	O
no	O
cost	B
to	O
participate	O
in	O
sre19	O
(	O
i.e.	O
,	O
the	O
evaluation	B
data	B
,	O
web	O
platform	O
,	O
and	O
scoring	O
software	O
will	O
be	O
available	O
free	O
of	O
charge	O
)	O
,	O
participating	O
teams	O
must	O
be	O
represented	O
at	O
the	O
post	O
-	O
evaluation	B
workshop2	O
to	O
be	O
co	O
-	O
located	O
with	O
ieee	O
asru	O
workshop	O
in	O
sentosa	O
,	O
singapore	O
,	O
on	O
december	O
12	O
-	O
13	O
,	O
2019	O
.	O
information	B
about	O
evaluation	B
registration	O
can	O
be	O
found	O
on	O
the	O
sre19	O
website1	O
.	O
1https://www.nist.gov/itl/iad/mig/nist-2019-speaker-recognition-evaluation	O
2workshop	O
registration	O
is	O
required	O
.	O
1nist	O
2019	O
speaker	B
recognition	O
evaluation	B
plan	I
2	O
task	O
description	O
2.1	O
task	O
deﬁnition	O
the	O
task	O
for	O
the	O
sre19	O
is	O
individual	O
/	O
person	O
detection	B
:	O
given	O
a	O
test	B
video	O
segment	B
and	O
a	O
target	O
individual	O
’s	O
enrollment	O
video	O
,	O
automatically	O
determine	O
whether	O
the	O
target	O
individual	O
is	O
present	O
in	O
the	O
test	B
segment	B
.	O
the	O
test	B
segment	B
along	O
with	O
the	O
enrollment	O
segment	B
from	O
a	O
designated	O
target	O
individual	O
constitute	O
a	O
trial	O
.	O
the	O
system	O
is	O
required	O
to	O
process	B
each	O
trial	O
independently	O
and	O
to	O
output	B
a	O
log	B
-	O
likelihood	B
ratio	I
(	O
llr	O
)	O
,	O
using	O
natural	O
(	O
base	O
e	O
)	O
logarithm	O
,	O
for	O
that	O
trial	O
.	O
the	O
llr	O
for	O
a	O
given	O
trial	O
including	O
a	O
test	B
segment	B
s	O
is	O
deﬁned	O
as	O
follows	O
(	O
cid:18	O
)	O
p	O
(	O
s|h	O
)	O
(	O
cid:19	O
)	O
llr(s	O
)	O
=	O
log	B
0	O
.	O
(	O
1	O
)	O
p	O
(	O
s|h	O
)	O
1	O
where	O
p	O
(	O
·	O
)	O
denotes	O
the	O
probability	B
distribution	O
function	O
(	O
pdf	O
)	O
,	O
and	O
h	O
and	O
h	O
represent	O
the	O
null	O
(	O
i.e.	O
,	O
the	O
0	O
1	O
target	O
individual	O
is	O
present	O
in	O
s	O
)	O
and	O
alternative	O
(	O
i.e.	O
,	O
the	O
target	O
individual	O
is	O
not	O
present	O
in	O
s	O
)	O
hypotheses	B
,	O
respectively	O
.	O
2.2	O
training	O
condition	B
the	O
training	O
condition	B
is	O
deﬁned	O
as	O
the	O
amount	B
of	O
data	B
/	O
resources	O
used	O
to	O
build	O
an	O
individual	O
/	O
person	O
recognition	O
system	O
.	O
unlike	O
sre16	O
and	O
sre18	O
,	O
this	O
year	O
’s	O
evaluation	B
only	O
offers	O
the	O
open	O
training	O
condition	B
that	O
allows	O
the	O
use	O
of	O
any	O
publicly	O
available	O
and/or	O
proprietary	O
data	B
for	O
system	O
training	O
and	O
development	O
.	O
the	O
motivation	O
behind	O
this	O
decision	O
is	O
twofold	O
.	O
first	O
,	O
results	B
from	O
the	O
most	O
recent	O
nist	O
sres	O
(	O
i.e.	O
,	O
sre16	O
and	O
sre18	O
)	O
indicate	O
limited	O
performance	O
improvements	B
,	O
if	O
any	O
,	O
from	O
unconstrained	O
training	O
compared	O
to	O
ﬁxed	O
training	O
.	O
we	O
note	O
,	O
however	O
,	O
that	O
participants	B
cited	O
lack	O
of	O
time	B
and/or	O
resources	O
during	O
the	O
evaluation	B
period	O
for	O
not	O
demonstrating	O
signiﬁcant	O
improvement	O
with	O
open	O
vs	O
ﬁxed	O
training	O
.	O
second	O
,	O
the	O
number	O
of	O
publicly	O
available	O
large	O
-	O
scale	O
data	B
resources	O
that	O
can	O
be	O
used	O
for	O
speaker	B
and	O
individual	O
/	O
person	O
recognition	O
has	O
dramatically	O
increased	O
over	O
the	O
past	O
few	O
years	O
(	O
e.g.	O
,	O
see	O
voxceleb3	O
and	O
sitw4	O
)	O
.	O
therefore	O
,	O
removing	O
the	O
ﬁxed	O
training	O
condition	B
will	O
allow	O
more	O
in	O
-	O
depth	O
exploration	O
into	O
the	O
gains	O
that	O
can	O
be	O
achieved	O
with	O
the	O
availability	O
of	O
unconstrained	O
resources	O
given	O
the	O
success	O
of	O
data	B
-	O
hungry	O
neural	B
network	I
based	O
approaches	O
in	O
the	O
most	O
recent	O
evaluation	B
(	O
i.e.	O
sre18	O
)	O
.	O
for	O
the	O
sake	O
of	O
convenience	O
,	O
in	O
particular	O
for	O
the	O
audio	O
-	O
visual	O
and	O
visual	O
-	O
only	O
tracks	B
,	O
nist	O
will	O
also	O
provide	O
two	O
development	O
sets	O
that	O
can	O
be	O
used	O
for	O
system	O
training	O
and	O
development	O
purposes	O
:	O
•	O
janus	O
multimedia	O
dataset	O
(	O
ldc2019e55	O
)	O
•	O
2019	O
nist	O
speaker	B
recognition	O
evaluation	B
audio	O
-	O
visual	O
development	B
set	I
(	O
ldc2019e56	O
)	O
the	O
ldc2019e55	O
,	O
which	O
has	O
been	O
extracted	O
from	O
the	O
iarpa	O
janus	O
benchmark	O
-	O
c	O
datatset	O
,	O
is	O
available	O
from	O
the	O
linguistic	O
data	B
consortium	O
(	O
ldc	O
)	O
,	O
subject	O
to	O
approval	O
of	O
the	O
ldc	O
data	B
license	O
agreement	O
.	O
the	O
ldc2019e56	O
contains	O
the	O
original	O
videos	B
from	O
which	O
the	O
vast	O
portion	O
of	O
sre18	O
dev	O
/	O
test	B
sets	O
were	O
com-	O
piled	O
.	O
participants	B
can	O
obtain	O
this	O
dataset	O
through	O
the	O
evaluation	B
web	O
platform	O
(	O
https://sre.nist.gov	O
)	O
after	O
they	O
have	O
signed	O
the	O
ldc	O
data	B
license	O
agreement	O
.	O
although	O
sre19	O
allows	O
unconstrained	O
system	O
training	O
and	O
development	O
,	O
participating	O
teams	O
must	O
pro-	O
vide	O
a	O
sufﬁcient	O
description	O
of	O
speech	O
and	O
non	O
-	O
speech	O
data	B
resources	O
as	O
well	O
as	O
pre	O
-	O
trained	O
models	B
used	O
during	O
the	O
training	O
and	O
development	O
of	O
their	O
systems	O
(	O
see	O
section	O
6.4.2	O
)	O
.	O
2.3	O
enrollment	O
conditions	O
the	O
enrollment	O
condition	B
is	O
deﬁned	O
as	O
the	O
number	O
of	O
video	O
segments	O
provided	O
to	O
create	O
a	O
target	O
speaker	B
model	B
.	O
there	O
is	O
only	O
one	O
enrollment	O
condition	B
for	O
the	O
sre19	O
:	O
3http://www.robots.ox.ac.uk/~vgg/data/voxceleb/	O
4http://www.speech.sri.com/projects/sitw/	O
page	O
2	O
of	O
9nist	O
2019	O
speaker	B
recognition	O
evaluation	B
plan	I
•	O
one	O
-	O
segment	B
–	O
in	O
which	O
the	O
system	O
is	O
given	O
only	O
one	O
video	O
segment	B
,	O
that	O
can	O
vary	O
in	O
duration	O
from	O
a	O
few	O
seconds	B
to	O
several	O
minutes	O
,	O
to	O
build	O
the	O
model	B
of	O
the	O
target	O
individual	O
.	O
note	O
that	O
for	O
the	O
audio	O
track	O
,	O
speech	O
extracted	O
from	O
the	O
enrollment	O
video	O
serves	O
as	O
enrollment	O
data	B
,	O
while	O
for	O
the	O
visual	O
track	O
,	O
face	O
frame(s	O
)	O
(	O
i.e.	O
,	O
frames	O
in	O
which	O
the	O
face	O
of	O
the	O
target	O
individual	O
is	O
visible	O
)	O
extracted	O
from	O
the	O
video	O
serve	O
that	O
purpose	O
.	O
since	O
nist	O
will	O
only	O
be	O
releasing	O
video	O
ﬁles	O
for	O
sre19	O
,	O
participants	B
are	O
responsible	O
for	O
extracting	O
the	O
relevant	O
data	B
(	O
i.e.	O
,	O
speech	O
or	O
face	O
frames	O
)	O
for	O
subsequent	O
processing	B
.	O
as	O
in	O
the	O
most	O
recent	O
evaluations	O
,	O
gender	O
labels	O
will	O
not	O
be	O
provided	O
for	O
the	O
enrollment	O
segments	O
in	O
the	O
test	B
set	B
.	O
2.4	O
test	B
conditions	O
the	O
test	B
conditions	O
for	O
the	O
sre19	O
are	O
as	O
follows	O
:	O
•	O
the	O
test	B
segment	B
video	O
duration	O
may	O
vary	O
from	O
a	O
few	O
seconds	B
to	O
several	O
minutes	O
.	O
•	O
the	O
test	B
video	O
can	O
contain	O
audio	O
-	O
visual	O
data	B
from	O
potentially	O
multiple	O
individuals	O
.	O
•	O
there	O
will	O
be	O
both	O
same	O
-	O
gender	O
and	O
cross	O
-	O
gender	O
trials	O
.	O
3	O
performance	O
measurement	O
3.1	O
primary	O
metric	B
a	O
basic	O
cost	B
model	B
is	O
used	O
to	O
measure	O
the	O
individual	O
/	O
person	O
detection	B
performance	O
in	O
sre19	O
,	O
which	O
is	O
deﬁned	O
as	O
a	O
weighted	O
sum	O
of	O
false	O
-	O
reject	O
(	O
missed	O
detection	B
)	O
and	O
false	O
-	O
alarm	O
error	O
probabilities	O
for	O
some	O
decision	O
threshold	B
θ	O
as	O
follows	O
c	O
(	O
θ	O
)	O
=	O
c	O
×	O
p	O
×	O
p	O
(	O
θ	O
)	O
+	O
det	O
miss	B
target	O
miss	B
c	O
×	O
(	O
1	O
−	O
p	O
)	O
×	O
p	O
(	O
θ	O
)	O
,	O
(	O
2	O
)	O
falsealarm	O
target	O
falsealarm	O
where	O
the	O
parameters	O
of	O
the	O
cost	B
function	O
are	O
c	O
(	O
cost	B
of	O
a	O
missed	O
detection	B
)	O
and	O
c	O
(	O
cost	B
of	O
a	O
miss	B
falsealarm	O
spurious	O
detection	B
)	O
,	O
and	O
p	O
(	O
a	O
priori	O
probability	B
of	O
the	O
speciﬁed	O
target	O
individual	O
)	O
and	O
are	O
deﬁned	O
to	O
target	O
have	O
the	O
following	O
values	B
:	O
source	B
type	O
parameter	O
i	O
d	O
c	O
c	O
p	O
miss	B
falsealarm	O
target	O
av	O
1	O
1	O
1	O
0.05	O
table	O
2	O
:	O
the	O
sre19	O
detection	B
cost	B
parameters	O
to	O
improve	O
the	O
interpretability	O
of	O
the	O
cost	B
function	O
c	O
in	O
(	O
2	O
)	O
,	O
it	O
will	O
be	O
normalized	O
by	O
c	O
which	O
det	O
de	O
f	O
ault	O
is	O
deﬁned	O
as	O
the	O
best	O
cost	B
that	O
could	O
be	O
obtained	O
without	O
processing	B
the	O
input	B
data	B
(	O
i.e.	O
,	O
by	O
either	O
always	O
accepting	O
or	O
always	O
rejecting	O
the	O
segment	B
individual(s	O
)	O
as	O
matching	O
the	O
target	O
individual	O
,	O
whichever	O
gives	O
the	O
lower	O
cost	B
)	O
,	O
as	O
follows	O
c	O
(	O
θ	O
)	O
c	O
(	O
θ	O
)	O
=	O
det	O
,	O
(	O
3	O
)	O
norm	B
c	O
de	O
f	O
ault	O
where	O
c	O
is	O
deﬁned	O
as	O
de	O
f	O
ault	O
(	O
cid:40	O
)	O
c	O
×	O
p	O
,	O
c	O
=	O
min	O
miss	B
target	O
(	O
4	O
)	O
de	O
f	O
ault	O
c	O
×	O
(	O
1	O
−	O
p	O
)	O
.	O
falsealarm	O
target	O
page	O
3	O
of	O
9nist	O
2019	O
speaker	B
recognition	O
evaluation	B
plan	I
substituting	O
the	O
set	B
of	O
parameter	O
values	B
from	O
table	O
2	O
into	O
(	O
4	O
)	O
yields	O
c	O
=	O
c	O
×	O
p	O
.	O
(	O
5	O
)	O
de	O
f	O
ault	O
miss	B
target	O
substituting	O
c	O
and	O
c	O
in	O
(	O
3	O
)	O
with	O
(	O
2	O
)	O
and	O
(	O
5	O
)	O
,	O
respectively	O
,	O
along	O
with	O
some	O
algebraic	O
manipulations	O
det	O
de	O
f	O
ault	O
yields	O
c	O
(	O
θ	O
)	O
=	O
p	O
(	O
θ	O
)	O
+	O
β	O
×	O
p	O
(	O
θ	O
)	O
,	O
(	O
6	O
)	O
norm	B
miss	B
falsealarm	O
where	O
β	O
is	O
deﬁned	O
as	O
β	O
=	O
cfalsealarm	O
×	O
1	O
−	O
ptarget	O
.	O
(	O
7	O
)	O
c	O
p	O
miss	B
target	O
the	O
actual	O
detection	B
cost	B
will	O
be	O
computed	O
from	O
the	O
trial	O
scores	O
by	O
applying	O
a	O
detection	B
threshold	B
of	O
log(β	O
)	O
,	O
where	O
log	B
denotes	O
the	O
natural	O
logarithm	O
.	O
the	O
detection	B
threshold	B
will	O
be	O
computed	O
for	O
β	O
with	O
1	O
p	O
=	O
0.05	O
.	O
the	O
primary	O
cost	B
measure	O
for	O
the	O
sre19	O
is	O
then	O
deﬁned	O
as	O
target1	O
c	O
=	O
c	O
(	O
log(β	O
)	O
)	O
.	O
(	O
8)	O
primary	O
norm	B
1	O
in	O
addition	O
to	O
c	O
,	O
a	O
minimum	O
detection	B
cost	B
will	O
also	O
be	O
computed	O
by	O
using	O
the	O
detection	B
threshold	B
primary	O
that	O
minimizes	O
the	O
detection	B
cost	B
.	O
nist	O
will	O
make	O
available	O
the	O
script	O
that	O
calculates	O
the	O
primary	O
metric	B
,	O
on	O
the	O
evaluation	B
web	O
platform	O
.	O
4	O
data	B
description	O
the	O
data	B
collected	O
by	O
the	O
ldc	O
as	O
part	O
of	O
the	O
video	O
annotation	O
for	O
speech	O
technology	O
(	O
vast	O
)	O
corpus	B
to	O
support	O
speaker	B
recognition	O
research	B
will	O
be	O
used	O
to	O
compile	O
the	O
sre19	O
development	O
and	O
test	B
sets	O
.	O
the	O
vast	O
corpus	B
contains	O
amateur	O
video	O
recordings	O
(	O
such	O
as	O
video	O
blogs	O
)	O
collected	O
by	O
the	O
ldc	O
from	O
various	O
online	O
media	O
hosting	O
services	O
.	O
the	O
videos	B
vary	O
in	O
duration	O
from	O
a	O
few	O
seconds	B
to	O
several	O
minutes	O
and	O
include	O
speech	O
spoken	O
in	O
english	O
.	O
each	O
video	O
may	O
contain	O
audio	O
-	O
visual	O
data	B
from	O
potentially	O
multiple	O
individuals	O
who	O
may	O
or	O
may	O
not	O
be	O
visible	O
in	O
the	O
recording	B
,	O
therefore	O
manually	O
produced	O
diarization	B
labels	O
(	O
i.e.	O
,	O
speaker	B
time	I
marks	O
)	O
,	O
as	O
well	O
as	O
key	O
face	O
frames5	O
and	O
bounding	O
boxes	O
(	O
that	O
mark	O
an	O
individual	O
’s	O
face	O
in	O
the	O
video	O
)	O
will	O
be	O
provided	O
for	O
both	O
the	O
dev	O
set	B
and	O
test	B
set	B
enrollment	O
videos	B
(	O
but	O
not	O
for	O
the	O
test	B
videos	B
in	O
either	O
set	B
)	O
.	O
all	O
video	O
data	B
will	O
be	O
encoded	O
as	O
mpeg4	O
.	O
the	O
vast	O
development	O
and	O
test	B
sets	O
will	O
be	O
distributed	O
by	O
nist	O
via	O
the	O
online	O
evaluation	B
platform	O
(	O
https://sre.nist.gov	O
)	O
,	O
while	O
the	O
janus	O
multimedia	O
dataset	O
will	O
be	O
released	O
by	O
the	O
ldc	O
.	O
4.1	O
data	B
organization	O
the	O
development	O
and	O
test	B
sets	O
follow	O
a	O
similar	O
directory	O
structure	O
:	O
<	O
base	O
directory>/	O
readme.txt	O
data/	O
enrollment/	O
test/	O
docs/	O
4.2	O
trial	O
file	O
the	O
trial	O
ﬁle	O
,	O
named	O
sre19	O
av	O
{	O
dev|eval	O
}	O
trials.tsv	O
and	O
located	O
in	O
the	O
docs	O
directory	O
,	O
is	O
composed	O
of	O
a	O
header	O
and	O
a	O
set	B
of	O
records	O
where	O
each	O
record	O
describes	O
a	O
given	O
trial	O
.	O
each	O
record	O
is	O
a	O
single	O
line	O
containing	O
5note	O
that	O
only	O
a	O
few	O
(	O
out	O
of	O
potentially	O
many	O
)	O
target	O
face	O
frames	O
per	O
enrollment	O
video	O
have	O
been	O
manually	O
annotated	O
.	O
page	O
4	O
of	O
9nist	O
2019	O
speaker	B
recognition	O
evaluation	B
plan	I
three	O
ﬁelds	O
separated	O
by	O
a	O
tab	O
character	O
and	O
in	O
the	O
following	O
format	O
:	O
modelid	O
<	O
tab	O
>	O
segmentid	O
<	O
tab	O
>	O
side	O
<	O
newline	O
>	O
where	O
modelid	O
-	O
the	O
enrollment	O
identiﬁer	O
segmentid	O
-	O
the	O
test	B
segment	B
identiﬁer	O
side	O
-	O
the	O
channel6	O
for	O
example	O
:	O
modelid	O
segmentid	O
side	O
1001	O
sre19	O
dtadhlw	O
sre19	O
a	O
1001	O
sre19	O
dtaekaz	O
sre19	O
a	O
1001	O
sre19	O
dtaekbb	O
sre19	O
a	O
4.3	O
development	B
set	I
participants	B
in	O
the	O
sre19	O
will	O
receive	O
data	B
for	O
development	O
experiments	O
that	O
will	O
mirror	O
the	O
evaluation	B
conditions	O
,	O
and	O
will	O
include	O
:	O
•	O
videos	B
from	O
52	O
individuals	O
from	O
the	O
vast	O
portion	O
of	O
sre18	O
•	O
associated	O
metadata	O
which	O
will	O
be	O
located	O
in	O
the	O
docs	O
directory	O
as	O
outlined	O
in	O
section	O
4.1	O
:	O
–	O
sre19	O
av	O
dev	O
segment	B
key.tsv	O
contains	O
information	B
about	O
the	O
video	O
segments	O
as	O
well	O
as	O
the	O
individuals	O
within	O
them	O
,	O
and	O
includes	O
the	O
following	O
ﬁelds	O
:	O
∗	O
segmentid	O
(	O
segment	B
identiﬁer	O
)	O
∗	O
subjectid	O
(	O
ldc	O
speaker	B
i	O
d	O
)	O
∗	O
gender	O
(	O
male	O
or	O
female	O
)	O
∗	O
partition	O
(	O
enrollment	O
or	O
test	B
)	O
–	O
sre19	O
av	O
dev	O
enrollment	O
diarization.tsv	O
contains	O
manually	O
produced	O
time	B
marks	O
for	O
target	O
speakers	O
,	O
and	O
includes	O
the	O
following	O
ﬁelds	O
:	O
∗	O
segmentid	O
(	O
segment	B
identiﬁer	O
)	O
∗	O
speaker	B
type	O
(	O
speaker	B
type	O
,	O
always	O
“	O
target	O
”	O
)	O
∗	O
start	O
(	O
start	O
of	O
target	O
speaker	B
segment	B
time	B
mark	O
in	O
seconds	B
)	O
∗	O
end	O
(	O
end	O
of	O
target	O
speaker	B
segment	B
time	B
mark	O
in	O
seconds	B
)	O
–	O
sre19	O
av	O
dev	O
enrollment	O
boundingbox.tsv	O
contains	O
manually	O
produced	O
information	B
about	O
tar-	O
get	O
individuals	O
’	O
faces	O
(	O
e.g.	O
,	O
coordinates	O
)	O
in	O
videos	B
,	O
and	O
includes	O
the	O
following	O
ﬁelds	O
:	O
∗	O
segmentid	O
(	O
segment	B
identiﬁer	O
)	O
∗	O
speaker	B
type	O
(	O
speaker	B
type	O
,	O
always	O
“	O
target	O
”	O
)	O
∗	O
face	O
frame	B
sec	O
(	O
the	O
frame	B
in	O
which	O
a	O
target	O
individual	O
’s	O
face	O
is	O
visible	O
in	O
seconds	B
)	O
∗	O
bounding	O
box	O
(	O
coordinates	O
for	O
a	O
target	O
individual	O
’s	O
face	O
in	O
a	O
speciﬁed	O
frame	B
as	O
[	O
x1,y1,x2,y2	O
]	O
)	O
∗	O
face	O
covered	O
(	O
whether	O
the	O
a	O
target	O
individual	O
’s	O
face	O
is	O
covered	O
)	O
∗	O
eyewear	O
(	O
whether	O
the	O
a	O
target	O
individual	O
is	O
wearing	O
glasses	O
)	O
∗	O
facial	O
hair	O
(	O
whether	O
the	O
a	O
target	O
individual	O
has	O
facial	O
hair	O
)	O
6sre19	O
segments	O
will	O
be	O
assumed	O
single	B
channel	I
,	O
therefore	O
this	O
ﬁeld	O
is	O
always	O
”	O
a	O
”	O
page	O
5	O
of	O
9nist	O
2019	O
speaker	B
recognition	O
evaluation	B
plan	I
in	O
addition	O
to	O
the	O
data	B
noted	O
above	O
,	O
ldc	O
will	O
also	O
release	O
selected	O
data	B
resources	O
from	O
the	O
iarpa	O
janus	O
benchmark	O
-	O
c	O
,	O
namely	O
the	O
janus	O
multimedia	O
dataset7	O
(	O
ldc2019e55	O
)	O
.	O
these	O
development	B
data	I
may	O
be	O
used	O
for	O
any	O
purpose	O
.	O
4.4	O
training	O
set	B
section	O
2.2	O
describes	O
the	O
training	O
condition	B
for	O
the	O
sre19	O
(	O
i.e.	O
,	O
open	O
training	O
condition	B
)	O
.	O
participants	B
are	O
allowed	O
to	O
use	O
any	O
publicly	O
available	O
and/or	O
proprietary	O
data	B
they	O
have	O
available	O
for	O
system	O
training	O
and	O
development	O
purposes	O
.	O
the	O
sre19	O
participants	B
will	O
also	O
receive	O
two	O
dev	O
sets	O
(	O
i.e.	O
,	O
ldc2019e55	O
and	O
ldc2019e56	O
)	O
that	O
they	O
can	O
use	O
for	O
system	O
training	O
.	O
to	O
obtain	O
these	O
development	B
data	I
,	O
participants	B
must	O
sign	O
the	O
ldc	O
data	B
license	O
agreement	O
which	O
outlines	O
the	O
terms	B
of	O
the	O
data	B
usage	O
.	O
5	O
evaluation	B
rules	O
and	O
requirements	O
the	O
sre19	O
is	O
conducted	O
as	O
an	O
open	O
evaluation	B
where	O
the	O
test	B
data	I
is	O
sent	O
to	O
the	O
participants	B
to	O
process	B
locally	O
and	O
submit	O
the	O
output	B
of	O
their	O
systems	O
to	O
nist	O
for	O
scoring	O
.	O
as	O
such	O
,	O
the	O
participants	B
have	O
agreed	O
to	O
process	B
the	O
data	B
in	O
accordance	O
with	O
the	O
following	O
rules	O
:	O
•	O
the	O
participants	B
agree	O
to	O
make	O
at	O
least	O
one	O
valid	O
submission	O
for	O
the	O
open	O
training	O
condition	B
.	O
•	O
the	O
participants	B
agree	O
to	O
process	B
each	O
trial	O
independently	O
.	O
that	O
is	O
,	O
each	O
decision	O
for	O
a	O
trial	O
is	O
to	O
be	O
based	O
only	O
upon	O
the	O
speciﬁed	O
test	B
segment	B
and	O
target	O
speaker	B
enrollment	O
data	B
.	O
the	O
use	O
of	O
informa-	O
tion	O
about	O
other	O
test	B
segments	O
and/or	O
other	O
target	O
speaker	B
data	B
is	O
not	O
allowed	O
.	O
•	O
the	O
participants	B
agree	O
not	O
to	O
probe	O
the	O
enrollment	O
or	O
test	B
segments	O
via	O
manual	O
/	O
human	O
means	O
such	O
as	O
listening	O
to	O
or	O
watching	O
the	O
data	B
,	O
or	O
producing	O
the	O
manual	O
transcript	O
of	O
the	O
speech	O
,	O
or	O
producing	O
the	O
manual	O
face	O
coordinates	O
.	O
•	O
the	O
participants	B
are	O
allowed	O
to	O
use	O
any	O
automatically	O
derived	O
information	B
for	O
training	O
,	O
development	O
,	O
enrollment	O
,	O
or	O
test	B
segments	O
.	O
•	O
the	O
participants	B
are	O
allowed	O
to	O
use	O
information	B
available	O
in	O
the	O
header	O
of	O
the	O
video	O
ﬁles	O
.	O
•	O
the	O
participants	B
can	O
register	O
up	O
to	O
three	O
systems	O
for	O
each	O
track	O
(	O
i.e.	O
,	O
audio	O
,	O
audio	O
-	O
visual	O
,	O
and	O
visual	O
)	O
of	O
the	O
open	O
training	O
condition	B
,	O
one	O
of	O
which	O
under	O
each	O
track	O
should	O
be	O
designated	O
as	O
the	O
primary	O
system	O
.	O
bug-ﬁx	O
does	O
not	O
count	O
toward	O
this	O
limit	O
.	O
teams	O
can	O
make	O
unlimited	O
number	O
of	O
submissions	O
for	O
each	O
of	O
the	O
three	O
systems	O
until	O
the	O
evaluation	B
period	O
is	O
over	O
.	O
in	O
addition	O
to	O
the	O
above	O
data	B
processing	B
rules	O
,	O
participants	B
agree	O
to	O
comply	O
with	O
the	O
following	O
general	O
requirements	O
:	O
•	O
the	O
participants	B
agree	O
to	O
submit	O
reports	O
to	O
nist	O
that	O
describe	O
in	O
sufﬁcient	O
length	B
details	O
of	O
their	O
systems	O
and	O
submissions	O
.	O
the	O
system	O
description	O
reports	O
should	O
comply	O
with	O
guidelines	O
described	O
in	O
section	O
6.4.2	O
.	O
•	O
the	O
participants	B
agree	O
to	O
have	O
one	O
or	O
more	O
representatives	O
at	O
the	O
post	O
-	O
evaluation	B
workshop	O
,	O
to	O
present	O
a	O
meaningful	O
description	O
of	O
their	O
system(s	O
)	O
.	O
evaluation	B
participants	B
failing	O
to	O
do	O
so	O
will	O
be	O
excluded	O
from	O
future	O
evaluation	B
participation	O
.	O
•	O
the	O
participants	B
agree	O
to	O
the	O
guidelines	O
governing	O
the	O
publication	O
of	O
the	O
results	B
:	O
7the	O
data	B
is	O
described	O
in	O
detail	O
in	O
the	O
following	O
paper	O
:	O
g.	O
sell	O
,	O
k.	O
duh	O
,	O
d.	O
snyder	O
,	O
d.	O
etter	O
,	O
d.	O
garcia	O
-	O
romero	O
,	O
“	O
audio	O
-	O
visual	O
person	O
recognition	O
in	O
multimedia	O
data	B
from	O
the	O
iarpa	O
janus	O
program	O
,	O
”	O
in	O
proc	O
.	O
ieee	O
icassp	O
,	O
pp	O
.	O
3031	O
-	O
3035	O
,	O
2018	O
.	O
page	O
6	O
of	O
9nist	O
2019	O
speaker	B
recognition	O
evaluation	B
plan	I
–	O
participants	B
are	O
free	O
to	O
publish	O
results	B
for	O
their	O
own	O
system	O
but	O
must	O
not	O
publicly	O
compare	O
their	O
results	B
with	O
other	O
participants	B
(	O
ranking	O
,	O
score	B
differences	O
,	O
etc	O
.	O
)	O
without	O
explicit	O
written	O
consent	O
from	O
the	O
other	O
participants	B
.	O
–	O
while	O
participants	B
may	O
report	O
their	O
own	O
results	B
,	O
participants	B
may	O
not	O
make	O
advertising	O
claims	O
about	O
their	O
standing	O
in	O
the	O
evaluation	B
,	O
regardless	O
of	O
rank	O
,	O
or	O
winning	O
the	O
evaluation	B
,	O
or	O
claim	O
nist	O
endorsement	O
of	O
their	O
system(s	O
)	O
.	O
the	O
following	O
language	O
in	O
the	O
u.s	O
.	O
code	O
of	O
federal	O
reg-	O
ulations	O
(	O
15	O
c.f.r	O
.	O
§	O
200.113	O
)	O
shall	O
be	O
respected8	O
:	O
nist	O
does	O
not	O
approve	O
,	O
recommend	O
,	O
or	O
endorse	O
any	O
proprietary	O
product	O
or	O
proprietary	O
material	O
.	O
no	O
reference	B
shall	O
be	O
made	O
to	O
nist	O
,	O
or	O
to	O
reports	O
or	O
re-	O
sults	O
furnished	O
by	O
nist	O
in	O
any	O
advertising	O
or	O
sales	O
promotion	O
which	O
would	O
indicate	O
or	O
imply	O
that	O
nist	O
approves	O
,	O
recommends	O
,	O
or	O
endorses	O
any	O
proprietary	O
product	O
or	O
proprietary	O
material	O
,	O
or	O
which	O
has	O
as	O
its	O
purpose	O
an	O
intent	O
to	O
cause	O
directly	O
or	O
indirectly	O
the	O
advertised	O
product	O
to	O
be	O
used	O
or	O
purchased	O
because	O
of	O
nist	O
test	B
reports	O
or	O
results	B
.	O
–	O
at	O
the	O
conclusion	O
of	O
the	O
evaluation	B
nist	O
generates	O
a	O
report	O
summarizing	O
the	O
system	O
results	B
for	O
conditions	O
of	O
interest	O
,	O
but	O
these	O
results	B
/	O
charts	O
do	O
not	O
contain	O
the	O
participant	O
names	O
of	O
the	O
systems	O
involved	O
.	O
participants	B
must	O
not	O
publicly	O
publish	O
or	O
otherwise	O
disseminate	O
these	O
charts	O
.	O
–	O
the	O
report	O
that	O
nist	O
creates	O
should	O
not	O
be	O
construed	O
or	O
represented	O
as	O
endorsements	O
for	O
any	O
participant	O
’s	O
system	O
or	O
commercial	O
product	O
,	O
or	O
as	O
ofﬁcial	O
ﬁndings	O
on	O
the	O
part	O
of	O
nist	O
or	O
the	O
u.s	O
.	O
government	O
.	O
sites	O
failing	O
to	O
meet	O
the	O
above	O
noted	O
rules	O
and	O
requirements	O
,	O
will	O
be	O
excluded	O
from	O
future	O
evaluation	B
par-	O
ticipation	O
,	O
and	O
their	O
future	O
registrations	O
will	O
not	O
be	O
accepted	O
until	O
they	O
commit	O
to	O
fully	O
comply	O
with	O
the	O
rules	O
.	O
6	O
evaluation	B
protocol	O
to	O
facilitate	O
information	B
exchange	O
between	O
the	O
participants	B
and	O
nist	O
,	O
all	O
evaluation	B
activities	O
are	O
con-	O
ducted	O
over	O
a	O
web	O
-	O
interface	O
.	O
6.1	O
evaluation	B
account	O
participants	B
must	O
sign	O
up	O
for	O
an	O
evaluation	B
account	O
where	O
they	O
can	O
perform	O
various	O
activities	O
such	O
as	O
registering	O
for	O
the	O
evaluation	B
,	O
signing	O
the	O
data	B
license	O
agreement	O
,	O
as	O
well	O
as	O
uploading	O
the	O
submission	O
and	O
system	O
description	O
.	O
to	O
sign	O
up	O
for	O
an	O
evaluation	B
account	O
,	O
go	O
to	O
https://sre.nist.gov	O
.	O
the	O
password	O
must	O
be	O
at	O
least	O
12	O
characters	O
long	O
and	O
must	O
contain	O
a	O
mix	O
of	O
upper	O
and	O
lowercase	O
letters	O
,	O
numbers	O
,	O
and	O
symbols	O
.	O
after	O
the	O
evaluation	B
account	O
is	O
conﬁrmed	O
,	O
the	O
participant	O
is	O
asked	O
to	O
join	O
a	O
site	O
or	O
create	O
one	O
if	O
it	O
does	O
not	O
exist	O
.	O
the	O
participant	O
is	O
also	O
asked	O
to	O
associate	O
his	O
site	O
to	O
a	O
team	O
or	O
create	O
one	O
if	O
it	O
does	O
not	O
exist	O
.	O
this	O
allows	O
multiple	O
members	O
with	O
their	O
individual	O
accounts	O
to	O
perform	O
activities	O
on	O
behalf	O
of	O
their	O
site	O
and/or	O
team	O
(	O
e.g.	O
,	O
make	O
a	O
submission	O
)	O
in	O
addition	O
to	O
performing	O
their	O
own	O
activities	O
(	O
e.g.	O
,	O
requesting	O
workshop	O
invitation	O
letter	O
)	O
.	O
•	O
a	O
participant	O
is	O
deﬁned	O
as	O
a	O
member	O
or	O
representative	O
of	O
a	O
site	O
who	O
takes	O
part	O
in	O
the	O
evaluation	B
(	O
e.g.	O
,	O
john	O
doe	O
)	O
•	O
a	O
site	O
is	O
deﬁned	O
as	O
a	O
single	O
organization	O
(	O
e.g.	O
,	O
nist	O
)	O
•	O
a	O
team	O
is	O
deﬁned	O
as	O
a	O
group	O
of	O
organizations	O
collaborating	O
on	O
a	O
task	O
(	O
e.g.	O
,	O
team1	O
consisting	O
of	O
nist	O
and	O
ldc	O
)	O
8see	O
http://www.ecfr.gov/cgi-bin/ecfr?page=browse	O
page	O
7	O
of	O
9nist	O
2019	O
speaker	B
recognition	O
evaluation	B
plan	I
6.2	O
evaluation	B
registration	O
one	O
participant	O
from	O
a	O
site	O
must	O
formally	O
register	O
his	O
site	O
to	O
participate	O
in	O
the	O
evaluation	B
by	O
agreeing	O
to	O
the	O
terms	B
of	O
participation	O
.	O
for	O
more	O
information	B
about	O
the	O
terms	B
of	O
participation	O
,	O
see	O
section	O
5	O
.	O
6.3	O
data	B
license	O
agreement	O
one	O
participant	O
from	O
each	O
site	O
must	O
sign	O
the	O
ldc	O
data	B
license	O
agreement	O
to	O
obtain	O
the	O
development	O
/	O
training	B
data	I
for	O
the	O
sre19	O
.	O
6.4	O
submission	O
requirements	O
each	O
team	O
must	O
make	O
at	O
least	O
one	O
valid	O
submission	O
for	O
the	O
audio	O
-	O
only	O
and	O
the	O
audio	O
-	O
visual	O
tracks	B
,	O
process-	O
ing	O
all	O
test	B
segments	O
.	O
submissions	O
with	O
missing	O
test	B
segments	O
will	O
not	O
pass	O
the	O
validation	O
step	O
,	O
and	O
hence	O
will	O
be	O
rejected	O
.	O
submission	O
for	O
the	O
visual	O
-	O
only	O
track	O
is	O
optional	O
but	O
highly	O
encouraged	O
to	O
gain	O
insights	O
into	O
how	O
the	O
face	O
recognition	O
technology	O
compares	O
with	O
the	O
speaker	B
recognition	O
technology	O
on	O
the	O
same	O
data	B
.	O
each	O
team	O
is	O
required	O
to	O
submit	O
a	O
system	O
description	O
at	O
the	O
designated	O
time	B
(	O
see	O
section	O
7	O
)	O
.	O
the	O
evalua-	O
tion	O
results	B
are	O
made	O
available	O
only	O
after	O
the	O
system	O
description	O
report	O
is	O
received	O
and	O
conﬁrmed	O
to	O
comply	O
with	O
guidelines	O
described	O
in	O
section	O
6.4.2	O
.	O
6.4.1	O
system	O
output	B
format	O
the	O
system	O
output	B
ﬁle	O
is	O
composed	O
of	O
a	O
header	O
and	O
a	O
set	B
of	O
records	O
where	O
each	O
record	O
contains	O
a	O
trial	O
given	O
in	O
the	O
trial	O
ﬁle	O
(	O
see	O
section	O
4.2	O
)	O
and	O
a	O
log	B
likelihood	B
ratio	I
output	B
by	O
the	O
system	O
for	O
the	O
trial	O
.	O
the	O
order	B
of	O
the	O
trials	O
in	O
the	O
system	O
output	B
ﬁle	O
must	O
follow	O
the	O
same	O
order	B
as	O
the	O
trial	O
list	O
.	O
each	O
record	O
is	O
a	O
single	O
line	O
containing	O
4	O
ﬁelds	O
separated	O
by	O
tab	O
character	O
in	O
the	O
following	O
format	O
:	O
modelid	O
<	O
tab	O
>	O
segment	B
<	O
tab	O
>	O
side	O
<	O
tab	O
>	O
llr	O
<	O
newline	O
>	O
where	O
modelid	O
-	O
the	O
enrollment	O
identiﬁer	O
segmentid	O
-	O
the	O
test	B
segment	B
identiﬁer	O
side	O
-	O
the	O
channel	O
(	O
always	O
”	O
a	O
”	O
for	O
sre19	O
since	O
the	O
data	B
is	O
assumed	O
single	B
channel	I
)	O
llr	O
-	O
the	O
log	B
-	O
likelihood	B
ratio	I
for	O
example	O
:	O
modelid	O
segmentid	O
side	O
llr	O
1001	O
sre19	O
dtadhlw	O
sre19	O
a	O
0.79402	O
1001	O
sre19	O
dtaekaz	O
sre19	O
a	O
0.24256	O
1001	O
sre19	O
dtaekbb	O
sre19	O
a	O
0.01038	O
there	O
should	O
be	O
one	O
output	B
ﬁle	O
for	O
each	O
track	O
for	O
each	O
system	O
.	O
nist	O
will	O
make	O
available	O
the	O
script	O
that	O
validates	O
the	O
system	O
output	B
.	O
6.4.2	O
system	O
description	O
format	O
each	O
team	O
is	O
required	O
to	O
submit	O
a	O
system	O
description	O
.	O
the	O
system	O
description	O
must	O
include	O
the	O
following	O
items	O
:	O
•	O
a	O
complete	O
description	O
of	O
the	O
system	O
components	B
,	O
including	O
front	O
-	O
end	O
(	O
e.g.	O
,	O
speech	B
activity	I
detection	I
,	O
diarization	B
,	O
face	O
detection	B
,	O
face	O
tracking	O
,	O
features	O
,	O
normalization	O
)	O
and	O
back	O
-	O
end	O
(	O
e.g.	O
,	O
background	O
models	B
,	O
speaker	B
/	O
face	O
embedding	O
extractor	B
,	O
lda	O
/	O
plda	B
)	O
modules	O
along	O
with	O
their	O
conﬁgurations	O
page	O
8	O
of	O
9nist	O
2019	O
speaker	B
recognition	O
evaluation	B
plan	I
(	O
i.e.	O
,	O
ﬁlterbank	O
conﬁguration	O
,	O
dimensionality	O
and	O
type	O
of	O
the	O
acoustic	O
feature	O
parameters	O
,	O
as	O
well	O
as	O
the	O
acoustic	O
model	B
and	O
the	O
backend	O
model	B
conﬁgurations	O
)	O
,	O
•	O
a	O
complete	O
description	O
of	O
the	O
data	B
partitions	O
used	O
to	O
train	O
the	O
various	O
models	B
(	O
as	O
mentioned	O
above	O
)	O
.	O
teams	O
are	O
encouraged	O
to	O
report	O
how	O
having	O
access	O
to	O
the	O
development	B
set	I
(	O
labeled	O
and	O
unlabeled	O
)	O
impacted	O
the	O
performance	O
,	O
•	O
a	O
complete	O
description	O
of	O
the	O
system	O
combination	O
strategy	O
(	O
e.g.	O
,	O
score	B
normalization	O
/	O
calibration	O
for	O
fusion	O
)	O
used	O
for	O
audio	O
-	O
visual	O
individual	O
/	O
person	O
recognition	O
,	O
•	O
performance	O
of	O
the	O
submission	O
systems	O
(	O
primary	O
and	O
secondary	O
)	O
on	O
the	O
sre19	O
development	B
set	I
(	O
or	O
a	O
derivative	O
/	O
custom	O
dev	O
set	B
)	O
,	O
using	O
the	O
scoring	O
software	O
provided	O
via	O
the	O
web	O
platform	O
(	O
https://	O
sre.nist.gov	O
)	O
.	O
teams	O
are	O
encouraged	O
to	O
quantify	O
the	O
contribution	O
of	O
their	O
major	O
system	O
components	B
that	O
they	O
believe	O
resulted	O
in	O
signiﬁcant	O
performance	O
gains	O
,	O
•	O
a	O
report	O
of	O
the	O
cpu	O
(	O
single	O
threaded	O
)	O
and	O
gpu	O
execution	O
times	O
as	O
well	O
as	O
the	O
amount	B
of	O
memory	O
used	O
to	O
process	B
a	O
single	O
trial	O
(	O
i.e.	O
,	O
the	O
time	B
and	O
memory	O
used	O
for	O
creating	O
a	O
speaker	B
model	B
from	O
enrollment	O
data	B
as	O
well	O
as	O
processing	B
a	O
test	B
segment	B
to	O
compute	O
the	O
llr	O
)	O
.	O
the	O
system	O
description	O
should	O
follow	O
the	O
latest	O
ieee	O
icassp	O
conference	O
proceeding	O
template	O
.	O
7	O
schedule	O
milestone	O
date	O
evaluation	B
plan	I
published	O
august	O
14	O
,	O
2019	O
registration	O
period	O
august	O
15	O
-	O
september	O
16	O
,	O
2019	O
training	B
data	I
available	O
august	O
15	O
,	O
2019	O
evaluation	B
data	B
available	O
to	O
participants	B
august	O
15	O
,	O
2019	O
system	O
output	B
and	O
system	O
description	O
due	O
to	O
nist	O
october	O
21	O
,	O
2019	O
final	O
ofﬁcial	O
results	B
released	O
october	O
28	O
,	O
2019	O
post	O
-	O
evaluation	B
workshop	O
december	O
12–13	O
,	O
2019	O
page	O
9	O

overlapped	O
/	O
non	O
-	O
overlapped	B
speech	I
transition	O
point	B
detection	I
using	O
bag	O
-	O
of	O
-	O
audio	O
-	O
words	B
shikha	O
baghel1	O
,	O
s.	O
r.	O
mahadeva	O
prasanna2	O
,	O
and	O
prithwijit	O
guha1	O
1	O
department	O
of	O
electronics	O
and	O
electrical	O
engineering	O
indian	O
institute	O
of	O
technology	O
guwahati	O
,	O
assam	O
781039	O
,	O
india	O
2	O
department	O
of	O
electrical	O
engineering	O
indian	O
institute	O
of	O
technology	O
dharwad	O
,	O
dharwad-580011	O
,	O
india	O
email	O
:	O
shikha.baghel	O
,	O
prasanna	O
,	O
pguha	O
@iitg.ac.in	O
{	O
}	O
non	O
-	O
overlapped	O
overlapped	B
speech	I
non	O
-	O
overlapped	O
abstract	O
—	O
overlapped	B
speech	I
refers	O
to	O
an	O
audio	O
signal	B
which	O
speech	O
(	O
sp1	O
)	O
 	O
(	O
sp1	O
+	O
sp2	O
)	O
   	O
speech	O
(	O
sp2	O
)	O
coovnetralianpspsepdeescpheeocfhtwisooonre	O
mofotrheesmpeaaiknesrosusrpceeaskoifnegrsriomrufoltranspeoeauksleyr	O
.	O
mplitude	O
-00	O
..	O
5501	O
(	O
a	O
)	O
diarization	B
systems	I
.	O
this	O
work	O
presents	O
an	O
initial	O
study	O
to	O
identify	O
a	O
2	O
4	O
6	O
8	O
10	O
12	O
the	O
transition	O
points	O
of	O
overlapped	O
to	O
non	O
-	O
overlapped	B
speech	I
wide	O
band	O
spectrogram	O
4	O
and	O
vice	O
-	O
versa	O
.	O
characteristics	B
of	O
overlapped	O
and	O
non	O
-	O
overlapped	B
speech	I
are	O
examined	O
in	O
terms	B
of	O
the	O
vocal	O
tract	O
system	O
,	O
exci-	O
hz	O
)	O
2	O
(	O
b	O
)	O
t(eahxtceiiot)natoisofonulriscnoeeu	O
,	O
arracnepdcrhemdaoircdatcuiotlenartiis(oltnicpss)porefecstsirdpuuemeac.lhtsihsgienganhlailrl.betperrhteeseesnnuvtsemlotphoeef	O
frequency	B
(	O
k	O
040	O
2	O
narro4w	O
band	O
s6pectrogr8am	O
10	O
12	O
ten	O
largest	O
peaks	B
(	O
stlp	O
)	O
of	O
the	O
spectrum	B
and	O
mel	O
-	O
frequency	B
2	O
(	O
c	O
)	O
cepstral	O
coefﬁcients	O
(	O
mfccs	O
)	O
represent	O
the	O
vocal	O
tract	O
shape	O
0	O
information	B
.	O
the	O
modulation	O
spectrum	B
energy	O
(	O
modse	O
)	O
captures	O
0	O
2	O
4	O
6	O
8	O
10	O
12	O
time	B
(	O
sec	O
)	O
the	O
information	B
of	O
slowly	O
varying	O
temporal	O
envelope	O
of	O
speech	O
.	O
a	O
bag	O
-	O
of	O
-	O
audio	O
-	O
words	B
(	O
boaw	O
)	O
based	O
approach	O
is	O
used	O
to	O
detect	O
fig	O
.	O
1	O
.	O
illustrating	O
the	O
spectrogram	O
.	O
(	O
a	O
)	O
speech	B
signal	I
,	O
high	O
intensity	O
the	O
transition	O
points	O
.	O
news	O
debates	O
are	O
one	O
of	O
the	O
main	O
sources	O
of	O
(	O
b	O
)	O
wideband	O
spectrogram	O
,	O
and	O
(	O
c	O
)	O
narrowband	O
spectrogram	O
for	O
of	O
naturally	O
occurred	O
overlapped	B
speech	I
.	O
therefore	O
,	O
the	O
present	O
overlapped	B
speech	I
than	O
non	O
-	O
overlapped	B
speech	I
.	O
work	O
is	O
evaluated	O
on	O
indian	O
news	O
debate	O
scenario	O
.	O
a	O
high	O
identiﬁcation	O
rate	O
(	O
ir	O
)	O
and	O
low	O
spurious	O
rate	O
(	O
sr	O
)	O
is	O
observed	O
when	O
all	O
the	O
features	O
are	O
used	O
simultaneously	O
as	O
a	O
16d	O
feature(13-	O
overlapped	B
speech	I
can	O
be	O
produced	O
in	O
a	O
competitive	O
or	O
a	O
mfccs	O
,	O
he	O
of	O
lp	O
residual	O
,	O
stlp	O
and	O
modse	O
)	O
for	O
the	O
detection	B
non	O
-	O
competitive	O
scenario	O
[	O
4	O
]	O
.	O
competitive	O
overlapped	B
speech	I
task	O
.	O
is	O
produced	O
when	O
two	O
or	O
more	O
speakers	O
are	O
in	O
a	O
competition	O
index	O
terms	B
—	O
overlapped	B
speech	I
,	O
mfccs	O
,	O
excitation	O
source	B
,	O
to	O
grab	O
the	O
opportunity	O
for	O
speaking	O
,	O
and	O
thus	O
they	O
continue	O
hilbert	O
envelope	O
,	O
vocal	O
tract	O
system	O
,	O
modulation	O
spectrum	B
,	O
bag-	O
to	O
speak	O
simultaneously	O
for	O
a	O
signiﬁcant	O
duration	O
[	O
4	O
]	O
.	O
over-	O
of	O
-	O
audio	O
-	O
words	B
lapped	O
speech	O
present	O
in	O
news	O
debates	O
is	O
considered	O
as	O
the	O
competitive	O
one	O
.	O
in	O
a	O
non	O
-	O
competitive	O
scenario	O
,	O
speakers	O
co-	O
i.	O
introduction	O
operate	O
with	O
each	O
other	O
and	O
allow	O
others	O
to	O
speak	O
.	O
in	O
such	O
cases	O
,	O
overlapping	B
occur	O
for	O
a	O
small	O
duration	O
[	O
4	O
]	O
.	O
overlaps	B
overlapped	B
speech	I
is	O
produced	O
when	O
two	O
or	O
more	O
speakers	O
present	O
in	O
conversational	O
speech	O
are	O
an	O
example	O
of	O
a	O
non-	O
speak	O
simultaneously	O
.	O
it	O
is	O
considered	O
as	O
one	O
of	O
the	O
main	O
competitive	O
scenario	O
.	O
sources	O
of	O
error	O
for	O
diarization	B
systems	I
[	O
1	O
]	O
,	O
[	O
2	O
]	O
.	O
ryant	O
et	O
the	O
signal	B
characteristics	B
of	O
non	O
-	O
overlapped	B
speech	I
vary	O
al	O
.	O
[	O
3	O
]	O
discussed	O
the	O
importance	O
of	O
handling	O
overlapped	B
speech	I
signiﬁcantly	O
from	O
overlapped	B
speech	I
.	O
these	O
deviations	O
in	O
the	O
for	O
speaker	B
diarization	I
.	O
conventional	O
speech	O
processing	B
ap-	O
characteristics	B
can	O
be	O
observed	O
from	O
the	O
spectrograms	O
shown	O
plications	O
such	O
as	O
speech	O
and	O
speaker	B
recognition	O
,	O
consider	O
in	O
fig	O
.	O
1	O
.	O
spectrum	B
for	O
overlapped	B
speech	I
is	O
harmonically	O
speech	O
only	O
from	O
a	O
single	B
speaker	I
.	O
hence	O
,	O
the	O
overlapped	O
richer	O
than	O
non	O
-	O
overlapping	B
speech	I
due	O
to	O
the	O
presence	B
of	O
speech	O
regions	O
need	O
to	O
be	O
identiﬁed	O
and	O
processed	O
separately	O
.	O
more	O
than	O
one	O
fundamental	O
frequency	B
(	O
f	O
)	O
.	O
this	O
can	O
be	O
0	O
this	O
requires	O
the	O
detection	B
of	O
transition	O
points	O
from	O
non-	O
observed	O
from	O
the	O
narrowband	O
spectrum	B
shown	O
in	O
fig	O
.	O
1(c	O
)	O
.	O
overlapped	O
to	O
overlapped	B
speech	I
and	O
vice	O
-	O
versa	O
.	O
in	O
this	O
work	O
,	O
a	O
wideband	O
spectrogram	O
is	O
shown	O
in	O
fig	O
.	O
1(b	O
)	O
,	O
which	O
shows	O
non	O
-	O
overlapped	B
speech	I
refers	O
to	O
the	O
audio	O
signal	B
containing	O
higher	O
energy	O
for	O
overlapped	B
speech	I
than	O
non	O
-	O
overlapped	O
the	O
speech	O
of	O
only	O
one	O
speaker	B
at	O
a	O
time	B
.	O
this	O
study	O
aims	O
regions	O
.	O
fig	O
.	O
1(a	O
)	O
shows	O
a	O
12	O
sec	O
long	O
speech	B
signal	I
contains	O
to	O
detect	O
such	O
transition	O
points	O
in	O
news	O
debate	O
audio	O
.	O
the	O
non	O
-	O
overlapped	B
speech	I
for	O
ﬁrst	O
and	O
last	O
4	O
sec	O
,	O
and	O
overlapped	O
frequent	O
presence	B
of	O
overlapped	B
speech	I
in	O
news	O
debates	O
makes	O
speech	O
for	O
middle	O
4	O
sec	O
.	O
these	O
4	O
sec	O
long	O
overlapped	O
and	O
it	O
appropriate	O
to	O
consider	O
for	O
this	O
study	O
.	O
non	O
-	O
overlapped	B
speech	I
segments	O
are	O
taken	O
from	O
a	O
news	O
debate	O
978	O
-	O
1	O
-	O
7281	O
-	O
8895	O
-	O
9/20/$31.00	O
c	O
2020	O
ieee	O
audio	O
.	O
�	O
authorized	O
licensed	O
use	O
limited	O
to	O
:	O
cornell	O
university	O
library	O
.	O
downloaded	O
on	O
september	O
17,2020	O
at	O
07:34:33	O
utc	O
from	O
ieee	O
xplore	O
.	O
 	O
restrictions	O
apply	O
.	O
1	O
12	O
12	O
0.5	O
10	O
10	O
amplitude	O
01	O
0	O
20	O
40	O
(	O
a	O
)	O
60	O
80	O
100	O
amplitude	O
468	O
amplitude	O
468	O
0.5	O
2	O
2	O
0	O
0	O
20	O
4ti0me	O
(	O
(	O
bm)s6e0c	O
)	O
80	O
100	O
00	O
dft(1	O
a0p)0oints	O
200	O
00	O
dft1	O
p(0bo0)ints	O
200	O
fig	O
.	O
2	O
.	O
illustrating	O
he	O
of	O
lp	O
residual	O
.	O
(	O
a	O
)	O
non	O
-	O
overlapped	B
speech	I
fig	O
.	O
3	O
.	O
illustrating	O
spectral	O
peaks	B
for	O
one	O
frame	B
of	O
(	O
a	O
)	O
non	O
-	O
overlapped	O
contains	O
a	O
lower	O
residual	O
,	O
(	O
b	O
)	O
a	O
higher	O
residual	O
is	O
exhibited	O
for	O
speech	O
,	O
which	O
shows	O
lower	O
spectral	O
peaks	B
amplitude	O
,	O
and	O
(	O
b	O
)	O
over-	O
overlapped	B
speech	I
.	O
lapped	O
speech	O
with	O
higher	O
spectral	O
peaks	B
amplitude	O
.	O
thus	O
,	O
the	O
lp	O
residual	O
signal	B
exhibits	O
different	O
behavior	O
for	O
different	O
nature	O
of	O
spectrograms	O
for	O
overlapped	O
and	O
non-	O
both	O
the	O
speech	O
cases	O
.	O
overlapped	B
speech	I
motivates	O
to	O
study	O
the	O
speech	O
characteristics	B
he	O
of	O
lp	O
residual	O
–	O
a	O
12th	O
order	B
lp	O
analysis	B
is	O
performed	O
for	O
transition	O
point	B
detection	I
.	O
an	O
enhanced	O
time	B
-	O
frequency	B
to	O
obtain	O
the	O
corresponding	O
lp	O
residual	O
signal	B
.	O
the	O
time-	O
based	O
representation	O
called	O
pyknogram	O
has	O
been	O
used	O
for	O
varying	O
changes	O
of	O
the	O
excitation	O
characteristics	B
are	O
smeared	O
tracking	O
harmonic	O
patterns	O
present	O
in	O
speech	B
signal	I
for	O
de-	O
in	O
the	O
lp	O
residual	O
due	O
to	O
its	O
bipolar	O
nature	O
.	O
these	O
changes	O
are	O
tecting	O
overlapped	B
speech	I
[	O
2	O
]	O
.	O
youseﬁ	O
et	O
al	O
.	O
[	O
5	O
]	O
proposed	O
two	O
further	O
enhanced	O
by	O
computing	O
the	O
he	O
of	O
the	O
lp	O
residual	O
[	O
10	O
]	O
.	O
features	O
derived	O
from	O
online	O
convolutive	O
non	O
-	O
negative	O
matrix	O
fig	O
.	O
2	O
illustrates	O
the	O
higher	O
residual	O
error	O
for	O
overlapped	O
factorization	O
(	O
cnmf	O
)	O
.	O
boakye	O
et	O
al	O
.	O
[	O
6	O
]	O
explored	O
spectral	O
ﬂat-	O
speech	O
(	O
fig	O
.	O
2(b	O
)	O
)	O
than	O
that	O
in	O
non	O
-	O
overlapped	O
one	O
(	O
fig	O
.	O
2(a	O
)	O
)	O
.	O
ness	O
,	O
harmonic	O
energy	O
ratio	O
,	O
modulation	O
spectrogram	O
features	O
,	O
similarly	O
,	O
fig	O
.	O
5(b	O
)	O
represents	O
the	O
he	O
of	O
lp	O
residual	O
(	O
blue	O
and	O
mfcc	O
features	O
for	O
overlapping	B
speech	I
detection	B
in	O
distant	O
color	O
)	O
,	O
which	O
shows	O
the	O
higher	O
values	B
for	O
overlapped	B
speech	I
microphone	O
audio	O
.	O
the	O
usefulness	O
of	O
fundamental	O
frequency	B
compared	O
to	O
the	O
non	O
-	O
overlap	O
one	O
.	O
(	O
f	O
)	O
and	O
related	O
features	O
have	O
also	O
been	O
explored	O
[	O
7	O
]	O
,	O
[	O
8	O
]	O
.	O
0	O
some	O
works	O
have	O
also	O
utilized	O
prosodic	O
and	O
voice	O
quality	B
b.	O
vocal	O
tract	O
system	O
features	O
features	O
such	O
as	O
loudness	O
,	O
voice	O
-	O
probability	B
jitter	O
,	O
shimmer	O
,	O
vocal	O
tract	O
shape	O
can	O
be	O
represented	O
in	O
terms	B
of	O
the	O
formants	O
and	O
logarithmic	O
harmonics	O
-	O
to	O
-	O
noise	O
ratio	O
(	O
loghnr	O
)	O
[	O
8	O
]	O
.	O
lin-	O
and	O
the	O
envelope	O
of	O
the	O
short	O
-	O
time	B
power	O
spectrum	B
of	O
the	O
ear	O
prediction	O
(	O
lp	O
)	O
residual	O
energy	O
and	O
lp	O
coefﬁcients	O
also	O
speech	B
signal	I
.	O
mfccs	O
capture	O
the	O
information	B
of	O
power	O
spec-	O
show	O
discrimination	O
between	O
non	O
-	O
overlapped	O
and	O
overlapped	O
trum	O
envelope	O
by	O
taking	O
human	O
perception	O
into	O
consideration	O
.	O
speech	O
[	O
9	O
]	O
.	O
short	O
-	O
time	B
spectra	O
of	O
speech	B
signal	I
show	O
spectral	O
peaks	B
corre-	O
this	O
work	O
presents	O
an	O
initial	O
study	O
done	O
in	O
the	O
direction	O
of	O
sponding	O
to	O
formant	O
locations	O
[	O
11	O
]	O
.	O
thus	O
,	O
the	O
ﬁrst	O
ten	O
largest	O
overlapped	O
/	O
non	O
-	O
overlapped	O
transition	O
point	B
detection	I
in	O
news	O
peaks	B
of	O
the	O
spectrum	B
can	O
be	O
considered	O
for	O
representing	O
debate	O
scenarios	O
.	O
excitation	O
source	B
,	O
vocal	O
tract	O
and	O
modulation	O
the	O
formant	O
information	B
.	O
spectra	O
of	O
overlapped	B
speech	I
are	O
spectrum	B
characteristics	B
of	O
a	O
speech	B
signal	I
are	O
explored	O
for	O
expected	O
to	O
have	O
sufﬁciently	O
higher	O
energies	O
distributed	O
up	O
this	O
work	O
(	O
section	O
ii	O
)	O
.	O
the	O
hilbert	O
envelope	O
(	O
he	O
)	O
of	O
lp	O
to	O
high	O
frequencies	O
due	O
to	O
the	O
superimposition	O
of	O
two	O
speech	O
residual	O
(	O
sub	O
-	O
section	O
ii	O
-	O
a	O
)	O
,	O
sum	O
of	O
ten	O
largest	O
peaks	B
(	O
stlp	O
)	O
signals	B
.	O
however	O
,	O
spectrum	B
energies	O
are	O
mostly	O
concentrated	O
(	O
sub	O
-	O
section	O
ii	O
-	O
b	O
)	O
,	O
modulation	O
spectrum	B
energy	O
(	O
modse	O
)	O
towards	O
low	O
frequencies	O
for	O
non	O
-	O
overlapped	B
speech	I
(	O
fig	O
.	O
1(b	O
)	O
)	O
.	O
(	O
sub	O
-	O
section	O
ii	O
-	O
c	O
)	O
and	O
mfcc	O
(	O
sub	O
-	O
section	O
ii	O
-	O
b	O
)	O
features	O
are	O
therefore	O
,	O
the	O
features	O
such	O
as	O
mfccs	O
and	O
sum	O
of	O
ten	O
studied	O
.	O
the	O
bag	O
-	O
of	O
-	O
audio	O
-	O
words	B
(	O
boaw	O
)	O
approach	O
is	O
used	O
largest	O
peaks	B
(	O
stlp	O
)	O
are	O
worth	O
exploring	O
in	O
this	O
study	O
.	O
to	O
transform	O
these	O
speech	O
features	O
into	O
distribution	O
based	O
rep-	O
resentation	O
(	O
section	O
iii	O
)	O
.	O
transition	O
points	O
are	O
detected	O
based	O
sum	O
of	O
ten	O
largest	O
spectral	O
peaks	B
(	O
stlp	O
)	O
–	O
ten	O
largest	O
peaks	B
are	O
picked	O
from	O
the	O
magnitude	O
spectrum	B
of	O
each	O
frame	B
on	O
the	O
dissimilarity	O
of	O
these	O
distributions	O
(	O
section	O
iv	O
)	O
.	O
the	O
and	O
summed	O
to	O
obtain	O
the	O
stlp	O
feature	O
.	O
fig	O
.	O
3	O
illustrates	O
proposed	O
approach	O
is	O
evaluated	O
on	O
a	O
news	O
debate	O
dataset	O
and	O
the	O
ten	O
largest	O
peaks	B
(	O
highlighted	O
in	O
red	O
circles	O
)	O
in	O
spectrum	B
the	O
results	B
are	O
discussed	O
in	O
section	O
v.	O
section	O
vi	O
concludes	O
for	O
one	O
frame	B
of	O
overlapped	O
(	O
fig	O
.	O
3(b	O
)	O
)	O
and	O
non	O
-	O
overlapped	O
the	O
present	O
work	O
and	O
discusses	O
the	O
future	O
directions	O
.	O
(	O
fig	O
.	O
3(a	O
)	O
)	O
speech	O
.	O
this	O
ﬁgure	O
shows	O
the	O
discriminative	O
be-	O
ii	O
.	O
features	O
for	O
overlapped	O
/	O
non	O
-	O
overlapped	O
havior	O
of	O
the	O
stlp	O
feature	O
for	O
both	O
the	O
classes	O
.	O
the	O
stlp	O
speech	O
transition	O
point	B
detection	I
feature	O
(	O
blue	O
color	O
)	O
is	O
plotted	O
in	O
fig	O
.	O
5(c	O
)	O
for	O
a	O
12	O
sec	O
long	O
this	O
section	O
explains	O
the	O
speech	O
features	O
used	O
for	O
transition	O
speech	B
signal	I
.	O
this	O
ﬁgure	O
shows	O
higher	O
values	B
of	O
stlp	O
for	O
point	B
detection	I
.	O
speech	B
signal	I
(	O
sampling	O
rate	O
,	O
f	O
=	O
8	O
khz	O
)	O
is	O
overlapped	B
speech	I
than	O
that	O
in	O
the	O
non	O
-	O
overlapped	O
regions	O
.	O
s	O
processed	O
with	O
a	O
frame	B
size	B
of	O
20	O
ms	O
,	O
and	O
a	O
shift	O
of	O
10	O
ms	O
to	O
mel	O
frequency	B
cepstral	O
coefﬁcients	O
(	O
mfcc	O
)	O
–	O
the	O
power	O
extract	O
features	O
.	O
spectrum	B
of	O
each	O
frame	B
is	O
mapped	O
onto	O
the	O
mel	O
scale	O
using	O
a	O
mel	O
ﬁlter	O
bank	O
with	O
26	O
overlapping	B
triangular	O
ﬁlters	O
.	O
the	O
ﬁrst	O
a.	O
excitation	O
source	B
feature	O
13	O
coefﬁcients	O
of	O
mfccs	O
are	O
considered	O
for	O
the	O
detection	B
of	O
the	O
lp	O
residual	O
signal	B
captures	O
the	O
excitation	O
source	B
infor-	O
transition	O
points	O
.	O
mation	O
of	O
a	O
speech	B
signal	I
[	O
10	O
]	O
.	O
the	O
lp	O
residual	O
represents	O
c.	O
modulation	O
spectrum	B
feature	O
the	O
error	O
in	O
predicting	O
the	O
current	O
sample	O
based	O
on	O
the	O
past	O
p	O
samples	O
.	O
this	O
error	O
is	O
expected	O
to	O
be	O
higher	O
in	O
overlapped	O
modulation	O
refers	O
to	O
the	O
slowly	O
varying	O
temporal	O
envelope	O
speech	O
due	O
to	O
the	O
presence	B
of	O
more	O
than	O
one	O
speaker	B
’s	O
speech	O
.	O
of	O
speech	O
.	O
the	O
envelope	O
of	O
speech	O
can	O
be	O
varied	O
according	O
authorized	O
licensed	O
use	O
limited	O
to	O
:	O
cornell	O
university	O
library	O
.	O
downloaded	O
on	O
september	O
17,2020	O
at	O
07:34:33	O
utc	O
from	O
ieee	O
xplore	O
.	O
 	O
restrictions	O
apply	O
.	O
0.5	O
non	O
-	O
overlapped	O
overlapped	O
non	O
-	O
overlapped	O
0	O
speech	O
speech	O
speech	O
−0.50	O
100	O
200	O
300	O
400	O
500	O
1	O
1	O
time	B
(	O
a(m	O
)	O
sec	O
)	O
-10	O
(	O
a	O
)	O
0.5	O
2	O
4	O
6	O
8	O
10	O
12	O
amplitude	O
0010	O
2	O
4	O
6	O
filt8er	O
(	O
nbu)m10ber	O
12	O
14	O
16	O
18	O
mplitude	O
0120	O
2	O
4	O
6	O
8	O
10	O
12	O
(	O
b	O
)	O
−10	O
100	O
2t00ime	O
(	O
mse3c0)0	O
400	O
500	O
a0.51	O
(	O
c	O
)	O
1	O
(	O
c	O
)	O
0	O
0.5	O
2	O
4	O
6	O
8	O
10	O
12	O
00	O
2	O
4	O
6	O
8	O
10	O
12	O
14	O
16	O
18	O
1	O
filter	O
(	O
ndu)mber	O
0.5	O
(	O
d	O
)	O
0	O
2	O
4	O
6	O
8	O
10	O
12	O
fig	O
.	O
4	O
.	O
illustrating	O
modulation	O
spectrum	B
energy	O
.	O
(	O
a	O
)	O
non	O
-	O
overlapped	O
time(sec	O
)	O
speech	O
,	O
(	O
b	O
)	O
modulation	O
spectrum	B
energy	O
components	B
from	O
the	O
critical	O
fig	O
.	O
5	O
.	O
illustrating	O
speech	O
speciﬁc	O
features	O
.	O
(	O
a	O
)	O
speech	B
signal	I
of	O
12	O
sec	O
band	O
ﬁlters	O
for	O
non	O
-	O
overlapped	B
speech	I
,	O
(	O
c	O
)	O
overlapped	B
speech	I
,	O
(	O
d	O
)	O
duration	O
,	O
(	O
b	O
)	O
he	O
of	O
lp	O
residual	O
,	O
(	O
c	O
)	O
sum	O
of	O
ten	O
largest	O
spectral	O
peaks	B
modulation	O
spectrum	B
energy	O
components	B
from	O
the	O
critical	O
band	O
ﬁlters	O
(	O
stlp	O
)	O
,	O
(	O
d	O
)	O
modulation	O
spectrum	B
energy	O
(	O
modse	O
)	O
.	O
the	O
blue	O
color	O
for	O
overlapped	B
speech	I
which	O
is	O
higher	O
than	O
non	O
-	O
overlapped	B
speech	I
.	O
plots	O
(	O
(	O
b	O
)	O
,	O
(	O
c	O
)	O
and	O
(	O
d	O
)	O
)	O
represent	O
raw	O
features	O
,	O
while	O
the	O
corresponding	O
smoothed	O
features	O
are	O
plotted	O
in	O
red	O
color	O
.	O
to	O
the	O
number	O
of	O
sound	O
units	O
spoken	O
per	O
unit	O
time	B
,	O
which	O
is	O
known	O
as	O
the	O
syllabic	O
rate	O
of	O
speech	O
.	O
in	O
the	O
case	O
of	O
overlapped	O
where	O
,	O
a	O
label	O
li	O
is	O
assigned	O
to	O
the	O
feature	O
vector	O
fi	O
.	O
this	O
speech	O
,	O
the	O
syllabic	O
rate	O
is	O
expected	O
to	O
be	O
higher	O
due	O
to	O
the	O
step	O
is	O
termed	O
as	O
the	O
vector	O
quantization	O
.	O
a	O
second	O
level	B
of	O
superimposition	O
of	O
more	O
than	O
one	O
speech	B
signal	I
.	O
feature	O
extraction	B
is	O
needed	O
to	O
execute	O
the	O
transition	O
point	O
modulation	O
spectrum	B
energy	O
(	O
modse	O
)	O
–	O
the	O
syllabic	O
rate	O
detection	B
.	O
after	O
vector	O
quantization	O
,	O
a	O
ﬁxed	O
size	B
feature	O
vector	O
can	O
be	O
represented	O
in	O
terms	B
of	O
the	O
modulation	O
spectrum	B
is	O
generated	O
by	O
considering	O
the	O
frequency	B
of	O
each	O
code-	O
energy	O
.	O
the	O
extraction	B
of	O
modulation	O
spectrum	B
energy	O
can	O
word	B
in	O
a	O
given	O
speech	B
signal	I
.	O
this	O
results	B
in	O
a	O
histogram	O
be	O
found	O
in	O
detail	O
in	O
[	O
12	O
]	O
.	O
a	O
higher	O
modulation	O
spectrum	B
representing	O
the	O
word	B
vector	O
.	O
mathematically	O
,	O
the	O
histogram	O
energy	O
is	O
expected	O
for	O
overlapped	B
speech	I
(	O
fig	O
.	O
4(d	O
)	O
)	O
than	O
non-	O
is	O
constructed	O
as	O
n	O
overlapped	O
one	O
(	O
fig	O
.	O
4(b	O
)	O
)	O
.	O
fig	O
.	O
4	O
illustrates	O
the	O
modulation	O
w	O
=	O
δ(l	O
,	O
j	O
)	O
;	O
j	O
=	O
1	O
,	O
2	O
,	O
.	O
.	O
.	O
k	O
(	O
3	O
)	O
j	O
i	O
energy	O
distribution	O
of	O
4	O
hz	O
component	O
for	O
a	O
frame	B
.	O
however	O
,	O
i=1	O
fig	O
.	O
5(d	O
)	O
illustrates	O
the	O
modse	O
feature	O
(	O
blue	O
color	O
)	O
for	O
a	O
12	O
where	O
,	O
δ	O
(	O
.	O
)	O
denotes	O
�	O
the	O
kronecker	O
delta	O
,	O
l	O
is	O
the	O
label	O
of	O
ith	O
i	O
sec	O
long	O
speech	B
signal	I
.	O
feature	O
vector	O
and	O
n	O
is	O
the	O
total	O
number	O
of	O
feature	O
vectors	O
.	O
the	O
frequency	B
of	O
occurrence	O
of	O
jth	O
code	O
-	O
word	B
in	O
a	O
given	O
duration	O
iii	O
.	O
methodology	O
:	O
bag	O
of	O
audio	O
words	B
is	O
represented	O
by	O
w	O
;	O
j	O
=	O
1	O
,	O
2	O
,	O
.	O
.	O
.	O
k	O
(	O
fig	O
.	O
6(b	O
)	O
)	O
.	O
histograms	O
j	O
the	O
bag	O
-	O
of	O
-	O
audio	O
-	O
words	B
(	O
boaw	O
)	O
approach	O
is	O
motivated	O
are	O
considered	O
as	O
the	O
second	O
level	B
representation	O
of	O
features	O
.	O
by	O
the	O
bag	O
-	O
of	O
-	O
words	B
(	O
bow	O
)	O
representation	O
used	O
in	O
text	O
anal-	O
the	O
dissimilarity	O
between	O
two	O
consecutive	O
histograms	O
are	O
ysis	O
.	O
the	O
bow	O
approach	O
is	O
basically	O
used	O
to	O
represent	O
text	O
calculated	O
for	O
transition	O
point	B
detection	I
.	O
a	O
higher	O
similarity	B
documents	O
.	O
the	O
words	B
appearing	O
in	O
the	O
natural	O
language	O
are	O
between	O
two	O
histograms	O
indicates	O
their	O
belongingness	O
to	O
thr	O
considered	O
as	O
the	O
units	O
in	O
bow	O
(	O
text	O
ﬁle	O
)	O
,	O
and	O
thus	O
these	O
units	O
same	O
category	O
.	O
are	O
discrete	O
one	O
.	O
while	O
,	O
in	O
boaw	O
(	O
audio	O
ﬁle	O
)	O
approach	O
,	O
audio	O
words	B
are	O
not	O
discrete	O
.	O
however	O
,	O
audio	O
words	B
are	O
obtained	O
by	O
iv	O
.	O
overlapped	O
/	O
non	O
-	O
overlapped	B
speech	I
a	O
clustering	B
method	B
to	O
demonstrate	O
the	O
original	O
feature	O
space	O
transition	O
point	B
detection	I
perfectly	O
.	O
the	O
boaw	O
approach	O
provides	O
a	O
ﬁxed	O
size	B
histogram	O
section	O
ii	O
illustrates	O
the	O
different	O
behavior	O
of	O
features	O
for	O
as	O
a	O
feature	O
.	O
overlapped	O
and	O
non	O
-	O
overlapped	B
speech	I
.	O
the	O
evidences	O
from	O
all	O
the	O
boaw	O
approach	O
is	O
described	O
in	O
fig	O
.	O
6	O
.	O
first	O
,	O
k-	O
the	O
features	O
need	O
to	O
be	O
combined	O
for	O
the	O
effective	O
transition	O
means	O
clustering	B
is	O
performed	O
on	O
the	O
extracted	O
features	O
to	O
point	B
detection	I
.	O
the	O
he	O
of	O
lp	O
residual	O
,	O
stlp	O
,	O
and	O
modse	O
obtain	O
representative	O
audio	O
words	B
(	O
basic	O
units	O
)	O
for	O
the	O
boaw	O
are	O
combined	O
to	O
create	O
a	O
3	O
dimensional	O
feature	O
(	O
3d	O
feature	O
)	O
.	O
approach	O
(	O
fig	O
.	O
6(a	O
)	O
)	O
.	O
the	O
number	O
of	O
clusters	O
(	O
k	O
)	O
is	O
varied	O
from	O
mfccs(13d	O
)	O
and	O
3d	O
feature	O
are	O
combined	O
to	O
create	O
a	O
16d	O
2	O
to	O
10	O
and	O
ﬁnalized	O
the	O
one	O
at	O
which	O
the	O
minimum	O
detection	B
feature	O
for	O
the	O
detection	B
task	O
.	O
in	O
fig	O
.	O
5(b	O
)	O
,	O
(	O
c	O
)	O
and	O
(	O
d	O
)	O
,	O
error	O
is	O
achieved	O
.	O
for	O
this	O
work	O
,	O
k	O
=	O
5	O
is	O
used	O
.	O
the	O
set	B
of	O
k	O
some	O
lower	O
feature	O
values	B
(	O
blue	O
color	O
)	O
are	O
observed	O
in	O
the	O
centroids	O
act	O
as	O
the	O
code	O
-	O
book	O
of	O
the	O
system	O
which	O
is	O
given	O
overlapped	B
speech	I
region	O
than	O
that	O
in	O
the	O
non	O
-	O
overlapped	O
as	O
regions	O
.	O
these	O
lower	O
values	B
observed	O
in	O
overlapped	B
speech	I
cb	O
=	O
c1	O
,	O
c2	O
,	O
.	O
.	O
.	O
ck	O
(	O
1	O
)	O
may	O
be	O
attributed	O
to	O
the	O
presence	B
of	O
silence	B
or	O
non	O
-	O
speech	O
{	O
}	O
where	O
,	O
cj	O
;	O
j	O
=	O
1	O
,	O
2	O
,	O
.	O
.	O
.	O
k	O
are	O
the	O
k	O
centroids	O
.	O
these	O
centroids	O
regions	O
.	O
this	O
may	O
affect	O
the	O
overall	O
detection	B
performance	O
.	O
act	O
as	O
the	O
primary	O
words	B
(	O
basic	O
units	O
)	O
that	O
are	O
considered	O
to	O
be	O
therefore	O
,	O
smoothing	O
is	O
performed	O
over	O
a	O
period	O
of	O
1	O
sec	O
present	O
in	O
an	O
input	B
signal	B
.	O
these	O
words	B
(	O
centroids	O
)	O
are	O
termed	O
on	O
the	O
raw	O
features	O
to	O
remove	O
such	O
spurious	O
regions	O
.	O
this	O
as	O
audio	O
words	B
to	O
highlight	O
the	O
fact	O
that	O
they	O
are	O
associated	O
is	O
plotted	O
by	O
red	O
color	O
in	O
fig	O
.	O
5(b	O
)	O
,	O
(	O
c	O
)	O
and	O
(	O
d	O
)	O
.	O
with	O
atomic	O
and	O
perceptual	O
units	O
of	O
hearing	O
,	O
and	O
not	O
to	O
the	O
in	O
the	O
boaw	O
approach	O
,	O
the	O
transition	O
point	B
detection	I
is	O
linguistic	O
units	O
.	O
further	O
,	O
the	O
learned	O
code	O
-	O
book	O
is	O
used	O
to	O
label	O
based	O
on	O
the	O
dissimilarity	O
between	O
the	O
distribution	O
of	O
two	O
an	O
input	B
data	B
which	O
is	O
mathematically	O
given	O
as	O
audio	O
ﬁles	O
.	O
the	O
detection	B
is	O
performed	O
using	O
3d	O
features	O
,	O
13-	O
li	O
=	O
arg	O
min	O
fi	O
cj	O
;	O
j	O
=	O
1	O
,	O
2	O
,	O
.	O
.	O
.	O
k	O
(	O
2	O
)	O
mfccs	O
,	O
and	O
16d	O
feature	O
,	O
separately	O
.	O
these	O
features	O
are	O
the	O
j	O
|	O
−	O
|	O
authorized	O
licensed	O
use	O
limited	O
to	O
:	O
cornell	O
university	O
library	O
.	O
downloaded	O
on	O
september	O
17,2020	O
at	O
07:34:33	O
utc	O
from	O
ieee	O
xplore	O
.	O
 	O
restrictions	O
apply	O
.	O
(	O
a	O
)	O
50	O
(	O
cid:0)speech	O
signal	B
efxetraatcutrioen	O
extracted	O
features	O
ckl	O
-	O
umsetearninsg	O
 	O
k	O
-	O
clusters	O
centers	O
histogram	O
1	O
2400	O
(	O
a	O
)	O
histogram	O
1	O
12340000	O
(	O
c	O
)	O
histogram	O
1	O
2400	O
(	O
e	O
)	O
(	O
audio	O
words	B
)	O
0	O
1	O
2	O
3	O
4	O
5	O
0	O
1	O
2	O
3	O
4	O
5	O
0	O
1	O
2	O
3	O
4	O
5	O
(	O
b	O
)	O
num	O
of	O
bins	O
num	O
of	O
bins	O
(	O
a	O
)	O
num	O
of	O
bins	O
feature	O
bag	O
of	O
audio	O
50	O
sape	O
sehcohr	O
ti	O
sd	O
ucorantsioidne	O
oref	O
d	O
extraction	B
extracted	O
features	O
words	B
histogram	O
of	O
considered	O
histogram	O
2	O
2400	O
(	O
b	O
)	O
histogram	O
2	O
246000	O
(	O
d	O
)	O
histogram	O
2	O
12340000	O
(	O
f	O
)	O
 	O
speech	O
of	O
short	O
duration	O
0	O
1	O
2	O
3	O
4	O
5	O
0	O
1	O
2	O
3	O
4	O
5	O
0	O
1	O
2	O
3	O
4	O
5	O
num	O
of	O
bins	O
num	O
of	O
bins	O
num	O
of	O
bins	O
(	O
c	O
)	O
audio	O
words	B
fig	O
.	O
7	O
.	O
demonstrating	O
histograms	O
for	O
,	O
non	O
-	O
overlapped	B
speech	I
which	O
feature	O
bag	O
of	O
audio	O
shows	O
similar	O
shape	O
for	O
(	O
a	O
)	O
histogram	O
1	O
and	O
(	O
b	O
)	O
histogram	O
2	O
,	O
transition	O
extraction	B
words	B
from	O
non	O
-	O
overlap	O
to	O
overlapped	B
speech	I
which	O
shows	O
different	O
shape	O
dissimilarity	O
for	O
both	O
the	O
histograms	O
(	O
c	O
)	O
and	O
(	O
d	O
)	O
,	O
overlapped	B
speech	I
which	O
shows	O
measure	O
feature	O
bag	O
of	O
audio	O
similar	O
shape	O
for	O
both	O
histograms	O
(	O
e	O
)	O
and	O
(	O
f	O
)	O
.	O
extraction	B
words	B
dotted	O
rectangles	O
show	O
transition	O
 	O
regions	O
and	O
peaks	B
correspond	O
 	O
to	O
transition	O
points	O
 	O
the	O
total	O
number	O
of	O
bins	O
in	O
histograms	O
.	O
the	O
otsu	O
threshold-	O
fig	O
.	O
6	O
.	O
illustrating	O
bag	O
-	O
of	O
-	O
audio	O
-	O
words	B
approach	O
.	O
(	O
a	O
)	O
code	O
-	O
book	O
ing	O
,	O
an	O
adaptive	O
thresholding	O
approach	O
,	O
is	O
performed	O
on	O
the	O
generation	O
from	O
the	O
extracted	O
features	O
of	O
the	O
entire	O
speech	O
,	O
(	O
b	O
)	O
his-	O
dissimilarity	O
values	B
calculated	O
by	O
using	O
eq	O
.	O
4	O
.	O
the	O
regions	O
togram	O
generation	O
with	O
the	O
help	O
of	O
code	O
-	O
book	O
and	O
features	O
extracted	O
over	O
which	O
dissimilarity	O
crosses	O
the	O
threshold	B
are	O
considered	O
from	O
short	O
-	O
duration	O
speech	O
,	O
(	O
c	O
)	O
transition	O
point	B
detection	I
based	O
on	O
as	O
the	O
regions	O
of	O
interest	O
i.e.	O
,	O
the	O
transition	O
regions	O
.	O
the	O
the	O
dissimilarity	O
between	O
two	O
consecutive	O
histograms	O
.	O
differentiation	O
for	O
the	O
detected	O
transition	O
regions	O
is	O
performed	O
ﬁrst	O
level	B
of	O
feature	O
representation	O
and	O
considered	O
as	O
inputs	O
for	O
to	O
detect	O
the	O
peaks	B
in	O
the	O
dissimilarity	O
values	B
and	O
mark	O
these	O
the	O
boaw	O
approach	O
.	O
fig	O
.	O
6(c	O
)	O
illustrates	O
the	O
transition	O
point	O
peak	O
locations	O
as	O
the	O
transition	O
points	O
.	O
a	O
tolerance	O
window	O
of	O
detection	B
approach	O
used	O
in	O
this	O
work	O
.	O
the	O
boaw	O
approach	O
50	O
ms	O
is	O
used	O
to	O
declare	O
a	O
detected	O
point	O
as	O
a	O
true	O
transition	O
transforms	O
ﬁrst	O
level	B
features	O
into	O
the	O
labeled	O
data	B
using	O
vector	O
point	O
.	O
quantization	O
.	O
the	O
labeled	O
data	B
is	O
further	O
processed	O
in	O
the	O
v.	O
results	B
and	O
discussion	O
following	O
manner	O
.	O
a	O
time	B
instance	O
t	O
is	O
considered	O
as	O
a	O
counter	O
at	O
which	O
the	O
decision	O
of	O
transition	O
point	O
is	O
to	O
be	O
made	O
.	O
this	O
the	O
proposed	O
approach	O
is	O
evaluated	O
on	O
news	O
debates	O
broad-	O
counter	O
is	O
moved	O
across	O
the	O
entire	O
speech	O
ﬁle	O
with	O
an	O
incre-	O
casted	O
in	O
an	O
indian	O
news	O
channel	O
.	O
short	O
audio	O
ﬁles	O
of	O
12	O
sec	O
ment	O
of	O
10	O
ms	O
.	O
a	O
duration	O
of	O
1	O
sec	O
is	O
considered	O
on	O
both	O
sides	O
duration	O
are	O
generated	O
from	O
broadcast	O
news	O
debates	O
.	O
the	O
ﬁrst	O
of	O
this	O
tth	O
instance	O
to	O
compute	O
the	O
histograms	O
for	O
both	O
of	O
these	O
and	O
last	O
4	O
sec	O
of	O
each	O
audio	O
ﬁle	O
contains	O
the	O
non	O
-	O
overlapping	B
1	O
sec	O
intervals	O
(	O
fig	O
.	O
6(c	O
)	O
)	O
.	O
if	O
these	O
histograms	O
belong	O
to	O
the	O
speech	O
of	O
two	O
different	O
speakers	O
(	O
say	O
,	O
sp1	O
and	O
sp2	O
)	O
.	O
the	O
same	O
speech	O
region	O
i.e.	O
,	O
either	O
overlapped	O
or	O
non	O
-	O
overlapped	O
middle	O
4	O
sec	O
(	O
i.e.	O
the	O
speech	O
from	O
4	O
to	O
8	O
sec	O
)	O
contains	O
speech	O
,	O
then	O
the	O
shape	O
of	O
these	O
histograms	O
is	O
expected	O
to	O
overlapped	B
speech	I
of	O
two	O
speakers	O
(	O
say	O
,	O
sp1	O
+	O
sp2	O
)	O
.	O
this	O
be	O
similar	O
.	O
this	O
results	B
in	O
a	O
low	O
dissimilarity	O
value	O
between	O
4	O
sec	O
of	O
overlapped	B
speech	I
is	O
taken	O
from	O
naturally	O
occurred	O
the	O
two	O
histograms	O
.	O
the	O
dissimilarity	O
value	O
is	O
expected	O
to	O
instances	O
of	O
overlapping	B
speech	I
of	O
the	O
same	O
news	O
debate	O
.	O
increase	O
as	O
the	O
counter	O
t	O
moves	O
from	O
one	O
speech	O
region	O
to	O
such	O
12	O
sec	O
long	O
speech	O
ﬁles	O
(	O
fig	O
.	O
1(a	O
)	O
)	O
are	O
synthetically	O
others	O
and	O
is	O
maximum	O
when	O
tth	O
time	B
instance	O
is	O
the	O
transition	O
generated	O
by	O
concatenating	O
4	O
sec	O
of	O
non	O
-	O
overlapped	B
speech	I
point	O
.	O
at	O
such	O
points	O
,	O
the	O
shape	O
of	O
both	O
of	O
the	O
histograms	O
is	O
of	O
sp1	O
,	O
4	O
sec	O
of	O
overlapped	B
speech	I
of	O
sp1	O
+	O
sp2	O
and	O
4	O
sec	O
of	O
different	O
as	O
they	O
belong	O
to	O
different	O
speech	O
categories	O
.	O
fig	O
.	O
7	O
non	O
-	O
overlapped	B
speech	I
of	O
sp2	O
.	O
for	O
the	O
evaluation	B
of	O
current	O
shows	O
the	O
similar	O
shape	O
for	O
histogram	O
1	O
and	O
histogram	O
2	O
for	O
work	O
,	O
256	O
such	O
ﬁles	O
are	O
used	O
.	O
the	O
motive	O
of	O
the	O
synthetic	O
both	O
the	O
categories	O
i.e.	O
overlapped	O
(	O
fig	O
.	O
7(e	O
)	O
and	O
(	O
f	O
)	O
)	O
and	O
generation	O
of	O
speech	O
ﬁles	O
is	O
to	O
make	O
sure	O
the	O
presence	B
of	O
non	O
-	O
overlapped	B
speech	I
(	O
fig	O
.	O
7(a	O
)	O
and	O
(	O
b	O
)	O
)	O
.	O
fig	O
.	O
7(c	O
)	O
and	O
(	O
d	O
)	O
overlapped	B
speech	I
for	O
sufﬁcient	O
duration	O
for	O
analysis	B
purposes	O
.	O
show	O
two	O
histograms	O
for	O
the	O
transition	O
from	O
non	O
-	O
overlapped	O
to	O
the	O
present	O
work	O
studies	O
the	O
overlapped	B
speech	I
containing	O
overlapped	B
speech	I
.	O
the	O
shape	O
of	O
these	O
histograms	O
is	O
different	O
only	O
two	O
simultaneous	O
speakers	O
.	O
speech	O
signals	B
are	O
resampled	O
since	O
histogram	O
1	O
(	O
fig	O
.	O
7(c	O
)	O
)	O
corresponds	O
to	O
non	O
-	O
overlapped	O
to	O
8	O
khz	O
.	O
speech	O
,	O
and	O
histogram	O
2	O
(	O
fig	O
.	O
7(d	O
)	O
)	O
belongs	O
to	O
the	O
overlapped	O
the	O
performance	O
of	O
the	O
proposed	O
method	B
is	O
measured	O
in	O
speech	O
.	O
therefore	O
,	O
a	O
higher	O
dissimilarity	O
value	O
is	O
expected	O
terms	B
of	O
the	O
identiﬁcation	O
rate	O
(	O
ir	O
)	O
and	O
spurious	O
rate	O
(	O
sr	O
)	O
.	O
during	O
the	O
transitions	O
than	O
the	O
homogeneous	O
region	O
(	O
i.e.	O
,	O
either	O
ir	O
is	O
the	O
percentage	B
of	O
correctly	O
identiﬁed	O
transition	O
points	O
,	O
overlapped	O
or	O
non	O
-	O
overlapped	O
region	O
)	O
,	O
and	O
is	O
maximum	O
at	O
the	O
and	O
sr	O
is	O
the	O
percentage	B
of	O
falsely	O
identiﬁed	O
transition	O
points	O
.	O
transition	O
point	O
.	O
the	O
performance	O
in	O
terms	B
of	O
ir	O
and	O
sr	O
for	O
different	O
features	O
the	O
dissimilarity	O
between	O
two	O
distributions	O
p	O
and	O
q	O
is	O
with	O
respect	O
to	O
different	O
threshold	B
values	B
is	O
mentioned	O
in	O
the	O
calculated	O
by	O
the	O
bhattacharyya	O
distance	B
which	O
is	O
given	O
as	O
table	O
i.	O
the	O
present	O
work	O
is	O
evaluated	O
for	O
three	O
different	O
n	O
thresholds	O
η1	O
,	O
η2	O
,	O
and	O
η3	O
as	O
1.5	O
,	O
1.3	O
,	O
and	O
1.1	O
times	O
of	O
the	O
bd(p	O
,	O
q	O
)	O
=	O
1	O
(	O
p(j)q(j	O
)	O
)	O
(	O
4	O
)	O
otsu	O
threshold	B
of	O
respective	O
features	O
and	O
observed	O
the	O
similar	O
−	O
j=0	O
performance	O
for	O
these	O
three	O
thresholds	O
.	O
the	O
ir	O
for	O
the	O
3d	O
�	O
�	O
where	O
,	O
bd(p	O
,	O
q	O
)	O
is	O
the	O
bhattacharyya	O
dissimilarity	O
,	O
n	O
is	O
feature	O
is	O
lower	O
than	O
the	O
13d	O
feature	O
and	O
16d	O
features	O
.	O
since	O
3d	O
authorized	O
licensed	O
use	O
limited	O
to	O
:	O
cornell	O
university	O
library	O
.	O
downloaded	O
on	O
september	O
17,2020	O
at	O
07:34:33	O
utc	O
from	O
ieee	O
xplore	O
.	O
 	O
restrictions	O
apply	O
.	O
1	O
table	O
i	O
h	O
results	B
in	O
terms	B
of	O
identification	O
rate	O
(	O
ir	O
)	O
and	O
spurious	O
rate	O
eec	O
0	O
p	O
(	O
sr	O
)	O
s	O
−1	O
0	O
5	O
10	O
15	O
20	O
25	O
30	O
speech	O
speciﬁc	O
features	O
(	O
a	O
)	O
threshold	B
3d	O
feature	O
13d	O
feature	O
16d	O
feature	O
1	O
↓	O
ir	O
sr	O
ir	O
sr	O
ir	O
sr	O
0.5	O
feηηηa123tu===re111	O
...	O
c531o×××ntηηηaoooitttnssssuuu	O
st655l077p	O
...	O
175898as	O
th344922e	O
...	O
824v101oca777l220t	O
...	O
806ra868ct	O
f222e779a	O
...	O
193tu131re	O
w777444h	O
...	O
851ic567h	O
is222455o	O
...	O
848n532e	O
bhattacharya	O
dissimilarity	O
0.0101500	O
55	O
1100	O
1155((bc	O
)	O
)	O
2200	O
2255	O
3300	O
dimensional	O
and	O
may	O
not	O
capture	O
all	O
the	O
aspects	O
of	O
vocal	O
tract	O
0.5	O
shape	O
which	O
may	O
be	O
captured	O
by	O
the	O
13	O
dimensional	O
mfccs	O
.	O
0	O
the	O
ir	O
for	O
13d	O
feature	O
is	O
almost	O
comparable	O
but	O
lower	O
than	O
0	O
5	O
10	O
15	O
20	O
25	O
30	O
(	O
d	O
)	O
the	O
ir	O
of	O
16d	O
feature	O
.	O
since	O
,	O
16d	O
feature	O
considered	O
excitation	O
time	B
in	O
sec	O
source	B
and	O
modulation	O
spectrum	B
along	O
with	O
the	O
vocal	O
tract	O
fig	O
.	O
8	O
.	O
illustrating	O
the	O
transition	O
point	B
detection	I
in	O
a	O
32	O
sec	O
long	O
shape	O
while	O
13d	O
feature	O
considered	O
only	O
vocal	O
tract	O
shape	O
news	O
debate	O
segment	B
containing	O
naturally	O
occured	O
transitions	O
:	O
(	O
a	O
)	O
information	B
.	O
the	O
sr	O
is	O
highest	O
for	O
the	O
3d	O
feature	O
and	O
lowest	O
speech	B
signal	I
with	O
solid	O
red	O
lines	O
represent	O
actual	O
transition	O
points	O
,	O
for	O
the	O
16d	O
features	O
.	O
therefore	O
16d	O
feature	O
is	O
preferable	O
for	O
the	O
transition	O
point	B
detection	I
using	O
(	O
b	O
)	O
3d	O
feature	O
which	O
shows	O
more	O
overlapped	O
/	O
non	O
-	O
overlapped	B
speech	I
transition	O
point	B
detection	I
number	O
of	O
spurious	O
detection	B
highlighted	O
by	O
green	O
dotted	O
rectangles	O
,	O
(	O
c	O
)	O
13d	O
feature	O
which	O
shows	O
comparatively	O
lesser	O
number	O
of	O
spurious	O
than	O
the	O
other	O
two	O
features	O
.	O
detection	B
than	O
3d	O
feature	O
,	O
and	O
(	O
d	O
)	O
16d	O
feature	O
which	O
shows	O
least	O
the	O
present	O
approach	O
is	O
also	O
evaluated	O
on	O
a	O
short	O
segment	B
number	O
of	O
spurious	O
detection	B
.	O
(	O
32	O
sec	O
duration	O
)	O
of	O
news	O
debate	O
.	O
this	O
short	O
segment	B
contains	O
naturally	O
occurred	O
transitions	O
in	O
a	O
news	O
debate	O
scenario	O
.	O
the	O
speech	B
signal	I
of	O
this	O
short	O
segment	B
is	O
shown	O
in	O
fig	O
.	O
8(a	O
)	O
,	O
where	O
references	B
red	O
solid	O
vertical	O
lines	O
represent	O
the	O
actual	O
transition	O
points	O
.	O
[	O
1	O
]	O
m.	O
moattar	O
and	O
m.	O
homayounpour	O
,	O
“	O
a	O
review	O
on	O
speaker	B
diarization	I
fig	O
.	O
8(b	O
)	O
,	O
(	O
c	O
)	O
and	O
(	O
d	O
)	O
show	O
the	O
detected	O
transition	O
points	O
by	O
systems	O
and	O
approaches	O
,	O
”	O
speech	B
communication	I
,	O
vol	O
.	O
54	O
,	O
no	O
.	O
10	O
,	O
pp	O
.	O
solid	O
vertical	O
blue	O
lines	O
using	O
3d	O
feature	O
,	O
13d	O
feature	O
and	O
16d	O
1065–1103	O
,	O
2012	O
.	O
[	O
2	O
]	O
n.	O
shokouhi	O
and	O
j.	O
h.	O
l.	O
hansen	O
,	O
“	O
teagerkaiser	O
energy	O
operators	O
feature	O
,	O
respectively	O
.	O
some	O
spurious	O
transition	O
points	O
are	O
also	O
for	O
overlapped	B
speech	I
detection	B
,	O
”	O
ieee	O
/	O
acm	O
transactions	O
on	O
audio	O
,	O
detected	O
by	O
the	O
proposed	O
approach	O
.	O
those	O
are	O
highlighted	O
by	O
speech	O
,	O
and	O
language	B
processing	I
,	O
vol	O
.	O
25	O
,	O
no	O
.	O
5	O
,	O
pp	O
.	O
1035–1047	O
,	O
may	O
2017	O
.	O
the	O
green	O
dotted	O
rectangles	O
(	O
fig	O
.	O
8(b	O
)	O
,	O
(	O
c	O
)	O
and	O
(	O
d	O
)	O
)	O
.	O
it	O
can	O
be	O
[	O
3	O
]	O
n.	O
ryant	O
,	O
k.	O
church	O
,	O
c.	O
cieri	O
,	O
a.	O
cristia	O
,	O
j.	O
du	O
,	O
s.	O
ganapathy	O
,	O
and	O
observed	O
that	O
the	O
number	O
of	O
spurious	O
transition	O
points	O
is	O
large	O
m.	O
liberman	O
,	O
“	O
first	O
dihard	B
challenge	I
evaluation	B
plan	I
,	O
”	O
2018	O
,	O
tech	O
.	O
rep	O
.	O
,	O
in	O
case	O
of	O
3d	O
feature	O
in	O
comparison	O
with	O
the	O
other	O
two	O
features	O
.	O
2018	O
.	O
all	O
actual	O
transition	O
points	O
are	O
detected	O
by	O
using	O
13d	O
feature	O
[	O
4	O
]	O
s.	O
a.	O
chowdhury	O
,	O
m.	O
danieli	O
,	O
and	O
g.	O
riccardi	O
,	O
“	O
annotating	O
and	O
cat-	O
egorizing	O
competition	O
in	O
overlap	O
speech	O
,	O
”	O
in	O
2015	O
ieee	O
international	O
and	O
16d	O
feature	O
,	O
but	O
the	O
number	O
of	O
spurious	O
transition	O
points	O
conference	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
(	O
icassp	O
)	O
,	O
april	O
is	O
more	O
in	O
case	O
of	O
13d	O
feature	O
than	O
16d	O
feature	O
.	O
this	O
shows	O
2015	O
,	O
pp	O
.	O
5316–5320	O
.	O
that	O
the	O
16d	O
feature	O
is	O
more	O
suitable	O
for	O
the	O
task	O
than	O
the	O
other	O
[	O
5	O
]	O
m.	O
youseﬁ	O
,	O
n.	O
shokouhi	O
,	O
and	O
j.	O
h.	O
hansen	O
,	O
“	O
assessing	O
speaker	B
engage-	O
ment	O
in	O
2-person	O
debates	O
:	O
overlap	B
detection	I
in	O
united	O
states	O
presidential	O
two	O
features	O
.	O
debates	O
,	O
”	O
in	O
interspeech	O
,	O
2018	O
,	O
pp	O
.	O
2117–2121	O
.	O
[	O
6	O
]	O
k.	O
boakye	O
,	O
o.	O
vinyals	O
,	O
and	O
g.	O
friedland	O
,	O
“	O
two	O
’s	O
a	O
crowd	O
:	O
improving	O
vi	O
.	O
conclusion	O
and	O
future	O
directions	O
speaker	B
diarization	I
by	O
automatically	O
identifying	O
and	O
excluding	O
over-	O
lapped	O
speech	O
,	O
”	O
in	O
ninth	O
annual	B
conference	I
of	O
the	O
international	O
speech	O
speech	O
speciﬁc	O
features	O
are	O
explored	O
for	O
the	O
communication	B
association	O
,	O
2008	O
,	O
pp	O
.	O
32–35	O
.	O
[	O
7	O
]	O
yang	O
shao	O
and	O
deliang	O
wang	O
,	O
“	O
co	O
-	O
channel	O
speaker	B
identiﬁcation	O
overlapped	O
/	O
non	O
-	O
overlapped	B
speech	I
transition	O
point	B
detection	I
using	O
usable	O
speech	O
extraction	B
based	O
on	O
multi	O
-	O
pitch	B
tracking	O
,	O
”	O
in	O
ieee	O
for	O
news	O
debate	O
scenario	O
.	O
the	O
he	O
of	O
lp	O
residual	O
,	O
sum	O
of	O
ten	O
international	O
conference	O
on	O
acoustics	B
,	O
speech	O
,	O
and	O
signal	B
processing	I
largest	O
spectral	O
peaks	B
(	O
stlp	O
)	O
,	O
modulation	O
spectrum	B
energy	O
(	O
icassp	O
)	O
.	O
,	O
vol	O
.	O
2	O
,	O
2003	O
,	O
pp	O
.	O
ii–205	O
.	O
[	O
8	O
]	O
e.	O
kurti	O
,	O
g.	O
j.	O
brown	O
,	O
and	O
b.	O
wells	O
,	O
“	O
resources	O
for	O
turn	O
competition	O
(	O
modse	O
)	O
,	O
and	O
mfccs	O
are	O
studied	O
for	O
this	O
work	O
.	O
this	O
work	O
in	O
overlapping	B
talk	O
,	O
”	O
speech	B
communication	I
,	O
vol	O
.	O
55	O
,	O
no	O
.	O
5	O
,	O
pp	O
.	O
721	O
–	O
utilizes	O
the	O
excitation	O
source	B
,	O
modulation	O
spectrum	B
,	O
and	O
vocal	O
743	O
,	O
2013	O
.	O
tract	O
characteristics	B
for	O
the	O
transition	O
point	B
detection	I
task	O
.	O
[	O
9	O
]	O
j.	O
t.	O
geiger	O
,	O
f.	O
eyben	O
,	O
b.	O
schuller	O
,	O
and	O
g.	O
rigoll	O
,	O
“	O
detecting	O
overlapping	B
speech	I
with	O
long	O
short	O
-	O
term	O
memory	O
recurrent	O
neural	B
networks	I
,	O
”	O
in	O
this	O
work	O
is	O
an	O
initial	O
attempt	O
in	O
the	O
direction	O
of	O
character-	O
proceedings	O
interspeech	O
,	O
2013	O
,	O
pp	O
.	O
1668–1672	O
.	O
izing	O
overlapped	B
speech	I
and	O
detecting	O
the	O
transition	O
points	O
.	O
[	O
10	O
]	O
t.	O
ananthapadmanabha	O
and	O
b.	O
yegnanarayana	O
,	O
“	O
epoch	O
extraction	B
from	O
linear	O
prediction	O
residual	O
for	O
identiﬁcation	O
of	O
closed	O
glottis	O
interval	O
,	O
”	O
the	O
present	O
work	O
studies	O
overlapped	B
speech	I
of	O
only	O
two	O
ieee	O
transactions	O
on	O
acoustics	B
,	O
speech	O
,	O
and	O
signal	B
processing	I
,	O
vol	O
.	O
27	O
,	O
simultaneous	O
speakers	O
.	O
as	O
such	O
,	O
we	O
intend	O
to	O
extend	O
the	O
work	O
no	O
.	O
4	O
,	O
pp	O
.	O
309–319	O
,	O
aug	O
1979	O
.	O
by	O
doing	O
analysis	B
on	O
a	O
large	O
data	B
taken	O
from	O
news	O
debates	O
[	O
11	O
]	O
b.	O
k.	O
khonglah	O
and	O
s.	O
r.	O
m.	O
prasanna	O
,	O
“	O
speech	O
/	O
music	O
classiﬁcation	O
using	O
speech	O
-	O
speciﬁc	O
features	O
,	O
”	O
digital	O
signal	B
processing	I
,	O
vol	O
.	O
48	O
,	O
pp	O
.	O
considering	O
overlapped	B
speech	I
of	O
more	O
than	O
two	O
simultaneous	O
71–83	O
,	O
2016	O
.	O
speakers	O
.	O
the	O
harmonic	O
patterns	O
present	O
in	O
the	O
spectra	O
of	O
non-	O
[	O
12	O
]	O
s.	O
greenberg	O
and	O
b.	O
e.	O
d.	O
kingsbury	O
,	O
“	O
the	O
modulation	O
spectrogram	O
:	O
in	O
overlapped	B
speech	I
are	O
expected	O
to	O
be	O
disturbed	O
in	O
overlapped	O
pursuit	O
of	O
an	O
invariant	O
representation	O
of	O
speech	O
,	O
”	O
in	O
ieee	O
international	O
conference	O
on	O
acoustics	B
,	O
speech	O
,	O
and	O
signal	B
processing	I
,	O
vol	O
.	O
3	O
,	O
1997	O
,	O
speech	O
.	O
therefore	O
,	O
harmonic	O
patterns	O
present	O
in	O
speech	O
signals	B
pp	O
.	O
1647–1650	O
.	O
need	O
to	O
be	O
explored	O
as	O
an	O
extension	O
of	O
this	O
work	O
.	O
authorized	O
licensed	O
use	O
limited	O
to	O
:	O
cornell	O
university	O
library	O
.	O
downloaded	O
on	O
september	O
17,2020	O
at	O
07:34:33	O
utc	O
from	O
ieee	O
xplore	O
.	O
 	O
restrictions	O

interspeech	O
2017	O
august	O
20–24	O
,	O
2017	O
,	O
stockholm	O
,	O
sweden	O
speaker	B
diarization	I
using	O
convolutional	O
neural	B
network	I
for	O
statistics	B
accumulation	O
reﬁnement	O
zbyneˇk	O
zaj´ıc1	O
,	O
marek	O
hru	O
´	O
z1	O
,	O
ludeˇk	O
mu¨	O
ller1,2	O
university	O
of	O
west	O
bohemia	O
faculty	O
of	O
applied	O
sciences	O
1ntis	O
-	O
new	O
technologies	O
for	O
the	O
information	B
society	O
and	O
2dept	O
.	O
of	O
cybernetics	O
,	O
univerzitn´ı	O
8	O
,	O
306	O
14	O
plzenˇ	O
,	O
czech	O
republic	O
zzajic@ntis.zcu.cz	O
,	O
mhruz@ntis.zcu.cz	O
,	O
muller@ntis.zcu.cz	O
abstract	O
process	B
and	O
use	O
a	O
simple	O
constant	O
length	B
window	O
segmentation	B
of	O
speech	O
[	O
3	O
,	O
5	O
]	O
.	O
the	O
aim	O
of	O
this	O
paper	O
is	O
to	O
investigate	O
the	O
beneﬁt	O
of	O
information	B
the	O
success	O
of	O
dnns	O
in	O
the	O
speech	B
recognition	I
task	O
[	O
13	O
]	O
from	O
a	O
speaker	B
change	I
detection	B
system	O
based	O
on	O
convolutional	O
leads	O
in	O
recent	O
times	O
to	O
their	O
exploitation	O
in	O
sd	O
systems	O
.	O
dnns	O
neural	B
network	I
(	O
cnn	O
)	O
when	O
applied	O
to	O
the	O
process	B
of	O
accumu-	O
are	O
utilized	O
in	O
the	O
task	O
of	O
the	O
segmentation	B
[	O
11	O
,	O
14	O
]	O
or	O
in	O
the	O
lation	O
of	O
statistics	B
for	O
an	O
i	O
-	O
vector	O
generation	O
.	O
the	O
investigation	O
clustering	B
process	B
[	O
15	O
,	O
16	O
]	O
.	O
in	O
[	O
17	O
]	O
dnns	O
are	O
used	O
to	O
replace	O
is	O
carried	O
out	O
on	O
the	O
problem	O
of	O
diarization	B
.	O
in	O
our	O
system	O
,	O
the	O
unsupervised	O
universal	O
background	O
model	B
(	O
ubm	O
)	O
for	O
the	O
ac-	O
output	B
of	O
the	O
cnn	O
is	O
a	O
probability	B
value	O
of	O
a	O
speaker	B
change	I
cumulation	O
of	O
statistics	B
in	O
the	O
i	O
-	O
vector	O
generation	O
.	O
dnn	O
was	O
in	O
a	O
conversation	O
for	O
a	O
given	O
time	B
segment	B
.	O
according	O
to	O
this	O
also	O
applied	O
to	O
the	O
representation	O
of	O
the	O
speaker	B
in	O
[	O
18	O
,	O
19	O
]	O
or	O
probability	B
,	O
we	O
cut	O
the	O
conversation	O
into	O
short	O
segments	O
that	O
are	O
very	O
recently	O
in	O
[	O
20	O
]	O
and	O
in	O
[	O
21	O
]	O
,	O
where	O
the	O
triplet	O
loss	O
paradigm	O
then	O
represented	O
by	O
the	O
i	O
-	O
vector	O
(	O
to	O
describe	O
a	O
speaker	B
in	O
it	O
)	O
.	O
we	O
was	O
used	O
for	O
training	O
the	O
dnn	O
descriptor	O
with	O
extremely	O
short	O
propose	O
a	O
technique	B
to	O
utilize	O
the	O
information	B
from	O
the	O
cnn	O
speech	O
turn	O
.	O
for	O
the	O
weighting	O
of	O
the	O
acoustic	O
data	B
in	O
a	O
segment	B
to	O
reﬁne	O
the	O
statistics	B
accumulation	O
process	B
.	O
this	O
technique	B
enables	O
us	O
in	O
our	O
previous	O
papers	O
[	O
14	O
,	O
22	O
]	O
we	O
applied	O
a	O
cnn	O
to	O
the	O
to	O
represent	O
the	O
speaker	B
better	O
in	O
the	O
ﬁnal	O
i	O
-	O
vector	O
.	O
the	O
experi-	O
problem	O
of	O
scd	O
.	O
the	O
main	O
difference	O
between	O
our	O
approach	O
ments	O
on	O
the	O
english	O
part	O
of	O
the	O
callhome	O
corpus	B
show	O
that	O
our	O
and	O
the	O
one	O
in	O
others	O
works	O
lies	O
in	O
the	O
fact	O
that	O
we	O
introduce	O
a	O
proposed	O
reﬁnement	O
of	O
the	O
statistics	B
accumulation	O
is	O
beneﬁcial	O
spectrogram	O
to	O
a	O
cnn	O
and	O
let	O
the	O
net	O
compute	O
its	O
own	O
features	O
.	O
with	O
the	O
relative	O
improvement	O
of	O
diarization	B
error	I
rate	I
almost	O
cnns	O
were	O
introduced	O
in	O
[	O
23	O
]	O
to	O
cope	O
with	O
the	O
prob-	O
by	O
16	O
%	O
when	O
compared	O
to	O
the	O
speaker	B
diarization	I
system	I
with-	O
lem	O
of	O
image	O
classiﬁcation	O
.	O
they	O
were	O
popularized	O
by	O
out	O
statistics	B
reﬁnement	O
.	O
krizhevsky	O
et	O
al	O
.	O
[	O
24	O
]	O
with	O
updated	O
design	O
blocks	O
such	O
as	O
rec-	O
index	O
terms	B
:	O
convolutional	O
neural	B
network	I
,	O
speaker	B
change	I
tiﬁed	O
linear	O
units	O
(	O
relu	O
)	O
or	O
max	O
pooling	O
instead	O
of	O
average	B
detection	B
,	O
speaker	B
diarization	I
,	O
i	O
-	O
vector	O
,	O
statistics	B
accumulation	O
pooling	O
.	O
when	O
a	O
cnn	O
is	O
trained	O
on	O
large	O
scale	O
datasets	B
one	O
can	O
observe	O
its	O
capability	O
to	O
learn	O
discriminative	O
features	O
on	O
its	O
1	O
.	O
introduction	O
own	O
.	O
furthermore	O
,	O
the	O
net	O
is	O
able	O
to	O
learn	O
a	O
semantic	O
represen-	O
tation	O
of	O
the	O
data	B
.	O
our	O
experiments	O
with	O
the	O
cnn	O
in	O
the	O
task	O
the	O
problem	O
of	O
speaker	B
diarization	I
(	O
sd	O
)	O
is	O
crucial	O
for	O
many	O
of	O
scd	O
exhibited	O
better	O
results	B
than	O
classical	O
approaches	O
based	O
speech	O
applications	O
dealing	O
with	O
real	O
data	B
,	O
where	O
only	O
one	O
on	O
bic	B
.	O
the	O
input	B
of	O
the	O
network	B
is	O
a	O
spectrogram	O
of	O
a	O
segment	B
speaker	B
occurrence	O
in	O
a	O
recording	B
can	O
not	O
be	O
ensured	O
.	O
the	O
sd	O
of	O
the	O
original	O
waveform	O
and	O
the	O
output	B
is	O
a	O
probability	B
that	O
problem	O
is	O
deﬁned	O
as	O
a	O
task	O
of	O
categorizing	O
speakers	O
in	O
an	O
un-	O
there	O
is	O
a	O
speaker	B
change	I
in	O
the	O
middle	O
of	O
the	O
segment	B
.	O
when	O
labeled	O
conversation	O
,	O
without	O
any	O
prior	O
information	B
regarding	O
the	O
cnn	O
is	O
applied	O
to	O
the	O
whole	O
recording	B
in	O
a	O
sliding	O
window	O
the	O
number	O
and	O
identities	O
of	O
the	O
speakers	O
.	O
different	O
approaches	O
fashion	O
a	O
probability	B
signal	B
of	O
the	O
speaker	B
change	I
is	O
obtained	O
.	O
were	O
proposed	O
to	O
solve	O
this	O
task	O
[	O
1	O
]	O
.	O
the	O
most	O
common	O
ap-	O
further	O
processing	B
of	O
this	O
signal	B
is	O
needed	O
to	O
determine	O
where	O
proach	O
to	O
the	O
sd	O
consists	O
of	O
the	O
segmentation	B
of	O
an	O
input	B
sig-	O
a	O
change	B
occurs	O
.	O
in	O
our	O
previous	O
work	O
,	O
we	O
detected	O
peaks	B
using	O
nal	O
,	O
followed	O
by	O
the	O
merging	O
of	O
the	O
segments	O
into	O
clusters	O
cor-	O
non	O
-	O
maximum	O
suppression	O
.	O
responding	O
to	O
individual	O
speakers	O
[	O
2	O
,	O
3	O
]	O
.	O
alternatively	O
,	O
the	O
seg-	O
in	O
this	O
paper	O
,	O
our	O
goal	O
is	O
to	O
determine	O
whether	O
the	O
cnn	O
mentation	O
and	O
the	O
clustering	B
step	O
can	O
be	O
combined	O
into	O
a	O
single	O
also	O
offers	O
any	O
useful	O
information	B
about	O
the	O
homogeneity	O
of	O
a	O
iterative	O
process	B
[	O
4	O
]	O
.	O
in	O
this	O
paper	O
,	O
we	O
investigate	O
the	O
state	O
-	O
of-	O
speaker	B
in	O
a	O
segment	B
.	O
for	O
this	O
purpose	O
,	O
we	O
propose	O
a	O
reﬁnement	O
the	O
-	O
art	O
off	O
-	O
line	O
sd	O
system	O
based	O
on	O
the	O
i	O
-	O
vector	O
representation	O
of	O
accumulation	O
of	O
statistics	B
for	O
i	O
-	O
vector	O
generation	O
and	O
apply	O
it	O
of	O
the	O
speech	B
segments	I
[	O
3	O
,	O
5	O
]	O
(	O
other	O
approaches	O
utilize	O
e.g.	O
hid-	O
to	O
our	O
sd	O
system	O
[	O
14	O
]	O
.	O
den	O
markov	O
models	B
[	O
6	O
,	O
7	O
]	O
)	O
.	O
the	O
speaker	B
change	I
detection	B
(	O
scd	O
)	O
is	O
often	O
applied	O
to	O
the	O
audio	O
signal	B
to	O
obtain	O
segments	O
which	O
ideally	O
contain	O
a	O
speech	O
2	O
.	O
speaker	B
diarization	I
system	I
of	O
a	O
single	B
speaker	I
[	O
2	O
]	O
.	O
commonly	O
used	O
approaches	O
to	O
the	O
scd	O
include	O
the	O
bayesian	O
information	B
criterion	B
(	O
bic	B
)	O
,	O
generalized	O
our	O
sd	O
system	O
[	O
14	O
]	O
is	O
based	O
on	O
the	O
i	O
-	O
vectors	O
[	O
25	O
]	O
that	O
repre-	O
likelihood	B
ratio	I
(	O
glr	O
)	O
,	O
kullback	O
-	O
leibler	O
divergence	O
[	O
8	O
,	O
9	O
]	O
,	O
sent	O
speech	B
segments	I
,	O
as	O
introduced	O
in	O
[	O
26	O
]	O
.	O
these	O
segments	O
support	O
vector	O
machine	O
(	O
svm	O
)	O
[	O
10	O
]	O
and	O
deep	O
neural	O
net-	O
are	O
obtained	O
from	O
the	O
previous	O
step	O
using	O
scd	O
based	O
on	O
cnn	O
.	O
works	O
(	O
dnns	O
)	O
[	O
11	O
,	O
12	O
]	O
.	O
however	O
,	O
in	O
a	O
spontaneous	O
telephone	O
the	O
resulting	O
i	O
-	O
vectors	O
are	O
clustered	O
in	O
order	B
to	O
determine	O
which	O
conversation	O
containing	O
very	O
short	O
speaker	B
turns	O
and	O
frequent	O
parts	O
of	O
the	O
signal	B
were	O
produced	O
by	O
the	O
same	B
speaker	I
.	O
a	O
dia-	O
overlapping	B
speech	I
,	O
diarization	B
systems	I
often	O
omit	O
the	O
scd	O
gram	O
of	O
our	O
diarization	B
system	O
can	O
be	O
seen	O
in	O
figure	O
1	O
.	O
copyright	O
©	O
2017	O
isca	O
3562	O
http://dx.doi.org/10.21437/interspeech.2017-51the	O
speaker	B
’s	O
supervector	O
ψ	O
[	O
28	O
]	O
for	O
given	O
data	B
o	O
is	O
a	O
con-	O
catenation	O
of	O
the	O
zeroth	O
and	O
ﬁrst	O
statistical	O
moments	O
of	O
o.	O
our	O
proposed	O
reﬁnement	O
of	O
this	O
process	B
of	O
statistics	B
accumulation	O
is	O
described	O
in	O
section	O
3	O
.	O
next	O
,	O
we	O
extract	O
the	O
i	O
-	O
vectors	O
from	O
the	O
supervectors	O
.	O
su-	O
figure	O
1	O
:	O
diagram	O
of	O
the	O
diarization	B
process	B
.	O
pervectors	O
have	O
usually	O
a	O
high	O
dimension	O
d	O
=	O
m	O
∗	O
(	O
d	O
+	O
1	O
)	O
f	O
that	O
is	O
given	O
by	O
the	O
number	O
of	O
mixtures	O
m	O
in	O
the	O
ubm	O
and	O
the	O
d	O
dimensionality	O
of	O
the	O
feature	O
vectors	O
o	O
.	O
the	O
i	O
-	O
vectors	O
2.1	O
.	O
segmentation	B
f	O
t	O
are	O
a	O
compact	O
representation	O
of	O
the	O
information	B
encoded	O
in	O
the	O
for	O
the	O
segmentation	B
step	O
,	O
we	O
use	O
the	O
scd	O
approach	O
based	O
on	O
supervectors	O
,	O
mostly	O
the	O
information	B
about	O
the	O
identity	O
of	O
the	O
cnn	O
[	O
14	O
]	O
.	O
the	O
cnn	O
as	O
a	O
regressor	O
is	O
trained	O
supervised	O
on	O
speaker	B
.	O
factor	B
analysis	I
(	O
fa	O
)	O
[	O
29	O
]	O
(	O
or	O
extended	O
joint	O
factor	B
spectrograms	O
of	O
the	O
acoustic	O
signal	B
with	O
a	O
reference	B
information	B
analysis	B
(	O
jfa	O
)	O
[	O
30	O
]	O
to	O
handle	O
more	O
sessions	O
of	O
each	O
speaker	B
)	O
is	O
l	O
about	O
the	O
existing	O
speaker	B
changes	O
.	O
the	O
value	O
of	O
the	O
function	O
used	O
for	O
dimensionality	O
reduction	O
of	O
the	O
supervector	O
of	O
statis-	O
l	O
in	O
time	B
t	O
is	O
computed	O
via	O
the	O
formula	O
in	O
equation	O
1	O
.	O
we	O
call	O
tics	O
.	O
the	O
generative	O
i	O
-	O
vector	O
model	B
has	O
the	O
form	O
this	O
labeling	O
a	O
fuzzy	O
labeling	O
.	O
it	O
has	O
a	O
shape	O
of	O
a	O
triangle	O
and	O
the	O
main	O
idea	O
behind	O
it	O
is	O
to	O
model	B
the	O
uncertainty	O
of	O
human	O
ψ	O
=	O
m0	O
+	O
t	O
w	O
+	O
(	O
cid:15	O
)	O
,	O
w	O
∼	O
n	O
(	O
0	O
,	O
i	O
)	O
,	O
(	O
cid:15	O
)	O
∼	O
n	O
(	O
0	O
,	O
σ	O
)	O
,	O
(	O
5	O
)	O
labeling	O
.	O
where	O
t	O
(	O
of	O
size	B
d	O
×	O
d	O
)	O
is	O
called	O
the	O
total	O
variability	O
space	O
(	O
cid:18	O
)	O
(	O
cid:19	O
)	O
w	O
l(t	O
)	O
=	O
max	O
0	O
,	O
1	O
−	O
mini	O
(	O
|t	O
−	O
si|	O
)	O
,	O
(	O
1	O
)	O
matrix	O
,	O
w	O
is	O
the	O
segment	B
’s	O
i	O
-	O
vector	O
of	O
dimension	O
dw	O
having	O
τ	O
standard	O
gaussian	O
distribution	O
,	O
m	O
is	O
the	O
mean	O
vector	O
of	O
ψ	O
,	O
0	O
however	O
often	O
approximated	O
by	O
the	O
ubm	O
’s	O
mean	O
supervector	O
,	O
where	O
s	O
is	O
the	O
time	B
of	O
ith	O
speaker	B
change	I
and	O
τ	O
=	O
0.6	O
is	O
the	O
i	O
and	O
(	O
cid:15	O
)	O
is	O
residual	O
noise	O
with	O
a	O
diagonal	O
covariance	O
matrix	O
σ	O
with	O
tolerance	O
which	O
models	B
the	O
level	B
of	O
uncertainty	O
of	O
the	O
man-	O
covariance	O
matrices	O
c	O
,	O
.	O
.	O
.	O
,	O
c	O
of	O
the	O
ubm	O
ordered	O
on	O
the	O
1	O
m	O
ual	O
labeling	O
.	O
figure	O
2	O
depicts	O
an	O
example	O
of	O
a	O
spectrogram	O
,	O
diagonal	O
.	O
the	O
i	O
-	O
vectors	O
are	O
also	O
length	B
-	O
normalized	O
[	O
31	O
]	O
.	O
de-	O
the	O
values	B
of	O
the	O
labeling	O
and	O
the	O
cnn	O
output	B
as	O
a	O
probability	B
tails	O
about	O
the	O
training	O
of	O
total	O
variability	O
space	O
matrix	O
t	O
can	O
of	O
speaker	B
change	I
p	O
(	O
a	O
number	O
between	O
zero	O
and	O
one	O
)	O
.	O
the	O
be	O
found	O
in	O
[	O
32	O
,	O
33	O
]	O
.	O
speaker	B
changes	O
are	O
identiﬁed	O
as	O
peaks	B
in	O
the	O
signal	B
p	O
using	O
because	O
of	O
the	O
differences	O
between	O
each	O
conversation	O
(	O
and	O
non	O
-	O
maximum	O
suppression	O
with	O
a	O
suitable	O
window	O
size	B
.	O
the	O
the	O
similarity	B
in	O
one	O
conversation	O
)	O
,	O
we	O
also	O
compute	O
a	O
conver-	O
detected	O
peaks	B
are	O
then	O
thresholded	O
to	O
remove	O
insigniﬁcant	O
lo-	O
sation	O
dependent	O
principal	O
component	O
analysis	B
(	O
pca	O
)	O
trans-	O
cal	O
maxima	O
.	O
the	O
signal	B
between	O
two	O
detected	O
speaker	B
changes	O
formation	O
[	O
26	O
]	O
,	O
which	O
further	O
reduces	O
the	O
dimensionality	O
of	O
the	O
is	O
considered	O
as	O
one	O
segment	B
.	O
the	O
minimum	O
duration	O
of	O
one	O
i	O
-	O
vector	O
.	O
the	O
beneﬁt	O
of	O
using	O
pca	O
instead	O
of	O
fa	O
approach	O
is	O
segment	B
is	O
limited	O
to	O
one	O
second	O
,	O
smaller	O
segments	O
are	O
joined	O
to	O
the	O
additional	O
information	B
about	O
the	O
importance	O
of	O
each	O
compo-	O
the	O
adjacent	O
one	O
in	O
order	B
to	O
obtain	O
sufﬁcient	O
information	B
about	O
nent	O
given	O
by	O
the	O
eigenvalue	O
of	O
the	O
corresponding	O
eigenvector	O
.	O
the	O
speaker	B
.	O
the	O
reduced	O
dimension	O
in	O
the	O
pca	O
latent	O
space	O
can	O
be	O
found	O
for	O
each	O
conversation	O
separately	O
depending	O
only	O
on	O
the	O
ratio	O
of	O
2.2	O
.	O
segment	B
description	O
eigenvalue	O
mass	O
.	O
to	O
describe	O
a	O
segment	B
we	O
ﬁrst	O
construct	O
a	O
supervector	O
of	O
accu-	O
mulated	O
statistics	B
.	O
supervectors	O
have	O
been	O
used	O
in	O
the	O
process	B
2.3	O
.	O
clustering	B
and	O
resegmentation	B
of	O
speaker	B
adaptation	O
[	O
27	O
]	O
where	O
they	O
serve	O
as	O
a	O
descriptor	O
of	O
given	O
i	O
-	O
vector	O
representations	O
of	O
the	O
extracted	O
segments	O
,	O
we	O
a	O
new	O
speaker	B
.	O
they	O
contain	O
the	O
zeroth	O
and	O
ﬁrst	O
statistical	O
mo-	O
perform	O
a	O
clustering	B
into	O
sets	O
of	O
i	O
-	O
vectors	O
describing	O
different	O
ments	O
of	O
speakers	O
’	O
data	B
related	O
to	O
a	O
ubm	O
.	O
the	O
ubm	O
is	O
mod-	O
speakers	O
.	O
this	O
is	O
a	O
coarse	O
clustering	B
on	O
the	O
level	B
of	O
the	O
segmen-	O
eled	O
as	O
a	O
gaussian	O
mixture	O
model	B
(	O
gmm	O
)	O
from	O
a	O
huge	O
amount	B
tation	O
given	O
by	O
scd	O
.	O
to	O
make	O
the	O
ﬁnal	O
diarization	B
more	O
pre-	O
of	O
speech	O
data	B
form	O
different	O
speakers	O
.	O
the	O
parameters	O
of	O
the	O
cise	O
we	O
reﬁne	O
it	O
by	O
resegmentation	B
.	O
we	O
compute	O
gmms	O
over	O
model	B
are	O
λ	O
=	O
{	O
ω	O
,	O
µ	O
,	O
c	O
}	O
m	O
,	O
where	O
m	O
is	O
the	O
num-	O
ubm	O
m	O
m	O
m	O
m=1	O
the	O
feature	O
vectors	O
o	O
,	O
one	O
gmm	O
per	O
speaker	B
cluster	O
.	O
then	O
the	O
ber	O
of	O
mixtures	O
in	O
the	O
ubm	O
,	O
ω	O
,	O
µ	O
,	O
c	O
are	O
the	O
weight	B
,	O
mean	O
t	O
m	O
m	O
m	O
whole	O
conversation	O
is	O
redistributed	O
frame	B
by	O
frame	B
according	O
to	O
and	O
covariance	O
of	O
the	O
mth	O
mixture	O
,	O
respectively	O
.	O
we	O
consider	O
the	O
likelihoods	O
of	O
the	O
gmms	O
.	O
only	O
diagonal	O
covariance	O
matrices	O
.	O
let	O
o	O
=	O
{	O
o	O
}	O
t	O
be	O
the	O
set	B
of	O
t	O
feature	O
vectors	O
o	O
of	O
a	O
t	O
t=1	O
t	O
3	O
.	O
statistics	B
reﬁnement	O
dimension	O
d	O
of	O
one	O
segment	B
of	O
conversation	O
,	O
and	O
ω	O
n	O
(	O
o	O
;	O
µ	O
,	O
c	O
)	O
because	O
of	O
the	O
uncertainty	O
about	O
the	O
assumption	O
that	O
there	O
is	O
γm(ot	O
)	O
=	O
(	O
cid:80)m	O
m	O
ω	O
nt	O
(	O
om	O
;	O
µ	O
m	O
,	O
c	O
)	O
(	O
2	O
)	O
a	O
speech	O
of	O
only	O
one	O
speaker	B
in	O
a	O
segment	B
,	O
not	O
all	O
data	B
from	O
m=1	O
m	O
t	O
m	O
m	O
the	O
segment	B
can	O
contribute	O
to	O
the	O
supervector	O
equally	O
.	O
in	O
a	O
tele-	O
be	O
the	O
posterior	O
probability	B
of	O
mth	O
mixture	O
given	O
a	O
feature	O
vec-	O
phone	O
conversation	O
,	O
crosstalk	O
is	O
frequent	O
around	O
the	O
place	O
of	O
tor	O
o	O
.	O
the	O
soft	O
count	O
of	O
the	O
mth	O
mixture	O
(	O
zeroth	O
statistical	O
mo-	O
speaker	B
change	I
and	O
also	O
rapid	O
changes	O
of	O
the	O
speakers	O
are	O
com-	O
t	O
ment	O
of	O
feature	O
vectors	O
)	O
is	O
mon	O
.	O
in	O
subsection	O
2.2	O
,	O
all	O
statistics	B
are	O
accumulated	O
into	O
the	O
su-	O
(	O
cid:88)t	O
pervector	O
with	O
the	O
weight	B
ωm	O
obtained	O
only	O
from	O
the	O
ubm	O
.	O
n	O
=	O
γ	O
(	O
o	O
)	O
(	O
3	O
)	O
m	O
m	O
t	O
this	O
weight	B
ω	O
in	O
equation	O
(	O
2	O
)	O
informs	O
about	O
the	O
relevance	O
of	O
m	O
t=1	O
the	O
acoustic	O
data	B
to	O
”	O
the	O
universal	O
speaker	B
”	O
,	O
in	O
other	O
words	B
,	O
how	O
and	O
the	O
sum	O
of	O
the	O
ﬁrst	O
statistical	O
moments	O
of	O
feature	O
vectors	O
likely	O
it	O
is	O
to	O
be	O
a	O
part	O
of	O
a	O
speech	O
.	O
this	O
weight	B
tells	O
us	O
nothing	O
with	O
respect	O
to	O
the	O
mth	O
mixture	O
is	O
about	O
the	O
homogeneity	O
of	O
the	O
speaker	B
in	O
the	O
segment	B
.	O
super-	O
vector	O
accumulation	O
,	O
originally	O
used	O
in	O
the	O
speaker	B
adaptation	O
t	O
(	O
cid:88	O
)	O
task	O
,	O
does	O
not	O
have	O
to	O
consider	O
the	O
homogeneity	O
of	O
the	O
speaker	B
b	O
=	O
γ	O
(	O
o	O
)	O
o	O
.	O
(	O
4	O
)	O
m	O
m	O
t	O
t	O
in	O
data	B
.	O
t=1	O
3563figure	O
2	O
:	O
the	O
input	B
speech	O
as	O
spectrogram	O
is	O
processed	O
by	O
the	O
cnn	O
into	O
the	O
output	B
function	O
p	O
(	O
a	O
probability	B
of	O
change	B
in	O
time	B
)	O
.	O
the	O
l	O
-	O
function	O
(	O
the	O
reference	B
speaker	I
change	B
)	O
for	O
the	O
cnn	O
training	O
is	O
depicted	O
on	O
top	O
.	O
note	O
:	O
the	O
output	B
of	O
cnn	O
in	O
time	B
t	O
is	O
only	O
a	O
number	O
.	O
for	O
this	O
purpose	O
,	O
we	O
are	O
exploring	O
the	O
output	B
of	O
the	O
cnn-	O
based	O
scd	O
as	O
a	O
probability	B
of	O
the	O
speaker	B
change	I
in	O
the	O
signal	B
.	O
although	O
the	O
audio	O
signal	B
is	O
cut	O
into	O
segments	O
according	O
to	O
the	O
maxima	O
peaks	B
in	O
the	O
function	O
p	O
(	O
the	O
cnn	O
output	B
)	O
,	O
the	O
shape	O
of	O
the	O
function	O
can	O
also	O
indicate	O
a	O
suspicious	O
part	O
of	O
the	O
segment	B
.	O
the	O
part	O
of	O
the	O
audio	O
segment	B
in	O
time	B
t	O
with	O
a	O
high	O
probabil-	O
ity	O
of	O
a	O
speaker	B
change	I
p	O
is	O
less	O
appropriate	O
to	O
represent	O
the	O
t	O
speaker	B
than	O
a	O
part	O
with	O
a	O
small	O
probability	B
p	O
.	O
thus	O
,	O
we	O
use	O
t	O
the	O
value	O
of	O
1	O
−	O
p	O
as	O
a	O
weighting	O
factor	B
of	O
the	O
signal	B
in	O
the	O
t	O
figure	O
3	O
:	O
two	O
speech	B
segments	I
with	O
the	O
probability	B
of	O
speaker	B
accumulation	O
process	B
.	O
the	O
reﬁnement	O
of	O
equation	O
(	O
2	O
)	O
is	O
repre-	O
change	B
p	O
,	O
the	O
ﬁrst	O
one	O
with	O
crosstalk	O
on	O
the	O
end	O
of	O
the	O
segment	B
sented	O
by	O
the	O
formula	O
and	O
the	O
second	O
one	O
with	O
noise	O
disturbance	O
in	O
the	O
middle	O
of	O
the	O
segment	B
.	O
(	O
1	O
−	O
p	O
)	O
ω	O
n	O
(	O
o	O
;	O
µ	O
,	O
c	O
)	O
γ	O
(	O
o	O
)	O
=	O
t	O
m	O
t	O
m	O
m	O
.	O
(	O
6	O
)	O
m	O
t	O
(	O
cid:80)m	O
ω	O
n	O
(	O
o	O
;	O
µ	O
,	O
c	O
)	O
m=1	O
m	O
t	O
m	O
m	O
the	O
equations	O
(	O
3	O
)	O
and	O
(	O
4	O
)	O
stay	O
the	O
same	O
because	O
they	O
both	O
de-	O
pend	O
on	O
the	O
reﬁned	O
γ	O
(	O
o	O
)	O
from	O
the	O
equation	O
(	O
6	O
)	O
.	O
the	O
amount	B
m	O
t	O
of	O
data	B
for	O
the	O
statistics	B
accumulation	O
stay	O
the	O
same	O
only	O
the	O
importance	O
of	O
each	O
data	B
is	O
changed	O
.	O
4	O
.	O
discussion	O
the	O
limitation	O
of	O
the	O
segmentation	B
step	O
in	O
the	O
sd	O
system	O
is	O
figure	O
4	O
:	O
short	O
speech	B
segment	I
with	O
the	O
probability	B
of	O
speaker	B
a	O
minimal	O
length	B
of	O
the	O
segment	B
from	O
which	O
the	O
identity	O
of	O
change	B
p	O
containing	O
two	O
speakers	O
.	O
in	O
this	O
example	O
,	O
the	O
scd	O
the	O
speaker	B
can	O
be	O
extracted	O
.	O
in	O
telephone	O
conversations	O
,	O
the	O
system	O
fails	O
and	O
the	O
p	O
weight	B
of	O
statistics	B
does	O
not	O
help	O
to	O
reﬁne	O
speaker	B
change	I
can	O
occur	O
arbitrarily	O
often	O
in	O
time	B
.	O
in	O
these	O
the	O
accumulation	O
process	B
.	O
conditions	O
,	O
the	O
segments	O
should	O
be	O
long	O
enough	O
to	O
allow	O
the	O
extraction	B
of	O
speaker	B
identifying	O
information	B
while	O
limiting	O
the	O
risk	O
of	O
a	O
speaker	B
change	I
being	O
present	O
within	O
the	O
segment	B
.	O
still	O
,	O
the	O
other	O
scd	O
approaches	O
(	O
e.g.	O
glr	O
used	O
in	O
[	O
14	O
]	O
)	O
have	O
only	O
one	O
speaker	B
in	O
the	O
whole	O
segment	B
can	O
not	O
be	O
always	O
gua-	O
analogical	O
output	B
as	O
the	O
likelihood	B
function	O
of	O
a	O
speaker	B
change	I
.	O
ranteed	O
.	O
a	O
high	O
probability	B
value	O
of	O
a	O
speaker	B
change	I
from	O
the	O
but	O
for	O
the	O
purpose	O
of	O
weighting	O
,	O
the	O
information	B
from	O
other	O
cnn	O
represents	O
the	O
instability	O
of	O
homogeneity	O
of	O
a	O
speaker	B
in	O
scd	O
systems	O
is	O
inappropriate	O
because	O
usually	O
the	O
value	O
of	O
the	O
the	O
segment	B
.	O
this	O
instability	O
leads	O
to	O
the	O
propagation	O
of	O
faulty	O
change	B
is	O
not	O
in	O
the	O
interval	O
(	O
cid:104)0	O
,	O
1(cid:105	O
)	O
and	O
the	O
interval	O
is	O
changed	O
features	O
into	O
the	O
supervector	O
accumulation	O
process	B
.	O
such	O
faulty	O
for	O
every	O
conversation	O
.	O
features	O
usually	O
occur	O
on	O
the	O
boundaries	B
of	O
the	O
segment	B
,	O
where	O
a	O
high	O
risk	O
of	O
crosstalk	O
is	O
common	O
or	O
anywhere	O
in	O
the	O
segment	B
if	O
5	O
.	O
experiments	O
some	O
disturbance	O
in	O
the	O
acoustic	O
signal	B
is	O
present	O
,	O
see	O
figure	O
3	O
.	O
when	O
using	O
the	O
cnn	O
output	B
for	O
the	O
reﬁnement	O
of	O
the	O
statistics	B
the	O
experiment	O
was	O
designed	O
to	O
investigate	O
our	O
proposed	O
ap-	O
accumulation	O
we	O
suppress	O
the	O
effect	O
of	O
these	O
faulty	O
features	O
by	O
proach	O
to	O
reﬁnement	O
of	O
the	O
accumulation	O
of	O
statistics	B
represent-	O
weighting	O
them	O
down	O
.	O
ing	O
the	O
speaker	B
in	O
the	O
segment	B
of	O
conversation	O
.	O
nevertheless	O
,	O
there	O
are	O
still	O
known	O
limitations	O
of	O
our	O
pro-	O
posed	O
approach	O
.	O
in	O
rare	O
situations	O
,	O
when	O
the	O
speaker	B
change	I
5.1	O
.	O
corpus	B
is	O
missed	O
by	O
the	O
scd	O
as	O
seen	O
in	O
figure	O
4	O
,	O
we	O
will	O
only	O
penal-	O
ize	O
the	O
features	O
corresponding	O
to	O
boundaries	B
and	O
to	O
the	O
missed	O
the	O
experiment	O
was	O
carried	O
out	O
on	O
telephone	O
conversations	O
speaker	B
change	I
.	O
thus	O
the	O
segment	B
will	O
be	O
described	O
by	O
features	O
from	O
the	O
english	O
part	O
of	O
callhome	O
corpus	B
[	O
34	O
]	O
.	O
the	O
original	O
from	O
two	O
different	O
speakers	O
,	O
resulting	O
into	O
inaccurate	O
i	O
-	O
vector	O
two	O
channels	B
have	O
been	O
mixed	O
into	O
one	O
.	O
only	O
two	O
speaker	B
con-	O
representation	O
.	O
versations	O
were	O
selected	O
so	O
that	O
the	O
clustering	B
can	O
be	O
limited	O
to	O
3564two	O
clusters	O
.	O
this	O
is	O
109	O
conversations	O
in	O
total	O
each	O
with	O
about	O
table	O
1	O
:	O
der	O
[	O
%	O
]	O
of	O
the	O
sd	O
systems	O
with	O
the	O
i	O
-	O
vector	O
speaker	B
10	O
min	O
duration	O
in	O
a	O
single	O
telephone	O
channel	O
sampled	O
at	O
8	O
khz	O
.	O
representation	O
with	O
constant	O
length	B
window	O
segegmentation	O
for	O
training	O
of	O
the	O
cnn	O
,	O
only	O
35	O
conversations	O
were	O
used	O
,	O
the	O
and	O
scd	O
based	O
on	O
cnn	O
(	O
with	O
and	O
without	O
reﬁned	O
statistics	B
ac-	O
rest	O
was	O
used	O
for	O
testing	O
the	O
sd	O
system	O
.	O
cumulation	O
)	O
.	O
5.2	O
.	O
system	O
system	O
der	O
[	O
%	O
]	O
constant	O
length	B
window	O
seg	O
.	O
9.23	O
the	O
sd	O
system	O
presented	O
in	O
our	O
papers	O
[	O
14	O
,	O
35	O
]	O
uses	O
the	O
fea-	O
cnn	O
-	O
scd	O
without	O
reﬁnement	O
9.31	O
ture	O
extraction	B
based	O
on	O
linear	O
frequency	B
cepstral	O
coefﬁcients	O
cnn	O
-	O
scd	O
with	O
reﬁnement	O
7.84	O
(	O
lfccs	O
)	O
,	O
hamming	O
window	O
of	O
length	B
25	O
ms	O
with	O
10	O
ms	O
shift	O
of	O
the	O
window	O
.	O
there	O
are	O
25	O
triangular	O
ﬁlter	O
banks	O
which	O
are	O
spread	O
linearly	O
across	O
the	O
frequency	B
spectrum	B
,	O
and	O
20	O
lfccs	O
window	O
segmentation	B
is	O
small	O
because	O
of	O
the	O
resegmentation	B
are	O
extracted	O
.	O
delta	O
coefﬁcients	O
were	O
added	O
leading	O
to	O
a	O
40-	O
step	O
,	O
which	O
repairs	O
the	O
inaccurate	O
segmentation	B
produced	O
by	O
dimensional	O
feature	O
vector	O
(	O
d	O
=	O
40	O
)	O
.	O
instead	O
of	O
the	O
voice	O
f	O
the	O
constant	O
length	B
window	O
[	O
14	O
]	O
.	O
the	O
effect	O
of	O
resegmentation	B
activity	O
detector	O
,	O
the	O
reference	B
annotation	O
about	O
missed	O
speech	O
is	O
strong	O
because	O
there	O
is	O
sufﬁcient	O
amount	B
of	O
data	B
available	O
in	O
was	O
used	O
.	O
each	O
conversation	O
for	O
efﬁcient	O
training	O
of	O
gmm	O
.	O
however	O
,	O
our	O
for	O
segmentation	B
,	O
cnn	O
described	O
in	O
[	O
14	O
]	O
was	O
used	O
.	O
the	O
proposed	O
approach	O
to	O
reﬁned	O
statistics	B
accumulation	O
using	O
the	O
input	B
of	O
the	O
net	O
is	O
a	O
spectrogram	O
of	O
speech	O
of	O
length	B
1.4	O
sec-	O
output	B
from	O
the	O
cnn	O
-	O
based	O
scd	O
brings	O
a	O
more	O
precise	O
infor-	O
onds	O
and	O
the	O
shift	O
is	O
0.1	O
seconds	B
.	O
the	O
cnn	O
consists	O
of	O
three	O
mation	O
to	O
the	O
speaker	B
description	O
.	O
this	O
improvement	O
can	O
be	O
convolutional	O
layers	O
with	O
relu	O
activation	O
functions	O
.	O
there	O
is	O
seen	O
on	O
the	O
ﬁnal	O
der	O
of	O
the	O
system	O
even	O
after	O
resegmentation	B
a	O
max	O
-	O
pooling	O
layer	B
after	O
each	O
convolutional	O
layer	B
.	O
batch	O
nor-	O
step	O
.	O
malization	O
[	O
36	O
]	O
is	O
used	O
for	O
layer	B
output	B
normalization	O
.	O
there	O
are	O
two	O
fully	O
connected	O
layers	O
with	O
sigmoid	O
activation	O
func-	O
6	O
.	O
conclusions	O
tion	O
at	O
the	O
end	O
.	O
in	O
the	O
ﬁrst	O
convolutional	O
layer	B
,	O
there	O
are	O
ﬁlters	O
with	O
rectangular	O
shapes	O
that	O
serve	O
as	O
feature	O
extractors	O
.	O
the	O
most	O
of	O
the	O
dnn	O
based	O
sd	O
systems	O
introduced	O
in	O
section	O
1	O
two	O
intermediate	O
convolutional	O
layers	O
learn	O
a	O
higher	O
level	B
rep-	O
use	O
dnn	O
to	O
describe	O
a	O
speaker	B
in	O
a	O
relatively	O
short	O
segment	B
resentation	O
of	O
these	O
features	O
.	O
the	O
output	B
layer	B
consists	O
of	O
just	O
of	O
conversation	O
and	O
then	O
compare	O
two	O
representations	O
of	O
adja-	O
one	O
neuron	O
with	O
sigmoid	O
activation	O
function	O
.	O
thus	O
the	O
output	B
is	O
cent	O
segments	O
(	O
e.g.	O
so	O
called	O
d	O
-	O
vectors	O
[	O
12	O
]	O
)	O
to	O
decide	O
if	O
the	O
limited	O
between	O
zero	O
and	O
one	O
.	O
it	O
represents	O
the	O
probability	B
of	O
a	O
speaker	B
change	I
occurred	O
.	O
on	O
the	O
contrary	O
,	O
our	O
approach	O
using	O
speaker	B
change	I
in	O
the	O
middle	O
of	O
the	O
observed	O
spectrogram	O
.	O
for	O
the	O
cnn	O
-	O
based	O
scd	O
ﬁnds	O
the	O
possible	O
speaker	B
changes	O
in	O
spec-	O
the	O
training	O
of	O
the	O
cnn	O
,	O
we	O
use	O
a	O
binary	O
cross	O
entropy	O
loss	O
togram	O
and	O
additionally	O
uses	O
the	O
information	B
for	O
the	O
reﬁnement	O
function	O
.	O
it	O
is	O
optimized	O
by	O
stochastic	O
gradient	O
descent	O
with	O
of	O
accumulation	O
process	B
of	O
statistics	B
.	O
these	O
reﬁned	O
statistics	B
a	O
batch	O
size	B
of	O
64	O
.	O
the	O
learning	O
rate	O
is	O
changed	O
after	O
a	O
ﬁxed	O
represent	O
the	O
speaker	B
information	B
in	O
the	O
segment	B
better	O
than	O
the	O
number	O
of	O
iterations	O
by	O
a	O
factor	B
of	O
0.1	O
.	O
when	O
the	O
loss	O
function	O
classical	O
approach	O
to	O
the	O
statistics	B
accumulation	O
,	O
so	O
the	O
com-	O
is	O
stabilized	O
we	O
use	O
rmsprop	O
algorithm	O
for	O
ﬁne	O
tuning	O
of	O
the	O
puted	O
i	O
-	O
vector	O
is	O
more	O
precise	O
and	O
the	O
ﬁnal	O
diarization	B
error	I
of	O
network	B
’s	O
weights	O
.	O
the	O
whole	O
sd	O
system	O
is	O
reduced	O
.	O
our	O
next	O
goal	O
is	O
to	O
train	O
the	O
for	O
the	O
purpose	O
of	O
training	O
the	O
i	O
-	O
vector	O
we	O
have	O
used	O
the	O
cnn	O
to	O
represent	O
the	O
probability	B
of	O
the	O
speaker	B
homogeneity	O
following	O
corpora	B
:	O
nist	O
sre	O
2004	O
,	O
nist	O
sre	O
2005	O
,	O
nist	O
in	O
the	O
acoustics	B
signal	B
instead	O
of	O
the	O
probability	B
of	O
the	O
speaker	B
sre	O
2006	O
speaker	B
recognition	O
evaluations	O
[	O
37	O
,	O
38	O
,	O
39	O
]	O
and	O
the	O
change	B
.	O
also	O
,	O
we	O
want	O
to	O
replace	O
the	O
i	O
-	O
vector	O
with	O
a	O
dnn-	O
switchboard	O
1	O
release	O
2	O
and	O
switchboard	O
2	O
phase	O
3	O
[	O
40	O
,	O
41	O
]	O
.	O
based	O
vector	O
and	O
use	O
the	O
cnn	O
probability	B
of	O
the	O
speaker	B
change	I
we	O
model	B
the	O
ubm	O
as	O
a	O
gmm	O
with	O
m	O
=	O
1024	O
components	B
.	O
as	O
a	O
prior	O
when	O
constructing	O
this	O
vector	O
.	O
we	O
have	O
set	B
the	O
dimension	O
of	O
the	O
i	O
-	O
vector	O
to	O
d	O
=	O
400	O
and	O
w	O
we	O
have	O
used	O
the	O
conversational	O
dependent	O
pca	O
to	O
reduce	O
the	O
7	O
.	O
acknowledgements	O
dimension	O
further	O
.	O
we	O
use	O
eigenvectors	O
with	O
the	O
ratio	O
of	O
their	O
eigenvalue	O
mass	O
p	O
=	O
0.5	O
.	O
we	O
have	O
used	O
k	O
-	O
means	O
clustering	B
the	O
work	O
was	O
supported	O
by	O
the	O
ministry	O
of	O
education	O
,	O
youth	O
with	O
cosine	O
distance	B
to	O
obtain	O
the	O
speaker	B
clusters	O
.	O
and	O
sports	O
of	O
the	O
czech	O
republic	O
project	O
no	O
.	O
lo1506	O
.	O
access	O
to	O
computing	O
and	O
storage	O
facilities	O
(	O
cesnet	O
lm2015042	O
)	O
is	O
5.3	O
.	O
results	B
greatly	O
appreciated	O
.	O
we	O
use	O
the	O
diarization	B
error	I
rate	I
(	O
der	O
)	O
for	O
the	O
evaluation	B
8	O
.	O
references	B
of	O
our	O
approach	O
.	O
it	O
has	O
been	O
described	O
and	O
used	O
by	O
nist	O
in	O
the	O
rt	O
evaluations	O
[	O
42	O
]	O
.	O
we	O
use	O
the	O
standard	O
250	O
ms	O
tolerance	O
[	O
1	O
]	O
x.	O
a.	O
miro	O
,	O
s.	O
bozonnet	O
,	O
n.	O
evans	O
,	O
c.	O
fredouille	O
,	O
g.	O
friedland	O
,	O
around	O
the	O
reference	B
boundaries	B
.	O
der	O
is	O
a	O
combination	O
of	O
sev-	O
and	O
o.	O
vinyals	O
,	O
“	O
speaker	B
diarization	I
:	O
a	O
review	O
of	O
recent	O
re-	O
eral	O
types	O
of	O
errors	B
(	O
missed	O
speech	O
,	O
mislabeled	O
non	O
-	O
speech	O
,	O
in-	O
search	O
,	O
”	O
audio	O
,	O
speech	O
,	O
and	O
language	B
processing	I
,	O
vol	O
.	O
20	O
,	O
no	O
.	O
2	O
,	O
pp	O
.	O
356–370	O
,	O
2012	O
.	O
correct	O
speaker	B
cluster	O
)	O
.	O
we	O
assume	O
the	O
information	B
about	O
the	O
silence	B
in	O
all	O
testing	O
audios	O
is	O
available	O
and	O
correct	O
.	O
that	O
means	O
[	O
2	O
]	O
m.	O
rouvier	O
,	O
g.	O
dupuy	O
,	O
p.	O
gay	O
,	O
e.	O
khoury	O
,	O
t.	O
merlin	O
,	O
and	O
s.	O
meignier	O
,	O
“	O
an	O
open	O
-	O
source	B
state	O
-	O
of	O
-	O
the	O
-	O
art	O
toolbox	O
for	O
broad-	O
that	O
our	O
results	B
represent	O
only	O
the	O
error	O
of	O
incorrect	O
speaker	B
cast	O
news	O
diarization	B
,	O
”	O
in	O
interspeech	O
,	O
lyon	O
,	O
2013	O
,	O
p.	O
5	O
.	O
clusters	O
.	O
the	O
results	B
of	O
the	O
examined	O
systems	O
are	O
shown	O
in	O
ta-	O
ble	O
1	O
.	O
for	O
comparison	O
,	O
the	O
result	O
of	O
segmentation	B
using	O
only	O
[	O
3	O
]	O
g.	O
sell	O
and	O
d.	O
garcia	O
-	O
romero	O
,	O
“	O
speaker	B
diarization	I
with	O
plda	B
i	O
-	O
vector	O
scoring	O
and	O
unsupervised	O
calibration	O
,	O
”	O
in	O
ieee	O
spoken	O
constant	O
length	B
window	O
is	O
also	O
shown	O
.	O
using	O
this	O
approach	O
a	O
language	O
technology	O
workshop	O
,	O
south	O
lake	O
tahoe	O
,	O
2014	O
,	O
pp	O
.	O
conversation	O
is	O
divided	O
into	O
short	O
segments	O
and	O
the	O
system	O
then	O
413–417	O
.	O
relies	O
on	O
the	O
clustering	B
and	O
further	O
resegmentation	B
to	O
reﬁne	O
the	O
[	O
4	O
]	O
s.	O
h.	O
shum	O
,	O
n.	O
dehak	O
,	O
r.	O
dehak	O
,	O
and	O
j.	O
r.	O
glass	O
,	O
“	O
unsupervised	O
boundaries	B
.	O
methods	O
for	O
speaker	B
diarization	I
:	O
an	O
integrated	O
and	O
iterative	O
the	O
difference	O
in	O
the	O
results	B
of	O
the	O
system	O
using	O
cnn	O
-	O
scd	O
approach	O
,	O
”	O
audio	O
,	O
speech	O
,	O
and	O
language	B
processing	I
,	O
vol	O
.	O
21	O
,	O
without	O
reﬁnement	O
and	O
system	O
using	O
only	O
the	O
constant	O
length	B
no	O
.	O
10	O
,	O
pp	O
.	O
2015–2028	O
,	O
2013	O
.	O
3565[5	O
]	O
m.	O
senoussaoui	O
,	O
p.	O
kenny	O
,	O
t.	O
stafylakis	O
,	O
and	O
p.	O
dumouchel	O
,	O
“	O
a	O
[	O
26	O
]	O
s.	O
shum	O
,	O
n.	O
dehak	O
,	O
e.	O
chuangsuwanich	O
,	O
d.	O
reynolds	O
,	O
and	O
study	O
of	O
the	O
cosine	O
distance	B
-	O
based	O
mean	O
shift	O
for	O
telephone	O
j.	O
glass	O
,	O
“	O
exploiting	O
intra	O
-	O
conversation	O
variability	O
for	O
speaker	B
speech	O
diarization	B
,	O
”	O
audio	O
,	O
speech	O
and	O
language	B
processing	I
,	O
diarization	B
,	O
”	O
in	O
interspeech	O
,	O
florence	O
,	O
2011	O
,	O
pp	O
.	O
945–948	O
.	O
vol	O
.	O
22	O
,	O
no	O
.	O
1	O
,	O
pp	O
.	O
217–227	O
,	O
2014	O
.	O
[	O
27	O
]	O
z.	O
zaj´ıc	O
,	O
l.	O
machlica	O
,	O
and	O
l.	O
mu¨ller	O
,	O
“	O
robust	O
adaptation	O
tech-	O
[	O
6	O
]	O
c.	O
fredouille	O
,	O
s.	O
bozonnet	O
,	O
and	O
n.	O
evans	O
,	O
“	O
the	O
lia	O
-	O
eurecom	O
niques	O
dealing	O
with	O
small	O
amount	B
of	O
data	B
,	O
”	O
in	O
tsd	O
2012	O
.	O
lec-	O
rt	O
09	O
speaker	B
diarization	I
system	I
,	O
”	O
in	O
nist	O
rich	B
transcription	I
ture	O
notes	O
in	O
computer	B
science	O
,	O
vol	O
.	O
7499	O
,	O
brno	O
,	O
2012	O
,	O
pp	O
.	O
418	O
–	O
workshop	O
(	O
rt09	O
)	O
,	O
melbourne	O
,	O
usa	O
,	O
2009	O
.	O
487	O
.	O
[	O
7	O
]	O
o.	O
ben	O
-	O
harush	O
,	O
o.	O
ben	O
-	O
harush	O
,	O
i.	O
lapidot	O
,	O
and	O
h.	O
guterman	O
,	O
[	O
28	O
]	O
—	O
—	O
,	O
“	O
robust	O
statistic	O
estimates	O
for	O
adaptation	O
in	O
the	O
task	O
of	O
“	O
initialization	O
of	O
iterative	O
-	O
based	B
speaker	I
diarization	B
systems	I
for	O
speech	B
recognition	I
,	O
”	O
in	O
tsd	O
2010	O
.	O
lecture	O
notes	O
in	O
computer	B
telephone	O
conversations	O
,	O
”	O
ieee	O
transactions	O
on	O
audio	O
,	O
speech	O
,	O
science	O
,	O
vol	O
.	O
6231	O
.	O
brno	O
:	O
springer	O
,	O
berlin	O
,	O
heidelberg	O
,	O
2010	O
,	O
and	O
language	B
processing	I
,	O
vol	O
.	O
20	O
,	O
no	O
.	O
2	O
,	O
pp	O
.	O
414–425	O
,	O
2012	O
.	O
pp	O
.	O
464–471	O
.	O
[	O
8	O
]	O
a.	O
g.	O
adami	O
,	O
s.	O
s.	O
kajarekar	O
,	O
and	O
h.	O
hermansky	O
,	O
“	O
a	O
new	O
[	O
29	O
]	O
p.	O
kenny	O
and	O
p.	O
dumouchel	O
,	O
“	O
experiments	O
in	O
speaker	B
veriﬁcation	O
speaker	B
change	I
detection	B
method	B
for	O
two	O
-	O
speaker	B
segmenta-	O
using	O
factor	B
analysis	I
likelihood	B
ratios	O
,	O
”	O
in	O
odyssey	O
-	O
speaker	B
tion	O
,	O
”	O
in	O
icassp	O
,	O
vol	O
.	O
4	O
,	O
2002	O
,	O
pp	O
.	O
3908–3911	O
.	O
and	O
language	O
recognition	O
workshop	O
,	O
toledo	O
,	O
2004	O
,	O
pp	O
.	O
219–226	O
.	O
[	O
9	O
]	O
j.	O
ajmera	O
,	O
i.	O
mccowan	O
,	O
and	O
h.	O
bourlard	O
,	O
“	O
robust	B
speaker	I
[	O
30	O
]	O
p.	O
kenny	O
,	O
“	O
joint	O
factor	B
analysis	I
of	O
speaker	B
and	O
session	O
variabil-	O
change	B
detection	I
,	O
”	O
signal	B
processing	I
letters	O
,	O
ieee	O
,	O
vol	O
.	O
11	O
,	O
pp	O
.	O
ity	O
:	O
theory	O
and	O
algorithms	O
,	O
”	O
tech	O
.	O
rep	O
.	O
,	O
2006	O
.	O
649–651	O
,	O
2004	O
.	O
[	O
31	O
]	O
d.	O
garcia	O
-	O
romero	O
and	O
c.	O
y.	O
espy	O
-	O
wilson	O
,	O
“	O
analysis	B
of	O
i	O
-	O
vector	O
[	O
10	O
]	O
b.	O
fergani	O
,	O
m.	O
davy	O
,	O
and	O
a.	O
houacine	O
,	O
“	O
speaker	B
diarization	I
us-	O
length	B
normalization	O
in	O
speaker	B
recognition	O
systems	O
,	O
”	O
in	O
inter-	O
ing	O
one	O
-	O
class	O
support	O
vector	O
machines	O
,	O
”	O
speech	O
communica-	O
speech	O
,	O
florence	O
,	O
2011	O
,	O
pp	O
.	O
249–252	O
.	O
tion	O
,	O
vol	O
.	O
50	O
,	O
no	O
.	O
5	O
,	O
pp	O
.	O
355–365	O
,	O
2008	O
.	O
[	O
32	O
]	O
p.	O
kenny	O
,	O
p.	O
ouellet	O
,	O
n.	O
dehak	O
,	O
v.	O
gupta	O
,	O
and	O
p.	O
dumouchel	O
,	O
[	O
11	O
]	O
v.	O
gupta	O
,	O
“	O
speaker	B
change	I
point	B
detection	I
using	O
deep	O
neural	O
“	O
a	O
study	O
of	O
interspeaker	O
variability	O
in	O
speaker	B
veriﬁcation	O
,	O
”	O
nets	O
,	O
”	O
in	O
icassp	O
,	O
brisbane	O
,	O
2015	O
,	O
pp	O
.	O
4420–4424	O
.	O
ieee	O
transactions	O
on	O
audio	O
,	O
speech	O
,	O
and	O
language	B
processing	I
,	O
vol	O
.	O
16	O
,	O
no	O
.	O
5	O
,	O
pp	O
.	O
980–988	O
,	O
2008	O
.	O
[	O
12	O
]	O
r.	O
wang	O
,	O
m.	O
gu	O
,	O
l.	O
li	O
,	O
m.	O
xu	O
,	O
and	O
t.	O
f.	O
zheng	O
,	O
“	O
speaker	B
seg-	O
mentation	O
using	O
deep	O
speaker	B
vectors	O
for	O
fast	O
speaker	B
change	I
[	O
33	O
]	O
l.	O
machlica	O
and	O
z.	O
zaj´ıc	O
,	O
“	O
factor	B
analysis	I
and	O
nuisance	O
attribute	O
scenarios	O
,	O
”	O
in	O
icassp	O
,	O
new	O
orleans	O
,	O
2017	O
,	O
pp	O
.	O
5420–5424	O
.	O
projection	O
revisited	O
,	O
”	O
in	O
interspeech	O
,	O
portland	O
,	O
2012	O
,	O
pp	O
.	O
1570	O
–	O
1573	O
.	O
[	O
13	O
]	O
s.	O
furui	O
and	O
d.	O
itoh	O
,	O
“	O
neural	O
-	O
network	B
-	O
based	O
hmm	O
adaptation	O
for	O
noisy	O
speech	O
,	O
”	O
in	O
icassp	O
,	O
salt	O
lake	O
city	O
,	O
2001	O
,	O
pp	O
.	O
365–368	O
.	O
[	O
34	O
]	O
a.	O
canavan	O
,	O
d.	O
graff	O
,	O
and	O
g.	O
zipperlen	O
,	O
“	O
callhome	O
american	O
english	O
speech	O
,	O
ldc97s42	O
,	O
”	O
in	O
ldc	O
catalog	O
.	O
philadelphia	O
:	O
[	O
14	O
]	O
m.	O
hru´z	O
and	O
z.	O
zaj´ıc	O
,	O
“	O
convolutional	O
neural	B
network	I
for	O
linguistic	O
data	B
consortium	O
,	O
1997	O
.	O
speaker	B
change	I
detection	B
in	O
telephone	O
speaker	B
diarization	I
sys-	O
tem	O
,	O
”	O
in	O
icassp	O
,	O
new	O
orleans	O
,	O
2017	O
,	O
pp	O
.	O
4945–4949	O
.	O
[	O
35	O
]	O
z.	O
zaj´ıc	O
,	O
m.	O
kunesˇova	O
´	O
,	O
and	O
v.	O
radova	O
´	O
,	O
“	O
investigation	O
of	O
seg-	O
mentation	O
in	O
i	O
-	O
vector	O
based	B
speaker	I
diarization	B
of	O
telephone	O
[	O
15	O
]	O
j.	O
r.	O
hershey	O
,	O
z.	O
chen	O
,	O
j.	O
l.	O
roux	O
,	O
and	O
s.	O
watanabe	O
,	O
“	O
deep	O
clus-	O
speech	O
,	O
”	O
in	O
specom	O
.	O
budapest	O
:	O
springer	O
international	O
publish-	O
tering	O
:	O
discriminative	O
embeddings	O
for	O
segmentation	B
and	O
separa-	O
ing	O
,	O
2016	O
,	O
pp	O
.	O
411–418	O
.	O
tion	O
,	O
”	O
in	O
icassp	O
,	O
shanghai	O
,	O
2016	O
,	O
pp	O
.	O
31–35	O
.	O
[	O
36	O
]	O
s.	O
ioffe	O
and	O
c.	O
szegedy	O
,	O
“	O
batch	O
normalization	O
:	O
accelerating	O
[	O
16	O
]	O
r.	O
milner	O
and	O
t.	O
hain	O
,	O
“	O
dnn	O
-	O
based	B
speaker	I
clustering	B
for	O
deep	O
network	B
training	O
by	O
reducing	O
internal	O
covariate	O
shift	O
,	O
”	O
speaker	B
diarisation	O
,	O
”	O
in	O
interspeech	O
,	O
vol	O
.	O
08	O
-	O
12-sept	O
,	O
san	O
fran-	O
arxiv	O
,	O
vol	O
.	O
abs/1502.0	O
,	O
2015	O
.	O
cisco	O
,	O
2016	O
,	O
pp	O
.	O
2185–2189	O
.	O
[	O
37	O
]	O
a.	O
martin	O
and	O
m.	O
przybocki	O
,	O
“	O
2004	O
nist	O
speaker	B
recognition	O
[	O
17	O
]	O
g.	O
sell	O
,	O
d.	O
garcia	O
-	O
romero	O
,	O
and	O
a.	O
mccree	O
,	O
“	O
speaker	B
diariza-	O
evaluation	B
,	O
ldc2006s44	O
,	O
”	O
in	O
ldc	O
catalog	O
.	O
philadelphia	O
:	O
lin-	O
tion	O
with	O
i	O
-	O
vectors	O
from	O
dnn	O
senone	O
posteriors	O
,	O
”	O
in	O
interspeech	O
,	O
guistic	O
data	B
consortium	O
,	O
2011	O
.	O
dresden	O
,	O
2015	O
,	O
pp	O
.	O
3096–3099	O
.	O
[	O
38	O
]	O
nist	O
multimodal	O
information	B
group	O
,	O
“	O
2005	O
nist	O
speaker	B
[	O
18	O
]	O
s.	O
h.	O
yells	O
,	O
a.	O
stolcke	O
,	O
and	O
m.	O
slaney	O
,	O
“	O
artiﬁcial	O
neural	O
net-	O
recognition	O
evaluation	B
training	B
data	I
,	O
ldc2011s01	O
,	O
”	O
in	O
ldc	O
work	O
features	O
for	O
speaker	B
diarization	I
,	O
”	O
in	O
proc	O
.	O
ieee	O
spoken	O
catalog	O
.	O
philadelphia	O
:	O
linguistic	O
data	B
consortium	O
,	O
2011	O
.	O
language	O
technology	O
workshop	O
.	O
ieee	O
,	O
2014	O
,	O
pp	O
.	O
402–406	O
.	O
[	O
39	O
]	O
—	O
—	O
,	O
“	O
2006	O
nist	O
speaker	B
recognition	O
evaluation	B
training	O
set	B
,	O
[	O
19	O
]	O
n.	O
dawalatabad	O
,	O
s.	O
madikeri	O
,	O
c.	O
c.	O
sekhar	O
,	O
and	O
h.	O
a.	O
murthy	O
,	O
ldc2011s09	O
,	O
”	O
in	O
ldc	O
catalog	O
,	O
2011	O
.	O
“	O
two	O
-	O
pass	O
ib	O
based	B
speaker	I
diarization	B
system	O
using	O
meeting-	O
speciﬁc	O
ann	O
based	O
features	O
,	O
”	O
in	O
interspeech	O
,	O
san	O
francisco	O
,	O
[	O
40	O
]	O
d.	O
graff	O
,	O
d.	O
miller	O
,	O
and	O
k.	O
walker	O
,	O
“	O
switchboard-2	O
phase	O
iii	O
au-	O
2016	O
,	O
pp	O
.	O
2199–2203	O
.	O
dio	O
,	O
”	O
in	O
ldc	O
catalog	O
.	O
philadelphia	O
:	O
linguistic	O
data	B
consortium	O
,	O
1999	O
.	O
[	O
20	O
]	O
d.	O
garcia	O
-	O
romero	O
,	O
d.	O
snyder	O
,	O
g.	O
sell	O
,	O
d.	O
povey	O
,	O
and	O
a.	O
mccree	O
,	O
“	O
speaker	B
diarization	I
using	O
deep	O
neural	B
network	I
embedings	O
,	O
”	O
[	O
41	O
]	O
d.	O
graff	O
,	O
k.	O
walker	O
,	O
and	O
a.	O
canavan	O
,	O
“	O
switchboard-2	O
phase	O
ii	O
,	O
in	O
icassp	O
,	O
new	O
orleans	O
,	O
2017	O
,	O
pp	O
.	O
4930	O
–	O
4934	O
.	O
ldc99s79	O
,	O
”	O
in	O
ldc	O
catalog	O
.	O
philadelphia	O
:	O
linguistic	O
data	B
consortium	O
,	O
2002	O
.	O
[	O
21	O
]	O
h.	O
bredin	O
,	O
“	O
tristounet	O
:	O
triplet	O
loss	O
for	O
speaker	B
turn	O
embed-	O
ding	O
,	O
”	O
in	O
icassp	O
,	O
new	O
orleans	O
,	O
2017	O
,	O
pp	O
.	O
5430–5434	O
.	O
[	O
42	O
]	O
j.	O
g.	O
fiscus	O
,	O
n.	O
radde	O
,	O
j.	O
s.	O
garofolo	O
,	O
a.	O
le	O
,	O
j.	O
ajot	O
,	O
and	O
c.	O
laprun	O
,	O
“	O
the	O
rich	B
transcription	I
2006	O
spring	O
meeting	O
recog-	O
[	O
22	O
]	O
m.	O
hru´z	O
and	O
m.	O
kunesˇova	O
´	O
,	O
“	O
convolutional	O
neural	B
network	I
in	O
nition	O
evaluation	B
,	O
”	O
machine	O
learning	O
for	O
multimodal	O
interaction	O
,	O
the	O
task	O
of	O
speaker	B
change	I
detection	B
,	O
”	O
in	O
specom	O
.	O
budapest	O
:	O
vol	O
.	O
4299	O
,	O
pp	O
.	O
309–322	O
,	O
2006	O
.	O
springer	O
international	O
publishing	O
,	O
2016	O
,	O
pp	O
.	O
191–198	O
.	O
[	O
23	O
]	O
y.	O
lecun	O
,	O
b.	O
boser	O
,	O
j.	O
s.	O
denker	O
,	O
d.	O
henderson	O
,	O
r.	O
e.	O
howard	O
,	O
w.	O
hubbard	O
,	O
and	O
l.	O
d.	O
jackel	O
,	O
“	O
backpropagation	O
applied	O
to	O
handwritten	O
zip	O
code	O
recognition	O
,	O
”	O
neural	O
computation	O
,	O
vol	O
.	O
1	O
,	O
no	O
.	O
4	O
,	O
pp	O
.	O
541–551	O
,	O
1989	O
.	O
[	O
24	O
]	O
a.	O
krizhevsky	O
,	O
i.	O
sutskever	O
,	O
and	O
g.	O
e.	O
hinton	O
,	O
“	O
imagenet	O
classi-	O
ﬁcation	O
with	O
deep	O
convolutional	O
neural	B
networks	I
,	O
”	O
in	O
advances	O
in	O
neural	O
information	B
processing	B
systems	O
,	O
2012	O
,	O
pp	O
.	O
1106–1114	O
.	O
[	O
25	O
]	O
n.	O
dehak	O
,	O
p.	O
j.	O
kenny	O
,	O
r.	O
dehak	O
,	O
p.	O
dumouchel	O
,	O
and	O
p.	O
ouel-	O
let	O
,	O
“	O
front	O
-	O
end	O
factor	B
analysis	I
for	O
speaker	B
veriﬁcation	O
,	O
”	O
ieee	O
transactions	O
on	O
audio	O
,	O
speech	O
,	O
and	O
language	B
processing	I
,	O
vol	O
.	O
19	O
,	O
no	O
.	O
4	O
,	O
pp	O
.	O
788–798	O
,	O
2011	O

the	O
second	O
dihard	O
diarization	B
challenge	B
:	O
dataset	O
,	O
task	O
,	O
and	O
baselines	O
neville	O
ryant1	O
,	O
kenneth	O
church2	O
,	O
christopher	O
cieri1	O
,	O
alejandrina	O
cristia3	O
,	O
jun	O
du4	O
,	O
sriram	O
ganapathy5	O
,	O
mark	O
liberman1	O
1linguistic	O
data	B
consortium	O
,	O
university	O
of	O
pennsylvania	O
,	O
philadelphia	O
,	O
pa	O
,	O
usa	O
2baidu	O
research	B
,	O
sunnyvale	O
,	O
ca	O
,	O
usa	O
3laboratoire	O
de	O
sciences	O
cognitives	O
et	O
de	O
psycholinguistique	O
,	O
de´pt	O
d’e´tudes	O
cognitives	O
,	O
ens	O
,	O
ehess	O
,	O
cnrs	O
,	O
psl	O
university	O
,	O
paris	O
,	O
france	O
4university	O
of	O
science	O
and	O
technology	O
of	O
china	O
,	O
hefei	O
,	O
china	O
5electrical	O
engineering	O
department	O
,	O
indian	O
institute	O
of	O
science	O
,	O
bangalore	O
,	O
india	O
nryant@ldc.upenn.edu	O
9	O
1	O
0	O
abstract	O
backchannels	O
and	O
overlapping	B
speech	I
are	O
both	O
common	O
in	O
con-	O
2	O
versation	O
,	O
this	O
may	O
have	O
resulted	O
in	O
an	O
over	O
-	O
optimistic	O
assess-	O
n	O
 	O
this	O
paper	O
introduces	O
the	O
second	O
dihard	B
challenge	I
,	O
the	O
sec-	O
ment	O
of	O
performance	O
even	O
within	O
these	O
domains1	O
[	O
11	O
]	O
.	O
ond	O
in	O
a	O
series	O
of	O
speaker	B
diarization	I
challenges	B
intended	O
to	O
u	O
it	O
is	O
against	O
this	O
backdrop	O
that	O
the	O
jsalt-2017	O
workshop	O
improve	O
the	O
robustness	O
of	O
diarization	B
systems	I
to	O
variation	O
in	O
j	O
[	O
12	O
]	O
and	O
dihard	O
challenges2	O
emerged	O
.	O
the	O
dihard	O
series	O
  	O
recording	B
equipment	O
,	O
noise	O
conditions	O
,	O
and	O
conversational	O
do-	O
8	O
of	O
challenges	B
introduce	O
a	O
new	O
common	O
task	O
for	O
diarization	B
that	O
main	O
.	O
the	O
challenge	B
comprises	O
four	O
tracks	B
evaluating	O
diariza-	O
1	O
is	O
intended	O
both	O
to	O
facilitate	O
comparison	O
of	O
current	O
and	O
future	O
tion	O
performance	O
under	O
two	O
input	B
conditions	O
(	O
single	B
channel	I
  	O
systems	O
through	O
standardized	O
data	B
,	O
tasks	O
,	O
and	O
metrics	O
and	O
pro-	O
  	O
vs.	O
multi	O
-	O
channel	O
)	O
and	O
two	O
segmentation	B
conditions	O
(	O
diariza-	O
]	O
mote	O
work	O
on	O
robust	O
diarization	B
systems	I
;	O
that	O
is	O
systems	O
,	O
that	O
s	O
tion	O
from	O
a	O
reference	B
speech	O
segmentation	B
vs.	O
diarization	B
from	O
are	O
able	O
to	O
accurately	O
handle	O
highly	O
interactive	O
and	O
overlapping	B
a	O
scratch	O
)	O
.	O
in	O
order	B
to	O
prevent	O
participants	B
from	O
overtuning	O
to	O
a	O
speech	O
from	O
a	O
range	O
of	O
conversational	O
domains	O
,	O
while	O
being	O
re-	O
particular	O
combination	O
of	O
recording	B
conditions	O
and	O
conversa-	O
.	O
silient	O
to	O
variation	O
in	O
recording	B
equipment	O
,	O
recording	B
environ-	O
s	O
tional	O
domain	B
,	O
recordings	O
are	O
drawn	O
from	O
a	O
variety	O
of	O
sources	O
ment	O
,	O
reverberation	O
,	O
ambient	O
noise	O
,	O
number	O
of	O
speakers	O
,	O
and	O
s	O
ranging	O
from	O
read	O
audiobooks	O
to	O
meeting	O
speech	O
,	O
to	O
child	O
lan-	O
e	O
speaker	B
demographics	O
.	O
as	O
with	O
the	O
nist	O
rt	O
evaluations	O
,	O
der	O
guage	O
acquisition	O
recordings	O
,	O
to	O
dinner	O
parties	O
,	O
to	O
web	O
video	O
.	O
e	O
is	O
adopted	O
as	O
the	O
primary	O
evaluation	B
metric	B
,	O
but	O
without	O
use	O
of	O
we	O
describe	O
the	O
task	O
and	O
metrics	O
,	O
challenge	B
design	O
,	O
datasets	B
,	O
[	O
collars	O
or	O
exclusion	O
of	O
overlapping	B
speech	I
.	O
there	O
are	O
no	O
con-	O
  	O
and	O
baseline	B
systems	O
for	O
speech	O
enhancement	O
,	O
speech	B
activity	I
  	O
straints	O
on	O
training	B
data	I
,	O
with	O
participants	B
allowed	O
to	O
use	O
any	O
1	O
detection	B
,	O
and	O
diarization	B
.	O
combination	O
of	O
public	O
/	O
proprietary	O
data	B
for	O
system	O
development	O
.	O
v	O
index	O
terms	B
:	O
speaker	B
diarization	I
,	O
speaker	B
recognition	O
,	O
robust	O
the	O
initial	O
dihard	B
challenge	I
(	O
dihard	O
i	O
)	O
[	O
13	O
]	O
ran	O
during	O
9	O
asr	B
,	O
noise	O
,	O
conversational	O
speech	O
,	O
dihard	B
challenge	I
the	O
spring	O
of	O
2018	O
and	O
attracted	O
registrations	O
from	O
20	O
teams	O
,	O
of	O
3	O
8	O
1	O
.	O
introduction	O
which	O
13	O
submitted	O
systems	O
.	O
as	O
expected	O
,	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
sys-	O
7	O
tems	O
performed	O
poorly	O
,	O
with	O
ﬁnal	O
der	O
on	O
the	O
evaluation	B
set	I
for	O
0	O
speaker	B
diarization	I
,	O
often	O
referred	O
to	O
as	O
“	O
who	O
spoke	O
when	O
”	O
,	O
the	O
top	O
systems	O
ranging	O
from	O
23.73	O
%	O
[	O
14	O
]	O
when	O
provided	O
with	O
.	O
is	O
the	O
task	O
of	O
determining	O
how	O
many	O
speakers	O
are	O
present	O
in	O
reference	B
speech	B
activity	I
detection	I
(	O
sad	O
)	O
marks	O
to	O
35.51	O
%	O
[	O
15	O
]	O
6	O
when	O
forced	O
to	O
perform	O
diarization	B
from	O
scratch	O
.	O
these	O
error	O
a	O
conversation	O
and	O
correctly	O
identifying	O
all	O
segments	O
for	O
each	O
0	O
rates	B
rates	B
are	O
more	O
than	O
double	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
for	O
call-	O
9	O
speaker	B
.	O
in	O
addition	O
to	O
being	O
an	O
interesting	O
technical	O
chal-	O
1	O
lenge	O
,	O
it	O
forms	O
an	O
important	O
part	O
of	O
the	O
pre	O
-	O
processing	B
pipeline	O
home	O
[	O
16	O
]	O
at	O
the	O
time	B
[	O
4	O
,	O
5	O
]	O
.	O
for	O
some	O
domains	O
,	O
error	B
rates	I
:	O
for	O
speech	O
-	O
to	O
-	O
text	O
and	O
is	O
essential	O
for	O
making	O
objective	O
mea-	O
for	O
the	O
best	O
systems	O
exceeded	O
49	O
%	O
when	O
using	O
reference	B
sad	O
v	O
surements	O
of	O
turn	O
-	O
taking	O
behavior	O
.	O
early	O
work	O
in	O
this	O
area	O
and	O
75	O
%	O
when	O
performing	O
diarization	B
from	O
scratch	O
!	O
xi	O
was	O
driven	O
by	O
the	O
nist	O
rich	B
transcription	I
(	O
rt	O
)	O
evaluations	O
the	O
second	O
dihard	B
challenge	I
(	O
dihard	O
ii	O
)	O
[	O
17	O
]	O
,	O
like	O
[	O
1	O
]	O
,	O
which	O
ran	O
between	O
2002	O
and	O
2009	O
.	O
in	O
addition	O
to	O
driving	O
its	O
predecessor	O
,	O
examines	O
diarization	B
system	O
performance	O
un-	O
ar	O
substantial	O
performance	O
improvements	B
,	O
especially	O
for	O
meeting	O
der	O
two	O
sad	O
conditions	O
:	O
diarization	B
from	O
a	O
supplied	O
refer-	O
speech	O
,	O
the	O
rt	O
evaluations	O
introduced	O
the	O
diarization	B
error	I
rate	I
ence	O
sad	O
and	O
diarization	B
from	O
scratch	O
.	O
as	O
with	O
dihard	O
i	O
,	O
(	O
der	O
)	O
metric	B
,	O
which	O
remains	O
the	O
principal	O
evaluation	B
metric	B
in	O
it	O
includes	O
a	O
single	B
channel	I
input	B
condition	B
utilizing	O
wideband	O
this	O
area	O
.	O
since	O
the	O
rt	O
evaluation	B
series	O
ended	O
in	O
2009	O
,	O
diariza-	O
speech	O
sampled	O
from	O
11	O
demanding	O
domains	O
,	O
ranging	O
from	O
tion	O
performance	O
has	O
continued	O
to	O
improve	O
,	O
though	O
the	O
lack	O
clean	O
,	O
nearﬁeld	O
recordings	O
of	O
read	O
audiobooks	O
to	O
extremely	O
of	O
a	O
common	O
task	O
has	O
resulted	O
in	O
fragmentation	O
with	O
individ-	O
noisy	O
,	O
highly	O
interactive	O
,	O
farﬁeld	O
recordings	O
of	O
speech	O
in	O
restau-	O
ual	O
research	B
groups	O
focusing	O
on	O
different	O
datasets	B
or	O
domains	O
rants	O
to	O
child	O
language	O
data	B
recorded	O
in	O
the	O
home	O
using	O
lena	O
(	O
e.g.	O
,	O
conversational	O
telephone	B
speech	I
[	O
2	O
,	O
3	O
,	O
4	O
,	O
5	O
,	O
6	O
]	O
,	O
broadcast	O
vests	O
.	O
unlike	O
dihard	O
i	O
,	O
it	O
additionally	O
offers	O
a	O
multichan-	O
[	O
7	O
,	O
8	O
]	O
,	O
or	O
meeting	O
[	O
9	O
,	O
10	O
]	O
)	O
.	O
at	O
best	O
,	O
this	O
has	O
made	O
comparing	O
nel	O
input	B
condition	B
requiring	O
participants	B
to	O
perform	O
diarization	B
performance	O
difﬁcult	O
,	O
while	O
at	O
worst	O
it	O
may	O
have	O
engendered	O
from	O
farﬁeld	O
microphone	O
arrays	O
of	O
dinner	O
party	O
speech	O
drawn	O
overﬁtting	O
to	O
individual	O
domains	O
/	O
datasets	B
resulting	O
in	O
systems	O
1see	O
,	O
for	O
instance	O
,	O
the	O
release	O
of	O
ibm	O
’s	O
diarization	B
api	O
in	O
2017	O
.	O
that	O
do	O
not	O
generalize	O
.	O
moreover	O
,	O
the	O
majority	O
of	O
this	O
work	O
has	O
the	O
feature	O
worked	O
well	O
for	O
simple	O
cases	O
,	O
but	O
when	O
run	O
by	O
users	O
on	O
evaluated	O
systems	O
using	O
a	O
modiﬁed	O
version	O
of	O
der	O
in	O
which	O
real	O
inputs	O
,	O
the	O
performance	O
was	O
found	O
to	O
be	O
lacking	O
,	O
especially	O
for	O
speech	O
within	O
250	O
ms	O
of	O
reference	B
boundaries	B
and	O
overlapped	O
overlaps	B
,	O
back	O
-	O
channels	B
,	O
and	O
short	O
turns	O
.	O
speech	O
are	O
excluded	O
from	O
scoring	O
.	O
as	O
short	O
segments	O
such	O
as	O
2https://coml.lscp.ens.fr/dihard/index.htmlfrom	O
the	O
chime-5	O
corpus	B
[	O
18	O
]	O
.	O
for	O
the	O
ﬁrst	O
time	B
,	O
we	O
also	O
table	O
1	O
:	O
overview	O
of	O
dihard	O
ii	O
datasets	B
.	O
for	O
the	O
chime-	O
provide	O
participants	B
with	O
baseline	B
systems	O
for	O
speech	O
enhance-	O
5	O
(	O
multichannel	B
)	O
data	B
,	O
each	O
kinect	O
is	O
treated	O
as	O
a	O
separate	O
ment	O
,	O
sad	O
,	O
and	O
diarization	B
,	O
as	O
well	O
as	O
results	B
obtained	O
with	O
recording	B
.	O
these	O
systems	O
for	O
all	O
tracks	B
.	O
input	B
condition	B
set	B
duration	O
(	O
hours	B
)	O
#	O
recordings	O
2	O
.	O
tracks	B
single	B
channel	I
dev	O
23.81	O
192	O
eval	O
22.49	O
194	O
the	O
challenge	B
features	O
two	O
audio	O
input	B
conditions	O
:	O
dev	O
262.41	O
105	O
multichannel	B
eval	O
31.24	O
12	O
•	O
single	B
channel	I
–	O
systems	O
are	O
provided	O
with	O
a	O
single	B
channel	I
of	O
audio	O
for	O
each	O
recording	B
.	O
depending	O
on	O
the	O
recording	B
source	B
,	O
this	O
channel	O
may	O
be	O
taken	O
from	O
a	O
sin-	O
gle	O
distant	O
microphone	O
,	O
a	O
single	B
channel	I
from	O
a	O
distant	O
speaker	B
is	O
paired	O
with	O
a	O
system	B
speaker	I
with	O
an	O
identical	O
seg-	O
microphone	O
array	O
,	O
a	O
mix	O
of	O
head	O
-	O
mounted	O
or	O
array	O
mi-	O
mentation	O
to	O
100	O
%	O
in	O
the	O
case	O
where	O
none	O
of	O
the	O
system	O
speak-	O
crophones	O
,	O
or	O
a	O
mix	O
of	O
binaural	O
microphones	O
.	O
ers	O
overlap	O
any	O
of	O
the	O
reference	B
speakers	O
.	O
•	O
multichannel	B
–	O
each	O
recording	B
session	O
contains	O
output	B
fa	O
+	O
miss	B
from	O
one	O
or	O
more	O
distant	O
microphone	O
arrays	O
,	O
each	O
con-	O
jerref	O
=	O
total	O
(	O
1	O
)	O
taining	O
multiple	O
channels	B
.	O
participants	B
are	O
instructed	O
to	O
treat	O
the	O
arrays	O
separately	O
,	O
producing	O
one	O
output	B
per	O
ar-	O
all	O
metrics	O
are	O
computed	O
using	O
version	O
1.0.1	O
of	O
the	O
dscore	O
ray	O
.	O
they	O
are	O
free	O
to	O
use	O
as	O
few	O
or	O
as	O
many	O
of	O
the	O
chan-	O
tool3	O
without	O
the	O
use	O
of	O
forgiveness	O
collars	O
and	O
with	O
scoring	O
of	O
nels	O
on	O
each	O
array	O
as	O
they	O
wish	O
to	O
perform	O
diarization	B
.	O
overlapped	B
speech	I
.	O
as	O
system	O
performance	O
is	O
strongly	O
tied	O
to	O
the	O
quality	B
of	O
the	O
4	O
.	O
datasets	B
sad	O
component	O
,	O
we	O
also	O
include	O
two	O
sad	O
conditions	O
:	O
•	O
reference	B
sad	O
–	O
systems	O
are	O
provided	O
with	O
a	O
refer-	O
4.1	O
.	O
overview	O
ence	O
speech	O
segmentation	B
that	O
is	O
generated	O
by	O
merging	O
the	O
dihard	O
ii	O
development	O
and	O
evaluation	B
sets	O
draw	O
from	O
speaker	B
turns	O
in	O
the	O
reference	B
diarization	B
.	O
a	O
diverse	O
set	B
of	O
sources	O
exhibiting	O
wide	O
variation	O
in	O
recording	B
•	O
system	O
sad	O
–	O
systems	O
are	O
provided	O
with	O
just	O
the	O
raw	O
equipment	O
,	O
recording	B
environment	O
,	O
ambient	O
noise	O
,	O
number	O
of	O
audio	O
input	B
for	O
each	O
recording	B
session	O
and	O
are	O
responsi-	O
speakers	O
,	O
and	O
speaker	B
demographics	O
.	O
the	O
single	B
channel	I
input	B
ble	O
for	O
producing	O
their	O
own	O
speech	O
segmentation	B
.	O
condition	B
(	O
tracks	B
1	O
and	O
2	O
)	O
dataset	O
is	O
a	O
superset	O
of	O
that	O
used	O
in	O
dihard	O
i	O
,	O
though	O
6	O
hours	B
of	O
additional	O
material	O
have	O
been	O
together	O
,	O
this	O
yields	O
the	O
following	O
four	O
evaluation	B
tracks	B
:	O
added	O
to	O
ensure	O
that	O
all	O
domains	O
are	O
represented	O
in	O
both	O
the	O
de-	O
•	O
track	O
1	O
–	O
single	B
channel	I
audio	O
using	O
reference	B
sad	O
velopment	O
and	O
evaluation	B
set	I
.	O
additionally	O
,	O
two	O
domains	O
where	O
•	O
track	O
2	O
–	O
single	B
channel	I
audio	O
using	O
system	O
sad	O
the	O
dihard	O
i	O
annotation	O
was	O
deemed	O
suspect	O
(	O
child	O
language	O
and	O
web	O
video	O
)	O
have	O
been	O
entirely	O
resegmented	O
.	O
for	O
the	O
multi-	O
•	O
track	O
3	O
–	O
multichannel	B
audio	O
using	O
reference	B
sad	O
channel	O
input	B
condition	B
(	O
tracks	B
3	O
and	O
4	O
)	O
we	O
use	O
the	O
multi	O
-	O
party	O
•	O
track	O
4	O
–	O
multichannel	B
audio	O
using	O
system	O
sad	O
dinner	O
recordings	O
originally	O
collected	O
for	O
and	O
exposed	O
during	O
the	O
chime-5	O
challenge	B
[	O
18	O
]	O
.	O
the	O
development	O
and	O
evaluation	B
all	O
teams	O
are	O
required	O
to	O
register	O
for	O
at	O
least	O
one	O
of	O
track	O
1	O
or	O
sets	O
are	O
summarized	O
in	O
table	O
1	O
.	O
track	O
3	O
.	O
the	O
development	B
set	I
includes	O
reference	B
diarization	B
and	O
speech	O
segmentation	B
and	O
may	O
be	O
used	O
for	O
any	O
purpose	O
includ-	O
3	O
.	O
performance	O
metrics	O
ing	O
system	O
development	O
or	O
training	O
.	O
as	O
with	O
dihard	O
i	O
,	O
there	O
as	O
in	O
dihard	O
i	O
,	O
the	O
primary	O
metric	B
is	O
der	O
[	O
1	O
]	O
,	O
which	O
is	O
the	O
is	O
no	O
training	O
set	B
,	O
with	O
participants	B
free	O
to	O
train	O
their	O
systems	O
on	O
sum	O
of	O
missed	O
speech	O
,	O
false	B
alarm	I
speech	O
,	O
and	O
speaker	B
mis-	O
any	O
proprietary	O
and/or	O
public	O
data	B
.	O
both	O
the	O
development	O
and	O
classiﬁcation	O
error	B
rates	I
.	O
because	O
systems	O
are	O
provided	O
with	O
evaluation	B
sets	O
will	O
be	O
submitted	O
for	O
publication	O
via	O
ldc	O
at	O
the	O
the	O
reference	B
speech	O
segmentation	B
for	O
tracks	B
1	O
and	O
3	O
,	O
for	O
these	O
end	O
of	O
the	O
evaluation	B
.	O
tracks	B
,	O
it	O
exclusively	O
measures	O
speaker	B
misclassiﬁcation	O
error	O
.	O
this	O
is	O
the	O
metric	B
used	O
to	O
rank	O
systems	O
on	O
the	O
leaderboard	O
.	O
4.2	O
.	O
single	B
channel	I
data	B
(	O
tracks	B
1	O
and	O
2	O
)	O
for	O
each	O
system	O
we	O
also	O
compute	O
a	O
secondary	O
metric	B
,	O
jac-	O
the	O
single	B
channel	I
input	B
condition	B
development	O
and	O
evaluation	B
card	O
error	B
rate	I
(	O
jer	O
)	O
,	O
which	O
is	O
newly	O
developed	O
for	O
dihard	O
sets	O
consist	O
of	O
selections	O
of	O
5	O
-	O
10	O
minute	O
duration	O
samples	O
drawn	O
ii	O
.	O
jer	O
is	O
based	O
on	O
the	O
jaccard	O
similarity	B
index	O
[	O
19	O
,	O
20	O
]	O
,	O
a	O
met-	O
from	O
11	O
conversational	O
domains	O
,	O
each	O
including	O
approximately	O
ric	O
commonly	O
used	O
to	O
evaluate	O
the	O
output	B
of	O
image	O
segmenta-	O
2	O
hours	B
of	O
audio	O
.	O
the	O
full	O
set	B
of	O
domains	O
is	O
described	O
below	O
tion	O
systems	O
,	O
which	O
is	O
deﬁned	O
as	O
the	O
ratio	O
between	O
the	O
sizes	O
of	O
with	O
ldc	O
catalog	O
numbers	O
where	O
appropriate	O
.	O
unless	O
other-	O
the	O
intersections	O
and	O
unions	O
of	O
two	O
sets	O
of	O
segments	O
.	O
an	O
opti-	O
wise	O
speciﬁed	O
,	O
all	O
speech	O
is	O
english	O
,	O
though	O
not	O
necessarily	O
by	O
mal	O
mapping	O
between	O
speakers	O
in	O
the	O
reference	B
diarization	B
and	O
native	O
or	O
even	O
ﬂuent	O
speakers	O
.	O
all	O
audio	O
is	O
distributed	O
via	O
ldc	O
speakers	O
in	O
the	O
system	O
diarization	B
is	O
determined	O
and	O
for	O
each	O
as	O
16	O
khz	O
,	O
monochannel	O
flac	O
ﬁles	O
.	O
pair	O
the	O
jaccard	O
index	O
of	O
their	O
segmentations	O
is	O
computed	O
.	O
jer	O
is	O
deﬁned	O
as	O
1	O
minus	O
the	O
average	B
of	O
these	O
scores	O
,	O
expressed	O
as	O
•	O
audiobooks	O
–	O
amateur	O
recordings	O
of	O
public	O
domain	B
en-	O
a	O
percentage	B
.	O
that	O
is	O
,	O
it	O
is	O
the	O
mean	O
of	O
eq	O
.	O
1	O
across	O
all	O
refer-	O
glish	O
works	O
drawn	O
from	O
librivox	O
;	O
care	O
was	O
taken	O
to	O
ence	O
speakers	O
ref	O
,	O
where	O
total	O
is	O
the	O
duration	O
of	O
the	O
union	O
of	O
avoid	O
overlap	O
with	O
librispeech	O
[	O
21	O
]	O
(	O
unpublished	O
)	O
reference	B
and	O
system	B
speaker	I
segments	O
,	O
fa	O
is	O
the	O
total	O
system	O
•	O
broadcast	O
interview	O
–	O
student	O
produced	O
interviews	O
with	O
speaker	B
time	I
not	O
attributed	O
to	O
the	O
reference	B
speaker	I
,	O
and	O
miss	B
newsmakers	O
of	O
the	O
day	O
taken	O
from	O
a	O
late	O
1970s	O
college	O
is	O
the	O
total	O
reference	B
speaker	I
time	B
not	O
attributed	O
to	O
the	O
system	B
speaker	I
.	O
it	O
ranges	O
from	O
0	O
%	O
in	O
the	O
case	O
where	O
each	O
reference	B
3https://github.com/nryant/dscoreradio	O
show	O
;	O
recorded	O
on	O
open	O
reel	O
tapes	O
before	O
being	O
dinner	O
parties	O
from	O
18	O
homes	O
.	O
the	O
evaluation	B
set	I
is	O
identical	O
digitized	O
and	O
contributed	O
to	O
ldc	O
(	O
unpublished	O
)	O
to	O
the	O
chime-5	O
evaluation	B
set	I
and	O
consists	O
of	O
5	O
hours	B
of	O
din-	O
•	O
child	O
language	O
–	O
day	O
-	O
long	O
recordings	O
of	O
6	O
-	O
18	O
month	O
ner	O
parties	O
from	O
2	O
homes	O
.	O
each	O
party	O
was	O
recorded	O
using	O
6	O
old	O
vocalizations	O
collected	O
at	O
home	O
by	O
university	O
of	O
microsoft	O
kinect	O
devices	O
(	O
4	O
channel	O
linear	O
arrays	O
)	O
distributed	O
rochester	O
researchers	O
for	O
the	O
seedlings	O
corpus	B
[	O
22	O
]	O
throughout	O
the	O
home	O
in	O
such	O
a	O
way	O
that	O
the	O
conversation	O
was	O
al-	O
ways	O
present	O
on	O
each	O
array	O
.	O
due	O
to	O
a	O
combination	O
of	O
clock	O
drift	O
•	O
clinical	O
–	O
interviews	O
with	O
12	O
-	O
16	O
year	O
old	O
children	O
in-	O
and	O
random	O
frame	B
dropping	O
,	O
the	O
kinects	O
within	O
each	O
record-	O
tended	O
to	O
determine	O
whether	O
or	O
not	O
they	O
ﬁt	O
the	O
clinical	O
di-	O
ing	O
session	O
exhibit	O
massive	O
desynchronization	O
,	O
both	O
with	O
each	O
agnosis	O
for	O
autism	O
;	O
all	O
recordings	O
conducted	O
at	O
the	O
cen-	O
other	O
and	O
with	O
the	O
binaural	O
recording	B
devices	O
worn	O
by	O
partici-	O
ter	O
for	O
autism	O
research	B
(	O
car	O
)	O
of	O
the	O
childrens	O
hospital	O
pants	O
.	O
for	O
this	O
reason	O
,	O
each	O
kinect	O
device	O
is	O
treated	O
separately	O
of	O
philadelphia	O
(	O
chop	O
)	O
using	O
a	O
mixture	O
of	O
cameras	O
and	O
with	O
the	O
resulting	O
development	O
and	O
evaluation	B
sets	O
having	O
du-	O
ceiling	O
mounted	O
microphones	O
(	O
unpublished	O
)	O
rations	O
of	O
262.4	O
hours	B
and	O
31.2	O
hours	B
respectively	O
.	O
all	O
audio	O
is	O
•	O
courtroom	O
–	O
oral	O
arguments	O
from	O
the	O
2001	O
term	O
of	O
the	O
distributed	O
via	O
the	O
university	O
of	O
shefﬁeld	O
as	O
16	O
khz	O
wav	O
ﬁles	O
.	O
u.s	O
.	O
supreme	O
court	O
that	O
were	O
digitized	O
for	O
the	O
oyez	O
project	O
;	O
recordings	O
are	O
summed	O
from	O
individual	O
table-	O
4.4	O
.	O
processing	B
mounted	O
microphones	O
,	O
one	O
per	O
speaker	B
(	O
unpublished	O
)	O
a	O
limited	O
number	O
of	O
recordings	O
contained	O
regions	O
carrying	O
per-	O
•	O
map	O
task	O
–	O
recordings	O
of	O
map	O
tasks	O
in	O
which	O
one	O
par-	O
sonal	O
identifying	O
information	B
(	O
pii	O
)	O
,	O
which	O
were	O
removed	O
prior	O
ticipant	O
,	O
the	O
leader	O
,	O
describes	O
a	O
route	O
drawn	O
on	O
a	O
map	O
to	O
publication	O
.	O
for	O
the	O
clinical	O
and	O
restaurant	O
domains	O
,	O
this	O
to	O
the	O
other	O
participant	O
,	O
the	O
follower	O
,	O
who	O
attempts	O
to	O
was	O
done	O
at	O
ldc	O
by	O
low	O
-	O
pass	O
ﬁltering	O
using	O
a	O
10th	O
order	B
but-	O
draw	O
the	O
same	O
route	O
on	O
a	O
copy	O
of	O
the	O
map	O
lacking	O
the	O
terworth	O
ﬁlter	O
with	O
a	O
passband	O
of	O
0	O
to	O
400	O
hz	O
.	O
to	O
avoid	O
abrupt	O
route	O
and	O
optionally	O
lacking	O
some	O
landmarks	O
;	O
audio	O
was	O
transitions	O
in	O
the	O
resulting	O
waveform	O
,	O
the	O
effect	O
of	O
the	O
ﬁlter	O
was	O
recorded	O
via	O
close	O
-	O
talking	O
microphones	O
under	O
quiet	O
con-	O
gradually	O
faded	O
in	O
and	O
out	O
at	O
the	O
beginning	O
and	O
end	O
of	O
the	O
re-	O
ditions	O
(	O
previously	O
released	O
as	O
ldc96s38	O
)	O
gions	O
using	O
a	O
ramp	O
of	O
40	O
ms	O
.	O
in	O
the	O
case	O
of	O
the	O
sociolinguis-	O
•	O
meeting	O
–	O
meetings	O
with	O
between	O
3	O
and	O
7	O
participants	B
,	O
tic	O
ﬁeld	O
recordings	O
domain	B
and	O
the	O
chime-5	O
data	B
,	O
pii	O
was	O
re-	O
each	O
recorded	O
with	O
a	O
variety	O
of	O
close	O
-	O
talking	O
and	O
distant	O
moved	O
by	O
the	O
original	O
creators	O
of	O
the	O
corpora	B
.	O
in	O
the	O
former	O
microphones	O
,	O
from	O
which	O
a	O
single	O
,	O
centrally	O
located	O
dis-	O
case	O
,	O
pii	O
was	O
replaced	O
by	O
tones	O
of	O
matched	O
duration	O
,	O
while	O
in	O
tant	O
microphone	O
was	O
selected	O
;	O
the	O
development	B
set	I
draws	O
the	O
latter	O
case	O
it	O
was	O
zeroed	O
out	O
.	O
pii	O
containing	O
regions	O
are	O
ig-	O
from	O
the	O
nist	O
spring	O
2004	O
rich	B
transcription	I
evalua-	O
nored	O
during	O
scoring	O
.	O
tion	O
(	O
ldc2007s11	O
and	O
ldc2007s12	O
)	O
while	O
the	O
evalu-	O
ation	O
set	B
draws	O
from	O
previously	O
upublished	O
recordings	O
4.5	O
.	O
annotation	O
conducted	O
for	O
the	O
darpa	O
robust	O
omnipresent	O
auto-	O
matic	O
recognition	O
(	O
roar	O
)	O
project	O
at	O
ldc	O
in	O
2001	O
reference	B
segmentation	B
and	O
speaker	B
labeling	O
was	O
produced	O
by	O
•	O
restaurant	O
–	O
≈1	O
hour	O
sessions	O
involving	O
3	O
-	O
6	O
diners	O
annotators	O
at	O
ldc	O
using	O
a	O
tool	O
equipped	O
with	O
playback	O
,	O
wave-	O
form	O
and	O
spectrogram	O
display	O
.	O
annotators	O
were	O
instructed	O
to	O
recorded	O
on	O
a	O
binaural	O
microphone	O
worn	O
by	O
one	O
partici-	O
split	O
on	O
pauses	O
>	O
200	O
ms	O
,	O
where	O
a	O
pause	O
was	O
deﬁned	O
as	O
any	O
pant	O
in	O
restaurants	O
with	O
varying	O
room	O
acoustics	B
and	O
noise	O
stretch	O
of	O
time	B
during	O
which	O
the	O
speaker	B
was	O
not	O
producing	O
vo-	O
levels	O
;	O
inspired	O
by	O
the	O
nsf	O
hearables	O
challenge	B
and	O
ex-	O
calization	O
(	O
e.g.	O
,	O
backchannels	O
,	O
ﬁlled	O
pauses	O
,	O
singing	O
,	O
speech	O
er-	O
tended	O
by	O
ldc	O
for	O
dihard	O
(	O
unpublished	O
)	O
rors	O
and	O
disﬂuencies	O
,	O
infant	O
babbling	O
or	O
vocalizations	O
,	O
laughter	O
,	O
•	O
sociolinguistic	O
ﬁeld	O
recordings	O
–	O
sociolinguistic	O
inter-	O
coughs	O
,	O
breaths	O
,	O
lipsmacks	O
,	O
and	O
humming	O
)	O
of	O
any	O
kind	O
.	O
bound-	O
views	O
recorded	O
under	O
ﬁeld	O
conditions	O
during	O
the	O
1960s	O
aries	O
were	O
placed	O
within	O
10	O
ms	O
of	O
the	O
true	O
boundary	O
,	O
taking	O
care	O
and	O
1970s	O
;	O
recorded	O
under	O
diverse	O
locations	O
and	O
condi-	O
not	O
to	O
truncate	O
sounds	O
at	O
edges	O
of	O
words	B
(	O
e.g.	O
,	O
utterance-ﬁnal	O
tions	O
with	O
subjects	O
ranging	O
from	O
15	O
to	O
81	O
years	O
of	O
age	O
fricatives	O
)	O
.	O
where	O
individual	O
close	O
talking	O
microphones	O
were	O
and	O
representing	O
diverse	O
ethnicities	O
,	O
backgrounds	O
,	O
and	O
available	O
for	O
speakers	O
,	O
annotation	O
was	O
performed	O
separately	O
for	O
dialects	O
of	O
world	O
english	O
;	O
the	O
development	B
set	I
draws	O
each	O
speaker	B
using	O
their	O
individual	O
microphone	O
.	O
due	O
to	O
time	B
from	O
slx	O
(	O
ldc2003t15	O
)	O
and	O
the	O
evaluation	B
set	I
from	O
constraints	O
,	O
this	O
manual	O
segmentation	B
process	B
could	O
not	O
be	O
im-	O
dass	O
(	O
ldc2012s03	O
&	O
ldc2016s05	O
)	O
plemented	O
for	O
the	O
multichannel	B
development	B
data	I
;	O
for	O
this	O
data	B
,	O
•	O
sociolinguistic	O
lab	O
recordings	O
–	O
sociolinguistic	O
inter-	O
segmentation	B
was	O
taken	O
from	O
the	O
turn	O
boundaries	B
established	O
views	O
recorded	O
as	O
part	O
of	O
mixer6	O
(	O
ldc2013s03	O
)	O
un-	O
during	O
the	O
original	O
chime-5	O
transcription	B
.	O
der	O
quiet	O
conditions	O
in	O
a	O
controlled	O
environment	O
;	O
ses-	O
an	O
additional	O
post	O
-	O
processing	B
step	O
was	O
necessary	O
for	O
the	O
sions	O
were	O
recorded	O
with	O
a	O
variety	O
of	O
close	O
-	O
talking	O
and	O
chime-5	O
annotation	O
to	O
correct	O
for	O
the	O
lack	O
of	O
synchroniza-	O
distant	O
microphones	O
from	O
which	O
a	O
single	O
,	O
centrally	O
lo-	O
tion	O
between	O
binaural	O
recording	B
devices	O
and	O
kinects	O
.	O
for	O
each	O
cated	O
distant	O
microphone	O
was	O
selected	O
kinect	O
,	O
the	O
lag	O
between	O
that	O
array	O
and	O
the	O
binaural	O
recording	B
de-	O
•	O
web	O
video	O
–	O
english	O
and	O
mandarin	O
amateur	O
videos	B
col-	O
vices	O
was	O
estimated	O
at	O
regular	O
intervals	O
using	O
normalized	O
cross-	O
lected	O
from	O
online	O
sharing	O
sites	O
(	O
e.g.	O
,	O
youtube	O
and	O
correlation	O
.	O
the	O
speech	O
boundaries	B
etablished	O
by	O
annotation	O
on	O
vimeo	O
)	O
as	O
part	O
of	O
the	O
video	O
annotation	O
for	O
speech	O
tech-	O
the	O
binaural	O
devices	O
were	O
then	O
corrected	O
for	O
each	O
kinect	O
using	O
nologies	O
(	O
vast	O
)	O
[	O
23	O
]	O
collection	O
(	O
mostly	O
unpublished	O
)	O
these	O
estimated	O
lags	O
.	O
4.3	O
.	O
multichannel	B
data	B
(	O
tracks	B
3	O
and	O
4	O
)	O
5	O
.	O
baseline	B
system	I
the	O
multichannel	B
input	B
condition	B
development	O
and	O
evaluation	B
5.1	O
.	O
speech	O
enhancement	O
sets	O
are	O
drawn	O
from	O
the	O
chime-5	O
dinner	O
party	O
corpus	B
[	O
18	O
]	O
,	O
a	O
corpus	B
of	O
conversational	O
speech	O
collected	O
during	O
dinner	O
parties	O
for	O
speech	O
enhancement	O
we	O
use	O
a	O
densely	O
-	O
connected	O
lstm	O
held	O
in	O
real	O
homes	O
.	O
the	O
development	B
set	I
combines	O
the	O
chime-	O
architecture	B
[	O
24	O
,	O
25	O
,	O
26	O
]	O
trained	O
to	O
predict	O
the	O
ideal	O
ratio	O
5	O
training	O
and	O
development	O
sets	O
and	O
encompasses	O
45	O
hours	B
of	O
masks	O
(	O
irm	O
)	O
[	O
27	O
]	O
of	O
speech	O
from	O
log	B
-	O
power	O
spectra	O
(	O
lps	O
)	O
fea	O
-	O
tures	O
.	O
the	O
model	B
is	O
trained	O
via	O
progressive	O
multi	O
-	O
target	O
learning	O
table	O
2	O
:	O
baseline	B
performance	O
(	O
measured	O
by	O
der	O
and	O
jer	O
)	O
[	O
24	O
,	O
28	O
]	O
using	O
400	O
hours	B
of	O
noisy	O
speech	O
produced	O
by	O
corrupt-	O
on	O
dev	O
and	O
eval	O
sets	O
for	O
all	O
tracks	B
.	O
the	O
enh	O
.	O
column	O
indicates	O
ing	O
clean	O
utterances	B
from	O
wsj0	O
[	O
29	O
]	O
and	O
a	O
50	O
hour	O
chinese	O
whether	O
or	O
not	O
speech	O
enhancement	O
was	O
applied	O
prior	O
to	O
sad	O
.	O
speech	O
corpus	B
from	O
the	O
863	O
program	O
[	O
30	O
]	O
.	O
utterances	B
were	O
cor-	O
rupted	O
using	O
115	O
noise	O
types	O
[	O
24	O
]	O
at	O
3	O
snr	O
levels	O
(	O
-5db	O
,	O
0db	O
,	O
track	O
enh	O
.	O
der	O
(	O
%	O
)	O
jer	O
(	O
%	O
)	O
and	O
5db	O
)	O
.	O
the	O
trained	O
models	B
as	O
well	O
as	O
scripts	O
for	O
applying	O
dev	O
eval	O
dev	O
eval	O
them	O
,	O
are	O
distributed	O
through	O
github4	O
.	O
track	O
1	O
no	O
23.70	O
25.99	O
56.20	O
59.51	O
track	O
2	O
no	O
46.33	O
50.12	O
69.26	O
72.1	O
track	O
2	O
yes	O
38.26	O
40.86	O
62.59	O
66.60	O
5.2	O
.	O
beamforming	O
track	O
3	O
no	O
59.73	O
50.85	O
68.00	O
65.91	O
for	O
the	O
multichannel	B
tracks	B
,	O
we	O
use	O
weighted	O
delay	O
-	O
and	O
-	O
sum	O
track	O
4	O
no	O
87.55	O
83.41	O
88.08	O
85.12	O
beamforming	O
as	O
implemented	O
in	O
beamformit	O
[	O
31	O
]	O
.	O
beamform-	O
track	O
4	O
yes	O
82.49	O
77.34	O
83.6	O
80.42	O
ing	O
is	O
applied	O
independently	O
for	O
each	O
kinect	O
in	O
each	O
session	O
using	O
all	O
four	O
channels	B
following	O
the	O
chime-5	O
recipe	O
[	O
18	O
]	O
.	O
5.5	O
.	O
baseline	B
results	B
5.3	O
.	O
speech	B
activity	I
detection	I
der	O
and	O
jer	O
of	O
the	O
baseline	B
system	I
on	O
both	O
the	O
development	O
the	O
baselines	O
for	O
tracks	B
2	O
and	O
4	O
use	O
webrtc’s5	O
sad	O
as	O
imple-	O
and	O
evaluation	B
sets	O
for	O
each	O
track	O
are	O
presented	O
in	O
table	O
2	O
.	O
the	O
mented	O
in	O
the	O
py	O
-	O
webrtc	O
python	O
package6	O
.	O
scripts	O
for	O
perform-	O
speech	O
enhancement	O
module	O
is	O
used	O
only	O
for	O
tracks	B
2	O
and	O
4	O
as	O
a	O
pre	O
-	O
processing	B
front	O
-	O
end	O
for	O
the	O
sad	O
pipeline	O
as	O
the	O
diariza-	O
ing	O
sad	O
using	O
the	O
same	O
settings	O
used	O
to	O
obtain	O
the	O
baseline	B
results	B
are	O
distributed	O
through	O
github4	O
.	O
tion	O
system	O
did	O
not	O
show	O
improvements	B
using	O
the	O
enhanced	O
au-	O
dio	O
.	O
the	O
scores	O
obtained	O
by	O
the	O
challenge	B
baseline	B
are	O
quite	O
high	O
,	O
with	O
track	O
1	O
der	O
roughly	O
in	O
line	O
with	O
the	O
performance	O
of	O
5.4	O
.	O
diarization	B
the	O
best	O
dihard	O
i	O
systems	O
[	O
14	O
,	O
15	O
,	O
25	O
]	O
and	O
track	O
2	O
der	O
5	O
%	O
higher	O
than	O
for	O
dihard	O
i	O
(	O
15	O
%	O
without	O
enhancement	O
)	O
,	O
which	O
the	O
diarization	B
baseline	B
is	O
based	O
on	O
the	O
previously	O
published	O
kaldi	O
[	O
32	O
]	O
recipe7	O
for	O
jhu	O
’s	O
submission	O
to	O
dihard	O
i	O
[	O
14	O
]	O
.	O
at	O
we	O
suspect	O
reﬂects	O
a	O
combination	O
of	O
superior	O
sad	O
components	B
in	O
those	O
systems	O
and	O
the	O
more	O
careful	O
segmentation	B
for	O
the	O
child	O
a	O
high	O
level	B
,	O
the	O
system	O
performs	O
diarization	B
by	O
dividing	O
each	O
language	O
and	O
web	O
video	O
domains	O
in	O
dihard	O
ii	O
.	O
error	B
rates	I
recording	B
into	O
short	O
overlapping	B
segments	O
,	O
extracting	O
x	O
-	O
vectors	O
are	O
noticeably	O
higher	O
for	O
tracks	B
3	O
and	O
4	O
,	O
reaching	O
50.85	O
%	O
and	O
[	O
33	O
,	O
34	O
]	O
,	O
scoring	O
with	O
probabilistic	O
linear	O
discriminant	B
analysis	I
77.34	O
%	O
respectively	O
,	O
though	O
,	O
again	O
,	O
these	O
rates	B
are	O
roughly	O
in	O
(	O
plda	B
)	O
[	O
35	O
]	O
,	O
and	O
clustering	B
using	O
agglomerative	O
hierarchical	O
line	O
with	O
those	O
observed	O
for	O
the	O
best	O
dihard	O
i	O
systems	O
on	O
clustering	B
(	O
ahc	O
)	O
[	O
36	O
]	O
.	O
in	O
contrast	O
to	O
the	O
original	O
jhu	O
system	O
,	O
the	O
two	O
most	O
difﬁcult	O
domains	O
in	O
that	O
challenge	B
:	O
restaurant	O
and	O
we	O
omit	O
the	O
variational	O
bayes	O
resegmentation	B
step	O
[	O
37	O
]	O
.	O
the	O
trained	O
models	B
are	O
distributed	O
through	O
github8	O
.	O
child	O
language	O
.	O
the	O
x	O
-	O
vector	O
extractor	B
conﬁguration	O
is	O
identical	O
to	O
that	O
used	O
6	O
.	O
conclusion	O
in	O
previous	O
speaker	B
recognition	O
and	O
diarization	B
systems	I
[	O
34	O
,	O
14	O
]	O
with	O
two	O
exceptions	O
:	O
i	O
)	O
30	O
dimensional	O
mel	O
frequency	B
cepstral	O
the	O
ﬁeld	O
of	O
speaker	B
diarization	I
has	O
changed	O
drastically	O
in	O
the	O
coefﬁcient	O
(	O
mfcc	O
)	O
features	O
are	O
used	O
instead	O
of	O
mel	O
ﬁlterbank	O
two	O
short	O
years	O
we	O
have	O
been	O
running	O
this	O
challenge	B
.	O
in	O
the	O
lead	O
features	O
;	O
ii	O
)	O
the	O
embedding	O
layer	B
uses	O
512	O
dimensions	O
.	O
mfccs	O
up	O
to	O
dihard	O
i	O
,	O
the	O
research	B
community	O
was	O
fragmented	O
and	O
are	O
extracted	O
every	O
10	O
ms	O
using	O
a	O
25	O
ms	O
window	O
and	O
mean-	O
most	O
research	B
concentrated	O
on	O
relatively	O
easy	O
datasets	B
using	O
for-	O
normalized	O
using	O
a	O
3	O
second	O
sliding	O
window	O
.	O
for	O
training	O
we	O
giving	O
evaluation	B
metrics	I
.	O
this	O
both	O
made	O
comparison	O
of	O
sys-	O
use	O
a	O
combination	O
of	O
voxceleb	O
1	O
and	O
voxceleb	O
2	O
[	O
38	O
,	O
39	O
]	O
aug-	O
tems	O
difﬁcult	O
and	O
led	O
some	O
to	O
believe	O
that	O
diarization	B
was	O
rela-	O
mented	O
with	O
additive	O
noise	O
and	O
reverberation	O
according	O
to	O
the	O
tively	O
solved	O
and	O
uninteresting	O
.	O
however	O
,	O
we	O
were	O
pleased	O
by	O
recipe	O
from	O
[	O
33	O
]	O
.	O
segments	O
under	O
4	O
seconds	B
duration	O
are	O
dis-	O
the	O
response	O
to	O
dihard	O
i	O
,	O
both	O
during	O
the	O
evaluation	B
and	O
after	O
,	O
carded	O
,	O
resulting	O
in	O
a	O
training	O
set	B
with	O
7,323	O
speakers	O
.	O
rever-	O
demonstrating	O
that	O
there	O
is	O
interest	O
in	O
robust	O
diarization	B
.	O
this	O
beration	O
is	O
added	O
by	O
convolution	O
with	O
room	O
responses	O
from	O
the	O
renewed	O
energy	O
is	O
on	O
display	O
in	O
dihard	O
ii	O
,	O
which	O
attracted	O
rir	O
dataset	O
[	O
40	O
]	O
,	O
while	O
additive	O
noises	O
are	O
drawn	O
from	O
the	O
mu-	O
48	O
registered	O
teams	O
from	O
17	O
countries	O
,	O
more	O
than	O
doubling	O
the	O
san	O
dataset	O
[	O
41	O
]	O
.	O
at	O
test	B
time	B
,	O
x	O
-	O
vectors	O
are	O
extracted	O
from	O
1.5	O
number	O
of	O
teams	O
registered	O
for	O
dihard	O
i.	O
it	O
is	O
also	O
evident	O
in	O
second	O
segments	O
with	O
0.75	O
second	O
overlap	O
.	O
the	O
recent	O
announcement	O
of	O
the	O
fearless	O
steps	B
challenge	B
,	O
which	O
following	O
extraction	B
,	O
x	O
-	O
vectors	O
are	O
pre	O
-	O
processed	O
to	O
per-	O
includes	O
diarization	B
among	O
its	O
tasks	O
.	O
we	O
hope	O
that	O
this	O
year	O
’s	O
form	O
domain	B
adaptation	O
to	O
the	O
dihard	O
ii	O
dataset	O
.	O
this	O
is	O
done	O
contributions	O
lead	O
to	O
marked	O
progress	O
toward	O
the	O
goal	O
of	O
truly	O
by	O
normalizing	O
with	O
a	O
global	O
mean	O
and	O
whitening	O
transform	O
robust	O
diarization	B
.	O
learned	O
from	O
the	O
dihard	O
ii	O
development	B
set	I
.	O
the	O
whitened	O
x	O
-	O
vectors	O
are	O
then	O
length	B
normalized	O
[	O
42	O
]	O
and	O
used	O
to	O
train	O
a	O
7	O
.	O
acknowledgements	O
gaussian	O
plda	B
model	B
[	O
35	O
]	O
using	O
a	O
subset	O
of	O
voxceleb	O
consist-	O
ing	O
of	O
segments	O
of	O
at	O
least	O
3	O
seconds	B
duration	O
.	O
following	O
plda	B
we	O
would	O
like	O
to	O
thank	O
harshah	O
vardhan	O
ma	O
,	O
prachi	O
singh	O
,	O
and	O
lei	O
sun	O
for	O
their	O
help	O
in	O
preparing	O
the	O
baseline	B
sytems	O
scoring	O
,	O
clustering	B
is	O
performed	O
using	O
ahc	O
with	O
the	O
threshold	B
and	O
results	B
.	O
we	O
would	O
also	O
like	O
to	O
acknowledge	O
the	O
gener-	O
set	B
by	O
minimizing	O
der	O
on	O
the	O
development	B
data	I
.	O
ous	O
support	O
of	O
agence	O
nationale	O
de	O
la	O
recherche	O
(	O
anr-16-	O
data-0004	O
aclew	O
,	O
anr-14-ce30	O
-	O
0003	O
mechelex	O
,	O
anr-	O
4https://github.com/staplesinla/denoising_dihard18	O
17-eure-0017	O
)	O
,	O
the	O
j.	O
s.	O
mcdonnell	O
foundation	O
,	O
and	O
the	O
lin-	O
5https://webrtc.org/	O
guistic	O
data	B
consortium	O
as	O
well	O
as	O
the	O
chime-5	O
challenge	B
for	O
6https://github.com/wiseman/py-webrtcvad	O
allowing	O
us	O
use	O
of	O
their	O
data	B
.	O
7https://github.com/kaldi-asr/kaldi/tree/master/egs/dihard_2018/v2	O
8https://github.com/iiscleap/dihard_2019_baseline_alltracks8	O
.	O
references	B
[	O
21	O
]	O
v.	O
panayotov	O
,	O
g.	O
chen	O
,	O
d.	O
povey	O
,	O
and	O
s.	O
khudanpur	O
,	O
“	O
lib-	O
rispeech	O
:	O
an	O
asr	B
corpus	B
based	O
on	O
public	O
domain	B
audio	O
books	O
,	O
”	O
[	O
1	O
]	O
j.	O
g.	O
fiscus	O
,	O
j.	O
ajot	O
,	O
m.	O
michel	O
,	O
and	O
j.	O
s.	O
garofolo	O
,	O
“	O
the	O
rich	O
in	O
proc	O
.	O
icassp	O
,	O
2015	O
,	O
pp	O
.	O
5206–5210	O
.	O
transcription	B
2006	O
spring	O
meeting	O
recognition	O
evaluation	B
,	O
”	O
in	O
international	O
workshop	O
on	O
machine	O
learning	O
for	O
multimodal	O
in-	O
[	O
22	O
]	O
e.	O
bergelson	O
,	O
“	O
bergelson	O
seedlings	O
homebank	O
corpus	B
,	O
”	O
2016	O
,	O
teraction	O
.	O
springer	O
,	O
2006	O
,	O
pp	O
.	O
309–322	O
.	O
doi:10.21415	O
/	O
t5pk6d	O
.	O
[	O
23	O
]	O
j.	O
tracey	O
and	O
s.	O
strassel	O
,	O
“	O
vast	O
:	O
a	O
corpus	B
of	O
video	O
annotation	O
[	O
2	O
]	O
g.	O
sell	O
and	O
d.	O
garcia	O
-	O
romero	O
,	O
“	O
speaker	B
diarization	I
with	O
plda	B
for	O
speech	O
technologies	O
,	O
”	O
in	O
proc	O
.	O
lrec	O
,	O
2018	O
.	O
i	O
-	O
vector	O
scoring	O
and	O
unsupervised	O
calibration	O
,	O
”	O
in	O
proc	O
.	O
ieee	O
spo-	O
ken	O
language	O
technology	O
workshop	O
(	O
slt	O
)	O
,	O
2014	O
,	O
pp	O
.	O
413–417	O
.	O
[	O
24	O
]	O
t.	O
gao	O
,	O
j.	O
du	O
,	O
l.-r	O
.	O
dai	O
,	O
and	O
c.-h	O
.	O
lee	O
,	O
“	O
densely	O
connected	O
pro-	O
gressive	O
learning	O
for	O
lstm	O
-	O
based	O
speech	O
enhancement	O
,	O
”	O
in	O
proc	O
.	O
[	O
3	O
]	O
w.	O
zhu	O
and	O
j.	O
pelecanos	O
,	O
“	O
online	O
speaker	B
diarization	I
using	O
icassp	O
,	O
2018	O
,	O
pp	O
.	O
5054–5058	O
.	O
adapted	O
i	O
-	O
vector	O
transforms	O
,	O
”	O
in	O
proc	O
.	O
icassp	O
,	O
2016	O
.	O
[	O
25	O
]	O
l.	O
sun	O
,	O
j.	O
du	O
,	O
c.	O
jiang	O
,	O
x.	O
zhang	O
,	O
s.	O
he	O
,	O
b.	O
yin	O
,	O
and	O
c.-h	O
.	O
[	O
4	O
]	O
d.	O
garcia	O
-	O
romero	O
,	O
d.	O
snyder	O
,	O
g.	O
sell	O
,	O
d.	O
povey	O
,	O
and	O
a.	O
mccree	O
,	O
lee	O
,	O
“	O
speaker	B
diarization	I
with	O
enhancing	O
speech	O
for	O
the	O
first	O
di-	O
“	O
speaker	B
diarization	I
using	O
deep	O
neural	B
network	I
embeddings	O
,	O
”	O
in	O
hard	O
challenge	B
,	O
”	O
proc	O
.	O
interspeech	O
,	O
pp	O
.	O
2793–2797	O
,	O
2018	O
.	O
proc	O
.	O
icassp	O
,	O
2017	O
,	O
pp	O
.	O
4930–4934	O
.	O
[	O
26	O
]	O
l.	O
sun	O
,	O
j.	O
du	O
,	O
t.	O
gao	O
,	O
y.-d	O
.	O
lu	O
,	O
y.	O
tsao	O
,	O
c.-h	O
.	O
lee	O
,	O
and	O
n.	O
ryant	O
,	O
[	O
5	O
]	O
q.	O
wang	O
,	O
c.	O
downey	O
,	O
l.	O
wan	O
,	O
p.	O
a.	O
mansﬁeld	O
,	O
and	O
i.	O
l.	O
moreno	O
,	O
“	O
a	O
novel	O
lstm	O
-	O
based	O
speech	O
preprocessor	O
for	O
speaker	B
diariza-	O
“	O
speaker	B
diarization	I
with	O
lstm	O
,	O
”	O
in	O
proc	O
.	O
icassp	O
,	O
2018	O
,	O
pp	O
.	O
tion	O
in	O
realistic	O
mismatch	O
conditions	O
,	O
”	O
in	O
proc	O
.	O
icassp	O
,	O
2018	O
,	O
pp	O
.	O
5239–5243	O
.	O
5234–5238	O
.	O
[	O
6	O
]	O
a.	O
zhang	O
,	O
q.	O
wang	O
,	O
z.	O
zhu	O
,	O
j.	O
paisley	O
,	O
and	O
c.	O
wang	O
,	O
“	O
fully	O
su-	O
[	O
27	O
]	O
s.	O
srinivasan	O
,	O
n.	O
roman	O
,	O
and	O
d.	O
wang	O
,	O
“	O
binary	O
and	O
ratio	O
time-	O
pervised	O
speaker	B
diarization	I
,	O
”	O
proc	O
.	O
icassp	O
,	O
2019	O
.	O
frequency	B
masks	O
for	O
robust	O
speech	B
recognition	I
,	O
”	O
speech	O
commu-	O
nication	O
,	O
vol	O
.	O
48	O
,	O
no	O
.	O
11	O
,	O
pp	O
.	O
1486–1501	O
,	O
2006	O
.	O
[	O
7	O
]	O
m.	O
rouvier	O
,	O
g.	O
dupuy	O
,	O
p.	O
gay	O
,	O
e.	O
khoury	O
,	O
t.	O
merlin	O
,	O
and	O
s.	O
meignier	O
,	O
“	O
an	O
open	O
-	O
source	B
state	O
-	O
of	O
-	O
the	O
-	O
art	O
toolbox	O
for	O
broad-	O
[	O
28	O
]	O
l.	O
sun	O
,	O
j.	O
du	O
,	O
l.-r	O
.	O
dai	O
,	O
and	O
c.-h	O
.	O
lee	O
,	O
“	O
multiple	O
-	O
target	O
deep	O
cast	O
news	O
diarization	B
,	O
”	O
in	O
proc	O
.	O
interspeech	O
,	O
2013	O
,	O
pp	O
.	O
1477–1481	O
.	O
learning	O
for	O
lstm	O
-	O
rnn	O
based	O
speech	O
enhancement	O
,	O
”	O
in	O
proc	O
.	O
hscma	O
,	O
2017	O
,	O
pp	O
.	O
136–140	O
.	O
[	O
8	O
]	O
i.	O
vin˜als	O
,	O
a.	O
ortega	O
,	O
j.	O
a.	O
v.	O
lo´pez	O
,	O
a.	O
miguel	O
,	O
and	O
e.	O
lleida	O
,	O
“	O
domain	B
adaptation	O
of	O
plda	B
models	B
in	O
broadcast	O
diarization	B
by	O
[	O
29	O
]	O
j.	O
s.	O
garofolo	O
et	O
al	O
.	O
,	O
csr	O
-	O
i	O
(	O
wsj0	O
)	O
complete	O
ldc93s6a	O
.	O
means	O
of	O
unsupervised	O
speaker	B
clustering	B
.	O
”	O
in	O
proc	O
.	O
interspeech	O
,	O
philadelphia	O
:	O
linguistic	O
data	B
consortium	O
,	O
1993	O
.	O
2017	O
,	O
pp	O
.	O
2829–2833	O
.	O
[	O
30	O
]	O
y.	O
l.	O
qian	O
,	O
s.	O
x.	O
lin	O
,	O
y.	O
d.	O
zhang	O
,	O
y.	O
liu	O
,	O
h.	O
liu	O
,	O
and	O
q.	O
liu	O
,	O
“	O
an	O
introduction	O
to	O
corpora	B
resources	O
of	O
863	O
program	O
for	O
chinese	O
[	O
9	O
]	O
s.	O
h.	O
yella	O
and	O
h.	O
bourlard	O
,	O
“	O
improved	O
overlap	O
speech	O
diarization	B
language	B
processing	I
and	O
human	O
-	O
machine	O
interaction	O
,	O
”	O
proc	O
.	O
alr	O
,	O
of	O
meeting	O
recordings	O
using	O
long	O
-	O
term	O
conversational	O
features	O
,	O
”	O
in	O
2004	O
.	O
proc	O
.	O
icassp	O
,	O
2013	O
,	O
pp	O
.	O
7746–7750	O
.	O
[	O
31	O
]	O
x.	O
anguera	O
,	O
c.	O
wooters	O
,	O
and	O
j.	O
hernando	O
,	O
“	O
acoustic	O
beamform-	O
[	O
10	O
]	O
s.	O
h.	O
yella	O
,	O
a.	O
stolcke	O
,	O
and	O
m.	O
slaney	O
,	O
“	O
artiﬁcial	O
neural	B
network	I
ing	O
for	O
speaker	B
diarization	I
of	O
meetings	O
,	O
”	O
ieee	O
trans	O
.	O
audio	O
,	O
features	O
for	O
speaker	B
diarization	I
,	O
”	O
in	O
proc	O
.	O
ieee	O
spoken	B
language	I
speech	O
,	O
language	O
process	B
,	O
vol	O
.	O
15	O
,	O
no	O
.	O
7	O
,	O
pp	O
.	O
2011–2022	O
,	O
2007	O
.	O
technology	O
workshop	O
,	O
2014	O
,	O
pp	O
.	O
402–406	O
.	O
[	O
32	O
]	O
d.	O
povey	O
,	O
a.	O
ghoshal	O
,	O
g.	O
boulianne	O
,	O
l.	O
burget	O
,	O
o.	O
glembek	O
,	O
[	O
11	O
]	O
r.	O
milner	O
and	O
t.	O
hain	O
,	O
“	O
segment	B
-	O
oriented	O
evaluation	B
of	O
speaker	B
n.	O
goel	O
,	O
m.	O
hannemann	O
,	O
p.	O
motlicek	O
,	O
y.	O
qian	O
,	O
p.	O
schwarz	O
et	O
al	O
.	O
,	O
diarisation	O
performance	O
,	O
”	O
in	O
proc	O
.	O
icassp	O
,	O
2016	O
,	O
pp	O
.	O
5460–5464	O
.	O
“	O
the	O
kaldi	O
speech	B
recognition	I
toolkit	O
,	O
”	O
ieee	O
signal	B
processing	I
[	O
12	O
]	O
n.	O
ryant	O
,	O
e.	O
bergelson	O
,	O
k.	O
church	O
,	O
a.	O
cristia	O
,	O
j.	O
du	O
,	O
s.	O
ganap-	O
society	O
,	O
tech	O
.	O
rep	O
.	O
,	O
2011	O
.	O
athy	O
,	O
s.	O
khudanpur	O
,	O
d.	O
kowalski	O
,	O
m.	O
krishnamoorthy	O
,	O
r.	O
kul-	O
[	O
33	O
]	O
d.	O
snyder	O
,	O
p.	O
ghahremani	O
,	O
d.	O
povey	O
,	O
d.	O
garcia	O
-	O
romero	O
,	O
shreshta	O
et	O
al	O
.	O
,	O
“	O
enhancement	O
and	O
analysis	B
of	O
conversational	O
y.	O
carmiel	O
,	O
and	O
s.	O
khudanpur	O
,	O
“	O
deep	O
neural	B
network	I
-	O
based	O
speech	O
:	O
jsalt	O
2017	O
,	O
”	O
in	O
proc	O
.	O
icassp	O
,	O
2018	O
,	O
pp	O
.	O
5154–5158	O
.	O
speaker	B
embeddings	I
for	O
end	O
-	O
to	O
-	O
end	O
speaker	B
veriﬁcation	O
,	O
”	O
in	O
2016	O
[	O
13	O
]	O
n.	O
ryant	O
,	O
k.	O
church	O
,	O
c.	O
cieri	O
,	O
a.	O
cristia	O
,	O
j.	O
du	O
,	O
ieee	O
spoken	B
language	I
technology	O
workshop	O
,	O
2016	O
,	O
pp	O
.	O
165	O
–	O
s.	O
ganapathy	O
,	O
and	O
m.	O
liberman	O
,	O
“	O
first	O
dihard	O
chal-	O
170	O
.	O
lenge	O
evaluation	B
plan	I
,	O
”	O
tech	O
.	O
rep	O
.	O
,	O
2018	O
.	O
[	O
online	O
]	O
.	O
available	O
:	O
[	O
34	O
]	O
d.	O
snyder	O
,	O
d.	O
garcia	O
-	O
romero	O
,	O
g.	O
sell	O
,	O
d.	O
povey	O
,	O
and	O
s.	O
khudan-	O
https://zenodo.org/record/1199638	O
pur	O
,	O
“	O
x	O
-	O
vectors	O
:	O
robust	O
dnn	O
embeddings	O
for	O
speaker	B
recogni-	O
[	O
14	O
]	O
g.	O
sell	O
,	O
d.	O
snyder	O
,	O
a.	O
mccree	O
,	O
d.	O
garcia	O
-	O
romero	O
,	O
j.	O
villalba	O
,	O
tion	O
,	O
”	O
in	O
proc	O
.	O
icassp	O
,	O
2018	O
,	O
pp	O
.	O
5329–5333	O
.	O
m.	O
maciejewski	O
,	O
v.	O
manohar	O
,	O
n.	O
dehak	O
,	O
d.	O
povey	O
,	O
s.	O
watanabe	O
[	O
35	O
]	O
s.	O
j.	O
prince	O
and	O
j.	O
h.	O
elder	O
,	O
“	O
probabilistic	O
linear	O
discriminant	O
anal-	O
et	O
al	O
.	O
,	O
“	O
diarization	B
is	O
hard	O
:	O
some	O
experiences	O
and	O
lessons	O
learned	O
ysis	O
for	O
inferences	O
about	O
identity	O
,	O
”	O
in	O
2007	O
ieee	O
11th	O
interna-	O
for	O
the	O
jhu	O
team	O
in	O
the	O
inaugural	O
dihard	B
challenge	I
,	O
”	O
in	O
proc	O
.	O
tional	O
conference	O
on	O
computer	B
vision	O
,	O
2007	O
,	O
pp	O
.	O
1–8	O
.	O
interspeech	O
,	O
2018	O
,	O
pp	O
.	O
2808–2812	O
.	O
[	O
36	O
]	O
k.	O
j.	O
han	O
,	O
s.	O
kim	O
,	O
and	O
s.	O
s.	O
narayanan	O
,	O
“	O
strategies	O
to	O
im-	O
[	O
15	O
]	O
m.	O
diez	O
,	O
f.	O
landini	O
,	O
l.	O
burget	O
,	O
j.	O
rohdin	O
,	O
a.	O
silnova	O
,	O
prove	O
the	O
robustness	O
of	O
agglomerative	O
hierarchical	O
clustering	B
un-	O
k.	O
zmolıkova	O
´	O
,	O
o.	O
novotny	O
`	O
,	O
k.	O
vesely	O
`	O
,	O
o.	O
glembek	O
,	O
o.	O
plchot	O
der	O
data	B
source	B
variation	O
for	O
speaker	B
diarization	I
,	O
”	O
ieee	O
trans	O
.	O
au-	O
et	O
al	O
.	O
,	O
“	O
but	O
system	O
for	O
dihard	O
speech	O
diarization	B
challenge	B
dio	O
,	O
speech	O
,	O
language	O
process	B
,	O
vol	O
.	O
16	O
,	O
no	O
.	O
8	O
,	O
pp	O
.	O
1590–1601	O
,	O
2018	O
,	O
”	O
in	O
proc	O
.	O
interspeech	O
,	O
2018	O
,	O
pp	O
.	O
2798–2802	O
.	O
2008	O
.	O
[	O
16	O
]	O
c.	O
cieri	O
,	O
d.	O
miller	O
,	O
and	O
k.	O
walker	O
,	O
“	O
from	O
switchboard	O
to	O
fisher	O
:	O
[	O
37	O
]	O
m.	O
diez	O
,	O
l.	O
burget	O
,	O
and	O
p.	O
matejka	O
,	O
“	O
speaker	B
diarization	I
based	O
on	O
telephone	O
collection	O
protocols	O
,	O
their	O
uses	O
and	O
yields	O
,	O
”	O
in	O
proc	O
.	O
bayesian	O
hmm	O
with	O
eigenvoice	O
priors	O
,	O
”	O
in	O
proc	O
.	O
odyssey	O
,	O
2018	O
,	O
eurospeech	O
,	O
2003	O
.	O
pp	O
.	O
147–154	O
.	O
[	O
38	O
]	O
a.	O
nagrani	O
,	O
j.	O
s.	O
chung	O
,	O
and	O
a.	O
zisserman	O
,	O
“	O
voxceleb	O
:	O
[	O
17	O
]	O
n.	O
ryant	O
,	O
k.	O
church	O
,	O
c.	O
cieri	O
,	O
a.	O
cristia	O
,	O
j.	O
du	O
,	O
a	O
large	O
-	O
scale	O
speaker	B
identiﬁcation	O
dataset	O
,	O
”	O
arxiv	O
preprint	O
s.	O
ganapathy	O
,	O
and	O
m.	O
liberman	O
,	O
“	O
second	O
dihard	O
chal-	O
arxiv:1706.08612	O
,	O
2017	O
.	O
lenge	O
evaluation	B
plan	I
,	O
”	O
tech	O
.	O
rep	O
.	O
,	O
2019	O
.	O
[	O
online	O
]	O
.	O
available	O
:	O
https://coml.lscp.ens.fr/dihard/2019/second	O
dihard	O
eval	O
plan	O
v1.1.pdf	O
[	O
39	O
]	O
j.	O
s.	O
chung	O
,	O
a.	O
nagrani	O
,	O
and	O
a.	O
zisserman	O
,	O
“	O
voxceleb2	O
:	O
deep	O
speaker	B
recognition	O
,	O
”	O
proc	O
.	O
interspeech	O
,	O
pp	O
.	O
1086–1090	O
,	O
2018	O
.	O
[	O
18	O
]	O
j.	O
barker	O
,	O
s.	O
watanabe	O
,	O
e.	O
vincent	O
,	O
and	O
j.	O
trmal	O
,	O
“	O
the	O
fifth	O
‘	O
chime	O
’	O
speech	B
separation	I
and	O
recognition	O
challenge	B
:	O
dataset	O
,	O
[	O
40	O
]	O
t.	O
ko	O
,	O
v.	O
peddinti	O
,	O
d.	O
povey	O
,	O
m.	O
l.	O
seltzer	O
,	O
and	O
s.	O
khudanpur	O
,	O
task	O
and	O
baselines	O
,	O
”	O
in	O
proc	O
.	O
interspeech	O
,	O
2018	O
,	O
pp	O
.	O
1561–1565	O
.	O
“	O
a	O
study	O
on	O
data	B
augmentation	I
of	O
reverberant	O
speech	O
for	O
robust	O
speech	B
recognition	I
,	O
”	O
in	O
proc	O
.	O
icassp	O
,	O
2017	O
,	O
pp	O
.	O
5220–5224	O
.	O
[	O
19	O
]	O
l.	O
hamers	O
et	O
al	O
.	O
,	O
“	O
similarity	B
measures	O
in	O
scientometric	O
research	B
:	O
[	O
41	O
]	O
d.	O
snyder	O
,	O
g.	O
chen	O
,	O
and	O
d.	O
povey	O
,	O
“	O
musan	O
:	O
a	O
music	O
,	O
speech	O
,	O
the	O
jaccard	O
index	O
versus	O
salton	O
’s	O
cosine	O
formula	O
.	O
”	O
information	B
and	O
noise	O
corpus	B
,	O
”	O
arxiv	O
preprint	O
arxiv:1510.08484	O
,	O
2015	O
.	O
processing	B
and	O
management	O
,	O
vol	O
.	O
25	O
,	O
no	O
.	O
3	O
,	O
pp	O
.	O
315–18	O
,	O
1989	O
.	O
[	O
42	O
]	O
d.	O
garcia	O
-	O
romero	O
and	O
c.	O
y.	O
espy	O
-	O
wilson	O
,	O
“	O
analysis	B
of	O
i	O
-	O
vector	O
[	O
20	O
]	O
r.	O
real	O
and	O
j.	O
m.	O
vargas	O
,	O
“	O
the	O
probabilistic	O
basis	O
of	O
jaccard	O
’s	O
length	B
normalization	O
in	O
speaker	B
recognition	O
systems	O
,	O
”	O
in	O
proc	O
.	O
in-	O
index	O
of	O
similarity	B
,	O
”	O
systematic	O
biology	O
,	O
vol	O
.	O
45	O
,	O
no	O
.	O
3	O
,	O
pp	O
.	O
380	O
–	O
terspeech	O
,	O
2011	O
,	O
pp	O
.	O
249–252	O
.	O
385	O
,	O

second	O
dihard	B
challenge	I
evaluation	B
plan	I
version	O
1.2	O
neville	O
ryanta	O
,	O
kenneth	O
churchb	O
,	O
christopher	O
cieria	O
,	O
alejandrina	O
cristiac	O
,	O
jun	O
dud	O
,	O
sriram	O
ganapathye	O
,	O
and	O
mark	O
libermana	O
alinguistic	O
data	B
consortium	O
,	O
university	O
of	O
pennsylvania	O
,	O
philadelphia	O
,	O
pa	O
,	O
usa	O
bbaidu	O
research	B
,	O
sunnyvale	O
,	O
ca	O
,	O
usa	O
claboratoire	O
de	O
sciences	O
cognitives	O
et	O
psycholinguistique	O
,	O
ens	O
,	O
paris	O
,	O
france	O
duniversity	O
of	O
science	O
and	O
technology	O
of	O
china	O
,	O
hefei	O
,	O
china	O
eelectrical	O
engineering	O
department	O
,	O
indian	O
institute	O
of	O
science	O
,	O
bangalore	O
,	O
india	O
june	O
18	O
,	O
2019	O
1	O
introduction	O
dihard	O
ii	O
is	O
the	O
second	O
in	O
a	O
series	O
of	O
diarization	B
challenges	B
focusing	O
on	O
“	O
hard	O
”	O
diarization	B
;	O
that	O
is	O
,	O
speaker	B
diarization	I
for	O
challenging	O
recordings	O
where	O
there	O
is	O
an	O
expectation	O
that	O
the	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
will	O
fare	O
poorly	O
.	O
as	O
with	O
other	O
evaluations	O
in	O
this	O
series	O
,	O
dihard	O
ii	O
is	O
intended	O
to	O
both	O
(	O
1	O
)	O
support	O
speaker	B
diarization	I
research	B
through	O
the	O
creation	O
and	O
distribution	O
of	O
novel	O
data	B
sets	O
and	O
(	O
2	O
)	O
measure	O
and	O
calibrate	O
the	O
performance	O
of	O
systems	O
on	O
these	O
data	B
sets	O
.	O
the	O
results	B
of	O
the	O
challenge	B
will	O
be	O
presented	O
at	O
a	O
special	O
session	O
at	O
interspeech	O
2019	O
in	O
graz	O
,	O
austria	O
.	O
the	O
task	O
evaluated	O
in	O
the	O
challenge	B
is	O
speaker	B
diarization	I
;	O
that	O
is	O
,	O
the	O
task	O
of	O
determining	O
“	O
who	O
spoke	O
when	O
”	O
in	O
a	O
multispeaker	O
environment	O
based	O
only	O
on	O
audio	O
recordings	O
.	O
as	O
with	O
dihard	O
i	O
,	O
development	O
and	O
evaluation	B
sets	O
will	O
be	O
provided	O
by	O
the	O
organizers	O
,	O
but	O
there	O
is	O
no	O
ﬁxed	O
training	O
set	B
with	O
the	O
result	O
that	O
participants	B
are	O
free	O
to	O
train	O
their	O
systems	O
on	O
any	O
proprietary	O
and/or	O
public	O
data	B
.	O
once	O
again	O
,	O
these	O
development	O
and	O
evaluation	B
sets	O
will	O
be	O
drawn	O
from	O
a	O
diverse	O
sampling	O
of	O
sources	O
including	O
monologues	O
,	O
map	O
task	O
dialogues	O
,	O
broadcast	O
interviews	O
,	O
sociolinguistic	O
interviews	O
,	O
meeting	O
speech	O
,	O
speech	O
in	O
restaurants	O
,	O
clinical	O
recordings	O
,	O
extended	O
child	O
language	O
acquisition	O
recordings	O
from	O
lena	O
vests	O
,	O
and	O
youtube	O
videos	B
.	O
however	O
,	O
there	O
are	O
several	O
key	O
diﬀerences	O
from	O
dihard	O
i	O
:	O
•	O
two	O
tracks	B
evaluating	O
diarization	B
of	O
multi	O
-	O
channel	O
recordings	O
have	O
been	O
added	O
;	O
these	O
tracks	B
will	O
use	O
recordings	O
of	O
dinner	O
parties	O
provided	O
by	O
the	O
organizers	O
of	O
chime-5	O
•	O
the	O
evaluation	B
period	O
has	O
been	O
lengthened	O
(	O
from	O
4	O
weeks	O
to	O
16	O
weeks	O
)	O
•	O
jaccard	B
error	I
rate	O
replaces	O
mutual	O
information	B
as	O
the	O
secondary	O
metric	B
•	O
baseline	B
systems	O
and	O
results	B
will	O
be	O
provided	O
to	O
participants	B
participation	O
in	O
the	O
evaluation	B
is	O
open	O
to	O
all	O
who	O
are	O
interested	O
and	O
willing	O
to	O
comply	O
with	O
the	O
rules	O
laid	O
out	O
in	O
this	O
evaluation	B
plan	I
.	O
there	O
is	O
no	O
cost	B
to	O
participate1	O
,	O
though	O
participants	B
are	O
encouraged	O
to	O
submit	O
a	O
paper	O
to	O
the	O
corresponding	O
interspeech	O
2019	O
special	O
session	O
.	O
accepted	O
papers	O
will	O
be	O
presented	O
at	O
the	O
special	O
session	O
at	O
interspeech	O
2019	O
in	O
graz	O
,	O
austria	O
in	O
september	O
2019	O
.	O
1access	O
to	O
the	O
data	B
used	O
by	O
tracks	B
1	O
and	O
2	O
is	O
free	O
to	O
all	O
participants	B
.	O
access	O
to	O
the	O
chime-5	O
audio	O
data	B
used	O
by	O
tracks	B
3	O
and	O
4	O
is	O
free	O
for	O
not	O
-	O
for	O
-	O
proﬁt	O
organizations	O
.	O
all	O
other	O
users	O
,	O
regardless	O
of	O
use	O
case	O
,	O
will	O
be	O
required	O
to	O
purchase	O
a	O
commercial	O
license	O
to	O
the	O
chime-5	O
data	B
.	O
for	O
more	O
details	O
,	O
see	O
:	O
https://licensing.sheffield.ac.uk/i/data/chime5.html	O
.	O
1for	O
questions	O
not	O
answered	O
in	O
this	O
document	O
or	O
to	O
join	O
the	O
dihard	O
mailing	O
list	O
,	O
please	O
visit	O
the	O
dihard	O
website	O
(	O
https://coml.lscp.ens.fr/dihard	O
)	O
or	O
contact	O
dihardchallenge@gmail.com	O
.	O
2	O
schedule	O
•	O
registration	O
period	O
–	O
january	O
30	O
through	O
march	O
15	O
,	O
2019	O
•	O
dev	O
/	O
eval	O
set	B
release	O
–	O
february	O
28	O
,	O
2019	O
•	O
scoring	O
server	O
opens	O
–	O
march	O
12	O
,	O
2019	O
•	O
baselines	O
released	O
–	O
week	O
of	O
march	O
11	O
,	O
2019	O
•	O
interspeech	O
abstract	O
submission	O
–	O
march	O
29	O
,	O
2019	O
•	O
interspeech	O
paper	O
submission	O
–	O
april	O
5	O
,	O
2019	O
•	O
camera	O
-	O
ready	O
papers	O
–	O
july	O
1	O
,	O
2019	O
•	O
system	O
descriptions	O
due	O
–	O
august	O
16	O
,	O
2019	O
•	O
interspeech	O
2019	O
special	O
session	O
–	O
september	O
15	O
-	O
19	O
,	O
2019	O
the	O
deadline	O
for	O
submission	O
of	O
ﬁnal	O
system	O
outputs	O
corresponds	O
to	O
the	O
interspeech	O
camera	O
-	O
ready	O
paper	O
deadline	O
(	O
july	O
1st	O
,	O
2019	O
midnight	O
anywhere	O
on	O
earth	O
)	O
.	O
3	O
task	O
3.1	O
task	O
deﬁnition	O
the	O
goal	O
of	O
the	O
challenge	B
is	O
to	O
automatically	O
detect	O
and	O
label	O
all	O
speaker	B
segments	I
in	O
each	O
recording	B
session	O
.	O
small	O
pauses	O
of	O
<	O
=	O
200	O
ms	O
by	O
a	O
speaker	B
are	O
not	O
considered	O
to	O
be	O
segmentation	B
breaks	O
and	O
should	O
be	O
bridged	O
into	O
a	O
single	O
continuous	O
segment	B
.	O
a	O
pause	O
by	O
a	O
speaker	B
is	O
deﬁned	O
as	O
any	O
segment	B
in	O
which	O
that	O
speaker	B
is	O
not	O
producing	O
a	O
vocalization	O
of	O
any	O
kind	O
.	O
by	O
vocalization	O
,	O
we	O
mean	O
speech	O
,	O
including	O
speech	O
errors	B
and	O
infant	O
babbling	O
,	O
but	O
also	O
vocal	O
noise	O
such	O
as	O
breaths	O
,	O
coughs	O
,	O
lipsmacks	O
,	O
sneezes	O
,	O
laughs	O
,	O
humming	O
or	O
any	O
other	O
noise	O
produced	O
by	O
the	O
speaker	B
by	O
means	O
of	O
the	O
vocal	O
apparatus	O
.	O
two	O
input	B
conditions	O
(	O
single	B
channel	I
vs.	O
multichannel	B
)	O
and	O
two	O
speech	B
activity	I
detection	I
(	O
sad	O
)	O
conditions	O
(	O
reference	B
sad	O
vs.	O
system	O
sad	O
)	O
will	O
be	O
considered	O
,	O
yielding	O
four	O
possible	O
evaluation	B
conditions	O
.	O
3.2	O
input	B
conditions	O
two	O
audio	O
input	B
conditions	O
are	O
considered	O
:	O
•	O
single	B
channel	I
–	O
in	O
the	O
single	B
channel	I
condition	B
,	O
systems	O
are	O
provided	O
with	O
a	O
single	B
channel	I
of	O
audio	O
for	O
each	O
recording	B
.	O
depending	O
on	O
the	O
recording	B
source	B
,	O
this	O
channel	O
may	O
be	O
taken	O
from	O
a	O
single	O
distant	O
microphone	O
,	O
a	O
single	B
channel	I
from	O
a	O
distant	O
microphone	O
array	O
,	O
a	O
mix	O
of	O
head	O
-	O
mounted	O
or	O
array	O
microphones	O
,	O
or	O
a	O
mix	O
of	O
binaural	O
microphones	O
.	O
•	O
multichannel	B
–	O
in	O
the	O
multichannel	B
condition	B
,	O
each	O
recording	B
session	O
contains	O
output	B
from	O
one	O
or	O
more	O
distant	O
microphone	O
arrays	O
,	O
each	O
containing	O
multiple	O
channels	B
.	O
participants	B
should	O
treat	O
the	O
arrays	O
separately	O
,	O
producing	O
one	O
output	B
per	O
array	O
.	O
they	O
are	O
free	O
to	O
use	O
as	O
few	O
or	O
as	O
many	O
of	O
the	O
channels	B
on	O
each	O
array	O
as	O
they	O
wish	O
to	O
perform	O
diarization	B
.	O
for	O
instance	O
,	O
if	O
the	O
recording	B
session	O
contains	O
6	O
2microphone	O
arrays	O
,	O
each	O
having	O
four	O
channels	B
,	O
participants	B
are	O
expected	O
to	O
produce	O
6	O
rttm	O
ﬁles	O
,	O
each	O
containing	O
the	O
result	O
of	O
their	O
diarization	B
system	O
for	O
a	O
single	O
array	O
.	O
the	O
single	B
channel	I
and	O
multichannel	B
conditions	O
use	O
diﬀerent	O
data	B
sets	O
with	O
the	O
former	O
drawing	O
data	B
from	O
dihard	O
i	O
and	O
the	O
latter	O
from	O
chime-5	O
.	O
for	O
more	O
information	B
about	O
the	O
construction	O
and	O
composition	O
of	O
the	O
data	B
,	O
please	O
see	O
section	O
5	O
.	O
for	O
both	O
conditions	O
a	O
development	B
set	I
will	O
be	O
distributed	O
,	O
which	O
may	O
be	O
used	O
for	O
any	O
purpose	O
including	O
system	O
development	O
or	O
training	O
.	O
3.3	O
sad	O
conditions	O
because	O
system	O
performance	O
is	O
strongly	O
inﬂuenced	O
by	O
the	O
quality	B
of	O
the	O
speech	O
segmentation	B
used	O
,	O
two	O
diﬀerent	O
sad	O
conditions	O
are	O
covered	O
:	O
•	O
reference	B
sad	O
–	O
in	O
the	O
reference	B
sad	O
condition	B
,	O
systems	O
are	O
provided	O
with	O
a	O
reference	B
speech	O
segmentation	B
that	O
is	O
generated	O
by	O
merging	O
speaker	B
turns	O
in	O
the	O
reference	B
diarization	B
.	O
•	O
system	O
sad	O
–	O
in	O
the	O
system	O
sad	O
condition	B
,	O
systems	O
are	O
provided	O
with	O
just	O
the	O
raw	O
audio	O
input	B
for	O
each	O
recording	B
session	O
and	O
are	O
responsible	O
for	O
producing	O
their	O
own	O
speech	O
segmentation	B
.	O
3.4	O
tracks	B
together	O
,	O
the	O
two	O
input	B
conditions	O
and	O
two	O
sad	O
conditions	O
yield	O
four	O
evaluation	B
tracks	B
:	O
•	O
track	O
1	O
–	O
diarization	B
from	O
single	B
channel	I
audio	O
using	O
reference	B
sad	O
•	O
track	O
2	O
–	O
diarization	B
from	O
single	B
channel	I
audio	O
using	O
system	O
sad	O
•	O
track	O
3	O
–	O
diarization	B
from	O
multichannel	B
audio	O
using	O
reference	B
sad	O
•	O
track	O
4	O
–	O
diarization	B
from	O
multichannel	B
audio	O
using	O
system	O
sad	O
tracks	B
1	O
and	O
2	O
are	O
identical	O
to	O
tracks	B
1	O
and	O
2	O
in	O
dihard	O
i	O
and	O
use	O
the	O
same	O
data	B
,	O
though	O
with	O
improved	O
annotation	O
and	O
additional	O
development	B
data	I
(	O
see	O
section	O
5	O
)	O
.	O
these	O
tracks	B
do	O
not	O
contain	O
any	O
chime-5	O
data	B
.	O
tracks	B
3	O
and	O
4	O
are	O
new	O
this	O
year	O
and	O
consist	O
exclusively	O
of	O
multi	O
-	O
person	O
dinner	O
party	O
conversations	O
taken	O
from	O
the	O
chime-5	O
corpus	B
.	O
all	O
participants	B
must	O
register	O
for	O
at	O
least	O
one	O
of	O
track	O
1	O
or	O
track	O
3	O
(	O
diarization	B
from	O
reference	B
sad	O
)	O
.	O
participation	O
in	O
tracks	B
2	O
and	O
4	O
is	O
optional	O
.	O
4	O
scoring	O
system	O
output	B
will	O
be	O
scored	O
by	O
comparison	O
to	O
human	O
reference	B
segmentation	B
with	O
performance	O
evaluated	O
by	O
two	O
metrics	O
:	O
•	O
diarization	B
error	I
rate	I
(	O
der	O
)	O
•	O
jaccard	B
error	I
rate	O
(	O
jer	O
)	O
4.1	O
diarization	B
error	I
rate	I
diarization	B
error	I
rate	I
(	O
der	O
)	O
,	O
introduced	O
for	O
the	O
nist	O
rich	B
transcription	I
spring	O
2003	O
evaluation	B
(	O
rt-03s	O
)	O
,	O
is	O
the	O
total	O
percentage	B
of	O
reference	B
speaker	I
time	B
that	O
is	O
not	O
correctly	O
attributed	O
to	O
a	O
speaker	B
,	O
where	O
“	O
correctly	O
3attributed	O
”	O
is	O
deﬁned	O
in	O
terms	B
of	O
an	O
optimal	O
mapping	O
between	O
the	O
reference	B
and	O
system	O
speakers	O
.	O
more	O
concretely	O
,	O
der	O
is	O
deﬁned	O
as	O
:	O
fa	O
+	O
miss	B
+	O
error	O
der	O
=	O
total	O
where	O
•	O
total	O
is	O
the	O
total	O
reference	B
speaker	I
time	B
;	O
that	O
is	O
,	O
the	O
sum	O
of	O
the	O
durations	O
of	O
all	O
reference	B
speaker	I
segments	O
•	O
fa	O
is	O
the	O
total	O
system	B
speaker	I
time	B
not	O
attributed	O
to	O
a	O
reference	B
speaker	I
•	O
miss	B
is	O
the	O
total	O
reference	B
speaker	I
time	B
not	O
attributed	O
to	O
a	O
system	B
speaker	I
•	O
error	O
is	O
the	O
total	O
reference	B
speaker	I
time	B
attributed	O
to	O
the	O
wrong	O
speaker	B
contrary	O
to	O
practice	O
in	O
the	O
nist	O
evaluations	O
,	O
no	O
forgiveness	O
collar	O
will	O
be	O
applied	O
to	O
the	O
reference	B
segments	O
prior	O
to	O
scoring	O
and	O
overlapping	B
speech	I
will	O
be	O
evaluated	O
.	O
for	O
more	O
details	O
please	O
consult	O
section	O
6	O
of	O
the	O
rt-09	O
evaluation	B
plan	I
and	O
the	O
source	B
to	O
the	O
nist	O
md	O
-	O
eval	O
scoring	O
tool2	O
.	O
4.2	O
jaccard	B
error	I
rate	O
in	O
addition	O
to	O
the	O
primary	O
metric	B
we	O
will	O
score	B
systems	O
using	O
jaccard	B
error	I
rate	O
(	O
jer	O
)	O
,	O
a	O
new	O
metric	B
developed	O
for	O
dihard	O
.	O
the	O
jaccard	B
error	I
rate	O
is	O
based	O
on	O
the	O
jaccard	O
index3	O
,	O
a	O
similarity	B
measure	O
used	O
to	O
evaluate	O
the	O
output	B
of	O
image	O
segmentation	B
systems	O
.	O
an	O
optimal	O
mapping	O
between	O
reference	B
and	O
system	O
speakers	O
is	O
determined	O
and	O
for	O
each	O
pair	O
the	O
jaccard	O
index	O
is	O
computed	O
.	O
the	O
jaccard	B
error	I
rate	O
is	O
then	O
deﬁned	O
as	O
1	O
minus	O
the	O
average	B
of	O
these	O
scores	O
.	O
while	O
similar	O
to	O
der	O
,	O
it	O
weights	O
every	O
speaker	B
’s	O
contribution	O
equally	O
,	O
regardless	O
of	O
how	O
much	O
speech	O
they	O
actually	O
produced	O
.	O
more	O
concretely	O
,	O
assume	O
we	O
have	O
n	O
reference	B
speakers	O
and	O
m	O
system	O
speakers	O
.	O
an	O
optimal	O
mapping	O
between	O
speakers	O
is	O
determined	O
using	O
the	O
hungarian	O
algorithm	O
so	O
that	O
each	O
reference	B
speaker	I
is	O
paired	O
with	O
at	O
most	O
one	O
system	B
speaker	I
and	O
each	O
system	B
speaker	I
with	O
at	O
most	O
one	O
reference	B
speaker	I
.	O
then	O
,	O
for	O
each	O
reference	B
speaker	I
ref	O
the	O
speaker	B
-	O
speciﬁc	O
jaccard	B
error	I
rate	O
jer	O
is	O
computed	O
as	O
:	O
ref	O
fa	O
+	O
miss	B
jer	O
=	O
ref	O
total	O
where	O
•	O
total	O
is	O
the	O
duration	O
of	O
the	O
union	O
of	O
reference	B
and	O
system	B
speaker	I
segments	O
;	O
if	O
the	O
reference	B
speaker	I
was	O
not	O
paired	O
with	O
a	O
system	B
speaker	I
,	O
it	O
is	O
the	O
duration	O
of	O
all	O
reference	B
speaker	I
segments	O
•	O
fa	O
is	O
the	O
total	O
system	B
speaker	I
time	B
not	O
attributed	O
to	O
the	O
reference	B
speaker	I
;	O
if	O
the	O
reference	B
speaker	I
was	O
not	O
paired	O
with	O
a	O
system	B
speaker	I
,	O
it	O
is	O
0	O
•	O
miss	B
is	O
the	O
total	O
reference	B
speaker	I
time	B
not	O
attributed	O
to	O
the	O
system	B
speaker	I
;	O
if	O
the	O
reference	B
speaker	I
was	O
not	O
paired	O
with	O
a	O
system	B
speaker	I
,	O
it	O
is	O
equal	O
to	O
total	O
the	O
jaccard	B
error	I
rate	O
then	O
is	O
the	O
average	B
of	O
the	O
speaker	B
speciﬁc	O
jaccard	B
error	I
rates	B
:	O
1	O
(	O
cid:88	O
)	O
jer	O
=	O
jer	O
n	O
ref	O
ref	O
as	O
with	O
der	O
no	O
forgiveness	O
collar	O
will	O
be	O
applied	O
to	O
the	O
reference	B
segments	O
prior	O
to	O
scoring	O
and	O
overlapping	B
speech	I
will	O
be	O
evaluated	O
.	O
2available	O
as	O
part	O
of	O
the	O
speech	B
recognition	I
scoring	O
toolkit	O
(	O
sctk	O
)	O
:	O
ftp://jaguar.ncsl.nist.gov/pub/sctk-2.4	O
.	O
10	O
-	O
20151007	O
-	O
1312z.tar.bz2	O
.	O
for	O
dihard	O
,	O
we	O
will	O
be	O
using	O
version	O
22	O
of	O
md	O
-	O
eval	O
.	O
3https://en.wikipedia.org/wiki/jaccard_index	O
4jer	O
and	O
der	O
are	O
highly	O
correlated	O
with	O
jer	O
typically	O
being	O
higher	O
,	O
especially	O
in	O
recordings	O
where	O
one	O
or	O
more	O
speakers	O
is	O
particularly	O
dominant	O
.	O
where	O
it	O
tends	O
to	O
track	O
der	O
is	O
in	O
outliers	O
where	O
the	O
diarization	B
is	O
especially	O
bad	O
,	O
resulting	O
in	O
one	O
or	O
more	O
unmapped	O
system	O
speakers	O
whose	O
speech	O
is	O
not	O
then	O
penalized	O
.	O
in	O
these	O
cases	O
,	O
where	O
der	O
can	O
easily	O
exceed	O
500	O
%	O
,	O
jer	O
will	O
never	O
exceed	O
100	O
%	O
and	O
may	O
be	O
far	O
lower	O
if	O
the	O
reference	B
speakers	O
are	O
handled	O
correctly	O
.	O
4.3	O
scoring	O
regions	O
in	O
most	O
cases	O
the	O
scoring	O
region	O
for	O
each	O
recording	B
will	O
be	O
the	O
entirety	O
of	O
the	O
recording	B
;	O
that	O
is	O
,	O
for	O
a	O
recording	B
of	O
duration	O
405.37	O
seconds	B
,	O
the	O
scoring	O
region	O
will	O
be	O
[	O
0	O
,	O
405.37	O
]	O
.	O
however	O
,	O
for	O
a	O
small	O
subset	O
of	O
the	O
recordings	O
,	O
personal	O
identifying	O
information	B
(	O
pii	O
)	O
has	O
been	O
removed	O
from	O
the	O
recording	B
,	O
either	O
by	O
low-	O
pass	O
ﬁltering	O
or	O
insertion	O
of	O
tones	O
or	O
zeroing	O
out	O
of	O
samples	O
.	O
for	O
these	O
recordings	O
,	O
the	O
scoring	O
regions	O
consists	O
of	O
the	O
entirety	O
of	O
the	O
recording	B
minus	O
these	O
regions	O
.	O
in	O
both	O
cases	O
the	O
scoring	O
regions	O
will	O
be	O
speciﬁed	O
by	O
un	O
-	O
partitioned	O
evaluation	B
map	O
(	O
uem	O
)	O
ﬁles	O
,	O
which	O
will	O
be	O
distributed	O
by	O
ldc	O
as	O
part	O
of	O
the	O
development	O
and	O
evaluation	B
releases	O
.	O
please	O
see	O
appendix	O
d	O
for	O
details	O
of	O
the	O
uem	O
ﬁle	O
format	O
.	O
4.4	O
scoring	O
tool	O
all	O
scoring	O
will	O
be	O
performed	O
using	O
version	O
1.0.1	O
of	O
dscore	O
,	O
which	O
is	O
maintained	O
as	O
a	O
github	O
repo	O
at	O
:	O
https://github.com/nryant/dscore	O
to	O
score	B
a	O
set	B
of	O
system	O
output	B
rttms	O
sys1.rttm	O
,	O
sys2.rttm	O
,	O
...	O
against	O
corresponding	O
reference	B
rttms	O
ref1.rttm	O
,	O
ref2.rttm	O
,	O
...	O
using	O
the	O
un	O
-	O
partitioned	O
evaluation	B
map	O
(	O
uem	O
)	O
all.uem	O
,	O
the	O
command	O
line	O
would	O
be	O
:	O
$	O
python	O
s	O
c	O
o	O
r	O
e	O
.	O
py	O
−u	O
a	O
l	O
l	O
.	O
uem	O
−r	O
r	O
e	O
f	O
1	O
.	O
rttm	O
r	O
e	O
f	O
2	O
.	O
rttm	O
.	O
.	O
.	O
−s	O
s	O
y	O
s	O
1	O
.	O
rttm	O
s	O
y	O
s	O
2	O
.	O
rttm	O
.	O
.	O
.	O
the	O
overall	O
and	O
per-ﬁle	O
results	B
for	O
der	O
and	O
jer	O
(	O
and	O
many	O
other	O
metrics	O
)	O
will	O
be	O
printed	O
to	O
stdout	O
as	O
a	O
table	O
.	O
for	O
additional	O
details	O
about	O
scoring	O
tool	O
usage	O
,	O
please	O
consult	O
the	O
documentation	O
for	O
the	O
github	O
repo	O
.	O
5	O
data	B
5.1	O
training	B
data	I
dihard	O
participants	B
may	O
use	O
any	O
publicly	O
available	O
or	O
proprietary	O
data	B
to	O
train	O
their	O
systems	O
,	O
with	O
the	O
exception	O
of	O
the	O
following	O
previously	O
released	O
corpora	B
,	O
from	O
which	O
portions	O
of	O
the	O
evaluation	B
set	I
are	O
drawn	O
:	O
•	O
dciem	O
map	O
task	O
corpus	B
(	O
ldc96s38	O
)	O
•	O
mixer6	O
speech	O
(	O
ldc2013s03	O
)	O
•	O
digital	O
archive	O
of	O
southern	O
speech	O
(	O
ldc2012s03	O
and	O
ldc2016s05	O
)	O
•	O
any	O
version	O
of	O
the	O
seedlings	O
corpus	B
,	O
whether	O
acquired	O
via	O
homebank	O
or	O
otherwise	O
•	O
dihard	O
i	O
evaluation	B
set	I
portions	O
of	O
mixer6	O
have	O
previously	O
been	O
excerpted	O
for	O
use	O
in	O
the	O
nist	O
sre10	O
and	O
sre12	O
evaluation	B
sets	O
,	O
which	O
also	O
may	O
not	O
be	O
used	O
.	O
all	O
training	B
data	I
should	O
be	O
thoroughly	O
documented	O
in	O
the	O
system	O
description	O
document	O
(	O
see	O
appendix	O
f	O
)	O
at	O
the	O
end	O
of	O
the	O
challenge	B
.	O
for	O
a	O
list	O
of	O
suggested	O
training	O
corpora	B
,	O
please	O
consult	O
appendix	O
e.	O
55.2	O
single	B
channel	I
data	B
the	O
single	B
channel	I
input	B
condition	B
development	O
and	O
evaluation	B
sets	O
(	O
used	O
for	O
tracks	B
1	O
and	O
2	O
)	O
consist	O
of	O
selections	O
of	O
5	O
-	O
10	O
minute	O
duration	O
samples4	O
drawn	O
from	O
11	O
domains	O
,	O
each	O
containing	O
approximately	O
2	O
hours	B
of	O
audio	O
.	O
for	O
most	O
domains	O
,	O
the	O
same	O
source	B
is	O
used	O
for	O
both	O
the	O
development	O
and	O
evaluation	B
set	I
,	O
though	O
in	O
some	O
cases	O
the	O
development	O
and	O
evaluation	B
sets	O
use	O
diﬀerent	O
sources	O
;	O
where	O
the	O
two	O
sets	O
draw	O
from	O
diﬀerent	O
sources	O
,	O
this	O
is	O
noted	O
.	O
for	O
a	O
detailed	O
explanation	O
of	O
the	O
domains	O
and	O
sources	O
,	O
please	O
consult	O
appendix	O
a.	O
5.2.1	O
development	B
data	I
the	O
full	O
composition	O
of	O
the	O
single	B
channel	I
input	B
condition	B
development	B
set	I
,	O
including	O
domains	O
,	O
the	O
sources	O
drawn	O
on	O
for	O
each	O
domain	B
,	O
durations	O
,	O
and	O
number	O
of	O
excerpts	O
,	O
is	O
presented	O
in	O
table	O
1	O
.	O
domain	B
source	B
duration	O
(	O
hours	B
)	O
#	O
recordings	O
audiobooks	O
librivox	O
2.01	O
12	O
broadcast	O
interview	O
youthpoint	O
2.06	O
12	O
child	O
language	O
seedlings	O
1.92	O
23	O
clinical	O
ados	O
2.18	O
24	O
courtroom	O
scotus	O
2.08	O
12	O
map	O
task	O
dciem	O
2.53	O
23	O
meeting	O
rt04	O
2.45	O
14	O
restaurant	O
cir	O
2.03	O
12	O
sociolinguistic	O
(	O
field	O
)	O
slx	O
2.01	O
12	O
sociolinguistic	O
(	O
lab	O
)	O
mixer6	O
2.67	O
16	O
web	O
video	O
vast	O
1.89	O
32	O
total	O
-	O
23.81	O
192	O
table	O
1	O
:	O
single	B
channel	I
condition	B
development	B
set	I
composition	O
.	O
for	O
explanation	O
of	O
domains	O
and	O
sources	O
,	O
consult	O
appendix	O
a.	O
5.2.2	O
evaluation	B
data	B
the	O
full	O
composition	O
of	O
the	O
single	B
channel	I
input	B
condition	B
development	B
set	I
,	O
including	O
domains	O
,	O
the	O
sources	O
drawn	O
on	O
for	O
each	O
domain	B
,	O
durations	O
,	O
and	O
number	O
of	O
excerpts	O
,	O
is	O
presented	O
in	O
table	O
2	O
.	O
note	O
that	O
this	O
set	B
uses	O
diﬀerent	O
sources	O
than	O
the	O
development	B
set	I
for	O
two	O
domains	O
:	O
•	O
the	O
meeting	O
domain	B
draws	O
from	O
roar	O
instead	O
of	O
rt04	O
•	O
the	O
sociolinguistic	O
(	O
field	O
)	O
domain	B
draws	O
from	O
dass	O
instead	O
of	O
slx	O
the	O
domain	B
from	O
which	O
each	O
sample	O
is	O
drawn	O
will	O
not	O
be	O
provided	O
during	O
the	O
evaluation	B
period	O
,	O
but	O
will	O
be	O
revealed	O
at	O
the	O
conclusion	O
of	O
the	O
evaluation	B
.	O
4excepting	O
data	B
drawn	O
from	O
the	O
web	O
video	O
domain	B
,	O
which	O
range	O
from	O
under	O
1	O
minute	O
to	O
more	O
than	O
10	O
minutes	O
.	O
6domain	O
source	B
duration	O
(	O
hours	B
)	O
#	O
recordings	O
audiobooks	O
librivox	O
-	O
-	O
broadcast	O
interview	O
youthpoint	O
-	O
-	O
child	O
language	O
seedlings	O
-	O
-	O
clinical	O
ados	O
-	O
-	O
courtroom	O
scotus	O
-	O
-	O
map	O
task	O
dciem	O
-	O
-	O
meeting	O
roar	O
-	O
-	O
restaurant	O
cir	O
-	O
-	O
sociolinguistic	O
(	O
field	O
)	O
dass	O
-	O
-	O
sociolinguistic	O
(	O
lab	O
)	O
mixer6	O
-	O
-	O
web	O
video	O
vast	O
-	O
-	O
total	O
-	O
22.49	O
194	O
table	O
2	O
:	O
single	B
channel	I
condition	B
evaluation	B
set	I
composition	O
.	O
for	O
explanation	O
of	O
domains	O
and	O
sources	O
,	O
consult	O
appendix	O
a.	O
5.2.3	O
segmentation	B
all	O
reference	B
diarization	B
was	O
produced	O
at	O
ldc	O
by	O
annotators	O
using	O
a	O
tool	O
equipped	O
with	O
a	O
spectrogam	O
display	O
.	O
annotators	O
were	O
instructed	O
to	O
segment	B
the	O
recordings	O
into	O
labeled	O
speaker	B
turns	O
,	O
splitting	O
on	O
pauses	O
>	O
200	O
ms	O
,	O
where	O
a	O
pause	O
by	O
speaker	B
“	O
s	O
”	O
is	O
deﬁned	O
as	O
any	O
segment	B
of	O
time	B
during	O
which	O
“	O
s	O
”	O
is	O
not	O
producing	O
a	O
vocalization	O
of	O
any	O
kind	O
,	O
where	O
vocalization	O
is	O
deﬁned	O
as	O
any	O
noise	O
produced	O
by	O
the	O
speaker	B
by	O
means	O
of	O
the	O
vocal	O
apparatus5	O
.	O
boundaries	B
were	O
placed	O
within	O
10	O
ms	O
of	O
the	O
true	O
boundary	O
,	O
taking	O
care	O
not	O
to	O
truncate	O
sounds	O
at	O
edges	O
of	O
words	B
(	O
e.g.	O
,	O
utterance-ﬁnal	O
fricatives	O
or	O
utterance	O
initial	O
stops	O
)	O
.	O
for	O
some	O
recordings	O
(	O
e.g.	O
,	O
those	O
from	O
roar	O
)	O
,	O
close	O
-	O
talking	O
microphones	O
existed	O
for	O
each	O
speaker	B
;	O
in	O
these	O
cases	O
,	O
segmentation	B
was	O
performed	O
separately	O
for	O
each	O
speaker	B
using	O
their	O
individual	O
microphone	O
.	O
reference	B
sad	O
was	O
then	O
derived	O
from	O
these	O
segmentations	O
by	O
merging	O
overlapping	B
speech	I
segments	O
and	O
removing	O
speaker	B
identiﬁcation	O
.	O
5.2.4	O
pii	O
a	O
limited	O
number	O
of	O
recordings	O
from	O
ados	O
,	O
cir	O
,	O
and	O
dass	O
contained	O
regions	O
carrying	O
personal	O
identifying	O
information	B
(	O
pii	O
)	O
,	O
which	O
had	O
to	O
be	O
removed	O
prior	O
to	O
publication	O
.	O
as	O
systems	O
have	O
no	O
way	O
of	O
plausibly	O
dealing	O
with	O
these	O
regions	O
,	O
they	O
will	O
not	O
be	O
scored	O
and	O
the	O
relevant	O
uem	O
ﬁles	O
reﬂect	O
this	O
.	O
the	O
method	B
used	O
to	O
de	O
-	O
identify	O
these	O
regions	O
diﬀers	O
from	O
source	B
to	O
source	B
,	O
with	O
some	O
opting	O
to	O
replace	O
pii	O
containing	O
regions	O
with	O
a	O
pure	O
tone	O
,	O
while	O
others	O
used	O
an	O
approach	O
based	O
on	O
low	O
-	O
pass	O
ﬁltering	O
.	O
please	O
see	O
appendix	O
a	O
for	O
details	O
about	O
how	O
pii	O
was	O
dealt	O
with	O
for	O
each	O
source	B
.	O
5.2.5	O
file	O
formats	O
all	O
audio	O
and	O
annotations	O
will	O
be	O
distributed	O
via	O
ldc	O
.	O
the	O
audio	O
will	O
be	O
distributed	O
as	O
single	B
channel	I
,	O
16	O
bit	O
flac	O
ﬁles	O
sampled	O
at	O
16	O
khz	O
,	O
while	O
reference	B
speech	O
segmentations	O
will	O
be	O
distributed	O
as	O
htk	O
label	O
ﬁles	O
.	O
in	O
the	O
case	O
of	O
the	O
development	B
set	I
,	O
a	O
reference	B
diarization	B
will	O
be	O
provided	O
,	O
which	O
will	O
be	O
distributed	O
as	O
rich	B
transcription	I
time	B
marked	O
(	O
rttm	O
)	O
ﬁles	O
.	O
for	O
details	O
regarding	O
these	O
ﬁle	O
formats	O
,	O
please	O
see	O
appendix	O
b	O
and	O
appendix	O
c.	O
5for	O
instance	O
,	O
speech	O
(	O
including	O
yelled	O
and	O
whispered	O
speech	O
)	O
,	O
backchannels	O
,	O
ﬁlled	O
pauses	O
,	O
singing	O
,	O
speech	O
errors	B
and	O
disﬂu-	O
encies	O
,	O
infant	O
babbling	O
or	O
vocalizations	O
,	O
laughter	O
,	O
coughs	O
,	O
breaths	O
,	O
lipsmacks	O
,	O
and	O
humming	O
.	O
75.2.6	O
diﬀerences	O
from	O
dihard	O
i	O
while	O
the	O
single	B
channel	I
input	B
condition	B
development	O
and	O
evaluation	B
sets	O
are	O
supersets	O
of	O
those	O
used	O
in	O
dihard	O
i	O
,	O
they	O
exhibit	O
several	O
notable	O
diﬀerences	O
:	O
•	O
the	O
seedlings	O
source	B
from	O
the	O
child	O
language	O
domain	B
has	O
been	O
re	O
-	O
annotated	O
from	O
scratch	O
to	O
correct	O
inconsistencies	O
and	O
outright	O
errors	B
present	O
in	O
dihard	O
i	O
•	O
the	O
vast	O
source	B
from	O
the	O
web	O
video	O
domain	B
has	O
been	O
re	O
-	O
annotated	O
from	O
scratch	O
to	O
correct	O
incon-	O
sistencies	O
and	O
outright	O
errors	B
present	O
in	O
dihard	O
i	O
•	O
the	O
dihard	O
i	O
sociolinguistic	O
interview	O
domain	B
has	O
been	O
split	O
into	O
two	O
domains	O
for	O
dihard	O
ii	O
:	O
–	O
sociolinguistic	O
(	O
field	O
)	O
–	O
sociolinguistic	O
interviews	O
conducted	O
in	O
the	O
ﬁeld	O
–	O
sociolinguistic	O
(	O
lab	O
)	O
–	O
sociolinguistic	O
interviews	O
conducted	O
in	O
a	O
laboratory	O
setting	O
•	O
two	O
additional	O
hours	B
of	O
mixer6	O
annotation	O
have	O
been	O
added	O
so	O
that	O
the	O
sociolinguistic	O
(	O
lab	O
)	O
domain	B
is	O
represented	O
in	O
both	O
the	O
development	O
and	O
evaluation	B
sets	O
•	O
two	O
hours	B
of	O
new	O
annotation	O
for	O
the	O
previously	O
unseen	O
dass	O
source	B
have	O
been	O
added	O
so	O
that	O
the	O
sociolinguistic	O
(	O
field	O
)	O
domain	B
is	O
represented	O
in	O
both	O
the	O
development	O
and	O
evaluation	B
sets	O
•	O
two	O
additional	O
hours	B
of	O
cir	O
annotation	O
have	O
been	O
added	O
so	O
that	O
the	O
restaurant	O
domain	B
is	O
rep-	O
resented	O
in	O
both	O
the	O
development	O
and	O
evaluation	B
sets	O
•	O
minor	O
errors	B
in	O
the	O
pre	O
-	O
processing	B
scripts	O
were	O
corrected	O
,	O
which	O
may	O
result	O
in	O
small	O
changes	O
to	O
the	O
speaker	B
segmentation	I
for	O
domains	O
which	O
did	O
not	O
undergo	O
complete	O
re	O
-	O
annotation	O
•	O
all	O
speaker	B
ids	O
and	O
ﬁle	O
ids	O
were	O
re	O
-	O
generated	O
•	O
regions	O
of	O
recordings	O
known	O
to	O
contain	O
pii	O
are	O
no	O
longer	O
scored	O
;	O
see	O
the	O
uem	O
ﬁles	O
distributed	O
with	O
the	O
development	O
and	O
evaluation	B
releases	O
for	O
each	O
recording	B
’s	O
scoring	O
regions	O
5.3	O
multichannel	B
data	B
the	O
multichannel	B
input	B
condition	B
development	O
and	O
evaluation	B
sets	O
are	O
drawn	O
from	O
the	O
chime-5	O
dinner	O
party	O
corpus	B
,	O
a	O
corpus	B
of	O
conversational	O
speech	O
collected	O
during	O
dinner	O
parties	O
held	O
in	O
real	O
homes	O
.	O
twenty	O
parties	O
were	O
recorded	O
,	O
each	O
lasting	O
between	O
2	O
and	O
3	O
hours	B
and	O
having	O
4	O
participants	B
:	O
two	O
hosts	O
and	O
two	O
guests	O
.	O
the	O
only	O
constraints	O
placed	O
on	O
these	O
parties	O
were	O
that	O
they	O
last	O
at	O
least	O
2	O
hours	B
and	O
consist	O
of	O
three	O
phases	O
,	O
each	O
of	O
which	O
was	O
held	O
in	O
a	O
diﬀerent	O
location	O
within	O
the	O
home	O
:	O
•	O
kitchen	O
–	O
where	O
the	O
meal	O
was	O
prepared	O
•	O
dining	O
–	O
area	O
the	O
meal	O
was	O
eaten	O
in	O
•	O
living	O
–	O
location	O
of	O
post	O
-	O
dinner	O
conversation	O
/	O
socializing	O
participants	B
were	O
allowed	O
to	O
move	O
freely	O
between	O
locations	O
and	O
speak	O
on	O
any	O
topics	O
they	O
desired	O
subject	O
to	O
the	O
requirement	O
that	O
each	O
phase	O
lasted	O
at	O
least	O
30	O
minutes	O
.	O
all	O
parties	O
were	O
recorded	O
using	O
commercially	O
available	O
microphone	O
arrays	O
representative	O
of	O
those	O
that	O
might	O
be	O
found	O
in	O
an	O
actual	O
home	O
or	O
oﬃce	O
environment	O
.	O
within	O
each	O
home	O
,	O
6	O
microsoft	O
kinect	O
devices	O
(	O
4	O
channel	O
linear	O
arrays	O
)	O
were	O
distributed	O
so	O
as	O
to	O
ensure	O
that	O
each	O
location	O
was	O
always	O
captured	O
by	O
at	O
least	O
two	O
arrays	O
.	O
this	O
yielded	O
24	O
channels	B
(	O
6	O
arrays	O
x	O
4	O
channels	B
per	O
array	O
)	O
of	O
audio	O
for	O
each	O
session	O
.	O
for	O
additional	O
details	O
regarding	O
the	O
recording	B
setup	B
,	O
please	O
consult	O
the	O
chime-5	O
website	O
.	O
85.3.1	O
development	B
set	I
the	O
dihard	O
ii	O
multichannel	B
input	B
condition	B
development	B
set	I
combines	O
the	O
chime-5	O
training	O
and	O
devel-	O
opment	O
sets	O
and	O
encompasses	O
45	O
hours	B
of	O
dinner	O
parties	O
from	O
18	O
homes	O
.	O
5.3.2	O
evaluation	B
set	I
the	O
dihard	O
ii	O
multichannel	B
input	B
condition	B
evaluation	B
set	I
is	O
identical	O
to	O
the	O
chime-5	O
evaluation	B
set	I
and	O
consists	O
of	O
5	O
hours	B
of	O
dinner	O
parties	O
from	O
2	O
homes	O
.	O
5.3.3	O
array	O
synchronization	O
due	O
to	O
a	O
combination	O
of	O
clock	O
drift	O
and	O
random	O
frame	B
dropping	O
,	O
the	O
kinects	O
within	O
each	O
recording	B
session	O
exhibit	O
massive	O
desynchronization	O
,	O
both	O
with	O
each	O
other	O
and	O
with	O
the	O
binaural	O
recording	B
devices	O
worn	O
by	O
participants	B
.	O
this	O
asynchrony	O
worsens	O
the	O
further	O
into	O
a	O
recording	B
session	O
one	O
goes	O
with	O
the	O
result	O
that	O
for	O
some	O
sessions	O
,	O
the	O
median	O
lag	O
between	O
one	O
device	O
and	O
another	O
is	O
on	O
the	O
order	B
of	O
seconds	B
by	O
the	O
time	B
participants	B
enter	O
into	O
the	O
post	O
-	O
dinner	O
socialization	O
period	O
.	O
for	O
this	O
reason	O
,	O
each	O
kinect	O
device	O
is	O
treated	O
separately	O
for	O
the	O
purpose	O
of	O
the	O
evaluation	B
,	O
meaning	O
that	O
for	O
each	O
session	O
participants	B
should	O
run	O
their	O
systems	O
once	O
per	O
array	O
,	O
resulting	O
in	O
6	O
rttms6	O
(	O
one	O
per	O
kinect	O
)	O
per	O
session	O
.	O
5.3.4	O
segmentation	B
the	O
multichannel	B
input	B
condition	B
evaluation	B
set	I
reference	B
diarization	B
was	O
created	O
manually	O
by	O
annotators	O
at	O
ldc	O
using	O
the	O
same	O
process	B
described	O
in	O
section	O
5.2.3	O
.	O
for	O
each	O
speaker	B
,	O
segmentation	B
was	O
performed	O
from	O
that	O
speaker	B
’s	O
binaural	O
recording	B
device	O
.	O
however	O
,	O
due	O
to	O
lack	O
of	O
synchronization	O
between	O
the	O
the	O
binaural	O
recording	B
devices	O
and	O
kinects	O
(	O
see	O
section	O
5.3.3	O
)	O
,	O
this	O
segmentation	B
then	O
had	O
to	O
be	O
corrected	O
for	O
each	O
array	O
.	O
the	O
correction	O
process	B
used	O
is	O
identical	O
to	O
that	O
used	O
for	O
chime-5	O
and	O
consists	O
of	O
two	O
stages7	O
:	O
•	O
every	O
10	O
seconds	B
,	O
estimate	O
the	O
current	O
delay	O
between	O
the	O
binaural	O
recording	B
device	O
and	O
the	O
kinect	O
using	O
normalized	O
cross	O
-	O
correlation	O
•	O
for	O
each	O
speaker	B
turn	O
,	O
shift	O
the	O
boundaries	B
established	O
for	O
the	O
binaural	O
recording	B
device	O
by	O
the	O
estimated	O
delay	O
due	O
to	O
time	B
constraints	O
,	O
the	O
ldc	O
manual	O
segmentation	B
process	B
could	O
not	O
be	O
implemented	O
for	O
the	O
devel-	O
opment	O
set	B
.	O
for	O
the	O
development	B
set	I
,	O
all	O
segmentations	O
come	O
from	O
the	O
turn	O
boundaries	B
established	O
during	O
chime-5	O
transcription	B
.	O
5.3.5	O
pii	O
portions	O
of	O
the	O
chime-5	O
corpus	B
contain	O
pii	O
or	O
sensitive	O
information	B
,	O
which	O
had	O
to	O
be	O
removed	O
prior	O
to	O
publication	O
.	O
these	O
regions	O
(	O
200	O
-	O
300	O
across	O
the	O
entire	O
corpus	B
)	O
have	O
been	O
zeroed	O
out	O
in	O
the	O
released	O
audio	O
.	O
5.3.6	O
file	O
formats	O
audio	O
will	O
be	O
distributed	O
via	O
university	O
of	O
sheﬃeld	O
,	O
while	O
annotations	O
will	O
be	O
distributed	O
via	O
ldc	O
.	O
all	O
audio	O
will	O
be	O
distributed	O
as	O
single	B
channel	I
,	O
16	O
bit	O
wav	O
ﬁles	O
sampled	O
at	O
16	O
khz	O
.	O
there	O
will	O
be	O
one	O
ﬁle	O
per	O
channel	O
6excepting	O
sessions	O
s05	O
and	O
s22	O
of	O
the	O
development	B
set	I
,	O
which	O
are	O
missing	O
arrays	O
u05	O
and	O
u03	O
respectively	O
.	O
7for	O
the	O
precise	O
implementation	O
,	O
see	O
https://github.com/chimechallenge/chime5-synchronisation	O
.	O
9for	O
each	O
microphone	O
array	O
,	O
yielding	O
16	O
ﬁles	O
per	O
recording	B
session	O
.	O
reference	B
speech	O
segmentations	O
will	O
be	O
distributed	O
as	O
htk	O
label	O
ﬁles	O
(	O
appendix	O
b	O
)	O
,	O
with	O
one	O
label	O
ﬁle	O
distributed	O
per	O
array	O
.	O
in	O
the	O
case	O
of	O
the	O
development	B
set	I
,	O
a	O
reference	B
diarization	B
will	O
be	O
provided	O
,	O
which	O
will	O
be	O
distributed	O
as	O
rich	B
transcription	I
time	B
marked	O
(	O
rttm	O
)	O
ﬁles	O
(	O
appendix	O
c	O
)	O
.	O
6	O
evaluation	B
rules	O
the	O
2019	O
dihard	B
challenge	I
is	O
an	O
open	O
evaluation	B
where	O
the	O
test	B
data	I
is	O
sent	O
to	O
participants	B
,	O
who	O
will	O
process	B
the	O
data	B
locally	O
and	O
submit	O
their	O
system	O
outputs	O
to	O
ldc	O
for	O
scoring	O
.	O
as	O
such	O
,	O
the	O
participants	B
have	O
agreed	O
to	O
process	B
the	O
data	B
in	O
accordance	O
with	O
the	O
following	O
rules	O
:	O
•	O
while	O
most	O
of	O
the	O
test	B
data	I
is	O
actually	O
,	O
or	O
eﬀectively	O
,	O
unexposed	O
,	O
portions	O
have	O
been	O
exposed	O
in	O
part	O
in	O
the	O
following	O
corpora	B
:	O
–	O
dciem	O
map	O
task	O
corpus	B
(	O
ldc96s38	O
)	O
–	O
mixer6	O
speech	O
(	O
ldc2013s03	O
)	O
–	O
digital	O
archive	O
of	O
southern	O
speech	O
(	O
ldc2012s03	O
and	O
ldc2016s05	O
)	O
–	O
nist	O
sre10	O
evaluation	B
data	B
–	O
nist	O
sre12	O
evaluation	B
data	B
–	O
dihard	O
i	O
evaluation	B
sets	O
–	O
the	O
seedlings	O
subset	O
of	O
homebank	O
use	O
of	O
these	O
corpora	B
is	O
prohibited	O
.	O
•	O
manual	O
/	O
human	O
investigation	O
of	O
the	O
evaluation	B
data	B
(	O
e.g.	O
,	O
listening	O
,	O
segmentation	B
,	O
or	O
transcription	B
)	O
prior	O
to	O
the	O
end	O
of	O
the	O
evaluation	B
is	O
disallowed	O
.	O
•	O
participants	B
are	O
allowed	O
to	O
use	O
any	O
automatically	O
derived	O
information	B
(	O
e.g.	O
,	O
automatic	O
identiﬁcation	O
of	O
the	O
domain	B
)	O
for	O
the	O
development	O
and	O
evaluation	B
ﬁles	O
.	O
•	O
during	O
the	O
evaluation	B
period	O
,	O
each	O
team	O
may	O
make	O
at	O
most	O
six	O
submissions	O
per	O
day	O
.	O
•	O
use	O
of	O
the	O
evaluation	B
server	O
for	O
per	O
-	O
recording	B
hyperparameter	O
tuning	O
(	O
e.g.	O
,	O
attempting	O
to	O
establish	O
the	O
reference	B
number	O
of	O
speakers	O
in	O
each	O
recording	B
by	O
systematically	O
altering	O
clustering	B
thresholds	O
one	O
recording	B
at	O
a	O
time	B
)	O
is	O
expressly	O
prohibited	O
.	O
we	O
are	O
being	O
very	O
generous	O
compared	O
to	O
other	O
machine	O
learning	O
competitions	O
with	O
our	O
submission	O
limits	O
,	O
so	O
please	O
do	O
not	O
abuse	O
them	O
.	O
if	O
teams	O
are	O
caught	O
violating	O
this	O
rule	O
,	O
we	O
will	O
be	O
forced	O
to	O
adopt	O
stricter	O
limits	O
.	O
in	O
addition	O
to	O
the	O
above	O
data	B
processing	B
rules	O
,	O
the	O
participants	B
agree	O
to	O
comply	O
with	O
the	O
following	O
general	O
requirements	O
:	O
•	O
the	O
participants	B
agree	O
to	O
submit	O
a	O
system	O
description	O
document	O
describing	O
the	O
algorithms	O
,	O
data	B
,	O
and	O
computational	O
resources	O
used	O
for	O
all	O
of	O
their	O
ﬁnal	O
systems	O
(	O
i.e.	O
,	O
systems	O
present	O
on	O
the	O
leaderboard	O
at	O
the	O
end	O
of	O
the	O
challenge	B
)	O
.	O
these	O
documents	O
will	O
be	O
submitted	O
at	O
the	O
end	O
of	O
the	O
evaluation	B
and	O
should	O
follow	O
the	O
format	O
set	B
forth	O
in	O
appendix	O
f.	O
•	O
the	O
participants	B
agree	O
to	O
deposit	O
the	O
rttm	O
outputs	O
of	O
their	O
ﬁnal	O
systems	O
on	O
zenodo	O
.	O
at	O
the	O
conclusion	O
of	O
the	O
challenge	B
,	O
the	O
organizers	O
will	O
deposit	O
an	O
archive	O
on	O
zenodo	O
containing	O
all	O
system	O
descriptions	O
and	O
ﬁnal	O
system	O
outputs	O
.	O
10failure	O
to	O
abide	O
by	O
these	O
rules	O
will	O
be	O
considered	O
grounds	O
for	O
disqualiﬁcation	O
and	O
will	O
result	O
in	O
loss	O
of	O
access	O
to	O
the	O
data	B
,	O
loss	O
of	O
access	O
to	O
the	O
scoring	O
server	O
,	O
and	O
the	O
removal	O
of	O
all	O
existing	O
submissions	O
from	O
the	O
scoring	O
server	O
.	O
7	O
evaluation	B
protocol	O
7.1	O
registration	O
to	O
register	O
for	O
the	O
evaluation	B
,	O
participants	B
should	O
email	O
dihardchallenge@gmail.com	O
with	O
the	O
subject	O
line	O
“	O
registration	O
”	O
and	O
the	O
following	O
details	O
:	O
•	O
organization	O
–	O
the	O
organization	O
competing	O
(	O
e.g.	O
,	O
nist	O
,	O
bbn	O
,	O
sri	O
)	O
•	O
team	O
name	O
–	O
the	O
name	O
to	O
displayed	O
on	O
the	O
leaderboard	O
•	O
tracks	B
–	O
which	O
tracks	B
they	O
will	O
be	O
competing	O
in	O
7.2	O
ldc	O
data	B
license	O
agreement	O
one	O
participant	O
from	O
each	O
site	O
must	O
sign	O
the	O
data	B
license	O
agreement	O
(	O
available	O
on	O
the	O
challenge	B
website	O
)	O
and	O
return	O
it	O
to	O
ldc	O
:	O
(	O
1	O
)	O
by	O
email	O
to	O
ldc@ldc.upenn.edu	O
or	O
(	O
2	O
)	O
by	O
facsimile	O
,	O
attention	O
:	O
membership	O
oﬃce	O
,	O
fax	O
number	O
(	O
+1	O
)	O
215	O
-	O
573	O
-	O
2175	O
.	O
they	O
will	O
also	O
need	O
to	O
create	O
an	O
ldc	O
online	O
user	O
account	O
(	O
https	O
:	O
//catalog.ldc.upenn.edu	O
/	O
signup	O
)	O
,	O
which	O
will	O
be	O
used	O
to	O
download	O
the	O
dev	O
and	O
eval	O
releases	O
.	O
7.3	O
chime-5	O
data	B
license	O
agreement	O
ldc	O
does	O
not	O
have	O
permission	O
to	O
distribute	O
the	O
chime-5	O
audio	O
data	B
.	O
consequently	O
,	O
teams	O
interested	O
in	O
participating	O
in	O
tracks	B
3	O
and	O
4	O
must	O
obtain	O
this	O
data	B
from	O
university	O
of	O
sheﬃeld	O
.	O
note	O
that	O
this	O
applies	O
to	O
all	O
interested	O
teams	O
,	O
even	O
those	O
who	O
participated	O
in	O
the	O
chime-5	O
challenge	B
.	O
to	O
do	O
so	O
,	O
visit	O
https://licensing.sheffield.ac.uk/i/data/chime5.html	O
and	O
select	O
the	O
appropriate	O
license	O
.	O
not	O
-	O
for	O
-	O
proﬁt	O
organizations	O
should	O
select	O
the	O
non	O
-	O
commercial	O
license	O
.	O
all	O
other	O
organizations	O
should	O
select	O
the	O
commercial	O
license	O
,	O
regardless	O
of	O
intended	O
use	O
for	O
the	O
data	B
.	O
7.4	O
baseline	B
systems	O
access	O
to	O
all	O
baseline	B
systems	O
is	O
provided	O
via	O
the	O
challenge	B
website	O
.	O
7.5	O
results	B
submission	O
all	O
system	O
submissions	O
will	O
be	O
done	O
via	O
an	O
instance	O
of	O
codalab	O
running	O
on	O
ldc	O
servers	O
.	O
for	O
instructions	O
on	O
how	O
to	O
register	O
an	O
account	O
and	O
submit	O
results	B
,	O
see	O
the	O
challenge	B
website	O
.	O
118	O
interspeech	O
special	O
session	O
the	O
results	B
of	O
the	O
challenge	B
will	O
be	O
presented	O
at	O
a	O
special	O
session	O
at	O
interspeech	O
2019	O
,	O
held	O
september	O
15	O
-	O
19	O
,	O
2018	O
in	O
graz	O
,	O
austria	O
.	O
researchers	O
wishing	O
to	O
submit	O
papers	O
should	O
do	O
so	O
through	O
the	O
interspeech	O
submission	O
portal	O
.	O
additional	O
instructions	O
will	O
be	O
provided	O
through	O
the	O
challenge	B
website	O
once	O
the	O
submission	O
portal	O
opens	O
.	O
9	O
updates	O
updates	O
to	O
this	O
evaluation	B
plan	I
will	O
be	O
made	O
available	O
via	O
the	O
mailing	O
list	O
and	O
the	O
challenge	B
website	O
(	O
https	O
:	O
//coml.lscp.ens.fr	O
/	O
dihard	O
/	O
index.html	O
)	O
.	O
12appendix	O
a	O
:	O
single	B
channel	I
condition	B
domains	O
and	O
sources	O
domains	O
•	O
audiobooks	O
excerpts	O
from	O
recordings	O
of	O
speakers	O
reading	O
aloud	O
passages	O
from	O
public	O
domain	B
english	O
language	O
texts	O
.	O
the	O
recordings	O
were	O
selected	O
from	O
librivox	O
and	O
each	O
recording	B
consists	O
of	O
a	O
single	O
,	O
amateur	O
reader	O
.	O
care	O
was	O
taken	O
to	O
make	O
sure	O
that	O
the	O
chapters	O
and	O
speakers	O
drawn	O
from	O
were	O
not	O
present	O
in	O
librispeech	O
,	O
which	O
also	O
draws	O
from	O
librivox	O
.	O
•	O
broadcast	O
interview	O
student	O
-	O
lead	O
radio	O
interviews	O
conducted	O
during	O
the	O
1970s	O
with	O
popular	O
ﬁgures	O
of	O
the	O
era	O
(	O
e.g.	O
,	O
ann	O
landers	O
,	O
mark	O
hamill	O
,	O
buckminster	O
fuller	O
,	O
and	O
isaac	O
asimov	O
)	O
.	O
the	O
recordings	O
are	O
selected	O
from	O
the	O
unpublished	O
ldc	O
youthpoint	O
corpus	B
.	O
•	O
child	O
language	O
excerpts	O
from	O
day	O
long	O
recordings	O
of	O
infant	O
(	O
6	O
to	O
18	O
months	O
)	O
speech	O
.	O
all	O
audio	O
was	O
recorded	O
in	O
the	O
home	O
using	O
a	O
lena	O
recording	B
device	O
,	O
which	O
consists	O
of	O
a	O
vest	O
worn	O
by	O
the	O
child	O
into	O
which	O
a	O
microphone	O
has	O
been	O
sewn	O
.	O
because	O
of	O
their	O
age	O
,	O
the	O
child	O
“	O
speech	O
”	O
consists	O
of	O
a	O
mixture	O
of	O
simplistic	O
speech	O
consisting	O
of	O
short	O
utterances	B
(	O
possible	O
very	O
disﬂuent	O
)	O
,	O
babbling	O
,	O
laughing	O
,	O
crying	O
,	O
and	O
diverse	O
uncategorizeable	O
non	O
-	O
speech	O
vocalizations	O
.	O
other	O
speakers	O
may	O
be	O
present	O
in	O
the	O
recording	B
,	O
typically	O
one	O
or	O
more	O
parents	O
,	O
but	O
also	O
siblings	O
,	O
friends	O
of	O
siblings	O
,	O
aunts	O
and	O
uncles	O
,	O
and	O
adult	O
friends	O
of	O
the	O
parents	O
.	O
some	O
of	O
the	O
recordings	O
have	O
quiet	O
backgrounds	O
,	O
while	O
others	O
have	O
radios	O
or	O
televisions	O
playing	O
.	O
all	O
recordings	O
were	O
taken	O
from	O
the	O
seedlings	O
corpus	B
.	O
•	O
clinical	O
recordings	O
of	O
autism	O
diagnostic	O
observation	O
schedule	O
(	O
ados	O
)	O
interviews	O
conducted	O
to	O
identify	O
whether	O
a	O
child	O
ﬁt	O
the	O
clinical	O
diagnosis	O
for	O
autism	O
.	O
ados	O
is	O
a	O
roughly	O
hour	O
long	O
semi	O
-	O
structured	O
interview	O
in	O
which	O
clinicians	O
attempt	O
to	O
elicit	O
language	O
that	O
diﬀerentiates	O
children	O
with	O
autism	O
spec-	O
trum	O
disorder	O
from	O
those	O
without	O
(	O
e.g.	O
,	O
“	O
what	O
does	O
being	O
a	O
friend	O
mean	O
to	O
you	O
?	O
”	O
)	O
.	O
the	O
children	O
included	O
in	O
this	O
collection	O
ranged	O
from	O
12	O
-	O
16	O
years	O
in	O
age	O
and	O
exhibit	O
a	O
range	O
of	O
diagnoses	O
from	O
autism	O
to	O
non	O
-	O
autism	O
language	O
disorder	O
to	O
adhd	O
to	O
typically	O
developing	O
.	O
interviews	O
are	O
typically	O
recorded	O
for	O
quality	B
assurance	O
purposes	O
;	O
in	O
this	O
case	O
,	O
the	O
recording	B
was	O
conducted	O
using	O
a	O
ceiling	O
mounted	O
microphone	O
.	O
the	O
recordings	O
are	O
selected	O
from	O
the	O
unpublished	O
ldc	O
ados	O
corpus	B
.	O
•	O
courtroom	O
recordings	O
of	O
oral	O
arguments	O
from	O
the	O
2001	O
term	O
of	O
the	O
u.s	O
.	O
supreme	O
court	O
.	O
the	O
original	O
recordings	O
were	O
made	O
using	O
individual	O
table	O
-	O
mounted	O
microphones	O
,	O
one	O
for	O
each	O
participant	O
,	O
which	O
could	O
be	O
switched	O
on	O
and	O
oﬀ	O
by	O
the	O
speakers	O
as	O
appropriate	O
.	O
the	O
outputs	O
of	O
these	O
microphones	O
were	O
summed	O
and	O
recorded	O
on	O
a	O
single	O
-	O
channel	O
reel	O
-	O
to	O
-	O
reel	O
analogue	O
tape	O
recorder	O
.	O
all	O
recordings	O
taken	O
from	O
scotus	O
,	O
an	O
unpublished	O
ldc	O
corpus	B
.	O
•	O
map	O
task	O
recordings	O
of	O
speakers	O
engaged	O
in	O
a	O
map	O
task	O
.	O
each	O
map	O
task	O
session	O
contains	O
two	O
speakers	O
sitting	O
opposite	O
one	O
another	O
at	O
a	O
table	O
.	O
each	O
speaker	B
has	O
a	O
map	O
visible	O
only	O
to	O
him	O
and	O
a	O
designated	O
role	O
as	O
either	O
“	O
leader	O
”	O
or	O
“	O
follower	O
”	O
.	O
the	O
leader	O
has	O
a	O
route	O
marked	O
on	O
his	O
map	O
and	O
is	O
tasked	O
with	O
communicating	O
this	O
route	O
to	O
the	O
follower	O
so	O
that	O
he	O
may	O
precisely	O
reproduce	O
it	O
on	O
his	O
own	O
map	O
.	O
though	O
each	O
speaker	B
was	O
recorded	O
on	O
a	O
separate	O
channel	O
via	O
a	O
close	O
-	O
talking	O
microphone	O
,	O
these	O
have	O
been	O
mixed	O
together	O
for	O
the	O
dihard	O
releases	O
.	O
the	O
recordings	O
are	O
drawn	O
from	O
the	O
dciem	O
map	O
task	O
corpus	B
(	O
ldc96s38	O
)	O
.	O
•	O
meeting	O
recordings	O
of	O
meetings	O
containing	O
between	O
3	O
and	O
7	O
speakers	O
.	O
the	O
speech	O
in	O
these	O
meetings	O
is	O
highly	O
in-	O
teractive	O
in	O
nature	O
consisting	O
of	O
large	O
amounts	O
of	O
spontaneous	O
speech	O
containing	O
frequent	O
interruptions	O
13and	O
overlapping	B
speech	I
.	O
for	O
each	O
meeting	O
a	O
single	O
,	O
centrally	O
located	O
distant	O
microphone	O
is	O
provided	O
,	O
which	O
may	O
exhibit	O
excessively	O
low	O
gain	O
.	O
for	O
the	O
development	B
set	I
,	O
these	O
meetings	O
are	O
drawn	O
from	O
rt04	O
,	O
while	O
for	O
the	O
evaluation	B
set	I
they	O
are	O
drawn	O
from	O
roar	O
.	O
•	O
restaurant	O
informal	O
conversations	O
recorded	O
in	O
restaurants	O
using	O
binaural	O
microphones	O
.	O
each	O
session	O
contains	O
between	O
4	O
and	O
7	O
speakers	O
seated	O
at	O
the	O
same	O
table	O
at	O
a	O
restaurant	O
at	O
lunchtime	O
and	O
was	O
recorded	O
from	O
a	O
binaural	O
microphone	O
worn	O
by	O
a	O
designated	O
facilitator	O
;	O
the	O
mix	O
of	O
the	O
two	O
channels	B
recorded	O
by	O
this	O
microphone	O
are	O
provided	O
.	O
this	O
data	B
exhibits	O
the	O
following	O
properties	O
,	O
which	O
are	O
expected	O
to	O
make	O
it	O
particularly	O
challenging	O
for	O
automated	O
segmentation	B
and	O
recognition	O
:	O
–	O
due	O
to	O
the	O
microphone	O
setup	B
,	O
the	O
majority	O
of	O
the	O
speakers	O
are	O
farﬁeld	O
–	O
background	O
speech	O
from	O
neighboring	O
tables	O
is	O
often	O
present	O
,	O
sometimes	O
at	O
levels	O
close	O
to	O
that	O
of	O
the	O
primary	O
speakers	O
in	O
the	O
conversation	O
–	O
background	B
noise	I
is	O
abundant	O
with	O
clinking	O
silverware	O
,	O
moving	O
chairs	O
/	O
tables	O
,	O
and	O
loud	O
music	O
all	O
common	O
–	O
the	O
conversations	O
are	O
informal	O
and	O
highly	O
interactive	O
with	O
interruptions	O
and	O
frequent	O
overlapped	B
speech	I
all	O
data	B
is	O
taken	O
from	O
ldc	O
’s	O
unpublished	O
cir	O
corpus	B
.	O
•	O
sociolinguistic	O
ﬁeld	O
recordings	O
sociolinguistic	O
interviews	O
recorded	O
under	O
ﬁeld	O
conditions	O
.	O
recordings	O
consists	O
of	O
a	O
single	O
interviewer	O
attempting	O
to	O
elicit	O
vernacular	O
speech	O
from	O
an	O
informant	O
during	O
informal	O
conversation	O
.	O
typically	O
,	O
interviews	O
were	O
recorded	O
in	O
the	O
home	O
,	O
though	O
occasionally	O
they	O
were	O
recorded	O
in	O
a	O
public	O
location	O
such	O
as	O
a	O
park	O
or	O
cafe	O
.	O
the	O
development	B
set	I
recordings	O
were	O
drawn	O
from	O
slx	O
and	O
the	O
evaluation	B
set	I
from	O
dass	O
.	O
•	O
sociolinguistic	O
lab	O
recordings	O
sociolinguistic	O
interviews	O
recorded	O
under	O
quiet	O
conditions	O
in	O
a	O
controlled	O
environment	O
.	O
all	O
data	B
is	O
taken	O
from	O
the	O
pzm	O
microphones	O
of	O
ldc	O
’s	O
mixer	O
6	O
collection	O
(	O
ldc23013s03	O
)	O
.	O
•	O
web	O
video	O
english	O
and	O
mandarin	O
amateur	O
videos	B
collected	O
from	O
online	O
video	O
sharing	O
sites	O
(	O
e.g.	O
,	O
youtube	O
and	O
vimeo	O
)	O
.	O
this	O
domain	B
is	O
expected	O
to	O
be	O
particularly	O
challenging	O
as	O
the	O
videos	B
present	O
a	O
diverse	O
set	B
of	O
topics	O
and	O
recording	B
conditions	O
;	O
in	O
particular	O
,	O
many	O
videos	B
contain	O
multiple	O
speakers	O
talking	O
in	O
a	O
noisy	O
environment	O
,	O
where	O
it	O
can	O
be	O
diﬃcult	O
to	O
distinguish	O
speech	O
from	O
other	O
kinds	O
of	O
sounds	O
.	O
all	O
data	B
is	O
selected	O
from	O
ldc	O
’s	O
vast	O
collection	O
.	O
sources	O
•	O
ados	O
ados	O
is	O
an	O
unpublished	O
ldc	O
corpus	B
consisting	O
of	O
transcribed	O
excerpts	O
from	O
ados	O
interviews	O
con-	O
ducted	O
at	O
the	O
center	O
for	O
autism	O
research	B
(	O
car	O
)	O
at	O
the	O
children	O
’s	O
hospital	O
of	O
philadelphia	O
(	O
chop	O
)	O
.	O
all	O
interviews	O
were	O
conducted	O
at	O
car	O
by	O
trained	O
clinicians	O
using	O
ados	O
module	O
3	O
.	O
the	O
interviews	O
were	O
recorded	O
using	O
a	O
mixture	O
of	O
cameras	O
and	O
audio	O
recorded	O
from	O
a	O
ceiling	O
mounted	O
microphone	O
.	O
portions	O
of	O
these	O
interviews	O
determined	O
by	O
a	O
clinician	O
to	O
be	O
particularly	O
diagnostic	O
were	O
then	O
segmented	O
and	O
transcribed	O
.	O
note	O
that	O
in	O
order	B
to	O
publish	O
this	O
data	B
,	O
it	O
had	O
to	O
be	O
de	O
-	O
identiﬁed	O
by	O
applying	O
a	O
low	O
-	O
pass	O
ﬁlter	O
to	O
regions	O
identiﬁed	O
as	O
containing	O
personal	O
identifying	O
information	B
(	O
pii	O
)	O
.	O
pitch	B
information	B
in	O
these	O
regions	O
is	O
still	O
recoverable	O
,	O
but	O
the	O
amplitude	O
levels	O
have	O
been	O
reduced	O
relative	O
to	O
the	O
original	O
signal	B
.	O
filtering	O
was	O
done	O
with	O
a	O
10th	O
order	B
butterworth	O
ﬁlter	O
with	O
a	O
passband	O
of	O
0	O
to	O
400	O
hz	O
.	O
to	O
avoid	O
abrupt	O
transitions	O
14	O
in	O
the	O
resulting	O
waveform	O
,	O
the	O
eﬀect	O
of	O
the	O
ﬁlter	O
was	O
gradually	O
faded	O
in	O
and	O
out	O
at	O
the	O
beginning	O
and	O
end	O
of	O
the	O
regions	O
using	O
a	O
ramp	O
of	O
40	O
ms	O
.	O
•	O
cir	O
conversations	O
in	O
restaurants	O
(	O
cir	O
)	O
is	O
a	O
collection	O
of	O
informal	O
speech	O
recorded	O
in	O
restaurants	O
that	O
ldc	O
originally	O
produced	O
for	O
the	O
nsf	O
hearables	O
challenge	B
,	O
an	O
nsf	O
-	O
sponsored	O
challenge	B
designed	O
to	O
promote	O
the	O
development	O
of	O
algorithms	O
or	O
methods	O
that	O
could	O
improve	O
hearing	O
in	O
a	O
noisy	O
setting	O
.	O
it	O
consists	O
of	O
conversations	O
between	O
3	O
and	O
6	O
speakers	O
,	O
all	O
ldc	O
or	O
penn	O
employees	O
,	O
seated	O
at	O
the	O
same	O
table	O
at	O
a	O
restaurant	O
near	O
the	O
university	O
of	O
pennsylvania	O
campus	O
.	O
recording	B
sessions	O
were	O
held	O
at	O
lunch	O
time	B
using	O
a	O
rotating	O
list	O
of	O
restaurants	O
exhibiting	O
diverse	O
acoustic	O
environments	O
and	O
typically	O
lasted	O
60	O
-	O
70	O
minutes	O
.	O
all	O
recordings	O
were	O
conducted	O
using	O
binaural	O
microphones	O
mounted	O
on	O
either	O
side	O
of	O
one	O
speaker	B
’s	O
head	O
.	O
a	O
limited	O
number	O
of	O
regions	O
from	O
one	O
recording	B
were	O
found	O
to	O
contain	O
pii	O
.	O
these	O
regions	O
were	O
de-	O
identiﬁed	O
using	O
the	O
same	O
low	O
-	O
pass	O
ﬁltering	O
approach	O
as	O
in	O
ados	O
•	O
dass	O
the	O
digital	O
archive	O
of	O
southern	O
speech	O
,	O
or	O
dass	O
,	O
is	O
a	O
corpus	B
of	O
interviews	O
(	O
each	O
lasting	O
anywhere	O
from	O
3	O
to	O
13	O
hours	B
)	O
recorded	O
during	O
the	O
late	O
60s	O
and	O
70s	O
in	O
the	O
gulf	O
coast	O
region	O
of	O
the	O
united	O
states	O
.	O
it	O
is	O
part	O
of	O
the	O
larger	O
linguistic	O
atlas	O
of	O
the	O
gulf	O
states	O
(	O
lags	O
)	O
,	O
a	O
long	O
-	O
running	O
project	O
that	O
attempted	O
to	O
preserve	O
the	O
speech	O
of	O
a	O
region	O
encompassing	O
louisiana	O
,	O
alabama	O
,	O
mississippi	O
,	O
and	O
florida	O
as	O
well	O
as	O
parts	O
of	O
texas	O
,	O
tennessee	O
,	O
arkansas	O
,	O
and	O
georgia	O
.	O
each	O
interview	O
was	O
conducted	O
in	O
the	O
ﬁeld	O
by	O
a	O
trained	O
interviewer	O
,	O
who	O
attempted	O
to	O
elicit	O
conversation	O
about	O
common	O
topics	O
like	O
family	O
,	O
the	O
weather	O
,	O
household	O
articles	O
,	O
agriculture	O
,	O
and	O
social	O
connections	O
.	O
it	O
is	O
distributed	O
by	O
ldc	O
as	O
ldc2012s03	O
and	O
ldc2016s05	O
.	O
due	O
to	O
the	O
nature	O
of	O
the	O
interviews	O
,	O
they	O
sometimes	O
contain	O
pii	O
or	O
sensitive	O
materials	O
.	O
all	O
such	O
regions	O
have	O
been	O
replaced	O
by	O
tones	O
of	O
matched	O
duration	O
.	O
unfortunately	O
,	O
this	O
process	B
does	O
not	O
appear	O
to	O
have	O
been	O
systematic	O
,	O
with	O
the	O
result	O
that	O
the	O
type	O
of	O
tone	O
(	O
pure	O
or	O
complex	O
)	O
,	O
power	O
,	O
and	O
frequency	B
diﬀers	O
across	O
the	O
corpus	B
.	O
•	O
dciem	O
the	O
dciem	O
map	O
task	O
corpus	B
(	O
ldc96s38	O
)	O
is	O
a	O
collection	O
of	O
recordings	O
of	O
two	O
-	O
person	O
map	O
tasks	O
recorded	O
for	O
the	O
dciem	O
sleep	O
deprivation	O
study	O
.	O
this	O
study	O
was	O
conducted	O
by	O
the	O
defense	O
and	O
civil	O
institute	O
of	O
environmental	O
medicine	O
(	O
department	O
of	O
national	O
defense	O
,	O
canada	O
)	O
to	O
evaluate	O
the	O
eﬀect	O
of	O
drugs	O
on	O
performance	O
degradation	O
in	O
sleep	O
deprived	O
individuals	O
.	O
three	O
drug	O
conditions	O
(	O
modaﬁnil	O
vs.	O
amphetamine	O
vs.	O
placebo	O
)	O
were	O
crossed	O
with	O
three	O
sleep	O
conditions	O
(	O
18	O
hours	B
vs.	O
48	O
hours	B
vs.	O
58	O
hours	B
awake	O
)	O
.	O
during	O
each	O
session	O
,	O
subjects	O
performed	O
a	O
battery	O
of	O
neuropsychological	O
tests	O
(	O
e.g.	O
,	O
tracking	O
tasks	O
,	O
time	B
estimation	B
tasks	O
,	O
attention	O
-	O
splitting	O
tasks	O
)	O
,	O
questionnaires	O
,	O
and	O
a	O
map	O
task	O
.	O
all	O
audio	O
was	O
recorded	O
via	O
close	O
-	O
talking	O
microphones	O
under	O
quiet	O
conditions	O
.	O
•	O
librivox	O
librivox	O
is	O
a	O
collection	O
of	O
public	O
domain	B
audiobooks	O
read	O
by	O
volunteers	O
from	O
around	O
the	O
world	O
.	O
it	O
consists	O
of	O
more	O
than	O
10,000	O
recordings	O
in	O
96	O
languages	O
.	O
portions	O
have	O
previously	O
appeared	O
in	O
the	O
popular	O
librispeech	O
corpus	B
,	O
though	O
care	O
was	O
taken	O
to	O
ensure	O
that	O
dihard	O
did	O
not	O
select	O
from	O
this	O
subset	O
.	O
•	O
mixer6	O
mixer	O
6	O
(	O
ldc2013s03	O
)	O
is	O
a	O
large	O
-	O
scale	O
collection	O
of	O
english	O
speech	O
across	O
multiple	O
environments	O
,	O
modalities	O
,	O
degrees	O
of	O
formality	O
,	O
and	O
channels	B
that	O
was	O
conducted	O
at	O
ldc	O
from	O
2009	O
through	O
2010	O
.	O
the	O
collection	O
consists	O
of	O
interviews	O
with	O
594	O
native	O
speakers	O
of	O
english	O
spanning	O
1,425	O
sessions	O
,	O
each	O
roughly	O
40	O
-	O
45	O
minutes	O
in	O
duration	O
.	O
each	O
session	O
contained	O
multiple	O
components	B
(	O
e.g.	O
,	O
informal	O
conversation	O
styled	O
after	O
a	O
sociolinguistic	O
interview	O
or	O
transcript	O
reading	O
)	O
and	O
was	O
captured	O
by	O
a	O
variety	O
of	O
microphones	O
,	O
including	O
lavalier	O
,	O
head	O
-	O
mounted	O
,	O
podium	O
,	O
shotgun	O
,	O
pzm	O
,	O
and	O
array	O
microphones	O
.	O
while	O
the	O
corpus	B
was	O
released	O
without	O
speaker	B
segmentation	I
or	O
transcripts	B
,	O
a	O
portion	O
of	O
the	O
corpus	B
15was	O
subsequently	O
transcribed	O
at	O
ldc	O
.	O
dihard	O
ii	O
draws	O
its	O
selections	O
from	O
this	O
subset	O
.	O
•	O
roar	O
roar	O
is	O
a	O
collection	O
of	O
multiparty	O
(	O
3	O
to	O
6	O
participant	O
)	O
conversations	O
recorded	O
by	O
ldc	O
as	O
part	O
of	O
the	O
darpa	O
roar	O
(	O
robust	O
omnipresent	O
automatic	O
recognition	O
)	O
project	O
in	O
fall	O
2001	O
.	O
while	O
portions	O
of	O
this	O
collection	O
have	O
previously	O
been	O
exposed	O
during	O
the	O
nist	O
rt	O
evaluations	O
,	O
all	O
dihard	O
data	B
comes	O
from	O
previously	O
unexposed	O
meetings	O
.	O
the	O
meetings	O
were	O
recorded	O
at	O
ldc	O
in	O
a	O
purpose	O
built	O
room	O
using	O
a	O
combination	O
of	O
lavalier	O
,	O
head	O
mounted	O
,	O
omnidirectional	O
,	O
pzm	O
,	O
shotgun	O
,	O
podium	O
,	O
and	O
array	O
microphones	O
.	O
for	O
each	O
meeting	O
,	O
a	O
single	O
centrally	O
located	O
distant	O
microphone	O
is	O
provided	O
.	O
•	O
rt04	O
rt04	O
consists	O
of	O
meeting	O
speech	O
released	O
as	O
part	O
of	O
the	O
nist	O
spring	O
2004	O
rich	B
transcription	I
(	O
rt-04s	O
)	O
meeting	O
recognition	O
evaluation	B
development	O
and	O
evaluation	B
sets	O
.	O
this	O
data	B
was	O
later	O
re	O
-	O
released	O
by	O
ldc	O
as	O
ldc2007s11	O
and	O
ldc2007s12	O
.	O
it	O
consists	O
of	O
recordings	O
of	O
multiparty	O
(	O
3	O
to	O
7	O
participant	O
)	O
meetings	O
held	O
at	O
multiple	O
sites	O
(	O
icsi	O
,	O
nist	O
,	O
cmu	O
,	O
and	O
ldc	O
)	O
,	O
each	O
with	O
a	O
diﬀerent	O
microphone	O
setup	B
.	O
for	O
dihard	O
,	O
a	O
single	B
channel	I
is	O
distributed	O
for	O
each	O
meeting	O
,	O
corresponding	O
to	O
the	O
rt-04s	O
single	O
distant	O
microphone	O
(	O
sdm	O
)	O
condition	B
.	O
audio	O
ﬁles	O
have	O
been	O
trimmed	O
from	O
the	O
original	O
recordings	O
to	O
the	O
11	O
minute	O
scoring	O
regions	O
speciﬁed	O
in	O
the	O
rt-04s	O
un	O
-	O
partitioned	O
evaluation	B
map	O
(	O
uem	O
)	O
ﬁles8	O
.	O
•	O
scotus	O
scotus	O
is	O
an	O
unpublished	O
ldc	O
corpus	B
consisting	O
of	O
oral	O
arguments	O
from	O
the	O
2001	O
term	O
of	O
the	O
u.s	O
.	O
supreme	O
court	O
.	O
the	O
recordings	O
were	O
transcribed	O
and	O
manually	O
word	B
-	O
aligned	O
as	O
part	O
of	O
the	O
oyez	O
project	O
,	O
then	O
forced	O
aligned	O
and	O
qced	O
at	O
ldc	O
.	O
•	O
seedlings	O
seedlings	O
is	O
a	O
corpus	B
of	O
child	O
speech	O
collected	O
at	O
the	O
university	O
of	O
rochester	O
.	O
excerpts	O
from	O
day	O
-	O
long	O
recordings	O
conducted	O
in	O
the	O
home	O
were	O
selected	O
,	O
then	O
segmented	O
and	O
transcribed	O
by	O
ldc	O
.	O
•	O
slx	O
slx	O
(	O
ldc2003t15	O
)	O
is	O
a	O
corpus	B
of	O
sociolinguistic	O
interviews	O
conducted	O
in	O
the	O
1960s	O
and	O
1970s	O
by	O
bill	O
labov	O
and	O
his	O
students	O
.	O
the	O
interview	O
subjects	O
range	O
in	O
age	O
from	O
15	O
to	O
81	O
and	O
represent	O
a	O
diverse	O
sampling	O
of	O
ethnicities	O
,	O
backgrounds	O
,	O
and	O
dialects	O
(	O
e.g.	O
,	O
southern	O
amercian	O
english	O
,	O
african	O
american	O
english	O
,	O
northern	O
england	O
,	O
and	O
scotland	O
)	O
.	O
while	O
the	O
recordings	O
have	O
good	O
sound	O
quality	B
for	O
ﬁeld	O
recordings	O
(	O
especially	O
from	O
that	O
era	O
)	O
,	O
they	O
were	O
collected	O
in	O
a	O
range	O
of	O
environments	O
ranging	O
from	O
noisy	O
homes	O
(	O
e.g.	O
,	O
small	O
children	O
running	O
around	O
in	O
the	O
background	O
)	O
to	O
public	O
parks	O
to	O
gas	O
stations	O
.	O
•	O
vast	O
the	O
video	O
annotation	O
for	O
speech	O
technologies	O
(	O
vast	O
)	O
corpus	B
is	O
a	O
(	O
mostly	O
)	O
unexposed	O
collection	O
of	O
approximately	O
2,900	O
hours	B
of	O
web	O
videos	B
(	O
e.g.	O
,	O
youtube	O
and	O
vimeo	O
)	O
intended	O
for	O
development	O
and	O
evaluation	B
of	O
speech	O
technologies	O
;	O
in	O
particular	O
,	O
speech	B
activity	I
detection	I
(	O
sad	O
)	O
,	O
diarization	B
,	O
language	O
identiﬁcation	O
(	O
lid	O
)	O
,	O
speaker	B
identiﬁcation	O
(	O
sid	O
)	O
,	O
and	O
speech	B
recognition	I
(	O
stt	O
)	O
.	O
collection	O
emphasized	O
videos	B
where	O
people	O
are	O
talking	O
with	O
a	O
particular	O
emphasis	O
on	O
videos	B
where	O
the	O
speakers	O
spoke	O
primarily	O
english	O
,	O
mandarin	O
,	O
and	O
arabic	O
,	O
which	O
comprise	O
the	O
bulk	O
of	O
the	O
corpus9	O
.	O
portions	O
of	O
this	O
corpus	B
have	O
been	O
exposed	O
previously	O
as	O
part	O
of	O
the	O
nist	O
2017	O
speech	O
analytic	O
technologies	O
evaluation	B
,	O
the	O
nist	O
2017	O
language	O
recognition	O
evaluation	B
,	O
nist	O
2018	O
speaker	B
recognition	O
evaluation	B
,	O
and	O
dihard	O
i.	O
•	O
youthpoint	O
youthpoint	O
is	O
an	O
unpublished	O
ldc	O
corpus	B
consisting	O
of	O
episodes	O
of	O
youthpoint	O
,	O
a	O
late	O
1970s	O
radio	O
program	O
run	O
by	O
students	O
at	O
the	O
university	O
of	O
pennsylvania	O
.	O
the	O
show	O
had	O
an	O
interview	O
format	O
similar	O
to	O
shows	O
such	O
as	O
npr	O
’s	O
fresh	O
air	O
and	O
consisted	O
of	O
interviews	O
between	O
university	O
of	O
pennsylvania	O
students	O
and	O
various	O
popular	O
ﬁgures	O
.	O
the	O
recordings	O
were	O
conducted	O
in	O
a	O
studio	O
on	O
open	O
reel	O
tapes	O
and	O
later	O
digitized	O
and	O
transcribed	O
at	O
ldc	O
.	O
8	O
in	O
cases	O
where	O
the	O
onset	O
or	O
oﬀset	O
of	O
a	O
scoring	O
region	O
was	O
found	O
to	O
bisect	O
a	O
speaker	B
turn	O
,	O
it	O
was	O
adjusted	O
to	O
fall	O
in	O
silence	B
adjacent	O
to	O
the	O
relevant	O
turn	O
.	O
9eight	O
languages	O
are	O
represented	O
in	O
total	O
:	O
arabic	O
,	O
english	O
,	O
mandarin	O
,	O
min	O
nan	O
,	O
spanish	O
,	O
portuguese	O
,	O
russian	O
,	O
and	O
polish	O
.	O
16appendix	O
b	O
:	O
speech	O
segmentation	B
label	O
ﬁles	O
for	O
each	O
recording	B
,	O
the	O
reference	B
speech	O
segmentation	B
will	O
be	O
provided	O
via	O
an	O
htk	O
label	O
ﬁle	O
listing	O
one	O
segment	B
per	O
line	O
,	O
each	O
line	O
consisting	O
of	O
three	O
space	O
-	O
delimited	O
ﬁelds	O
:	O
•	O
segment	B
onset	O
in	O
seconds	B
from	O
beginning	O
of	O
recording	B
•	O
segment	B
oﬀset	O
in	O
seconds	B
from	O
beginning	O
of	O
recording	B
•	O
segment	B
label	O
(	O
always	O
“	O
speech	O
”	O
)	O
for	O
example	O
:	O
0.10	O
1.41	O
speech	O
1.98	O
3.44	O
speech	O
5.0	O
7.52	O
speech	O
the	O
segments	O
in	O
these	O
ﬁles	O
are	O
guaranteed	O
to	O
be	O
disjoint	O
and	O
to	O
not	O
extend	O
beyond	O
the	O
boundaries	B
of	O
the	O
recording	B
session	O
.	O
17appendix	O
c	O
:	O
rttm	O
file	O
format	O
speciﬁcation	O
systems	O
should	O
output	B
their	O
diarizations	O
as	O
rich	B
transcription	I
time	B
marked	O
(	O
rttm	O
)	O
ﬁles	O
.	O
rttm	O
ﬁles	O
are	O
text	O
ﬁles	O
containing	O
one	O
turn	O
per	O
line	O
,	O
each	O
line	O
containing	O
ten	O
space	O
-	O
delimited	O
ﬁelds	O
:	O
•	O
type	O
–	O
segment	B
type	O
;	O
should	O
always	O
by	O
“	O
speaker	B
”	O
•	O
file	O
i	O
d	O
–	O
ﬁle	O
name	O
;	O
basename	O
of	O
the	O
recording	B
minus	O
extension	O
(	O
e.g.	O
,	O
“	O
rec1	O
a	O
”	O
)	O
•	O
channel	O
i	O
d	O
–	O
channel	O
(	O
1-indexed	O
)	O
that	O
turn	O
is	O
on	O
;	O
should	O
always	O
be	O
“	O
1	O
”	O
•	O
turn	O
onset	O
–	O
onset	O
of	O
turn	O
in	O
seconds	B
from	O
beginning	O
of	O
recording	B
•	O
turn	O
duration	O
–	O
duration	O
of	O
turn	O
in	O
seconds	B
•	O
orthography	O
field	O
–	O
should	O
always	O
by	O
“	O
<	O
na	O
>	O
”	O
•	O
speaker	B
type	O
–	O
should	O
always	O
be	O
“	O
<	O
na	O
>	O
”	O
•	O
speaker	B
name	O
–	O
name	O
of	O
speaker	B
of	O
turn	O
;	O
should	O
be	O
unique	O
within	O
scope	O
of	O
each	O
ﬁle	O
•	O
conﬁdence	O
score	B
–	O
system	O
conﬁdence	O
(	O
probability	B
)	O
that	O
information	B
is	O
correct	O
;	O
should	O
always	O
be	O
“	O
<	O
na	O
>	O
”	O
•	O
signal	B
lookahead	O
time	B
–	O
should	O
always	O
be	O
“	O
<	O
na	O
>	O
”	O
for	O
instance	O
:	O
speaker	B
cmu	O
20020319	O
-	O
1400	O
d01	O
none	O
1	O
130.430000	O
2.350	O
<	O
na	O
>	O
<	O
na	O
>	O
juliet	O
<	O
na	O
>	O
<	O
na	O
>	O
speaker	B
cmu	O
20020319	O
-	O
1400	O
d01	O
none	O
1	O
157.610000	O
3.060	O
<	O
na	O
>	O
<	O
na	O
>	O
tbc	O
<	O
na	O
>	O
<	O
na	O
>	O
speaker	B
cmu	O
20020319	O
-	O
1400	O
d01	O
none	O
1	O
130.490000	O
0.450	O
<	O
na	O
>	O
<	O
na	O
>	O
chek	O
<	O
na	O
>	O
<	O
na	O
>	O
18appendix	O
d	O
:	O
uem	O
file	O
format	O
speciﬁcation	O
un	O
-	O
partitioned	O
evaluation	B
map	O
(	O
uem	O
)	O
ﬁles	O
are	O
used	O
to	O
specify	O
the	O
scoring	O
regions	O
within	O
each	O
recording	B
.	O
for	O
each	O
scoring	O
region	O
,	O
the	O
uem	O
ﬁle	O
contains	O
a	O
line	O
with	O
the	O
following	O
four	O
space	O
-	O
delimited	O
ﬁelds	O
•	O
file	O
i	O
d	O
–	O
ﬁle	O
name	O
;	O
basename	O
of	O
the	O
recording	B
minus	O
extension	O
(	O
e.g.	O
,	O
“	O
rec1	O
a	O
”	O
)	O
•	O
channel	O
i	O
d	O
–	O
channel	O
(	O
1-indexed	O
)	O
that	O
scoring	O
region	O
is	O
on	O
•	O
onset	O
–	O
onset	O
of	O
scoring	O
region	O
in	O
seconds	B
from	O
beginning	O
of	O
recording	B
•	O
oﬀset	O
–	O
oﬀset	O
of	O
scoring	O
region	O
in	O
seconds	B
from	O
beginning	O
of	O
recording	B
for	O
instance	O
:	O
cmu	O
20020319	O
-	O
1400	O
d01	O
none	O
1	O
125.000000	O
727.090000	O
cmu	O
20020320	O
-	O
1500	O
d01	O
none	O
1	O
111.700000	O
615.330000	O
icsi	O
20010208	O
-	O
1430	O
d05	O
none	O
1	O
97.440000	O
697.290000	O
19appendix	O
e	O
:	O
data	B
resources	O
for	O
training	O
this	O
appendix	O
identiﬁes	O
a	O
(	O
non	O
-	O
exhaustive	O
)	O
list	O
of	O
publicly	O
available	O
corpora	B
suitable	O
for	O
system	O
training	O
.	O
corpora	B
containing	O
meeting	O
speech	O
ldc	O
corpora	B
•	O
icsi	O
meeting	O
speech	O
speech	O
(	O
ldc2004s02	O
)	O
•	O
icsi	O
meeting	O
transcripts	B
(	O
ldc2004t04	O
)	O
•	O
isl	O
meeting	O
speech	O
part	O
1	O
(	O
ldc2004s05	O
)	O
•	O
isl	O
meeting	O
transcripts	B
part	O
1	O
(	O
ldc2004t10	O
)	O
•	O
nist	O
meeting	O
pilot	O
corpus	B
speech	O
(	O
ldc2004s09	O
)	O
•	O
nist	O
meeting	O
pilot	O
corpus	B
transcripts	B
and	O
metadata	O
(	O
ldc2004t13	O
)	O
•	O
2004	O
spring	O
nist	O
rich	B
transcription	I
(	O
rt-04s	O
)	O
development	B
data	I
(	O
ldc2007s11	O
)	O
•	O
2004	O
spring	O
nist	O
rich	B
transcription	I
(	O
rt-04s	O
)	O
evaluation	B
data	B
(	O
ldc2007s12	O
)	O
•	O
2006	O
nist	O
spoken	O
term	O
detection	B
development	B
set	I
(	O
ldc2011s02	O
)	O
•	O
2006	O
nist	O
spoken	O
term	O
detection	B
evaluation	B
set	I
(	O
ldc2011s03	O
)	O
•	O
2005	O
spring	O
nist	O
rich	B
transcription	I
(	O
rt-05s	O
)	O
evaluation	B
set	I
(	O
ldc2011s06	O
)	O
non	O
-	O
ldc	O
corpora	B
•	O
augmented	O
multiparty	O
interaction	O
(	O
ami	O
)	O
meeting	O
corpus	B
(	O
http://groups.inf.ed.ac.uk/ami/corpus/	O
)	O
•	O
cstr	O
vctk	O
corpus	B
(	O
https://homepages.inf.ed.ac.uk/jyamagis/page3/page58/page58.html	O
)	O
conversational	O
telephone	B
speech	I
(	O
cts	O
)	O
corpora	B
ldc	O
corpora	B
•	O
callhome	O
mandarin	O
chinese	O
speech	O
(	O
ldc96s34	O
)	O
•	O
callhome	O
spanish	O
speech	O
(	O
ldc96s35	O
)	O
•	O
callhome	O
japanese	O
speech	O
(	O
ldc96s37	O
)	O
•	O
callhome	O
mandarin	O
chinese	O
transcripts	B
(	O
ldc96t16	O
)	O
•	O
callhome	O
spanish	O
transcripts	B
(	O
ldc96t17	O
)	O
•	O
callhome	O
japanese	O
transcripts	B
(	O
ldc96t18	O
)	O
•	O
callhome	O
american	O
english	O
speech	O
(	O
ldc97s42	O
)	O
•	O
callhome	O
german	O
speech	O
(	O
ldc97s43	O
)	O
•	O
callhome	O
egyptian	O
arabic	O
speech	O
(	O
ldc97s45	O
)	O
•	O
callhome	O
american	O
english	O
transcripts	B
(	O
ldc97t14	O
)	O
•	O
callhome	O
german	O
transcripts	B
(	O
ldc97t15	O
)	O
•	O
callhome	O
egyptian	O
arabic	O
transcripts	B
(	O
ldc97t19	O
)	O
•	O
callhome	O
egyptian	O
arabic	O
speech	O
supplement	O
(	O
ldc2002s37	O
)	O
20•	O
callhome	O
egyptian	O
arabic	O
transcripts	B
supplement	O
(	O
ldc2002t38	O
)	O
•	O
switchboard-1	O
release	O
2	O
(	O
ldc97s62	O
)	O
•	O
fisher	O
english	O
training	O
speech	O
part	O
1	O
speech	O
(	O
ldc2004s13	O
)	O
•	O
fisher	O
english	O
training	O
speech	O
part	O
1	O
transcripts	B
(	O
ldc2004t19	O
)	O
•	O
arabic	O
cts	O
levantine	O
fisher	O
training	B
data	I
set	B
3	O
,	O
speech	O
(	O
ldc2005s07	O
)	O
•	O
fisher	O
english	O
training	O
part	O
2	O
,	O
speech	O
(	O
ldc2005s13	O
)	O
•	O
arabic	O
cts	O
levantine	O
fisher	O
training	B
data	I
set	B
3	O
,	O
transcripts	B
(	O
ldc2005t03	O
)	O
•	O
fisher	O
english	O
training	O
part	O
2	O
,	O
transcripts	B
(	O
ldc2005t19	O
)	O
•	O
fisher	O
levantine	O
arabic	O
conversational	O
telephone	B
speech	I
(	O
ldc2007s02	O
)	O
•	O
fisher	O
levantine	O
arabic	O
conversational	O
telephone	B
speech	I
,	O
transcripts	B
(	O
ldc2007t04	O
)	O
•	O
fisher	O
spanish	O
speech	O
(	O
ldc2010s01	O
)	O
•	O
fisher	O
spanish	O
-	O
transcripts	B
(	O
ldc2010t04	O
)	O
other	O
corpora	B
ldc	O
corpora	B
•	O
speech	O
in	O
noisy	O
environments	O
(	O
spine	O
)	O
training	O
audio	O
(	O
ldc2000s87	O
)	O
•	O
speech	O
in	O
noisy	O
environments	O
(	O
spine	O
)	O
evaluation	B
audio	O
(	O
ldc2000s96	O
)	O
•	O
speech	O
in	O
noisy	O
environments	O
(	O
spine	O
)	O
training	O
transcripts	B
(	O
ldc2000t49	O
)	O
•	O
speech	O
in	O
noisy	O
environments	O
(	O
spine	O
)	O
evaluation	B
transcripts	B
(	O
ldc2000t54	O
)	O
•	O
speech	O
in	O
noisy	O
environments	O
(	O
spine2	O
)	O
part	O
1	O
audio	O
(	O
ldc2001s04	O
)	O
•	O
speech	O
in	O
noisy	O
environments	O
(	O
spine2	O
)	O
part	O
2	O
audio	O
(	O
ldc2001s06	O
)	O
•	O
speech	O
in	O
noisy	O
environments	O
(	O
spine2	O
)	O
part	O
3	O
audio	O
(	O
ldc2001s08	O
)	O
•	O
speech	O
in	O
noisy	O
environments	O
(	O
spine2	O
)	O
part	O
1	O
transcripts	B
(	O
ldc2001t05	O
)	O
•	O
speech	O
in	O
noisy	O
environments	O
(	O
spine2	O
)	O
part	O
2	O
transcripts	B
(	O
ldc2001t07	O
)	O
•	O
speech	O
in	O
noisy	O
environments	O
(	O
spine2	O
)	O
part	O
3	O
transcripts	B
(	O
ldc2001t09	O
)	O
•	O
santa	O
barbara	O
corpus	B
of	O
spoken	O
american	O
english	O
part	O
i	O
(	O
ldc2000s85	O
)	O
•	O
santa	O
barbara	O
corpus	B
of	O
spoken	O
american	O
english	O
part	O
ii	O
(	O
ldc2003s06	O
)	O
•	O
santa	O
barbara	O
corpus	B
of	O
spoken	O
american	O
english	O
part	O
iii	O
(	O
ldc2004s10	O
)	O
•	O
santa	O
barbara	O
corpus	B
of	O
spoken	O
american	O
english	O
part	O
iv	O
(	O
ldc2005s25	O
)	O
•	O
havic	O
pilot	O
transcription	B
(	O
ldc2016v01	O
)	O
•	O
nautilus	O
speaker	B
characterization	O
(	O
ldc2018s17	O
)	O
•	O
sri	O
speech	O
-	O
based	O
collaborative	O
learning	O
corpus	B
(	O
ldc2019s01	O
)	O
non	O
-	O
ldc	O
corpora	B
•	O
ava	O
activespeaker	O
(	O
http://research.google.com/ava/	O
)	O
•	O
ava	O
speech	O
(	O
http://research.google.com/ava/	O
)	O
21•	O
librispeech	O
(	O
http://www.openslr.org/12/	O
)	O
•	O
speakers	O
in	O
the	O
wild	O
(	O
sitw	O
)	O
(	O
http://www.speech.sri.com/projects/sitw/	O
)	O
•	O
voxceleb	O
(	O
http://www.robots.ox.ac.uk/~vgg/data/voxceleb/	O
)	O
•	O
voxceleb	O
2	O
(	O
http://www.robots.ox.ac.uk/~vgg/data/voxceleb/vox2.html	O
)	O
22appendix	O
f	O
:	O
system	O
descriptions	O
proper	O
interpretation	O
of	O
the	O
evaluation	B
results	B
requires	O
thorough	O
documentation	O
of	O
each	O
system	O
.	O
conse-	O
quently	O
,	O
at	O
the	O
end	O
of	O
the	O
evaluation	B
researchers	O
must	O
submit	O
a	O
pdf	O
that	O
jointly	O
describes	O
their	O
ﬁnal	O
systems	O
(	O
i.e.	O
,	O
those	O
appearing	O
on	O
the	O
leaderboard	O
at	O
the	O
end	O
of	O
the	O
challenge	B
)	O
in	O
suﬃcient	O
detail	O
for	O
a	O
fellow	O
researcher	O
to	O
understand	O
the	O
approach	O
and	O
data	B
/	O
computational	O
requirements	O
.	O
in	O
order	B
to	O
make	O
the	O
preparation	O
and	O
format	O
as	O
consistent	O
as	O
possible	O
,	O
participants	B
should	O
use	O
the	O
ieee	O
conference	O
proceedings	O
templates	O
:	O
https://www.ieee.org/conferences/publishing/templates.html	O
an	O
acceptable	O
system	O
description	O
should	O
include	O
the	O
following	O
information	B
:	O
•	O
authors	O
•	O
abstract	O
•	O
data	B
resources	O
•	O
detailed	O
description	O
of	O
algorithm	O
•	O
results	B
on	O
the	O
development	B
set	I
•	O
results	B
on	O
the	O
evaluation	B
set	I
•	O
hardware	O
requirements	O
system	O
names	O
used	O
within	O
this	O
document	O
should	O
be	O
consistent	O
with	O
those	O
used	O
on	O
the	O
leaderboard	O
.	O
if	O
for	O
some	O
reason	O
this	O
is	O
not	O
possible	O
,	O
then	O
a	O
section	O
should	O
be	O
included	O
that	O
provides	O
a	O
mapping	O
between	O
the	O
two	O
namespaces	O
.	O
if	O
a	O
large	O
number	O
of	O
systems	O
were	O
submitted	O
,	O
not	O
all	O
must	O
be	O
included	O
(	O
e.g.	O
,	O
tests	O
of	O
the	O
codalab	O
server	O
,	O
early	O
baselines	O
,	O
abandoned	O
approaches	O
)	O
,	O
but	O
at	O
a	O
minimum	O
the	O
four	O
best	O
performing	O
systems	O
for	O
each	O
track	O
should	O
be	O
described	O
.	O
section	O
1	O
:	O
authors	O
listing	O
of	O
people	O
whose	O
contributions	O
you	O
wish	O
acknowledged	O
.	O
this	O
section	O
is	O
optional	O
,	O
but	O
is	O
helpful	O
to	O
the	O
organizers	O
as	O
any	O
names	O
listed	O
in	O
this	O
section	O
will	O
be	O
listed	O
as	O
co	O
-	O
authors	O
for	O
the	O
zenodo	O
download	O
containing	O
the	O
challenge	B
results	B
.	O
section	O
2	O
:	O
abstract	O
a	O
short	O
(	O
a	O
few	O
sentences	O
)	O
high	O
-	O
level	B
description	O
of	O
the	O
system	O
.	O
section	O
3	O
:	O
data	B
resources	O
this	O
section	O
should	O
describe	O
the	O
data	B
used	O
for	O
training	O
including	O
both	O
volumes	O
and	O
sources	O
.	O
for	O
ldc	O
or	O
elra	O
corpora	B
,	O
catalog	O
ids	O
should	O
be	O
supplied	O
.	O
for	O
other	O
publicly	O
available	O
corpora	B
(	O
e.g.	O
,	O
ami	O
)	O
a	O
link	O
should	O
be	O
provided	O
.	O
in	O
cases	O
where	O
a	O
non	O
-	O
publicly	O
available	O
corpus	B
is	O
used	O
,	O
it	O
should	O
be	O
described	O
in	O
suﬃcient	O
detail	O
to	O
get	O
the	O
gist	O
of	O
its	O
composition	O
.	O
if	O
the	O
system	O
is	O
composed	O
of	O
multiple	O
components	B
and	O
diﬀerent	O
components	B
are	O
trained	O
using	O
diﬀerent	O
resources	O
,	O
there	O
should	O
be	O
an	O
accompanying	O
description	O
of	O
which	O
resources	O
were	O
used	O
for	O
which	O
components	B
.	O
section	O
4	O
:	O
detailed	O
description	O
of	O
algorithm	O
each	O
component	O
of	O
the	O
system	O
should	O
be	O
described	O
in	O
suﬃcient	O
detail	O
that	O
another	O
researcher	O
would	O
be	O
able	O
to	O
reimplement	O
it	O
.	O
you	O
may	O
be	O
brief	O
or	O
omit	O
entirely	O
description	O
of	O
components	B
that	O
are	O
standard	O
(	O
i.e.	O
,	O
no	O
need	O
to	O
list	O
the	O
standard	O
equations	O
underlying	O
an	O
lstm	O
or	O
gru	O
)	O
.	O
if	O
hyperparameter	O
tuning	O
was	O
performed	O
,	O
there	O
should	O
be	O
detailed	O
description	O
both	O
of	O
the	O
tuning	O
process	B
and	O
the	O
ﬁnal	O
hyperparameters	O
arrived	O
at	O
.	O
23we	O
suggest	O
including	O
subsections	O
for	O
each	O
major	O
phase	O
in	O
the	O
system	O
.	O
suggested	O
subsections	O
:	O
•	O
signal	B
processing	I
–	O
e.g.	O
,	O
signal	B
enhancement	O
,	O
denoising	O
,	O
source	B
separation	O
•	O
acoustic	B
features	I
–	O
e.g.	O
,	O
mfccs	O
,	O
plps	O
,	O
mel	O
ﬁterbank	O
,	O
pnccs	O
,	O
rasta	O
,	O
pitch	B
extraction	B
•	O
speech	B
activity	I
detection	I
details	O
–	O
relevant	O
only	O
for	O
tracks	B
2	O
and	O
4	O
•	O
segment	B
representation	O
–	O
e.g.	O
,	O
i	O
-	O
vectors	O
,	O
d	O
-	O
vectors	O
•	O
speaker	B
estimation	B
–	O
how	O
number	O
of	O
speakers	O
was	O
estimated	O
if	O
such	O
estimation	B
was	O
performed	O
•	O
clustering	B
method	B
–	O
e.g.	O
,	O
k	O
-	O
means	O
,	O
agglomerative	O
•	O
resegmentation	B
details	O
section	O
5	O
:	O
results	B
on	O
the	O
development	B
set	I
report	O
overall	O
der	O
and	O
jer	O
on	O
the	O
development	B
set	I
when	O
using	O
the	O
oﬃcial	O
scoring	O
tool	O
.	O
section	O
6	O
:	O
results	B
on	O
the	O
evaluation	B
set	I
report	O
overall	O
der	O
and	O
jer	O
on	O
the	O
evaluation	B
set	I
.	O
these	O
results	B
should	O
be	O
taken	O
straight	O
from	O
the	O
leader-	O
board	O
.	O
section	O
7	O
:	O
hardware	O
requirements	O
system	O
developers	O
should	O
report	O
the	O
hardware	O
requirements	O
for	O
both	O
training	O
and	O
at	O
test	B
time	B
:	O
•	O
total	O
number	O
of	O
cpu	O
cores	O
used	O
•	O
description	O
of	O
cpus	O
used	O
(	O
model	B
,	O
speed	O
,	O
number	O
of	O
cores	O
)	O
•	O
total	O
number	O
of	O
gpus	O
used	O
•	O
description	O
of	O
gpus	O
used	O
(	O
model	B
,	O
single	O
precision	O
tflops	O
,	O
memory	O
)	O
•	O
total	O
number	O
of	O
tpus	O
used	O
•	O
generations	O
of	O
tpus	O
used	O
(	O
e.g.	O
,	O
v2	O
vs	O
v3	O
)	O
•	O
total	O
available	O
ram	O
•	O
used	O
disk	O
storage	O
•	O
machine	O
learning	O
frameworks	O
used	O
(	O
e.g.	O
,	O
pytorch	O
,	O
tensorﬂow	O
,	O
cntk	O
)	O
system	O
execution	O
times	O
to	O
process	B
the	O
entire	O
development	B
set	I
must	O
be	O
reported	O

deep	O
neural	B
network	I
embeddings	O
for	O
text	O
-	O
independent	O
speaker	B
veriﬁcation	O
david	O
snyder	O
,	O
daniel	O
garcia	O
-	O
romero	O
,	O
daniel	O
povey	O
,	O
sanjeev	O
khudanpur	O
center	O
for	O
language	O
and	O
speech	O
processing	B
&	O
human	O
language	O
technology	O
center	O
of	O
excellence	O
,	O
the	O
johns	O
hopkins	O
university	O
,	O
usa	O
{	O
david.ryan.snyder	O
,	O
dpovey}@gmail.com	O
,	O
{	O
dgromero	O
,	O
khudanpur}@jhu.edu	O
abstract	O
model	B
(	O
ubm	O
)	O
that	O
is	O
used	O
to	O
collect	O
sufﬁcient	O
statistics	B
,	O
a	O
large	O
projection	O
matrix	O
to	O
extract	O
i	O
-	O
vectors	O
,	O
and	O
a	O
probabilistic	O
linear	O
this	O
paper	O
investigates	O
replacing	O
i	O
-	O
vectors	O
for	O
text	O
-	O
independent	O
discriminant	B
analysis	I
(	O
plda	B
)	O
backend	O
to	O
compute	O
a	O
similarity	B
speaker	B
veriﬁcation	O
with	O
embeddings	O
extracted	O
from	O
a	O
feed-	O
score	B
between	O
i	O
-	O
vectors	O
[	O
2	O
,	O
3	O
,	O
4	O
,	O
5	O
,	O
6	O
,	O
7	O
]	O
.	O
forward	O
deep	O
neural	B
network	I
.	O
long	O
-	O
term	O
speaker	B
characteris-	O
tics	O
are	O
captured	O
in	O
the	O
network	B
by	O
a	O
temporal	O
pooling	O
layer	B
traditionally	O
,	O
the	O
ubm	O
is	O
a	O
gaussian	O
mixture	O
model	B
that	O
aggregates	O
over	O
the	O
input	B
speech	O
.	O
this	O
enables	O
the	O
network	B
(	O
gmm	O
)	O
trained	O
on	O
acoustic	B
features	I
.	O
recent	O
work	O
has	O
shown	O
to	O
be	O
trained	O
to	O
discriminate	O
between	O
speakers	O
from	O
variable-	O
that	O
incorporating	O
an	O
asr	B
dnn	O
acoustic	O
model	B
can	O
improve	O
length	B
speech	B
segments	I
.	O
after	O
training	O
,	O
utterances	B
are	O
mapped	O
the	O
ubm	O
’s	O
ability	O
to	O
model	B
phonetic	O
content	O
[	O
8	O
,	O
9	O
,	O
10	O
,	O
11	O
,	O
12	O
]	O
.	O
directly	O
to	O
ﬁxed	O
-	O
dimensional	O
speaker	B
embeddings	I
and	O
pairs	O
of	O
however	O
,	O
this	O
comes	O
at	O
the	O
cost	B
of	O
greatly	O
increased	O
compu-	O
embeddings	O
are	O
scored	O
using	O
a	O
plda	B
-	O
based	O
backend	O
.	O
we	O
com-	O
tational	O
complexity	O
compared	O
to	O
traditional	O
systems	O
[	O
11	O
]	O
.	O
in	O
pare	O
performance	O
with	O
a	O
traditional	O
i	O
-	O
vector	O
baseline	B
on	O
nist	O
addition	O
,	O
the	O
advantages	O
of	O
incorporating	O
asr	B
dnns	O
into	O
the	O
sre	O
2010	O
and	O
2016	O
.	O
we	O
ﬁnd	O
that	O
the	O
embeddings	O
outperform	O
i	O
-	O
vector	O
pipeline	O
have	O
been	O
largely	O
isolated	O
to	O
english	O
language	O
i	O
-	O
vectors	O
for	O
short	O
speech	B
segments	I
and	O
are	O
competitive	O
on	O
long	O
speech	O
;	O
[	O
13	O
]	O
found	O
no	O
beneﬁt	O
in	O
a	O
multi	O
-	O
language	O
setting	O
.	O
for	O
duration	O
test	B
conditions	O
.	O
moreover	O
,	O
the	O
two	O
representations	O
are	O
these	O
reasons	O
,	O
we	O
restrict	O
the	O
scope	O
of	O
study	O
to	O
traditional	O
i-	O
complementary	O
,	O
and	O
their	O
fusion	O
improves	O
on	O
the	O
baseline	B
at	O
all	O
vector	O
systems	O
using	O
gmms	O
.	O
operating	O
points	O
.	O
similar	O
systems	O
have	O
recently	O
shown	O
promis-	O
ing	O
results	B
when	O
trained	O
on	O
very	O
large	O
proprietary	O
datasets	B
,	O
but	O
1.2	O
.	O
speaker	B
veriﬁcation	O
with	O
dnns	O
to	O
the	O
best	O
of	O
our	O
knowledge	B
,	O
these	O
are	O
the	O
best	O
results	B
reported	O
for	O
speaker	B
-	O
discriminative	O
neural	B
networks	I
when	O
trained	O
and	O
it	O
may	O
be	O
possible	O
to	O
produce	O
more	O
powerful	O
sv	O
systems	O
by	O
tested	O
on	O
publicly	O
available	O
corpora	B
.	O
training	O
them	O
to	O
directly	O
discriminate	O
between	O
speakers	O
.	O
some	O
index	O
terms	B
:	O
speaker	B
recognition	O
,	O
speaker	B
veriﬁcation	O
,	O
deep	O
studies	O
have	O
investigated	O
discriminatively	O
training	O
components	B
neural	B
networks	I
of	O
the	O
i	O
-	O
vector	B
system	I
[	O
14	O
,	O
15	O
]	O
.	O
given	O
their	O
success	O
in	O
other	O
ar-	O
eas	O
of	O
speech	O
technology	O
,	O
a	O
natural	O
alternative	O
is	O
to	O
use	O
dnns	O
1	O
.	O
introduction	O
trained	O
on	O
speaker	B
-	O
discriminative	O
tasks	O
.	O
in	O
early	O
systems	O
,	O
neu-	O
ral	O
networks	O
are	O
trained	O
to	O
classify	O
training	O
speakers	O
[	O
16	O
,	O
17	O
]	O
or	O
speaker	B
veriﬁcation	O
(	O
sv	O
)	O
is	O
the	O
task	O
of	O
authenticating	O
the	O
in	O
siamese	O
architectures	O
to	O
separate	O
same	O
-	O
speaker	B
and	O
different-	O
claimed	O
identity	O
of	O
a	O
speaker	B
,	O
based	O
on	O
some	O
speech	B
signal	I
speaker	B
pairs	O
[	O
18	O
,	O
19	O
,	O
20	O
]	O
.	O
after	O
training	O
,	O
frame	B
-	O
level	B
features	O
and	O
enrolled	O
speaker	B
record	O
.	O
typically	O
,	O
low	O
-	O
dimensional	O
rep-	O
are	O
extracted	O
from	O
the	O
networks	O
and	O
used	O
as	O
input	B
to	O
gaussian	O
resentations	O
rich	O
in	O
speaker	B
information	B
are	O
extracted	O
for	O
both	O
speaker	B
models	B
.	O
however	O
,	O
we	O
are	O
not	O
aware	O
of	O
any	O
work	O
sug-	O
enrollment	O
and	O
test	B
speech	O
,	O
and	O
compared	O
to	O
enable	O
a	O
same-	O
gesting	O
that	O
those	O
methods	O
are	O
competitive	O
with	O
modern	O
i	O
-	O
vector	O
or	O
-	O
different	O
speaker	B
decision	O
.	O
in	O
modern	O
systems	O
,	O
the	O
repre-	O
systems	O
for	O
text	O
-	O
independent	O
sv	O
.	O
sentations	O
are	O
usually	O
i	O
-	O
vectors	O
.	O
if	O
the	O
lexical	O
content	O
of	O
the	O
utterances	B
is	O
ﬁxed	O
to	O
some	O
phrase	O
,	O
the	O
task	O
is	O
considered	O
text-	O
progress	O
has	O
been	O
primarily	O
concentrated	O
in	O
text	O
-	O
dependent	O
dependent	O
,	O
otherwise	O
it	O
is	O
text	O
-	O
independent	O
.	O
this	O
paper	O
investi-	O
sv	O
on	O
large	O
proprietary	O
datasets	B
.	O
in	O
[	O
21	O
]	O
,	O
a	O
feed	O
-	O
forward	O
dnn	O
gates	O
replacing	O
i	O
-	O
vectors	O
with	O
embeddings	O
produced	O
by	O
a	O
deep	O
is	O
trained	O
to	O
classify	O
speakers	O
at	O
the	O
frame	B
-	O
level	B
,	O
on	O
the	O
phrase	O
neural	B
network	I
(	O
dnn	O
)	O
for	O
text	O
-	O
independent	O
sv	O
.	O
the	O
relative	O
“	O
ok	O
google	O
.	O
”	O
after	O
training	O
,	O
the	O
softmax	O
output	B
layer	B
is	O
dis-	O
strengths	O
and	O
weaknesses	O
of	O
this	O
approach	O
are	O
assessed	O
under	O
carded	O
and	O
speaker	B
representations	O
(	O
called	O
d	O
-	O
vectors	O
)	O
are	O
cre-	O
a	O
variety	O
of	O
conditions	O
.	O
in	O
some	O
practical	O
applications	O
,	O
ver-	O
ated	O
by	O
averaging	O
hidden	O
layer	B
activations	O
.	O
[	O
22	O
]	O
built	O
on	O
this	O
iﬁcation	O
must	O
be	O
performed	O
using	O
only	O
a	O
limited	O
amount	B
of	O
approach	O
for	O
the	O
same	O
application	B
,	O
by	O
training	O
an	O
end	O
-	O
to	O
-	O
end	O
test	B
speech	O
,	O
either	O
to	O
avoid	O
latency	O
in	O
an	O
online	O
application	B
or	O
system	O
to	O
discriminate	O
between	O
same	O
-	O
speaker	B
and	O
different-	O
due	O
to	O
limited	O
availability	O
.	O
to	O
supplement	O
the	O
core	O
2010	O
nist	O
speaker	B
pairs	O
.	O
speaker	B
recognition	O
evaluation	B
(	O
sre	O
)	O
,	O
we	O
construct	O
a	O
modiﬁed	O
recently	O
,	O
[	O
23	O
]	O
showed	O
that	O
an	O
end	O
-	O
to	O
-	O
end	O
system	O
that	O
version	O
in	O
which	O
the	O
enrollment	O
utterances	B
are	O
full	O
-	O
length	B
,	O
but	O
jointly	O
learns	O
embeddings	O
along	O
with	O
a	O
similarity	B
metric	B
could	O
the	O
test	B
utterances	B
have	O
been	O
truncated	O
to	O
the	O
ﬁrst	O
few	O
seconds	B
outperform	O
a	O
traditional	O
i	O
-	O
vector	O
baseline	B
for	O
text	O
-	O
independent	O
of	O
speech	O
.	O
finally	O
,	O
we	O
assess	O
performance	O
on	O
the	O
cantonese	O
sv	O
.	O
however	O
,	O
the	O
approach	O
required	O
a	O
large	O
number	O
of	O
in-	O
and	O
tagalog	O
nist	O
sre	O
2016	O
,	O
which	O
combines	O
short	O
-	O
duration	O
domain	B
training	O
speakers	O
to	O
be	O
effective	O
.	O
our	O
system	O
is	O
based	O
test	B
conditions	O
with	O
language	O
-	O
mismatch	O
.	O
on	O
[	O
23	O
]	O
,	O
but	O
modiﬁed	O
in	O
an	O
effort	O
to	O
improve	O
performance	O
on	O
smaller	O
,	O
publicly	O
available	O
datasets	B
.	O
we	O
split	O
the	O
end	O
-	O
to	O
-	O
end	O
ap-	O
1.1	O
.	O
speaker	B
veriﬁcation	O
with	O
i	O
-	O
vectors	O
proach	O
into	O
two	O
parts	O
:	O
a	O
dnn	O
to	O
produce	O
embeddings	O
and	O
a	O
sep-	O
most	O
text	O
-	O
independent	O
sv	O
systems	O
are	O
based	O
on	O
i	O
-	O
vectors	O
[	O
1	O
]	O
.	O
arate	O
backend	O
to	O
compare	O
pairs	O
of	O
embeddings	O
.	O
finally	O
,	O
instead	O
the	O
standard	O
system	O
consists	O
of	O
a	O
pipeline	O
of	O
generative	O
mod-	O
of	O
training	O
the	O
system	O
to	O
separate	O
same	O
-	O
speaker	B
and	O
different-	O
els	O
,	O
trained	O
on	O
independent	O
subtasks	O
:	O
a	O
universal	O
background	O
speaker	B
pairs	O
,	O
the	O
dnn	O
learns	O
to	O
classify	O
training	O
speakers.3.3	O
.	O
neural	B
network	I
architecture	B
the	O
network	B
,	O
illustrated	O
in	O
figure	O
1	O
,	O
consists	O
of	O
layers	O
that	O
op-	O
erate	O
on	O
speech	O
frames	O
,	O
a	O
statistics	B
pooling	O
layer	B
that	O
aggregates	O
over	O
the	O
frame	B
-	O
level	B
representations	O
,	O
additional	O
layers	O
that	O
oper-	O
ate	O
at	O
the	O
segment	B
-	O
level	B
,	O
and	O
ﬁnally	O
a	O
softmax	O
output	B
layer	B
.	O
the	O
nonlinearities	O
are	O
rectiﬁed	O
linear	O
units	O
(	O
relus	O
)	O
.	O
the	O
ﬁrst	O
5	O
layers	O
of	O
the	O
network	B
work	O
at	O
the	O
frame	B
level	B
,	O
with	O
a	O
time	B
-	O
delay	O
architecture	B
[	O
26	O
]	O
.	O
suppose	O
t	O
is	O
the	O
current	O
time	B
step	O
.	O
at	O
the	O
input	B
,	O
we	O
splice	O
together	O
frames	O
at	O
{	O
t	O
−	O
2	O
,	O
t	O
−	O
1	O
,	O
t	O
,	O
t	O
+	O
1	O
,	O
t	O
+	O
2	O
}	O
.	O
the	O
next	O
two	O
layers	O
splice	O
together	O
the	O
output	B
of	O
the	O
previous	O
layer	B
at	O
times	O
{	O
t−2	O
,	O
t	O
,	O
t+2	O
}	O
and	O
{	O
t−3	O
,	O
t	O
,	O
t+3	O
}	O
,	O
respectively	O
.	O
the	O
next	O
two	O
layers	O
also	O
operate	O
at	O
the	O
frame	B
-	O
level	B
,	O
but	O
without	O
any	O
added	O
temporal	O
context	O
.	O
in	O
total	O
,	O
the	O
frame-	O
level	B
portion	O
of	O
the	O
network	B
has	O
a	O
temporal	O
context	O
of	O
t	O
−	O
8	O
to	O
t	O
+	O
8	O
frames	O
.	O
layers	O
vary	O
in	O
size	B
,	O
from	O
512	O
to	O
1536	O
,	O
depending	O
on	O
the	O
splicing	O
context	O
used	O
.	O
the	O
statistics	B
pooling	O
layer	B
receives	O
the	O
output	B
of	O
the	O
ﬁnal	O
frame	B
-	O
level	B
layer	B
as	O
input	B
,	O
aggregates	O
over	O
the	O
input	B
segment	B
,	O
and	O
computes	O
its	O
mean	O
and	O
standard	O
deviation	O
.	O
these	O
segment-	O
level	B
statistics	B
are	O
concatenated	O
together	O
and	O
passed	O
to	O
two	O
ad-	O
figure	O
1	O
:	O
diagram	O
of	O
the	O
dnn	O
.	O
segment	B
-	O
level	B
embeddings	O
(	O
e.g.	O
,	O
ditional	O
hidden	O
layers	O
with	O
dimension	O
512	O
and	O
300	O
(	O
either	O
of	O
a	O
or	O
b	O
)	O
can	O
be	O
extracted	O
from	O
any	O
layer	B
of	O
the	O
network	B
after	O
the	O
which	O
may	O
be	O
used	O
to	O
compute	O
embeddings	O
)	O
and	O
ﬁnally	O
the	O
soft-	O
statistics	B
pooling	O
layer	B
.	O
max	O
output	B
layer	B
.	O
excluding	O
the	O
softmax	O
output	B
layer	B
(	O
because	O
it	O
is	O
not	O
needed	O
after	O
training	O
)	O
there	O
is	O
a	O
total	O
of	O
4.4	O
million	O
pa-	O
rameters	O
.	O
2	O
.	O
baseline	B
i	O
-	O
vector	B
system	I
3.4	O
.	O
training	O
the	O
baseline	B
is	O
a	O
traditional	O
i	O
-	O
vector	B
system	I
that	O
is	O
based	O
on	O
the	O
the	O
network	B
is	O
trained	O
to	O
classify	O
training	O
speakers	O
using	O
a	O
mul-	O
gmm	O
-	O
ubm	O
kaldi	O
recipe	O
described	O
in	O
[	O
11	O
]	O
.	O
the	O
front	O
-	O
end	O
fea-	O
ticlass	O
cross	O
entropy	O
objective	O
function	O
(	O
equation	O
1	O
)	O
.	O
the	O
pri-	O
tures	O
consist	O
of	O
20	O
mfccs	O
with	O
a	O
frame	B
-	O
length	B
of	O
25ms	O
that	O
mary	O
difference	O
between	O
this	O
and	O
training	O
in	O
[	O
16	O
,	O
17	O
,	O
21	O
]	O
is	O
that	O
are	O
mean	O
-	O
normalized	O
over	O
a	O
sliding	O
window	O
of	O
up	O
to	O
3	O
seconds	B
.	O
our	O
system	O
is	O
trained	O
to	O
predict	O
speakers	O
from	O
variable	O
-	O
length	B
delta	O
and	O
acceleration	O
are	O
appended	O
to	O
create	O
60	O
dimension	O
fea-	O
segments	O
,	O
rather	O
than	O
frames	O
.	O
suppose	O
there	O
are	O
k	O
speakers	O
in	O
ture	O
vectors	O
.	O
an	O
energy	O
-	O
based	O
vad	O
selects	O
features	O
correspond-	O
n	O
training	O
segments	O
.	O
then	O
p	O
(	O
spkr	O
|	O
x(n	O
)	O
)	O
is	O
the	O
probabil-	O
ing	O
to	O
speech	O
frames	O
.	O
the	O
ubm	O
is	O
a	O
2048	O
component	O
full-	O
k	O
1	O
:	O
t	O
covariance	O
gmm	O
.	O
the	O
system	O
uses	O
a	O
600	O
dimension	O
i	O
-	O
vector	O
ity	O
of	O
speaker	B
k	O
given	O
t	O
input	B
frames	O
x(1n	O
)	O
,	O
x(2n	O
)	O
,	O
...	O
x(tn	O
)	O
.	O
the	O
extractor	B
.	O
prior	O
to	O
plda	B
scoring	O
,	O
i	O
-	O
vectors	O
are	O
centered	O
,	O
di-	O
quantity	O
dnk	O
is	O
1	O
if	O
the	O
speaker	B
label	O
for	O
segment	B
n	O
is	O
k	O
,	O
other-	O
mensionality	O
reduced	O
to	O
150	O
using	O
lda	O
,	O
and	O
length	B
normalized	O
.	O
wise	O
it	O
’s	O
0	O
.	O
plda	B
scores	O
are	O
normalized	O
using	O
adaptive	O
s	O
-	O
norm	B
[	O
24	O
]	O
.	O
n	O
k	O
e	O
=	O
−	O
(	O
cid:88	O
)	O
(	O
cid:88	O
)	O
d	O
ln(p	O
(	O
spkr	O
|	O
x(n	O
)	O
)	O
)	O
(	O
1	O
)	O
nk	O
k	O
1	O
:	O
t	O
3	O
.	O
dnn	O
embedding	O
system	O
n=1	O
k=1	O
the	O
dnn	O
is	O
trained	O
on	O
the	O
combined	O
swbd	O
and	O
sre	O
data	B
3.1	O
.	O
overview	O
described	O
in	O
section	O
4.1	O
.	O
we	O
reﬁne	O
the	O
dataset	O
by	O
removing	O
any	O
recordings	O
that	O
are	O
less	O
than	O
10	O
seconds	B
long	O
,	O
and	O
any	O
speak-	O
the	O
proposed	O
system	O
is	O
a	O
feed	O
-	O
forward	O
dnn	O
(	O
depicted	O
in	O
fig-	O
ers	O
with	O
fewer	O
than	O
4	O
recordings	O
.	O
this	O
leaves	O
a	O
total	O
of	O
4,733	O
ure	O
1	O
)	O
that	O
computes	O
speaker	B
embeddings	I
from	O
variable	O
-	O
length	B
speakers	O
,	O
which	O
is	O
the	O
size	B
of	O
the	O
softmax	O
output	B
layer	B
.	O
acoustic	O
segments	O
.	O
the	O
architecture	B
is	O
based	O
on	O
the	O
end	O
-	O
to	O
-	O
end	O
to	O
reduce	O
sensitivity	O
to	O
utterance	O
length	B
,	O
it	O
is	O
desirable	O
to	O
system	O
described	O
in	O
[	O
23	O
]	O
.	O
however	O
,	O
an	O
end	O
-	O
to	O
-	O
end	O
approach	O
re-	O
train	O
the	O
dnn	O
on	O
speech	O
chunks	O
that	O
capture	O
the	O
range	O
of	O
du-	O
quires	O
a	O
large	O
amount	B
of	O
in	O
-	O
domain	B
data	B
to	O
be	O
effective	O
.	O
we	O
rations	O
we	O
expect	O
to	O
encounter	O
at	O
test	B
time	B
(	O
e.g.	O
,	O
a	O
few	O
seconds	B
replace	O
the	O
end	O
-	O
to	O
-	O
end	O
loss	O
with	O
a	O
multiclass	O
cross	O
entropy	O
ob-	O
to	O
a	O
few	O
minutes	O
)	O
.	O
however	O
,	O
gpu	O
memory	O
limitations	O
force	O
jective	O
.	O
in	O
addition	O
,	O
a	O
separately	O
trained	O
plda	B
backend	O
is	O
used	O
a	O
tradeoff	O
between	O
minibatch	O
size	B
and	O
maximum	O
training	O
ex-	O
to	O
compare	O
pairs	O
of	O
embeddings	O
.	O
this	O
enables	O
the	O
dnn	O
and	O
ample	O
length	B
.	O
as	O
a	O
comprise	O
,	O
we	O
pick	O
examples	O
that	O
range	O
similarity	B
metric	B
to	O
be	O
trained	O
on	O
potentially	O
different	O
datasets	B
.	O
from	O
2	O
to	O
10	O
seconds	B
(	O
200	O
to	O
1000	O
frames	O
)	O
along	O
with	O
a	O
mini-	O
the	O
network	B
is	O
implemented	O
using	O
the	O
nnet3	O
neural	B
network	I
li-	O
batch	O
size	B
of	O
32	O
to	O
64	O
.	O
the	O
example	O
speech	O
chunks	O
are	O
sampled	O
brary	O
in	O
the	O
kaldi	O
speech	B
recognition	I
toolkit	O
[	O
25	O
]	O
.	O
densely	O
from	O
the	O
recordings	O
,	O
resulting	O
in	O
about	O
3,400	O
examples	O
per	O
speaker	B
.	O
the	O
network	B
is	O
trained	O
for	O
several	O
epochs	O
using	O
3.2	O
.	O
features	O
natural	O
gradient	O
stochastic	O
gradient	O
descent	O
[	O
27	O
]	O
.	O
the	O
features	O
are	O
20	O
dimensional	O
mfccs	O
with	O
a	O
frame	B
-	O
length	B
3.5	O
.	O
speaker	B
embeddings	I
of	O
25ms	O
,	O
mean	O
-	O
normalized	O
over	O
a	O
sliding	O
window	O
of	O
up	O
to	O
3	O
seconds	B
.	O
the	O
same	O
energy	O
-	O
based	O
vad	O
from	O
section	O
2	O
ﬁlters	O
ultimately	O
,	O
the	O
goal	O
of	O
training	O
the	O
network	B
is	O
to	O
produce	O
em-	O
out	O
nonspeech	O
frames	O
.	O
instead	O
of	O
stacking	O
frames	O
at	O
the	O
input	B
,	O
beddings	O
that	O
generalize	O
well	O
to	O
speakers	O
that	O
have	O
not	O
been	O
short	O
-	O
term	O
temporal	O
context	O
is	O
handled	O
by	O
a	O
time	B
-	O
delay	O
dnn	O
seen	O
in	O
the	O
training	B
data	I
.	O
we	O
would	O
like	O
embeddings	O
to	O
capture	O
architecture	B
.	O
speaker	B
characteristics	B
over	O
the	O
entire	O
utterance	O
,	O
rather	O
than	O
atthe	O
frame	B
-	O
level	B
.	O
thus	O
,	O
any	O
layer	B
after	O
the	O
statistics	B
pooling	O
layer	B
ing	O
points	O
[	O
29	O
]	O
.	O
the	O
primary	O
metrics	O
are	O
abbreviated	O
to	O
dcf10	O
is	O
a	O
sensible	O
place	O
to	O
extract	O
the	O
embedding	O
from	O
.	O
we	O
do	O
not	O
and	O
dcf16	O
respectively	O
.	O
consider	O
the	O
presoftmax	O
afﬁne	O
layer	B
because	O
of	O
its	O
large	O
size	B
and	O
dependence	O
on	O
the	O
number	O
of	O
speakers	O
.	O
in	O
the	O
network	B
used	O
in	O
4.3	O
.	O
results	B
this	O
work	O
,	O
we	O
are	O
left	O
with	O
two	O
afﬁne	O
layers	O
from	O
which	O
to	O
ex-	O
in	O
the	O
following	O
results	B
,	O
ivector	O
refers	O
to	O
the	O
traditional	O
i	O
-	O
vector	O
tract	O
embeddings	O
.	O
these	O
are	O
depicted	O
in	O
figure	O
1	O
as	O
embeddings	O
baseline	B
described	O
in	O
section	O
2	O
.	O
the	O
labels	O
embedding	O
a	O
and	O
a	O
and	O
b.	O
embedding	O
a	O
is	O
the	O
output	B
of	O
an	O
afﬁne	O
layer	B
directly	O
embedding	O
b	O
denote	O
the	O
systems	O
consisting	O
of	O
embeddings	O
ex-	O
on	O
top	O
of	O
the	O
statistics	B
.	O
embedding	O
b	O
is	O
extracted	O
from	O
the	O
next	O
tracted	O
from	O
either	O
embedding	O
layer	B
of	O
the	O
same	O
dnn	O
(	O
see	O
sec-	O
afﬁne	O
layer	B
after	O
a	O
relu	O
,	O
and	O
so	O
it	O
is	O
a	O
nonlinear	O
function	O
of	O
the	O
tion	O
3.5	O
)	O
and	O
used	O
as	O
features	O
to	O
their	O
own	O
plda	B
backends	O
.	O
the	O
statistics	B
.	O
since	O
they	O
are	O
part	O
of	O
the	O
same	O
dnn	O
,	O
if	O
embedding	O
b	O
label	O
embeddings	O
is	O
the	O
average	B
of	O
the	O
plda	B
backends	O
for	O
the	O
is	O
computed	O
then	O
we	O
get	O
embedding	O
a	O
for	O
“	O
free	O
.	O
”	O
individual	O
embeddings	O
.	O
in	O
the	O
following	O
results	B
,	O
we	O
focus	O
on	O
comparing	O
the	O
i	O
-	O
vector	O
baseline	B
with	O
these	O
combined	O
embed-	O
3.6	O
.	O
plda	B
backend	O
dings	O
.	O
finally	O
,	O
fusion	O
refers	O
to	O
the	O
equally	O
weighted	O
sum	O
fusion	O
we	O
use	O
the	O
same	O
backend	O
for	O
i	O
-	O
vectors	O
and	O
embeddings	O
.	O
em-	O
of	O
the	O
plda	B
scores	O
of	O
ivector	O
and	O
embeddings	O
.	O
beddings	O
are	O
centered	O
and	O
dimensionality	O
is	O
reduced	O
using	O
lda	O
.	O
as	O
in	O
the	O
i	O
-	O
vector	B
system	I
,	O
we	O
found	O
that	O
an	O
lda	O
dimen-	O
4.3.1	O
.	O
nist	O
sre10	O
sion	O
of	O
25	O
%	O
of	O
the	O
original	O
worked	O
well	O
.	O
after	O
dimensional-	O
ity	O
reduction	O
,	O
the	O
embeddings	O
are	O
length	B
normalized	O
and	O
pairs	O
  	O
40	O
  	O
of	O
embeddings	O
are	O
compared	O
using	O
plda	B
.	O
plda	B
scores	O
are	O
normalized	O
using	O
adaptive	O
s	O
-	O
norm	B
[	O
24	O
]	O
.	O
as	O
described	O
in	O
sec-	O
tion	O
3.5	O
,	O
the	O
dnn	O
architecture	B
presents	O
the	O
option	O
of	O
using	O
em-	O
beddings	O
a	O
or	O
b	O
or	O
in	O
combination	O
.	O
instead	O
of	O
concatenating	O
  	O
20	O
  	O
embeddings	O
together	O
,	O
we	O
compute	O
separate	O
plda	B
backends	O
for	O
%	O
)	O
each	O
embedding	O
,	O
and	O
average	B
the	O
scores	O
.	O
n	O
   	O
10	O
  	O
y	O
(	O
i	O
4	O
.	O
experiments	O
bilit	O
  	O
5	O
   	O
a	O
b	O
o	O
4.1	O
.	O
training	B
data	I
pr	O
  	O
2	O
   	O
s	O
 	O
s	O
the	O
training	B
data	I
consists	O
of	O
telephone	B
speech	I
,	O
the	O
bulk	O
of	O
mi	O
  	O
1	O
   	O
which	O
is	O
english	O
.	O
the	O
swbd	O
portion	O
consists	O
of	O
switchboard	O
 	O
0.5	O
  	O
ivector	O
2	O
phases	O
1	O
,	O
2	O
,	O
and	O
3	O
,	O
and	O
switchboard	O
cellular	O
.	O
the	O
sre	O
por-	O
embeddings	O
tion	O
contains	O
nist	O
sres	O
from	O
2004	O
through	O
2008	O
.	O
in	O
total	O
,	O
fusion	O
there	O
are	O
about	O
65,000	O
recordings	O
from	O
6,500	O
speakers	O
.	O
the	O
i-	O
  	O
0.1	O
 	O
vector	O
ubm	O
and	O
extractor	B
as	O
well	O
as	O
the	O
speaker	B
discriminative	O
 	O
0.01	O
   	O
0.1	O
  	O
0.5	O
   	O
1	O
    	O
2	O
     	O
5	O
    	O
10	O
    	O
20	O
    	O
40	O
  	O
dnn	O
are	O
trained	O
on	O
this	O
data	B
.	O
both	O
systems	O
use	O
plda	B
-	O
based	O
false	B
alarm	I
probability	B
(	O
in	O
%	O
)	O
backends	O
trained	O
on	O
just	O
the	O
sre	O
data	B
.	O
finally	O
,	O
the	O
2016	O
nist	O
figure	O
2	O
:	O
det	O
curve	O
for	O
the	O
pooled	O
5	O
-	O
60s	O
portion	O
of	O
sre10	O
.	O
sre	O
was	O
distributed	O
with	O
an	O
unlabeled	O
set	B
of	O
2,472	O
utterances	B
in	O
cantonese	O
and	O
tagalog	O
.	O
for	O
both	O
systems	O
,	O
we	O
use	O
this	O
to	O
center	O
the	O
corresponding	O
evaluation	B
utterances	B
and	O
for	O
score	B
normal-	O
ization	O
.	O
table	O
1	O
:	O
eer(%	O
)	O
on	O
nist	O
sre10	O
4.2	O
.	O
evaluation	B
10s-10s	O
5s	O
10s	O
20s	O
60s	O
full	O
ivector	O
11.0	O
9.1	O
6.0	O
3.9	O
2.3	O
1.9	O
we	O
assess	O
performance	O
on	O
nist	O
2010	O
and	O
2016	O
speaker	B
recog-	O
embedding	O
a	O
11.0	O
9.5	O
5.7	O
3.9	O
3.0	O
2.6	O
nition	O
evaluations	O
[	O
28	O
,	O
29	O
]	O
.	O
in	O
the	O
remaining	O
sections	O
,	O
these	O
embedding	O
b	O
9.2	O
8.8	O
6.6	O
5.5	O
4.4	O
3.9	O
will	O
be	O
abbreviated	O
as	O
sre10	O
and	O
sre16	O
respectively	O
.	O
sre10	O
embeddings	O
7.9	O
7.6	O
5.0	O
3.8	O
2.9	O
2.6	O
consists	O
of	O
english	O
telephone	B
speech	I
.	O
our	O
evaluation	B
is	O
based	O
on	O
the	O
extended	O
core	O
condition	B
5	O
and	O
the	O
10s-10s	O
condition	B
.	O
fusion	O
8.1	O
6.8	O
4.3	O
2.9	O
2.1	O
1.8	O
to	O
supplement	O
the	O
core	O
sre10	O
condition	B
,	O
we	O
produce	O
addi-	O
tional	O
conditions	O
in	O
which	O
the	O
enrollment	O
utterances	B
are	O
full-	O
length	B
,	O
but	O
the	O
test	B
utterances	B
have	O
been	O
truncated	O
to	O
the	O
ﬁrst	O
t	O
∈	O
{	O
5	O
,	O
10	O
,	O
20	O
,	O
60	O
}	O
seconds	B
of	O
speech	O
,	O
as	O
determined	O
by	O
an	O
table	O
2	O
:	O
dcf10	O
on	O
nist	O
sre10	O
energy	O
-	O
based	O
vad	O
.	O
the	O
10s-10s	O
condition	B
was	O
part	O
of	O
the	O
ofﬁ-	O
cial	O
sre10	O
and	O
consists	O
of	O
test	B
and	O
enrollment	O
utterances	B
that	O
10s-10s	O
5s	O
10s	O
20s	O
60s	O
full	O
contain	O
about	O
10	O
seconds	B
of	O
speech	O
.	O
sre16	O
is	O
comprised	O
of	O
ivector	O
0.962	O
0.901	O
0.749	O
0.613	O
0.460	O
0.403	O
tagalog	O
and	O
cantonese	O
language	O
telephone	B
speech	I
.	O
the	O
enroll-	O
embedding	O
a	O
0.907	O
0.902	O
0.790	O
0.654	O
0.518	O
0.468	O
ment	O
utterances	B
contain	O
about	O
60	O
seconds	B
of	O
speech	O
while	O
the	O
embedding	O
b	O
0.951	O
0.927	O
0.866	O
0.828	O
0.782	O
0.768	O
test	B
utterances	B
range	O
from	O
10	O
to	O
60	O
seconds	B
of	O
speech	O
.	O
embeddings	O
0.854	O
0.875	O
0.738	O
0.667	O
0.567	O
0.539	O
in	O
addition	O
to	O
equal	O
error	O
-	O
rate	O
(	O
eer	B
)	O
,	O
results	B
are	O
reported	O
fusion	O
0.859	O
0.788	O
0.645	O
0.556	O
0.432	O
0.383	O
using	O
the	O
ofﬁcial	O
performance	O
metric	B
for	O
each	O
sre	O
.	O
for	O
sre10	O
,	O
this	O
metric	B
was	O
the	O
minimum	O
of	O
the	O
normalized	O
detection	B
cost	B
function	O
(	O
dcf	O
)	O
with	O
p	O
=	O
10−3	O
[	O
28	O
]	O
.	O
the	O
primary	O
sre16	O
target	O
metric	B
was	O
a	O
balanced	O
(	O
equalized	O
)	O
dcf	O
averaged	O
at	O
two	O
operat-	O
in	O
this	O
section	O
,	O
we	O
look	O
at	O
performance	O
on	O
the	O
sre10	O
con	O
-	O
ditions	O
described	O
in	O
section	O
4.2	O
.	O
tables	O
1	O
and	O
2	O
demonstrate	O
the	O
table	O
3	O
:	O
eer(%	O
)	O
on	O
nist	O
sre16	O
interplay	O
between	O
utterance	O
-	O
length	B
and	O
performance	O
on	O
sre10	O
.	O
we	O
see	O
that	O
i	O
-	O
vectors	O
are	O
still	O
dominant	O
for	O
the	O
longest	O
record-	O
cantonese	O
tagalog	O
pool	O
ings	O
,	O
and	O
outperform	O
embeddings	O
at	O
both	O
the	O
eer	B
and	O
dcf10	O
ivector	O
8.3	O
17.6	O
13.6	O
operating	O
points	O
.	O
however	O
,	O
as	O
the	O
test	B
utterance	O
length	B
de-	O
embedding	O
a	O
7.7	O
17.6	O
13.1	O
creases	O
,	O
the	O
performance	O
of	O
the	O
embeddings	O
improves	O
relative	O
embedding	O
b	O
7.8	O
17.4	O
13.1	O
to	O
the	O
baseline	B
.	O
at	O
20	O
seconds	B
of	O
test	B
speech	O
,	O
the	O
combined	O
embeddings	O
6.5	O
16.3	O
11.9	O
embeddings	O
are	O
3	O
%	O
better	O
than	O
i	O
-	O
vectors	O
in	O
eer	B
but	O
8	O
%	O
worse	O
fusion	O
6.3	O
15.4	O
11.3	O
at	O
dcf10	O
.	O
with	O
just	O
10	O
and	O
5	O
seconds	B
of	O
test	B
speech	O
,	O
the	O
em-	O
beddings	O
are	O
17	O
%	O
and	O
16	O
%	O
better	O
in	O
eer	B
and	O
slightly	O
better	O
at	O
dcf10	O
.	O
the	O
relative	O
advantage	O
of	O
embeddings	O
appears	O
to	O
be	O
largest	O
when	O
both	O
enrollment	O
and	O
test	B
utterances	B
are	O
short	O
:	O
in	O
table	O
4	O
:	O
dcf16	O
on	O
nist	O
sre	O
2016	O
the	O
column	O
labeled	O
10s-10s	O
both	O
the	O
test	B
and	O
enroll	O
utterances	B
contain	O
only	O
about	O
10	O
seconds	B
of	O
speech	O
,	O
and	O
we	O
see	O
that	O
the	O
cantonese	O
tagalog	O
pool	O
combined	O
embeddings	O
are	O
28	O
%	O
better	O
in	O
eer	B
and	O
11	O
%	O
better	O
in	O
ivector	O
0.549	O
0.842	O
0.711	O
dcf10	O
.	O
figure	O
2	O
illustrates	O
the	O
detection	B
error	O
tradeoff	O
(	O
det	O
)	O
embedding	O
a	O
0.532	O
0.835	O
0.689	O
curves	O
for	O
the	O
systems	O
when	O
pooled	O
across	O
the	O
truncated	O
test	B
embedding	O
b	O
0.630	O
0.851	O
0.741	O
conditions	O
.	O
although	O
embeddings	O
are	O
better	O
at	O
the	O
eer	B
operat-	O
embeddings	O
0.508	O
0.803	O
0.658	O
ing	O
point	O
,	O
they	O
favor	O
the	O
low	O
miss	B
rate	O
,	O
and	O
are	O
slightly	O
worse	O
fusion	O
0.442	O
0.794	O
0.622	O
when	O
compared	O
at	O
a	O
very	O
low	O
false	B
alarm	I
rate	O
.	O
since	O
the	O
i	O
-	O
vector	O
and	O
dnn	O
systems	O
are	O
so	O
dissimilar	O
,	O
we	O
expect	O
good	O
performance	O
from	O
their	O
fusion	O
.	O
we	O
observe	O
an	O
im-	O
provement	O
over	O
using	O
i	O
-	O
vectors	O
alone	O
at	O
all	O
operating	O
points	O
and	O
conditions	O
.	O
the	O
largest	O
improvement	O
is	O
in	O
eer	B
on	O
the	O
10s	O
con-	O
spectively	O
.	O
pooled	O
across	O
languages	O
,	O
we	O
see	O
that	O
the	O
combined	O
dition	O
,	O
which	O
is	O
28	O
%	O
better	O
than	O
the	O
baseline	B
.	O
even	O
on	O
the	O
full-	O
embeddings	O
outperforms	O
the	O
i	O
-	O
vector	O
baseline	B
by	O
13	O
%	O
in	O
eer	B
length	B
condition	B
,	O
where	O
i	O
-	O
vectors	O
are	O
strongest	O
,	O
there	O
is	O
a	O
5	O
%	O
and	O
7	O
%	O
in	O
dcf16	O
.	O
after	O
combining	O
with	O
i	O
-	O
vectors	O
,	O
the	O
im-	O
improvement	O
over	O
using	O
the	O
i	O
-	O
vectors	O
alone	O
,	O
in	O
both	O
dcf10	O
and	O
provement	O
increases	O
to	O
17	O
%	O
in	O
eer	B
and	O
13	O
%	O
in	O
dcf16	O
.	O
the	O
eer	B
.	O
det	O
plot	O
in	O
figure	O
3	O
shows	O
that	O
these	O
improvements	B
are	O
con-	O
sistent	O
across	O
operating	O
points	O
.	O
4.3.2	O
.	O
nist	O
sre16	O
although	O
the	O
embeddings	O
also	O
perform	O
better	O
on	O
tagalog	O
,	O
improvement	O
is	O
largest	O
for	O
the	O
cantonese	O
portion	O
.	O
compared	O
to	O
the	O
i	O
-	O
vector	O
baseline	B
,	O
the	O
embeddings	O
are	O
22	O
%	O
better	O
in	O
terms	B
of	O
  	O
80	O
  	O
eer	B
and	O
7	O
%	O
in	O
dcf16	O
.	O
the	O
fused	O
system	O
is	O
even	O
better	O
,	O
and	O
improves	O
on	O
the	O
i	O
-	O
vector	O
baseline	B
by	O
24	O
%	O
in	O
eer	B
and	O
19	O
%	O
in	O
  	O
60	O
  	O
dcf16	O
.	O
5	O
.	O
conclusions	O
%	O
)	O
  	O
40	O
  	O
n	O
 	O
y	O
(	O
i	O
in	O
this	O
paper	O
,	O
we	O
investigated	O
deep	O
neural	B
network	I
embeddings	O
abilit	O
  	O
20	O
  	O
fdoinr	O
gtesxatp	O
-	O
ipnedaerpteonbdeenctosmppeaektietirvveewriiﬁthcaatiotrna.diotiovnearallil-,vtehcetoermbbaesde--	O
b	O
o	O
line	O
and	O
are	O
complementary	O
when	O
fused	O
.	O
we	O
found	O
that	O
,	O
al-	O
pr	O
s	O
   	O
10	O
  	O
though	O
i	O
-	O
vectors	O
are	O
more	O
effective	O
on	O
the	O
full	O
-	O
length	B
sre10	O
,	O
s	O
mi	O
embeddings	O
are	O
better	O
on	O
the	O
short	O
duration	O
conditions	O
.	O
this	O
un-	O
  	O
5	O
   	O
derscores	O
the	O
ﬁndings	O
of	O
[	O
23	O
,	O
30	O
]	O
that	O
dnns	O
may	O
be	O
capable	O
of	O
ivector	O
producing	O
more	O
powerful	O
representations	O
of	O
speakers	O
from	O
short	O
embeddings	O
  	O
2	O
   	O
fusion	O
speech	B
segments	I
.	O
sre16	O
presented	O
the	O
challenge	B
of	O
language	O
  	O
1	O
   	O
mismatch	O
between	O
the	O
predominantly	O
english	O
training	B
data	I
and	O
 	O
0.01	O
   	O
0.1	O
  	O
0.5	O
   	O
1	O
    	O
2	O
     	O
5	O
    	O
10	O
    	O
20	O
    	O
40	O
  	O
the	O
cantonese	O
and	O
tagalog	O
evaluation	B
.	O
we	O
saw	O
that	O
embeddings	O
false	B
alarm	I
probability	B
(	O
in	O
%	O
)	O
outperformed	O
i	O
-	O
vectors	O
on	O
both	O
languages	O
,	O
suggesting	O
that	O
they	O
may	O
be	O
more	O
robust	O
to	O
this	O
domain	B
mismatch	O
.	O
although	O
the	O
re-	O
figure	O
3	O
:	O
det	O
curve	O
for	O
sre16	O
,	O
pooled	O
across	O
cantonese	O
and	O
sults	O
are	O
quite	O
promising	O
,	O
we	O
believe	O
that	O
plda	B
may	O
not	O
be	O
the	O
tagalog	O
.	O
optimal	O
similarity	B
metric	B
for	O
the	O
embeddings	O
.	O
in	O
future	O
work	O
,	O
we	O
will	O
use	O
the	O
method	B
described	O
in	O
this	O
paper	O
as	O
pretraining	O
in	O
this	O
section	O
,	O
we	O
evaluate	O
the	O
same	O
systems	O
from	O
section	O
for	O
the	O
fully	O
end	O
-	O
to	O
-	O
end	O
approach	O
in	O
[	O
23	O
]	O
,	O
so	O
that	O
a	O
more	O
appro-	O
4.3.1	O
on	O
sre16	O
.	O
using	O
the	O
same	O
embedding	O
and	O
i	O
-	O
vector	O
sys-	O
priate	O
similarity	B
metric	B
is	O
learned	O
along	O
with	O
the	O
embeddings	O
.	O
tems	O
for	O
both	O
sre10	O
and	O
sre16	O
avoids	O
the	O
complexity	O
of	O
de-	O
veloping	O
variants	O
of	O
each	O
system	O
that	O
are	O
optimized	O
for	O
different	O
6	O
.	O
acknowledgments	O
evaluations	O
.	O
however	O
,	O
this	O
does	O
cause	O
a	O
mismatch	O
between	O
the	O
predominately	O
english	O
training	B
data	I
(	O
used	O
to	O
optimize	O
both	O
sys-	O
this	O
work	O
was	O
partially	O
supported	O
by	O
nsf	O
grant	O
no	O
cri-	O
tems	O
)	O
and	O
the	O
tagalog	O
and	O
cantonese	O
evaluation	B
speech	O
.	O
as	O
a	O
1513128	O
,	O
nanyang	O
technological	O
university	O
(	O
ntu	O
)	O
science	O
result	O
,	O
the	O
performance	O
reported	O
here	O
may	O
lag	O
behind	O
that	O
of	O
of	O
learning	O
grant	O
,	O
national	O
institutes	O
of	O
standards	O
and	O
tech-	O
counterparts	O
optimized	O
speciﬁcally	O
for	O
sre16	O
.	O
nology	O
grant	O
no	O
70nanb16h039	O
.	O
the	O
authors	O
thank	O
patrick	O
tables	O
3	O
and	O
4	O
report	O
performance	O
in	O
eer	B
and	O
dcf16	O
re-	O
kenny	O
and	O
paola	O
garcia	O
for	O
their	O
helpful	O
discussions.7	O
.	O
references	B
[	O
19	O
]	O
—	O
—	O
,	O
“	O
extracting	O
speaker	B
-	O
speciﬁc	O
information	B
with	O
a	O
regularized	O
siamese	O
deep	O
network	B
,	O
”	O
in	O
advances	O
in	O
neural	O
information	B
pro-	O
[	O
1	O
]	O
n.	O
dehak	O
,	O
p.	O
kenny	O
,	O
r.	O
dehak	O
,	O
p.	O
dumouchel	O
,	O
and	O
p.	O
ouellet	O
,	O
cessing	O
systems	O
(	O
nips11	O
)	O
,	O
2011	O
.	O
“	O
front	O
-	O
end	O
factor	B
analysis	I
for	O
speaker	B
veriﬁcation	O
,	O
”	O
ieee	O
trans-	O
actions	O
on	O
audio	O
,	O
speech	O
,	O
and	O
language	B
processing	I
,	O
vol	O
.	O
19	O
,	O
[	O
20	O
]	O
a.	O
salman	O
,	O
“	O
learning	O
speaker	B
-	O
speciﬁc	O
characteristics	B
with	O
deep	O
no	O
.	O
4	O
,	O
pp	O
.	O
788–798	O
,	O
2011	O
.	O
neural	O
architecture	B
,	O
”	O
ph.d	O
.	O
dissertation	O
,	O
university	O
of	O
manchester	O
,	O
2012	O
.	O
[	O
2	O
]	O
s.	O
prince	O
and	O
j.	O
elder	O
,	O
“	O
probabilistic	O
linear	O
discriminant	B
analysis	I
for	O
inferences	O
about	O
identity	O
,	O
”	O
in	O
ieee	O
11th	O
international	O
confer-	O
[	O
21	O
]	O
e.	O
variani	O
,	O
x.	O
lei	O
,	O
e.	O
mcdermott	O
,	O
i.	O
moreno	O
,	O
and	O
j.	O
gonzalez-	O
ence	O
on	O
computer	B
vision	O
,	O
2007	O
.	O
iccv	O
2007	O
.	O
,	O
oct	O
2007	O
,	O
pp	O
.	O
1–8	O
.	O
dominguez	O
,	O
“	O
deep	O
neural	B
networks	I
for	O
small	O
footprint	O
text-	O
dependent	O
speaker	B
veriﬁcation	O
,	O
”	O
in	O
2014	O
ieee	O
international	O
con-	O
[	O
3	O
]	O
n.	O
bru¨mmer	O
and	O
e.	O
de	O
villiers	O
,	O
“	O
the	O
speaker	B
partitioning	O
prob-	O
ference	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
(	O
icassp	O
)	O
.	O
lem	O
.	O
”	O
in	O
odyssey	O
,	O
2010	O
,	O
p.	O
34	O
.	O
ieee	O
,	O
2014	O
,	O
pp	O
.	O
4052–4056	O
.	O
[	O
4	O
]	O
j.	O
villalba	O
and	O
n.	O
bru¨mmer	O
,	O
“	O
towards	O
fully	O
bayesian	O
speaker	B
[	O
22	O
]	O
g.	O
heigold	O
,	O
i.	O
moreno	O
,	O
s.	O
bengio	O
,	O
and	O
n.	O
shazeer	O
,	O
“	O
end	O
-	O
to-	O
recognition	O
:	O
integrating	O
out	O
the	O
between	O
-	O
speaker	B
covariance	O
.	O
”	O
in	O
end	O
text	O
-	O
dependent	O
speaker	B
veriﬁcation	O
,	O
”	O
in	O
2016	O
ieee	O
interna-	O
interspeech	O
,	O
2011	O
,	O
pp	O
.	O
505–508	O
.	O
tional	O
conference	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
[	O
5	O
]	O
p.	O
kenny	O
,	O
“	O
bayesian	O
speaker	B
veriﬁcation	O
with	O
heavy	O
-	O
tailed	O
pri-	O
(	O
icassp	O
)	O
.	O
ieee	O
,	O
2016	O
,	O
pp	O
.	O
5115–5119	O
.	O
ors	O
.	O
”	O
in	O
odyssey	O
,	O
2010	O
,	O
p.	O
14	O
.	O
[	O
23	O
]	O
d.	O
snyder	O
,	O
p.	O
ghahremani	O
,	O
d.	O
povey	O
,	O
d.	O
garcia	O
-	O
romero	O
,	O
[	O
6	O
]	O
d.	O
garcia	O
-	O
romero	O
and	O
c.	O
espy	O
-	O
wilson	O
,	O
“	O
analysis	B
of	O
i	O
-	O
vector	O
y.	O
carmiel	O
,	O
and	O
s.	O
khudanpur	O
,	O
“	O
deep	O
neural	B
network	I
-	O
based	O
length	B
normalization	O
in	O
speaker	B
recognition	O
systems	O
.	O
”	O
in	O
inter-	O
speaker	B
embeddings	I
for	O
end	O
-	O
to	O
-	O
end	O
speaker	B
veriﬁcation	O
,	O
”	O
in	O
spo-	O
speech	O
,	O
2011	O
,	O
pp	O
.	O
249–252	O
.	O
ken	O
language	O
technology	O
workshop	O
(	O
slt	O
)	O
,	O
2016	O
ieee	O
.	O
ieee	O
,	O
2016	O
.	O
[	O
7	O
]	O
d.	O
garcia	O
-	O
romero	O
,	O
x.	O
zhou	O
,	O
and	O
c.	O
espy	O
-	O
wilson	O
,	O
“	O
multicondi-	O
tion	O
training	O
of	O
gaussian	O
plda	B
models	B
in	O
i	O
-	O
vector	O
space	O
for	O
noise	O
[	O
24	O
]	O
s.	O
cumani	O
,	O
p.	O
d.	O
batzu	O
,	O
d.	O
colibro	O
,	O
c.	O
vair	O
,	O
p.	O
laface	O
,	O
and	O
v.	O
vasi-	O
and	O
reverberation	O
robust	B
speaker	I
recognition	O
,	O
”	O
in	O
2012	O
ieee	O
in-	O
lakakis	O
,	O
“	O
comparison	O
of	O
speaker	B
recognition	O
approaches	O
for	O
real	O
ternational	O
conference	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
process-	O
applications	O
,	O
”	O
in	O
interspeech	O
.	O
isca	O
,	O
2011	O
.	O
ing	O
(	O
icassp	O
)	O
.	O
ieee	O
,	O
2012	O
,	O
pp	O
.	O
4257–4260	O
.	O
[	O
25	O
]	O
d.	O
povey	O
,	O
a.	O
ghoshal	O
,	O
g.	O
boulianne	O
,	O
l.	O
burget	O
,	O
o.	O
glembek	O
,	O
[	O
8	O
]	O
p.	O
kenny	O
,	O
v.	O
gupta	O
,	O
t.	O
stafylakis	O
,	O
p.	O
ouellet	O
,	O
and	O
j.	O
alam	O
,	O
“	O
deep	O
n.	O
goel	O
,	O
m.	O
hannemann	O
,	O
p.	O
motl´ıcˇek	O
,	O
y.	O
qian	O
,	O
p.	O
schwarz	O
et	O
al	O
.	O
,	O
neural	B
networks	I
for	O
extracting	O
baum	O
-	O
welch	O
statistics	B
for	O
speaker	B
“	O
the	O
kaldi	O
speech	B
recognition	I
toolkit	O
,	O
”	O
in	O
proceedings	O
of	O
the	O
au-	O
recognition	O
,	O
”	O
in	O
proc	O
.	O
odyssey	O
,	O
2014	O
.	O
tomatic	O
speech	B
recognition	I
&	O
understanding	O
(	O
asru	O
)	O
workshop	O
,	O
2011	O
.	O
[	O
9	O
]	O
y.	O
lei	O
,	O
n.	O
scheffer	O
,	O
l.	O
ferrer	O
,	O
and	O
m.	O
mclaren	O
,	O
“	O
a	O
novel	O
scheme	O
for	O
speaker	B
recognition	O
using	O
a	O
phonetically	O
-	O
aware	O
deep	O
neural	O
[	O
26	O
]	O
v.	O
peddinti	O
,	O
d.	O
povey	O
,	O
and	O
s.	O
khudanpur	O
,	O
“	O
a	O
time	B
delay	O
neural	B
network	I
,	O
”	O
in	O
2014	O
ieee	O
international	O
conference	O
on	O
acoustics	B
,	O
network	B
architecture	B
for	O
efﬁcient	O
modeling	O
of	O
long	O
temporal	O
con-	O
speech	O
and	O
signal	B
processing	I
(	O
icassp	O
)	O
.	O
ieee	O
,	O
2014	O
,	O
pp	O
.	O
1695	O
–	O
texts	O
.	O
”	O
in	O
interspeech	O
,	O
2015	O
,	O
pp	O
.	O
3214–3218	O
.	O
1699	O
.	O
[	O
27	O
]	O
d.	O
povey	O
,	O
x.	O
zhang	O
,	O
and	O
s.	O
khudanpur	O
,	O
“	O
parallel	O
training	O
[	O
10	O
]	O
d.	O
garcia	O
-	O
romero	O
,	O
x.	O
zhang	O
,	O
a.	O
mccree	O
,	O
and	O
d.	O
povey	O
,	O
“	O
im-	O
of	O
deep	O
neural	B
networks	I
with	O
natural	O
gradient	O
and	O
parameter	O
proving	O
speaker	B
recognition	O
performance	O
in	O
the	O
domain	B
adapta-	O
averaging	O
,	O
”	O
corr	O
,	O
vol	O
.	O
abs/1410.7455	O
,	O
2015	O
.	O
[	O
online	O
]	O
.	O
available	O
:	O
tion	O
challenge	B
using	O
deep	O
neural	B
networks	I
,	O
”	O
in	O
spoken	B
language	I
http://arxiv.org/abs/1410.7455	O
technology	O
workshop	O
(	O
slt	O
)	O
,	O
2014	O
ieee	O
.	O
ieee	O
,	O
2014	O
,	O
pp	O
.	O
378	O
–	O
[	O
28	O
]	O
“	O
the	O
nist	O
year	O
2010	O
speaker	B
recognition	O
evaluation	B
plan	I
,	O
”	O
383	O
.	O
http://www.itl.nist.gov/iad/mig/tests/sre/2010/	O
,	O
2010	O
.	O
[	O
11	O
]	O
d.	O
snyder	O
,	O
d.	O
garcia	O
-	O
romero	O
,	O
and	O
d.	O
povey	O
,	O
“	O
time	B
delay	O
deep	O
[	O
29	O
]	O
“	O
nist	O
speaker	B
recognition	O
evaluation	B
2016	O
,	O
”	O
neural	B
network	I
-	O
based	O
universal	O
background	O
models	B
for	O
speaker	B
https://www.nist.gov/itl/iad/mig/speaker-recognition-evaluation-	O
recognition	O
,	O
”	O
in	O
2015	O
ieee	O
workshop	O
on	O
automatic	O
speech	O
2016/	O
,	O
2016	O
.	O
recognition	O
and	O
understanding	O
(	O
asru	O
)	O
.	O
ieee	O
,	O
2015	O
,	O
pp	O
.	O
92–97	O
.	O
[	O
30	O
]	O
d.	O
garcia	O
-	O
romero	O
,	O
d.	O
snyder	O
,	O
g.	O
sell	O
,	O
d.	O
povey	O
,	O
and	O
a.	O
mccree	O
,	O
[	O
12	O
]	O
f.	O
richardson	O
,	O
d.	O
reynolds	O
,	O
and	O
n.	O
dehak	O
,	O
“	O
deep	O
neural	B
network	I
“	O
speaker	B
diarization	I
using	O
deep	O
neural	B
network	I
embeddings	O
,	O
”	O
in	O
approaches	O
to	O
speaker	B
and	O
language	O
recognition	O
,	O
”	O
signal	B
process-	O
2017	O
ieee	O
international	O
conference	O
on	O
acoustics	B
,	O
speech	O
and	O
ing	O
letters	O
,	O
ieee	O
,	O
vol	O
.	O
22	O
,	O
no	O
.	O
10	O
,	O
pp	O
.	O
1671–1675	O
,	O
2015	O
.	O
signal	B
processing	I
(	O
icassp	O
)	O
.	O
ieee	O
,	O
2017	O
,	O
pp	O
.	O
4930–4934	O
.	O
[	O
13	O
]	O
o.	O
novotny	O
´	O
,	O
p.	O
mateˇjka	O
,	O
o.	O
glembeck	O
,	O
o.	O
plchot	O
,	O
f.	O
gre´zl	O
,	O
l.	O
bur-	O
get	O
,	O
and	O
j.	O
cˇ	O
ernocky	O
´	O
,	O
“	O
analysis	B
of	O
the	O
dnn	O
-	O
based	O
sre	O
systems	O
in	O
multi	O
-	O
language	O
conditions	O
,	O
”	O
in	O
spoken	B
language	I
technology	O
workshop	O
(	O
slt	O
)	O
,	O
2016	O
ieee	O
.	O
ieee	O
,	O
2016	O
.	O
[	O
14	O
]	O
o.	O
glembek	O
,	O
l.	O
burget	O
,	O
n.	O
brummer	O
,	O
o.	O
plchot	O
,	O
and	O
p.	O
matejka	O
,	O
“	O
discriminatively	O
trained	O
i	O
-	O
vector	O
extractor	B
for	O
speaker	B
veriﬁca-	O
tion	O
,	O
”	O
in	O
interspeech	O
,	O
2011	O
.	O
[	O
15	O
]	O
l.	O
burget	O
,	O
o.	O
plchot	O
,	O
s.	O
cumani	O
,	O
o.	O
glembek	O
,	O
p.	O
mateˇjka	O
,	O
and	O
n.	O
bru¨mmer	O
,	O
“	O
discriminatively	O
trained	O
probabilistic	O
linear	O
dis-	O
criminant	O
analysis	B
for	O
speaker	B
veriﬁcation	O
,	O
”	O
in	O
2011	O
ieee	O
inter-	O
national	O
conference	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
(	O
icassp	O
)	O
.	O
ieee	O
,	O
2011	O
,	O
pp	O
.	O
4832–4835	O
.	O
[	O
16	O
]	O
y.	O
konig	O
,	O
l.	O
heck	O
,	O
m.	O
weintraub	O
,	O
and	O
k.	O
sonmez	O
,	O
“	O
nonlinear	O
dis-	O
criminant	O
feature	O
extraction	B
for	O
robust	O
text	O
-	O
independent	O
speaker	B
recognition	O
,	O
”	O
in	O
proc	O
.	O
rla2c	O
,	O
esca	O
workshop	O
on	O
speaker	B
recog-	O
nition	O
and	O
its	O
commercial	O
and	O
forensic	O
applications	O
,	O
1998	O
.	O
[	O
17	O
]	O
l.	O
heck	O
,	O
y.	O
konig	O
,	O
k.	O
sonmez	O
,	O
and	O
m.	O
weintraub	O
,	O
“	O
robustness	O
to	O
telephone	O
handset	O
distortion	O
in	O
speaker	B
recognition	O
by	O
discrim-	O
inative	O
feature	O
design	O
,	O
”	O
in	O
speech	B
communication	I
,	O
vol	O
.	O
31	O
,	O
no	O
.	O
2	O
,	O
2000	O
,	O
pp	O
.	O
181–192	O
.	O
[	O
18	O
]	O
k.	O
chen	O
and	O
a.	O
salman	O
,	O
“	O
learning	O
speaker	B
-	O
speciﬁc	O
character-	O
istics	O
with	O
a	O
deep	O
neural	O
architecture	B
,	O
”	O
in	O
ieee	O
transactions	O
on	O
neural	B
networks	I
,	O
vol	O
.	O
22	O
,	O
no	O
.	O
11	O
,	O
2011	O
,	O
pp	O
.	O

impact	O
of	O
overlapping	B
speech	I
detection	B
on	O
speaker	B
diarization	I
for	O
broadcast	O
news	O
and	O
debates	O
delphine	O
charlet	O
,	O
claude	O
barras	O
,	O
jean	O
-	O
sylvain	O
liénard	O
to	O
cite	O
this	O
version	O
:	O
delphine	O
charlet	O
,	O
claude	O
barras	O
,	O
jean	O
-	O
sylvain	O
liénard	O
.	O
impact	O
of	O
overlapping	B
speech	I
detection	B
on	O
speaker	B
diarization	I
for	O
broadcast	O
news	O
and	O
debates	O
.	O
ieee	O
international	O
conference	O
on	O
acoustics	B
,	O
speech	O
,	O
and	O
signal	B
processing	I
,	O
jan	O
2013	O
,	O
vancouver	O
,	O
canada	O
.	O
￿hal-01836475￿	O
hal	O
i	O
d	O
:	O
hal-01836475	O
https://hal.archives-ouvertes.fr/hal-01836475	O
submitted	O
on	O
6	O
nov	O
2018	O
hal	O
is	O
a	O
multi	O
-	O
disciplinary	O
open	O
access	O
l’archive	O
ouverte	O
pluridisciplinaire	O
hal	O
,	O
est	O
archive	O
for	O
the	O
deposit	O
and	O
dissemination	O
of	O
sci-	O
destinée	O
au	O
dépôt	O
et	O
à	O
la	O
diffusion	O
de	O
documents	O
entific	O
research	B
documents	O
,	O
whether	O
they	O
are	O
pub-	O
scientifiques	O
de	O
niveau	O
recherche	O
,	O
publiés	O
ou	O
non	O
,	O
lished	O
or	O
not	O
.	O
the	O
documents	O
may	O
come	O
from	O
émanant	O
des	O
établissements	O
d’enseignement	O
et	O
de	O
teaching	O
and	O
research	B
institutions	O
in	O
france	O
or	O
recherche	O
français	O
ou	O
étrangers	O
,	O
des	O
laboratoires	O
abroad	O
,	O
or	O
from	O
public	O
or	O
private	O
research	B
centers	O
.	O
publics	O
ou	O
privés.impact	O
of	O
overlapping	B
speech	I
detection	B
on	O
speaker	B
diarization	I
for	O
broadcast	O
news	O
and	O
debates	O
delphine	O
charlet1	O
,	O
claude	O
barras2	O
and	O
jean	O
-	O
sylvain	O
lie´nard2	O
1orange	O
labs	O
,	O
france	O
telecom	O
,	O
lannion	O
,	O
france	O
2limsi	O
-	O
cnrs	O
,	O
univ	O
.	O
paris	O
-	O
sud	O
,	O
91403	O
,	O
orsay	O
,	O
france	O
1delphine.charlet@orange.com	O
,	O
2barras@limsi.fr	O
,	O
jslienard@gmail.com	O
abstract	O
2	O
.	O
etape	O
campaign	O
and	O
data	B
the	O
etape	O
evaluation	B
campaign	O
took	O
place	O
in	O
spring	O
2012	O
[	O
5	O
]	O
.	O
it	O
the	O
overlapping	B
speech	I
detection	B
systems	O
developped	O
by	O
orange	O
evaluated	O
segmentation	B
,	O
transcription	B
and	O
information	B
extraction	B
in	O
and	O
limsi	O
for	O
the	O
etape	O
evaluation	B
campaign	O
on	O
french	O
broadcast	O
the	O
audio	O
channel	O
of	O
french	O
tv	O
and	O
radio	O
broadcasts	O
.	O
this	O
work	O
news	O
and	O
debates	O
are	O
described	O
.	O
using	O
either	O
cepstral	O
features	O
or	O
a	O
addresses	O
the	O
segmentation	B
tasks	O
,	O
i.e.	O
the	O
multiple	O
speaker	B
detection	B
multi	O
-	O
pitch	B
analysis	B
,	O
a	O
f1-measure	O
for	O
overlapping	B
speech	I
detection	B
and	O
speaker	B
turn	O
segmentation	B
.	O
up	O
to	O
59.2	O
%	O
is	O
reported	O
on	O
the	O
tv	O
data	B
of	O
the	O
etape	O
evaluation	B
the	O
multiple	O
speaker	B
detection	B
task	O
(	O
ses-2	O
)	O
aims	O
at	O
detecting	O
set	B
,	O
where	O
6.7	O
%	O
of	O
the	O
speech	O
was	O
measured	O
as	O
overlapping	B
,	O
ranging	O
the	O
start	O
and	O
end	O
times	O
of	O
segments	O
containing	O
speech	O
from	O
more	O
from	O
1.2	O
%	O
in	O
the	O
news	O
to	O
10.7	O
%	O
in	O
the	O
debates	O
.	O
overlapping	B
speech	I
than	O
one	O
speaker	B
.	O
manual	O
annotation	O
of	O
overlaps	B
along	O
with	O
the	O
ref-	O
segments	O
were	O
excluded	O
during	O
the	O
speaker	B
diarization	I
stage	B
,	O
and	O
erence	O
transcription	B
was	O
provided	O
by	O
elda	O
,	O
and	O
the	O
temporal	O
extent	O
these	O
segments	O
were	O
further	O
labelled	O
with	O
the	O
two	O
nearest	O
speaker	B
of	O
the	O
overlaps	B
was	O
reﬁned	O
through	O
a	O
forced	O
alignment	O
between	O
the	O
labels	O
,	O
taking	O
into	O
account	O
the	O
temporal	O
distance	B
.	O
we	O
describe	O
the	O
reference	B
and	O
an	O
automatic	O
transcription2	O
.	O
due	O
to	O
the	O
exploratory	O
effects	O
of	O
this	O
strategy	O
for	O
various	O
overlapping	B
speech	I
systems	O
and	O
nature	O
of	O
the	O
task	O
,	O
several	O
metrics	O
were	O
proposed	O
but	O
no	O
ofﬁcial	O
met-	O
we	O
show	O
that	O
it	O
improves	O
the	O
diarization	B
error	I
rate	I
in	O
all	O
situations	O
ric	O
was	O
chosen	O
.	O
we	O
report	O
recall	O
and	O
precision	O
of	O
multiple	O
speech	O
and	O
up	O
to	O
26.1	O
%	O
relative	O
in	O
our	O
best	O
conﬁguration	O
.	O
detection	B
expressed	O
in	O
duration	O
,	O
with	O
non	O
-	O
speech	O
regions	O
excluded	O
index	O
terms	B
—	O
speaker	B
diarization	I
,	O
overlapping	B
speech	I
from	O
the	O
scoring	O
,	O
and	O
the	O
resulting	O
f1-measure	O
.	O
moreover	O
,	O
we	O
re-	O
strict	O
to	O
the	O
tv	O
data	B
since	O
the	O
forced	O
alignment	O
was	O
not	O
performed	O
for	O
the	O
radio	O
training	B
data	I
subset	O
.	O
performance	O
in	O
the	O
speaker	B
diarization	I
task	O
(	O
srl	O
)	O
is	O
measured	O
1	O
.	O
introduction	O
by	O
the	O
diarization	B
error	I
rate	I
(	O
der	O
)	O
as	O
the	O
sum	O
of	O
miss	B
detection	B
rate	O
,	O
false	B
alarm	I
rate	O
and	O
speaker	B
error	B
rate	I
,	O
where	O
speaker	B
error	O
automatic	O
speech	B
recognition	I
and	O
speaker	B
diarization	I
on	O
broadcast	O
rate	O
is	O
obtained	O
after	O
optimal	O
mapping	O
between	O
automatic	O
clusters	O
data	B
long	O
focused	O
on	O
contents	O
where	O
speech	O
overlaps	B
were	O
rare	O
,	O
or	O
and	O
reference	B
speakers3	O
.	O
usually	O
,	O
evaluation	B
of	O
speaker	B
diarization	I
excluded	O
speech	O
overlap	O
segments	O
from	O
their	O
evaluation	B
.	O
on	O
the	O
is	O
performed	O
after	O
excluding	O
regions	O
of	O
overlapped	B
speech	I
.	O
here	O
,	O
other	O
hand	O
,	O
studies	O
on	O
more	O
spontaneous	O
speech	O
from	O
multi	O
-	O
party	O
we	O
evaluate	O
the	O
system	O
including	O
overlapped	B
speech	I
regions	O
.	O
if	O
an	O
conversations	O
,	O
especially	O
telephone	O
conversations	O
and	O
meetings	O
re-	O
overlapped	B
speech	I
region	O
is	O
assigned	O
to	O
only	O
one	O
speaker	B
,	O
this	O
region	O
port	O
that	O
6	O
to	O
14	O
%	O
of	O
words	B
are	O
overlapped	O
[	O
1	O
,	O
2	O
]	O
,	O
and	O
overlapping	B
is	O
considered	O
as	O
missed	O
speech	O
for	O
the	O
second	O
speaker	B
.	O
if	O
an	O
non-	O
speech	O
was	O
identiﬁed	O
as	O
a	O
major	O
cause	O
of	O
error	O
for	O
speaker	B
diariza-	O
overlapped	B
speech	I
region	O
is	O
falsely	O
detected	O
as	O
overlapped	B
speech	I
tion	O
[	O
3	O
]	O
.	O
on	O
broadcast	O
data	B
,	O
the	O
assumption	O
that	O
speech	O
overlap	O
is	O
region	O
and	O
assigned	O
to	O
2	O
speakers	O
,	O
this	O
region	O
will	O
be	O
counted	O
as	O
negligible	O
is	O
no	O
longer	O
valid	O
,	O
when	O
it	O
comes	O
to	O
deal	O
with	O
political	O
false	B
alarm	I
speech	O
for	O
the	O
second	O
speaker	B
.	O
interviews	O
[	O
4	O
]	O
or	O
talk	O
-	O
shows	O
[	O
5	O
]	O
.	O
the	O
etape	O
tv	O
subset	O
consists	O
in	O
29	O
hours	B
of	O
data	B
(	O
18	O
hours	B
to	O
the	O
best	O
of	O
our	O
knowledge	B
,	O
all	O
the	O
published	O
studies	O
about	O
training	O
,	O
5.5	O
hours	B
development	O
and	O
5.5	O
hours	B
test	B
)	O
from	O
three	O
overlapped	B
speech	I
in	O
speaker	B
diarization	I
focused	O
on	O
meeting	O
data	B
french	O
tv	O
channels	B
(	O
lcp	O
,	O
bfm	O
and	O
tv8	O
)	O
with	O
news	O
(	O
bfm	O
story	O
,	O
or	O
on	O
telephone	O
conversations	O
.	O
this	O
work	O
focuses	O
on	O
overlapping	B
lcp	O
top	O
questions	O
)	O
,	O
debates	O
(	O
lcp	O
pile	O
et	O
face	O
,	O
lcp	O
c¸	O
a	O
vous	O
re-	O
speech	B
detection	I
in	O
french	O
tv	O
broadcasts	O
and	O
its	O
impact	O
on	O
speaker	B
garde	O
,	O
lcp	O
entre	O
les	O
lignes	O
)	O
and	O
reportages	O
from	O
a	O
local	O
tv	O
with	O
diarization	B
in	O
the	O
context	O
of	O
the	O
etape	O
evaluation	B
campaign1	O
.	O
the	O
unprofesionnal	O
speakers	O
(	O
tv8	O
la	O
place	O
du	O
village	O
)	O
.	O
for	O
the	O
whole	O
next	O
sections	O
describes	O
the	O
etape	O
evaluation	B
and	O
its	O
data	B
,	O
the	O
dataset	O
,	O
the	O
ratio	O
of	O
overlaps	B
amounts	O
to	O
5.9	O
%	O
,	O
ranging	O
from	O
1.8	O
%	O
proposed	O
overlapping	B
speech	I
detection	B
approaches	O
and	O
their	O
perfor-	O
in	O
the	O
news	O
to	O
3	O
%	O
in	O
the	O
reportage	O
and	O
8.7	O
%	O
in	O
the	O
debates	O
(	O
cf	O
.	O
mance	O
,	O
their	O
integration	O
for	O
speaker	B
diarization	I
and	O
concludes	O
with	O
table	O
1	O
)	O
.	O
the	O
mean	O
duration	O
of	O
overlap	O
segments	O
in	O
the	O
training	O
a	O
comparison	O
with	O
existing	O
work	O
.	O
set	B
is	O
1.07	O
sec	O
.	O
and	O
their	O
median	O
duration	O
is	O
0.72	O
sec	O
(	O
see	O
figure	O
1	O
for	O
the	O
normalized	O
histogram	O
of	O
overlap	O
durations	O
)	O
.	O
the	O
cumulated	O
duration	O
of	O
overlaps	B
on	O
the	O
same	O
figure	O
shows	O
that	O
overlaps	B
longer	O
experiments	O
were	O
performed	O
in	O
the	O
context	O
of	O
the	O
french	O
etape	O
evalu-	O
ation	O
campaign	O
.	O
limsi	O
work	O
was	O
partly	O
realized	O
as	O
part	O
of	O
the	O
quaero	O
pro-	O
gram	O
and	O
the	O
qcompere	O
project	O
,	O
respectively	O
funded	O
by	O
oseo	O
(	O
french	O
state	O
2thanks	O
to	O
olivier	O
galibert	O
from	O
lne	O
for	O
providing	O
these	O
alignments	O
to	O
agency	O
for	O
innovation	O
)	O
and	O
anr	O
(	O
french	O
national	O
research	B
agency	O
)	O
.	O
orange	O
the	O
etape	O
participants	B
.	O
work	O
was	O
partly	O
realized	O
as	O
part	O
of	O
the	O
percol	O
project	O
funded	O
by	O
anr	O
.	O
3der	O
reported	O
in	O
this	O
paper	O
were	O
computed	O
using	O
the	O
conventionnal	O
nist	O
1http://www.afcp-parole.org/etape.html	O
evaluation	B
tools	O
with	O
the	O
default	O
value	O
of	O
collar	O
of	O
250msthan	O
1	O
sec	O
.	O
cover	O
about	O
70	O
%	O
of	O
the	O
cumulated	O
duration	O
of	O
overlap-	O
thus	O
remaining	O
computationnaly	O
light	O
compared	O
to	O
other	O
multi	O
-	O
pitch	B
ping	O
speech	O
,	O
even	O
if	O
they	O
represent	O
only	O
35	O
%	O
of	O
the	O
occurences	O
.	O
the	O
estimators	O
.	O
let	O
pt	O
0	O
,	O
1	O
,	O
2	O
be	O
the	O
number	O
of	O
hypothesized	O
f0	O
∈	O
{	O
}	O
corpus	B
is	O
biased	O
towards	O
male	O
speakers	O
,	O
with	O
a	O
lot	O
of	O
journalists	O
and	O
output	B
by	O
the	O
multi	O
-	O
pitch	B
detector	O
for	O
the	O
frame	B
xt	O
.	O
this	O
value	O
is	O
politicians	O
:	O
there	O
are	O
160	O
male	O
vs.	O
43	O
female	O
speakers	O
in	O
the	O
training	O
then	O
smoothed	O
through	O
a	O
hamming	O
window	O
h	O
of	O
size	B
d	O
,	O
resulting	O
in	O
set	B
,	O
accounting	O
for	O
about	O
90	O
%	O
of	O
the	O
total	O
duration	O
,	O
and	O
overlaps	B
the	O
frame	B
-	O
level	B
harmonic	O
feature	O
ht	O
:	O
almost	O
exclusively	O
involve	O
male	O
speakers	O
.	O
d/2	O
1	O
−	O
h	O
=	O
h(j).p	O
t	O
t+j	O
j=￿−d/2	O
finally	O
,	O
a	O
frame	B
-	O
level	B
linear	O
combination	O
of	O
the	O
lt	O
and	O
ht	O
values	B
was	O
submitted	O
as	O
limsi	O
primary	O
system	O
to	O
the	O
etape	O
ses2	O
task	O
,	O
with	O
combination	O
weights	O
and	O
decision	O
thresholds	O
optimized	O
on	O
the	O
development	B
set	I
.	O
3.2	O
.	O
cepstral	O
features	O
by	O
orange	O
three	O
gmms	O
λi	O
i=0	O
...	O
2	O
with	O
256	O
gaussians	O
,	O
resp	O
.	O
for	O
male	O
{	O
}	O
non	O
-	O
overlapped	B
speech	I
,	O
female	O
non	O
-	O
overlapped	B
speech	I
and	O
over-	O
fig	O
.	O
1	O
.	O
distribution	O
of	O
overlap	O
durations	O
in	O
the	O
training	O
set	B
lapped	O
speech	O
,	O
were	O
trained	O
using	O
forced	O
-	O
alignement	O
between	O
au-	O
tomatic	O
and	O
reference	B
transcriptions	B
of	O
the	O
etape	O
training	B
data	I
provided	O
by	O
lne	O
.	O
cepstral	O
features	O
(	O
12	O
mfcc	O
and	O
log	B
-	O
energy	O
3	O
.	O
overlapping	B
speech	I
detection	B
with	O
their	O
ﬁrst	O
and	O
second	O
order	B
derivatives	O
)	O
are	O
computed	O
over	O
a	O
windows	O
of	O
32	O
ms	O
with	O
a	O
16	O
ms	O
frame	B
rate	O
.	O
a	O
2-class	O
hmm	O
this	O
section	O
describes	O
the	O
overlapping	B
speech	I
detection	B
systems	O
de-	O
(	O
overlapped	O
/	O
non	O
-	O
overlapped	O
(	O
with	O
male	O
and	O
female	O
gmm	O
models	B
)	O
veloped	O
by	O
limsi	O
and	O
orange	O
for	O
the	O
etape	O
evaluation	B
campaign	O
is	O
then	O
built	O
.	O
viterbi	O
decoding	O
,	O
only	O
applied	O
after	O
a	O
ﬁrst	O
external	O
and	O
their	O
performance	O
in	O
the	O
ses2	O
task	O
.	O
speech	O
/	O
non	O
-	O
speech	O
segmentation	B
step	O
,	O
is	O
associated	O
with	O
a	O
minimal	O
state	O
duration	O
(	O
2s	O
in	O
non	O
-	O
overlapped	B
speech	I
and	O
0.5s	O
in	O
overlapped	O
3.1	O
.	O
limsi	O
system	O
combining	O
cepstral	O
and	O
multi	O
-	O
pich	O
features	O
speech	O
)	O
.	O
finally	O
,	O
a	O
post	O
-	O
processing	B
ﬁltering	O
discards	O
all	O
the	O
detected	O
overlapped	O
-	O
speech	B
segments	I
whose	O
length	B
is	O
less	O
than	O
1s	O
.	O
this	O
was	O
for	O
the	O
limsi	O
system	O
,	O
three	O
gmm	O
λi	O
i=0	O
...	O
2	O
with	O
256	O
gaussians	O
,	O
the	O
system	O
integrated	O
to	O
in	O
the	O
diarization	B
process	B
submitted	O
to	O
the	O
{	O
}	O
respectively	O
for	O
non	O
-	O
speech	O
,	O
non	O
-	O
overlapping	B
speech	I
and	O
overlap-	O
etape	O
evaluation	B
campaign	O
.	O
ping	O
speech	O
,	O
are	O
trained	O
using	O
forced	O
alignement	O
between	O
automatic	O
since	O
the	O
campaign	O
,	O
the	O
post	O
-	O
processing	B
ﬁltering	O
based	O
on	O
the	O
and	O
reference	B
transcriptions	B
of	O
the	O
etape	O
training	B
data	I
provided	O
by	O
length	B
of	O
the	O
segments	O
has	O
been	O
replaced	O
with	O
a	O
ﬁltering	O
based	O
on	O
lne	O
.	O
cepstral	O
features	O
(	O
12	O
plp	O
and	O
log	B
-	O
energy	O
along	O
with	O
their	O
ﬁrst-	O
log	B
-	O
likelihood	B
ratio	I
value	O
at	O
the	O
segment	B
level	B
.	O
for	O
a	O
detected	O
over-	O
and	O
second	O
-	O
order	B
derivatives	O
)	O
are	O
computed	O
over	O
a	O
windows	O
of	O
30	O
ms	O
lapped	O
speech	B
segment	I
x	O
of	O
n	O
frames	O
(	O
x1	O
,	O
..	O
,	O
xn	O
)	O
,	O
whith	O
the	O
same	O
with	O
a	O
10	O
ms	O
step	O
.	O
the	O
frame	B
-	O
level	B
likelihood	B
-	O
ratio	O
(	O
llr	O
)	O
between	O
deﬁnition	O
as	O
above	O
,	O
the	O
conﬁdence	O
measure	O
is	O
:	O
the	O
multiple	O
-	O
speaker	B
model	B
f(x	O
λ2	O
)	O
and	O
the	O
two	O
other	O
hypothesis	B
|	O
icsomsmpoaorethdetdo	O
oavdeercaishioanmthmreinshgowldinodpotwimhizedanodntthheerdeesvueltlionpgmveanlut	O
eseltt	O
:	O
s(x	O
)	O
=	O
1	O
n	O
log	B
f(xt|λ2	O
)	O
log(n	O
)	O
f(x	O
λ	O
)	O
t	O
1	O
t=1	O
|	O
￿	O
d/2	O
1	O
the	O
conﬁdence	O
measure	O
s(x	O
)	O
is	O
compared	O
to	O
a	O
threshold	B
to	O
lt	O
=	O
−	O
h(j	O
)	O
.	O
log	B
f(x	O
fλ(x)t++j|fλ(2x	O
)	O
λ	O
)	O
validate	O
the	O
detection	B
or	O
not	O
.	O
the	O
length	B
normalisation	O
by	O
log(n	O
)	O
j=￿−d/2	O
t+j|	O
0	O
t+j|	O
1	O
iwnestheaavdeoofbthseervuesudatlhnat	O
tihsemloenagntdteotefcatvioornsthoefloovnegrldaeptpeecdtiospnese	O
.	O
cihndweeerde	O
,	O
in	O
our	O
developments	O
,	O
this	O
approach	O
was	O
found	O
to	O
perform	O
better	O
than	O
more	O
likely	O
to	O
be	O
correct	O
than	O
the	O
short	O
ones	O
.	O
a	O
viterbi	O
decoding	O
with	O
the	O
λi	O
models	B
as	O
proposed	O
in	O
[	O
6	O
]	O
(	O
either	O
{	O
}	O
with	O
a	O
minimal	O
duration	O
or	O
a	O
transition	O
penalty	O
)	O
.	O
3.3	O
.	O
development	O
and	O
evaluation	B
results	B
given	O
the	O
harmonic	O
nature	O
of	O
voiced	O
speech	O
,	O
it	O
can	O
be	O
expected	O
that	O
approaches	O
and	O
features	O
which	O
are	O
relevant	O
for	O
speech	O
separa-	O
for	O
limsi	O
system	O
,	O
the	O
performance	O
of	O
the	O
multi	O
-	O
pitch	B
system	O
was	O
tion	O
and	O
multi	O
-	O
pitch	B
detection	B
[	O
7	O
]	O
are	O
also	O
of	O
interest	O
for	O
overlapping	B
signiﬁcantly	O
worse	O
than	O
the	O
cepstral	O
system	O
on	O
the	O
development	B
set	I
speech	B
detection	I
.	O
we	O
performed	O
our	O
experiments	O
with	O
the	O
psh	O
al-	O
(	O
f1	O
measure	O
of	O
45.3	O
%	O
vs.	O
54.5	O
%	O
)	O
,	O
however	O
it	O
only	O
relies	O
on	O
a	O
frame-	O
gorithm	O
designed	O
by	O
lie´nard	O
et	O
al	O
.	O
[	O
8	O
]	O
.	O
it	O
is	O
based	O
on	O
a	O
frequential	O
level	B
ternary	O
feature	O
compared	O
to	O
the	O
13	O
real	O
-	O
valued	O
features	O
used	O
in	O
approach	O
and	O
uses	O
several	O
spectral	O
combs	O
.	O
spectral	O
combs	O
are	O
used	O
the	O
cepstral	O
system	O
.	O
the	O
optimal	O
size	B
for	O
the	O
hamming	O
smoothing	O
as	O
pattern	O
matching	O
tools	O
for	O
detecting	O
the	O
harmonic	O
structures	O
of	O
window	O
was	O
found	O
to	O
be	O
slightly	O
different	O
(	O
2.5	O
sec	O
.	O
for	O
lt	O
vs.	O
2	O
sec	O
.	O
voiced	O
segments	O
of	O
speech	O
.	O
the	O
dot	O
product	O
between	O
a	O
comb	O
and	O
for	O
ht	O
)	O
.	O
the	O
combination	O
of	O
both	O
systems	O
further	O
improved	O
the	O
f1	O
the	O
amplitude	O
spectrum	B
produces	O
a	O
pitch	B
function	O
exhibiting	O
local	O
performance	O
to	O
55.8	O
%	O
on	O
the	O
development	B
set	I
and	O
was	O
chosen	O
for	O
maxima	O
at	O
frequencies	O
where	O
f0	O
is	O
most	O
probable	O
.	O
but	O
in	O
the	O
mul-	O
the	O
limsi	O
primary	O
submission	O
to	O
the	O
etape	O
ses2	O
task	O
.	O
tipitch	O
cases	O
,	O
numerous	O
spurious	O
peaks	B
appear	O
.	O
to	O
strongly	O
attenu-	O
table	O
2	O
presents	O
the	O
results	B
on	O
the	O
evaluation	B
tv	O
subset	O
.	O
the	O
ate	O
them	O
,	O
two	O
families	O
of	O
combs	O
are	O
used	O
:	O
negative	O
teeth	O
comb	O
and	O
segment	B
length	B
ﬁltering	O
dramatically	O
improves	O
f1	O
value	O
of	O
orange	O
missing	O
teeth	O
comb	O
which	O
treat	O
selectively	O
harmonics	O
errors	B
and	O
sub-	O
cepstral	O
system	O
from	O
43.3	O
%	O
to	O
55.2	O
%	O
mainly	O
due	O
to	O
an	O
increase	O
in	O
harmonics	O
errors	B
.	O
the	O
algorithm	O
performs	O
a	O
frame	B
-	O
to	O
-	O
frame	B
analysis	B
precision	O
,	O
and	O
the	O
alternative	O
llr	O
ﬁltering	O
further	O
improves	O
it	O
to	O
over	O
a	O
50	O
ms	O
window	O
with	O
10	O
ms	O
step	O
without	O
any	O
post	O
-	O
processing	B
,	O
59.8	O
%	O
.	O
limsi	O
system	O
presents	O
a	O
f1-measure	O
slightly	O
lower	O
at	O
58.2%show	O
type	O
train	O
development	O
evaluation	B
all	O
news	O
5.6	O
/	O
297.9	O
(	O
1.9	O
%	O
)	O
1.1	O
/	O
67.6	O
(	O
1.7	O
%	O
)	O
0.8	O
/	O
66.4	O
(	O
1.2	O
%	O
)	O
7.6	O
/	O
431.9	O
(	O
1.8	O
%	O
)	O
debates	O
41.5	O
/	O
486.3	O
(	O
8.5	O
%	O
)	O
9.6	O
/	O
128.7	O
(	O
7.5	O
%	O
)	O
13.6	O
/	O
130.1	O
(	O
10.4	O
%	O
)	O
64.7	O
/	O
745.1	O
(	O
8.7	O
%	O
)	O
reportage	O
-	O
0.7	O
/	O
37.6	O
(	O
1.8	O
%	O
)	O
1.7	O
/	O
41.9	O
(	O
4.0	O
%	O
)	O
2.4	O
/	O
79.4	O
(	O
3.0	O
%	O
)	O
total	O
47.1	O
/	O
784.2	O
(	O
6.0	O
%	O
)	O
11.4	O
/	O
233.9	O
(	O
4.9	O
%	O
)	O
16.0	O
/	O
238.3	O
(	O
6.7	O
%	O
)	O
74.6	O
/	O
1256.4	O
(	O
5.9	O
%	O
)	O
table	O
1	O
.	O
duration	O
(	O
in	O
minutes	O
)	O
and	O
ratio	O
of	O
overlapping	B
speech	I
relative	O
to	O
total	O
speech	O
in	O
train	O
,	O
development	O
and	O
evaluation	B
subsets	O
,	O
depending	O
on	O
the	O
genre	O
of	O
the	O
show	O
with	O
a	O
lower	O
recall	O
(	O
52.7	O
%	O
vs.	O
64.3	O
%	O
)	O
but	O
a	O
better	O
precision	O
than	O
effective	O
,	O
and	O
closed	O
to	O
a	O
perfect	O
(	O
oracle	O
)	O
labeling	O
strategies	O
.	O
this	O
the	O
best	O
orange	O
system	O
(	O
64.9	O
%	O
vs.	O
56.0	O
%	O
)	O
.	O
as	O
could	O
be	O
expected	O
,	O
overlap	O
handling	O
scheme	O
has	O
been	O
commonly	O
adopted	O
in	O
the	O
studies	O
longer	O
overlaps	B
are	O
easier	O
to	O
detect	O
,	O
and	O
this	O
behaviour	O
is	O
illustrated	O
about	O
the	O
impact	O
of	O
overlapped	B
speech	I
in	O
speaker	B
diarization	I
(	O
e.g.	O
for	O
the	O
best	O
performing	O
o2	O
system	O
on	O
figure	O
2	O
where	O
the	O
overlap	O
[	O
10	O
]	O
)	O
.	O
here	O
,	O
we	O
perform	O
overlap	O
exclusion	O
and	O
propose	O
a	O
slightly	O
segments	O
in	O
the	O
reference	B
which	O
are	O
shorter	O
than	O
a	O
minimal	O
duration	O
modiﬁed	O
labeling	O
strategy	O
,	O
to	O
cope	O
with	O
the	O
errors	B
of	O
overlap	O
detec-	O
are	O
ignored	O
for	O
the	O
scoring	O
.	O
tion	O
:	O
overlap	O
labeling	O
:	O
always	O
label	O
the	O
segment	B
with	O
the	O
nearest	O
•	O
system	O
p	O
r	O
f1	O
speaker	B
(	O
in	O
time	B
)	O
,	O
and	O
label	O
with	O
the	O
second	O
nearest	O
speaker	B
orange	O
cepstral	O
29.9	O
78.5	O
43.3	O
only	O
if	O
its	O
temporal	O
distance	B
to	O
the	O
segment	B
is	O
below	O
a	O
given	O
orange	O
cepstral+length	O
ﬁltering	O
(	O
o1	O
)	O
45.5	O
70.2	O
55.2	O
threshold	B
ts	O
.	O
orange	O
cepstral+llr	O
ﬁltering	O
(	O
o2	O
)	O
56.0	O
64.3	O
59.8	O
this	O
variant	O
is	O
meant	O
to	O
cope	O
with	O
error	O
of	O
false	O
detection	B
of	O
over-	O
limsi	O
system	O
(	O
l1	O
)	O
64.9	O
52.7	O
58.2	O
lapped	O
speech	O
in	O
the	O
middle	O
of	O
a	O
speaker	B
turn	O
.	O
the	O
diarization	B
system	O
used	O
in	O
these	O
experiments	O
is	O
the	O
one	O
de-	O
table	O
2	O
.	O
precision	O
(	O
p	O
)	O
,	O
recall	O
(	O
r	O
)	O
and	O
f1-measure	O
of	O
overlap	O
detec-	O
velopped	O
by	O
orange	O
based	O
on	O
the	O
principles	O
of	O
[	O
11	O
]	O
:	O
the	O
ﬁrst	O
step	O
tion	O
on	O
the	O
etape	O
tv	O
evaluation	B
subset	O
for	O
the	O
different	O
systems	O
consists	O
in	O
building	O
an	O
agglomerative	O
clustering	B
of	O
speech	B
segments	I
(	O
ofﬁcial	O
submissions	O
to	O
the	O
etape	O
evaluation	B
in	O
bold	O
)	O
.	O
based	O
on	O
bayesian	O
information	B
criterion	B
(	O
where	O
each	O
cluster	O
is	O
mod-	O
eled	O
by	O
a	O
single	O
gaussian	O
with	O
a	O
full	O
covariance	O
matrix	O
)	O
.	O
when	O
each	O
cluster	O
contains	O
enough	O
data	B
to	O
model	B
the	O
voice	O
more	O
precisely	O
,	O
the	O
clusters	O
are	O
modeled	O
with	O
gaussians	O
mixture	O
,	O
and	O
the	O
agglomerative	O
clustering	B
is	O
pursued	O
with	O
a	O
distance	B
between	O
clusters	O
based	O
on	O
a	O
cross	O
-	O
likelihood	B
criterion	B
.	O
at	O
each	O
iteration	O
of	O
the	O
clustering	B
based	O
on	O
cross	O
-	O
likelihood	B
,	O
a	O
viterbi	O
decoding	O
is	O
also	O
performed	O
to	O
reseg-	O
ment	O
the	O
speech	O
data	B
into	O
speaker	B
turns	O
,	O
given	O
the	O
new	O
clusters	O
.	O
4.2	O
.	O
evaluations	O
in	O
the	O
figure	O
3	O
,	O
we	O
plot	O
the	O
diarization	B
error	I
rate	I
(	O
der	O
)	O
obtained	O
with	O
different	O
overlapping	B
speech	I
detection	B
systems	O
,	O
when	O
includ-	O
ing	O
overlapping	B
speech	I
in	O
the	O
evaluation	B
,	O
and	O
as	O
a	O
function	O
of	O
the	O
threshold	B
ts	O
.	O
for	O
comparison	O
,	O
the	O
baseline	B
system	I
processes	O
the	O
documents	O
without	O
detection	B
of	O
overlapped	B
speech	I
.	O
the	O
other	O
sys-	O
tems	O
apply	O
the	O
overlap	O
exclusion	O
step	O
,	O
and	O
the	O
proposed	O
new	O
label-	O
ing	O
strategy	O
,	O
using	O
one	O
of	O
the	O
proposed	O
overlapping	B
speech	I
detection	B
fig	O
.	O
2	O
.	O
performance	O
of	O
overlap	B
detection	I
as	O
a	O
function	O
of	O
minimal	O
segment	B
length	B
in	O
the	O
reference	B
for	O
o2	O
system	O
.	O
sbyystoemransgoe1t	O
,	O
ooth2eosrrll1.tatskheosfytshteemetwaiptheoch1awllaesngthee	O
.	O
foinnealsluyb	O
,	O
moriattcelde	O
experiments	O
(	O
i.e.	O
automatic	O
speaker	B
diarization	I
with	O
a	O
perfect	O
over-	O
lapping	O
speech	B
detection	I
)	O
are	O
also	O
reported	O
.	O
ts	O
=	O
0	O
corresponds	O
4	O
.	O
diarization	B
experiments	O
to	O
the	O
performances	O
obtained	O
when	O
a	O
second	O
speaker	B
label	O
is	O
never	O
attributed	O
to	O
the	O
detected	O
overlapping	B
speech	I
segments	O
.	O
on	O
the	O
con-	O
4.1	O
.	O
principle	O
trary	O
,	O
for	O
ts	O
=	O
a	O
second	O
speaker	B
label	O
is	O
always	O
attributed	O
to	O
these	O
∞	O
segments	O
.	O
in	O
previous	O
studies	O
about	O
speaker	B
diarization	I
in	O
meetings	O
[	O
3	O
]	O
,	O
de-	O
first	O
,	O
we	O
can	O
observe	O
that	O
,	O
whichever	O
overlapping	B
speech	I
de-	O
tailed	O
error	O
analysis	B
showed	O
that	O
overlapped	B
speech	I
was	O
a	O
major	O
tection	O
system	O
is	O
used	O
and	O
for	O
any	O
ts	O
,	O
it	O
always	O
outperforms	O
the	O
cause	O
of	O
error	O
,	O
and	O
[	O
9	O
]	O
proposed	O
two	O
methods	O
for	O
handling	O
overlap	O
baseline	B
system	I
without	O
overlapping	B
speech	I
detection	B
.	O
the	O
perfor-	O
in	O
speaker	B
diarization	I
:	O
mances	O
obtained	O
with	O
ts	O
=	O
0	O
(	O
only	O
one	O
speaker	B
is	O
assigned	O
to	O
the	O
overlap	O
exclusion	O
:	O
exclude	O
overlapped	B
speech	I
segments	O
from	O
overlapping	B
speech	I
segment	B
)	O
are	O
always	O
far	O
better	O
than	O
the	O
baseline	B
•	O
the	O
diarization	B
process	B
;	O
system	O
.	O
this	O
improvement	O
is	O
due	O
to	O
the	O
puriﬁcation	O
of	O
the	O
clus-	O
ters	O
,	O
which	O
are	O
only	O
fed	O
with	O
detected	O
non	O
-	O
overlapping	B
speech	I
.	O
it	O
overlap	O
labeling	O
:	O
label	O
the	O
overlapped	B
speech	I
segments	O
with	O
•	O
can	O
be	O
seen	O
that	O
the	O
best	O
automatic	O
system	O
reaches	O
the	O
same	O
perfor-	O
the	O
speaker	B
labels	I
of	O
the	O
2	O
nearest	O
speakers	O
(	O
in	O
time	B
)	O
.	O
mance	O
as	O
the	O
oracle	O
system	O
,	O
when	O
only	O
puriﬁcation	O
is	O
performed	O
.	O
on	O
oracle	O
experiments	O
,	O
with	O
perfect	O
overlap	B
detection	I
,	O
the	O
overlap	O
thus	O
,	O
even	O
though	O
the	O
performance	O
of	O
the	O
overlapping	B
speech	I
de-	O
labeling	O
strategies	O
with	O
the	O
2	O
nearest	O
speakers	O
proved	O
to	O
be	O
very	O
tector	O
is	O
average	B
(	O
f1=59.8	O
%	O
)	O
,	O
it	O
is	O
good	O
enough	O
for	O
the	O
exclusiontype	O
of	O
overlapping	B
baseline	B
der	O
with	O
show	O
speech	O
(	O
%	O
)	O
der	O
o2	O
detector	O
news	O
1.2	O
11.9	O
12.6	O
(	O
+5.6	O
%	O
)	O
debates	O
10.4	O
24.7	O
16.5	O
(	O
-33.2	O
%	O
)	O
reportage	O
4.0	O
41.6	O
29.8	O
(	O
-28.4	O
%	O
)	O
all	O
6.7	O
23.8	O
17.6	O
(	O
-26.1	O
%	O
)	O
table	O
4	O
.	O
relative	O
der	O
improvement	O
per	O
type	O
of	O
shows	O
for	O
the	O
best	O
diarization	B
system	O
integrating	O
o2	O
vs.	O
the	O
baseline	B
system	I
.	O
5	O
.	O
relation	O
to	O
prior	O
work	O
many	O
studies	O
have	O
been	O
published	O
on	O
overlapping	B
speech	I
detection	B
for	O
speaker	B
diarization	I
of	O
meetings	O
.	O
some	O
of	O
them	O
perform	O
source	B
separation	O
or	O
source	B
localization	O
relying	O
on	O
multiple	O
channel	O
record-	O
ings	O
[	O
12	O
,	O
13	O
,	O
14	O
,	O
15	O
]	O
which	O
are	O
not	O
available	O
for	O
broadcast	O
data	B
.	O
[	O
16	O
]	O
tested	O
various	O
features	O
for	O
overlapping	B
speech	I
detection	B
in	O
a	O
hmm-	O
based	O
segmenter	O
.	O
on	O
far-ﬁeld	O
recordings	O
of	O
the	O
ami	O
meeting	O
cor-	O
fig	O
.	O
3	O
.	O
diarization	B
error	I
rate	I
(	O
der	O
)	O
as	O
a	O
function	O
of	O
the	O
threshold	B
ts	O
pus	O
with	O
18	O
%	O
of	O
overlapped	B
speech	I
,	O
they	O
get	O
38	O
%	O
f	O
-	O
score	B
in	O
over-	O
controlling	O
the	O
attribution	O
of	O
the	O
second	O
speaker	B
.	O
laps	O
detection	B
.	O
features	O
such	O
as	O
silence	B
distribution	O
[	O
10	O
]	O
or	O
prosodic	B
features	I
[	O
17	O
]	O
also	O
gives	O
a	O
f	O
-	O
score	B
on	O
overlap	B
detection	I
around	O
40	O
%	O
in	O
meetings.[18	O
]	O
proposed	O
a	O
convolutive	O
non	O
-	O
negative	O
sparse	O
cod-	O
ing	O
approach	O
to	O
speech	O
overlap	B
detection	I
;	O
they	O
get	O
a	O
16.1	O
%	O
recall	O
overlaps	B
detector	O
m.d	O
.	O
f.a	O
.	O
ser	O
der	O
and	O
28.6	O
%	O
precision	O
of	O
overlapping	B
speech	I
detection	B
on	O
nist	O
rt	O
none	O
(	O
baseline	B
)	O
6.1	O
0.7	O
17.0	O
23.8	O
meetings	O
.	O
on	O
telephone	O
converstations,[19	O
]	O
used	O
entropy	O
features	O
o1	O
(	O
best	O
recall	O
)	O
1.6	O
4.9	O
14.6	O
21.2	O
estimated	O
in	O
the	O
time	B
domain	B
for	O
detecting	O
overlapping	B
speech	I
,	O
but	O
l1	O
(	O
best	O
precision	O
)	O
3.1	O
2.0	O
14.2	O
19.3	O
their	O
approach	O
is	O
only	O
suitable	O
in	O
a	O
two	O
-	O
speakers	O
situation	O
.	O
finally	O
,	O
o2	O
(	O
best	O
f1	O
)	O
2.0	O
3.0	O
12.6	O
17.6	O
relevant	O
research	B
for	O
overlapping	B
speech	I
detection	B
is	O
also	O
developed	O
oracle	O
2.1	O
1.3	O
12.6	O
16.0	O
in	O
the	O
context	O
of	O
single	O
-	O
channel	O
speech	B
separation	I
[	O
20	O
,	O
21	O
]	O
.	O
when	O
it	O
comes	O
to	O
the	O
integration	O
of	O
overlapping	B
speech	I
detec-	O
table	O
3	O
.	O
decomposition	O
of	O
the	O
diarization	B
error	I
rate	I
into	O
false	O
tion	O
in	O
speaker	B
diarization	I
system	I
,	O
the	O
classical	O
approach	O
consists	O
in	O
alarm	O
(	O
f.a	O
)	O
,	O
missed	O
detection	B
(	O
m.d	O
.	O
)	O
and	O
speaker	B
error	B
rate	I
(	O
ser	O
)	O
.	O
applying	O
exclusion	O
and	O
labeling	O
,	O
when	O
labeling	O
is	O
either	O
performed	O
with	O
speaker	B
posterior	O
probabilities	O
[	O
6	O
,	O
16	O
,	O
22	O
]	O
or	O
2-nearest	O
speaker	B
labeling	O
[	O
9	O
]	O
.	O
relative	O
improvement	O
of	O
der	O
such	O
as	O
4.2	O
%	O
[	O
23	O
]	O
,	O
6.5	O
%	O
[	O
18	O
]	O
,	O
7.2	O
%	O
[	O
17	O
]	O
,	O
12.4	O
%	O
[	O
22	O
]	O
and	O
18.7	O
%	O
[	O
10	O
]	O
have	O
been	O
re-	O
step	O
,	O
to	O
get	O
all	O
the	O
beneﬁts	O
of	O
the	O
puriﬁed	O
clusters	O
.	O
then	O
,	O
the	O
impact	O
ported	O
for	O
meetings	O
data	B
,	O
when	O
the	O
major	O
part	O
of	O
the	O
improvement	O
is	O
of	O
the	O
overlapping	B
speech	I
detections	O
on	O
the	O
labeling	O
strategies	O
can	O
due	O
to	O
the	O
exclusion	O
step	O
.	O
be	O
seen	O
on	O
the	O
rest	O
of	O
the	O
curves	O
.	O
for	O
the	O
system	O
with	O
high	O
recall	O
thus	O
,	O
our	O
work	O
on	O
broadcast	O
data	B
give	O
consistent	O
results	B
with	O
and	O
low	O
precision	O
on	O
overlapped	B
speech	I
detection	B
,	O
it	O
is	O
better	O
not	O
to	O
prior	O
studies	O
on	O
meetings	O
data	B
.	O
but	O
the	O
results	B
obtained	O
on	O
broadcast	O
always	O
assign	O
a	O
second	O
speaker	B
:	O
indeed	O
,	O
the	O
increase	O
of	O
errors	B
due	O
are	O
signiﬁcantly	O
better	O
than	O
those	O
reported	O
on	O
meetings	O
,	O
either	O
for	O
to	O
false	B
alarm	I
of	O
overlapped	B
speech	I
is	O
bigger	O
than	O
the	O
reduction	O
of	O
f	O
-	O
mesure	O
on	O
overlap	B
detection	I
or	O
for	O
relative	O
der	O
improvement	O
.	O
errors	B
due	O
to	O
the	O
attribution	O
of	O
segment	B
of	O
overlapped	B
speech	I
.	O
for	O
6	O
.	O
conclusions	O
the	O
other	O
systems	O
with	O
higher	O
precision	O
on	O
overlapped	B
speech	I
de-	O
tection	O
,	O
always	O
attributing	O
a	O
second	O
speaker	B
appears	O
to	O
be	O
a	O
valid	O
in	O
this	O
paper	O
,	O
we	O
have	O
studied	O
the	O
impact	O
of	O
overlapping	B
speech	I
strategy	O
.	O
table	O
3	O
shows	O
the	O
detailed	O
components	B
of	O
the	O
der	O
for	O
the	O
detection	B
in	O
speaker	B
diarization	I
for	O
broadcast	O
news	O
and	O
debates	O
.	O
“	O
always	O
2-nearest	O
speakers	O
”	O
strategy	O
,	O
with	O
the	O
different	O
overlapping	B
whereas	O
many	O
studies	O
have	O
been	O
done	O
in	O
the	O
context	O
of	O
meetings	O
speech	O
detectors	O
.	O
the	O
speaker	B
error	O
obtained	O
with	O
o2	O
is	O
the	O
same	O
as	O
diarization	B
,	O
this	O
is	O
the	O
ﬁrst	O
time	B
that	O
this	O
question	O
is	O
treated	O
and	O
the	O
one	O
obtained	O
with	O
the	O
oracle	O
detector	O
,	O
and	O
the	O
main	O
differences	O
evaluated	O
in	O
the	O
broadcast	O
context	O
.	O
the	O
basic	O
strategy	O
of	O
overlap	O
lies	O
in	O
the	O
false	B
alarm	I
rate	O
on	O
speaker	B
,	O
which	O
is	O
bigger	O
because	O
of	O
handling	O
proposed	O
in	O
[	O
9	O
]	O
has	O
been	O
applied	O
,	O
with	O
different	O
overlapped	O
the	O
false	B
alarm	I
of	O
overlapping	B
speech	I
detection	B
.	O
on	O
the	O
other	O
hand	O
,	O
speech	O
detectors	O
.	O
the	O
inﬂuence	O
of	O
the	O
second	O
-	O
speaker	B
labeling	O
step	O
the	O
limsi	O
approach	O
has	O
a	O
higher	O
precision	O
than	O
the	O
other	O
ones	O
and	O
has	O
been	O
studied	O
with	O
a	O
modiﬁed	O
labeling	O
strategy	O
.	O
the	O
experiments	O
leads	O
to	O
a	O
smaller	O
fale	O
alarm	O
rate	O
,	O
but	O
does	O
not	O
fully	O
beneﬁts	O
from	O
the	O
were	O
conducted	O
on	O
a	O
corpus	B
of	O
5.5	O
hours	B
of	O
7	O
different	O
tv	O
shows	O
clusters	O
puriﬁcation	O
,	O
thus	O
leading	O
to	O
a	O
higher	O
speaker	B
error	B
rate	I
.	O
with	O
a	O
varying	O
level	B
of	O
overlapped	B
speech	I
,	O
from	O
the	O
etape	O
eval-	O
uation	O
campaign	O
.	O
two	O
overlapping	B
speech	I
detection	B
systems	O
were	O
the	O
der	O
per	O
type	O
of	O
shows	O
(	O
news	O
,	O
debates	O
or	O
reportage	O
)	O
are	O
developed	O
by	O
orange	O
and	O
limsi	O
,	O
relying	O
on	O
standard	O
cepstral	O
fea-	O
presented	O
in	O
table	O
4	O
,	O
for	O
the	O
baseline	B
system	I
,	O
and	O
for	O
the	O
best	O
system	O
tures	O
or	O
on	O
a	O
multi	O
-	O
pitch	B
analysis	B
.	O
the	O
best	O
conﬁguration	O
presents	O
o2	O
(	O
along	O
with	O
the	O
relative	O
improvement	O
rate	O
)	O
,	O
and	O
the	O
overlapped	O
a	O
f1-measure	O
of	O
about	O
60	O
%	O
.	O
the	O
diarization	B
experiments	O
show	O
that	O
speech	O
ratio	O
per	O
type	O
of	O
shows	O
.	O
the	O
more	O
overlapping	B
speech	I
there	O
this	O
level	B
of	O
performance	O
is	O
sufﬁcient	O
to	O
provide	O
all	O
the	O
beneﬁts	O
of	O
is	O
in	O
the	O
data	B
,	O
the	O
better	O
the	O
improvement	O
due	O
to	O
overlapping	B
speech	I
the	O
exclusion	O
step	O
due	O
to	O
the	O
puriﬁcation	O
of	O
the	O
clusters	O
,	O
and	O
enable	O
handling	O
is	O
.	O
for	O
news	O
shows	O
with	O
very	O
little	O
amount	B
of	O
overlapped	O
also	O
improvement	O
at	O
the	O
labeling	O
step	O
.	O
the	O
der	O
decreases	O
from	O
speech	O
,	O
the	O
imprecision	O
due	O
to	O
the	O
overlapped	B
speech	I
detector	O
de-	O
23.8	O
%	O
with	O
no	O
overlap	O
handling	O
to	O
17.6	O
%	O
with	O
automatic	O
overlap	O
grades	O
the	O
overall	O
results	B
,	O
while	O
for	O
debates	O
shows	O
,	O
the	O
decrease	O
of	O
detection	B
.	O
der	O
reaches	O
33.2%.7	O
.	O
references	B
[	O
15	O
]	O
jose	O
pardo	O
,	O
xavier	O
anguera	O
,	O
and	O
chuck	O
wooter	O
,	O
“	O
speaker	B
di-	O
arization	O
for	O
multiple	O
distant	O
microphone	O
meetings	O
:	O
mixing	O
[	O
1	O
]	O
e.	O
shriberg	O
,	O
a.	O
stolcke	O
,	O
and	O
d.	O
baron	O
,	O
“	O
observations	O
on	O
over-	O
acoustic	B
features	I
and	O
inter	O
-	O
channel	O
time	B
differences	O
,	O
”	O
in	O
in-	O
lap	O
:	O
findings	O
and	O
implications	O
for	O
automatic	O
processing	B
of	O
terspeech	O
2006	O
-	O
icsl	O
,	O
pittsburgh	O
,	O
usa	O
,	O
september	O
2006	O
,	O
pp	O
.	O
multi	O
-	O
party	O
conversation	O
,	O
”	O
in	O
proceedings	O
of	O
the	O
7th	O
euro-	O
2194–2197	O
.	O
pean	O
conference	O
of	O
eurospeech	O
,	O
aalborg	O
,	O
september	O
2001	O
,	O
pp	O
.	O
[	O
16	O
]	O
k.	O
boakye	O
,	O
o.	O
vinyals	O
,	O
and	O
g.	O
friedland	O
,	O
“	O
two’sa	O
crowd	O
:	O
im-	O
1359–1362	O
.	O
proving	O
speaker	B
diarization	I
by	O
automatically	O
identifying	O
and	O
[	O
2	O
]	O
o.	O
cetin	O
and	O
e.	O
shriberg	O
,	O
“	O
errors	B
in	O
meetings	O
:	O
effects	O
be-	O
excluding	O
overlapped	B
speech	I
,	O
”	O
in	O
proc	O
.	O
interspeech	O
2008	O
,	O
fore	O
,	O
during	O
,	O
and	O
after	O
the	O
overlap	O
,	O
”	O
in	O
icassp	O
2006	O
,	O
toulouse	O
,	O
2008	O
,	O
pp	O
.	O
32–35	O
.	O
france	O
,	O
may	O
2006	O
.	O
[	O
17	O
]	O
m.	O
zelenak	O
and	O
j.	O
hernando	O
,	O
“	O
the	O
detection	B
of	O
overlapping	B
[	O
3	O
]	O
m.	O
huijbregts	O
and	O
c.	O
wooters	O
,	O
“	O
the	O
blame	O
game	O
:	O
performance	O
speech	O
with	O
prosodic	B
features	I
for	O
speaker	B
diarization	I
,	O
”	O
in	O
proc	O
.	O
analysis	B
of	O
speaker	B
diarization	I
system	I
components	B
,	O
”	O
in	O
proc	O
.	O
interspeech	O
2011	O
,	O
2011	O
,	O
pp	O
.	O
32–35	O
.	O
interspeech	O
,	O
antwerp	O
,	O
belgium	O
,	O
september	O
2007	O
.	O
[	O
18	O
]	O
r.	O
vipperla	O
,	O
j.	O
geiger	O
,	O
s.	O
bozonnet	O
,	O
d.	O
wang	O
,	O
n.	O
evans	O
,	O
[	O
4	O
]	O
gilles	O
adda	O
,	O
martine	O
adda	O
-	O
decker	O
,	O
claude	O
barras	O
,	O
b.	O
schuller	O
,	O
and	O
g.	O
rigoll	O
,	O
“	O
speech	O
overlap	B
detection	I
and	O
philippe	O
boula	O
de	O
mareu¨il	O
,	O
benoˆıt	O
habert	O
,	O
and	O
patrick	O
attribution	O
using	O
convolutive	O
non	O
-	O
negative	O
sparse	O
coding	O
,	O
”	O
in	O
paroubek	O
,	O
“	O
speech	O
overlap	O
and	O
interplay	O
with	O
disﬂuencies	O
icassp-12	O
,	O
2012	O
,	O
pp	O
.	O
4181–4184	O
.	O
in	O
political	O
interviews	O
,	O
”	O
in	O
international	O
workshop	O
on	O
par-	O
[	O
19	O
]	O
o.	O
ben	O
-	O
harush	O
,	O
h.	O
guterman	O
,	O
and	O
i.	O
lapidot	O
,	O
“	O
frame	B
level	B
alinguistic	O
speech	O
-	O
between	O
models	B
and	O
data	B
,	O
paraling	O
2007	O
,	O
entropy	O
based	O
overlapped	B
speech	I
detection	B
as	O
a	O
pre	O
-	O
processing	B
sarbru¨cken	O
,	O
august	O
2007	O
,	O
pp	O
.	O
41–46	O
.	O
stage	B
for	O
speaker	B
diarization	I
,	O
”	O
in	O
machine	O
learning	O
for	O
signal	B
[	O
5	O
]	O
g.	O
gravier	O
,	O
g.	O
adda	O
,	O
n.	O
paulson	O
,	O
m.	O
carre	O
´	O
,	O
a.	O
giraudel	O
,	O
processing	B
,	O
2009	O
.	O
mlsp	O
2009	O
.	O
ieee	O
international	O
workshop	O
o.	O
galibert	O
,	O
et	O
al	O
.	O
,	O
“	O
the	O
etape	O
corpus	B
for	O
the	O
evaluation	B
of	O
on	O
,	O
2009	O
,	O
pp	O
.	O
1–6	O
.	O
speech	O
-	O
based	O
tv	O
content	O
processing	B
in	O
the	O
french	O
language	O
,	O
”	O
[	O
20	O
]	O
p.	O
mowlaee	O
,	O
m.	O
g	O
christensen	O
,	O
z.	O
h	O
tan	O
,	O
and	O
s.	O
h	O
jensen	O
,	O
“	O
a	O
in	O
international	O
conference	O
on	O
language	O
resources	O
,	O
evalua-	O
map	O
criterion	B
for	O
detecting	O
the	O
number	O
of	O
speakers	O
at	O
frame	B
tion	O
and	O
corpora	B
,	O
2012	O
.	O
level	B
in	O
model	B
-	O
based	O
single	O
-	O
channel	O
speech	B
separation	I
,	O
”	O
in	O
sig-	O
[	O
6	O
]	O
k.	O
boakye	O
,	O
b.	O
trueba	O
-	O
hornero	O
,	O
o.	O
vinyals	O
,	O
and	O
g.	O
friedland	O
,	O
nals	O
,	O
systems	O
and	O
computers	O
(	O
asilomar	O
)	O
,	O
2010	O
conference	O
“	O
overlapped	B
speech	I
detection	B
for	O
improved	O
speaker	B
diarization	I
record	O
of	O
the	O
forty	O
fourth	O
asilomar	O
conference	O
on	O
,	O
2010	O
,	O
pp	O
.	O
in	O
multiparty	O
meetings	O
,	O
”	O
in	O
ieee	O
international	O
conference	O
on	O
538–541	O
.	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
(	O
icassp	O
)	O
,	O
2008	O
,	O
pp	O
.	O
[	O
21	O
]	O
r.	O
saeidi	O
,	O
p.	O
mowlaee	O
,	O
t.	O
kinnunen	O
,	O
z.	O
h	O
tan	O
,	O
m.	O
g	O
chris-	O
4353–4356	O
.	O
tensen	O
,	O
s.	O
h	O
jensen	O
,	O
and	O
p.	O
fra¨nti	O
,	O
“	O
improving	O
monaural	O
[	O
7	O
]	O
a.	O
de	O
cheveigne	O
´	O
,	O
“	O
multiple	O
f0	O
estimation	B
,	O
”	O
in	O
computational	O
speaker	B
identiﬁcation	O
by	O
double	O
-	O
talk	O
detection	B
,	O
”	O
in	O
eleventh	O
auditory	O
scene	O
analysis	B
:	O
principles	O
,	O
algorithms	O
and	O
appli-	O
annual	B
conference	I
of	O
the	O
international	O
speech	O
communica-	O
cations	O
,	O
deliang	O
wang	O
and	O
guy	O
j.	O
brown	O
,	O
eds	O
.	O
,	O
pp	O
.	O
65–70	O
.	O
tion	O
association	O
,	O
2010	O
.	O
wiley	O
/	O
ieee	O
press	O
,	O
2006	O
.	O
[	O
22	O
]	O
k.	O
boakye	O
,	O
o.	O
vinyals	O
,	O
and	O
g.	O
friedland	O
,	O
“	O
improved	O
over-	O
[	O
8	O
]	O
j	O
-	O
s	O
.	O
lie´nard	O
,	O
c.	O
barras	O
,	O
and	O
f.	O
signol	O
,	O
“	O
using	O
sets	O
of	O
combs	O
to	O
lapped	O
speech	O
handling	O
for	O
speaker	B
diarization	I
,	O
”	O
in	O
12th	O
an-	O
control	O
pitch	B
estimation	B
errors	B
,	O
”	O
proc	O
.	O
of	O
meetings	O
on	O
acous-	O
nual	O
conference	O
of	O
the	O
international	O
speech	B
communication	I
tics	O
,	O
vol	O
.	O
4	O
,	O
no	O
.	O
1	O
,	O
2008	O
.	O
association	O
,	O
florence	O
,	O
italy	O
,	O
2011	O
,	O
pp	O
.	O
941–944	O
.	O
[	O
9	O
]	O
s.	O
otterson	O
and	O
m.	O
ostendorf	O
,	O
“	O
efﬁcient	O
use	O
of	O
overlap	O
infor-	O
[	O
23	O
]	O
m.	O
huijbregts	O
,	O
d.	O
van	O
leeuwen	O
,	O
and	O
f.	O
de	O
jong	O
,	O
“	O
speech	O
over-	O
mation	O
in	O
speaker	B
diarization	I
,	O
”	O
in	O
proc	O
.	O
asru	O
,	O
kyoto	O
,	O
japan	O
,	O
lap	O
detection	B
in	O
a	O
two	O
-	O
pass	O
speaker	B
diarization	I
system	I
,	O
”	O
in	O
december	O
2007	O
.	O
proc	O
.	O
interpseech	O
,	O
2009	O
.	O
[	O
10	O
]	O
s.h	O
.	O
yella	O
and	O
f.	O
valente	O
,	O
“	O
speaker	B
diarization	I
of	O
overlapping	B
speech	I
based	O
on	O
silence	B
distribution	O
in	O
meetings	O
recordings	O
,	O
”	O
in	O
proc	O
.	O
interpseech	O
,	O
portland	O
,	O
usa	O
,	O
september	O
2012	O
.	O
[	O
11	O
]	O
c.	O
barras	O
,	O
x.	O
zhu	O
,	O
s.	O
meignier	O
,	O
and	O
j	O
-	O
l	O
.	O
gauvain	O
,	O
“	O
multi	O
-	O
stage	B
speaker	B
diarization	I
of	O
broadcast	O
news	O
,	O
”	O
ieee	O
transactions	O
on	O
audio	O
,	O
speech	O
and	O
language	B
processing	I
,	O
vol	O
.	O
14	O
,	O
no	O
.	O
5	O
,	O
pp	O
.	O
1505–1512	O
,	O
2006	O
.	O
[	O
12	O
]	O
thilo	O
pfau	O
,	O
daniel	O
p.w	O
.	O
ellis	O
,	O
and	O
andreas	O
stolcke	O
,	O
“	O
mul-	O
tispeaker	O
speech	B
activity	I
detection	I
for	O
the	O
icsi	O
meeting	O
recorder	O
,	O
”	O
in	O
proceedings	O
ieee	O
automatic	O
speech	O
recogni-	O
tion	O
and	O
understanding	O
workshop	O
-	O
asru	O
,	O
trento	O
,	O
italy	O
,	O
de-	O
cember	O
2001	O
.	O
[	O
13	O
]	O
s.	O
j.	O
wrigley	O
,	O
g.	O
j.	O
brown	O
,	O
v.	O
wan	O
,	O
and	O
s.	O
renals	O
,	O
“	O
speech	O
and	O
crosstalk	O
detection	B
in	O
multi	O
-	O
channel	O
audio	O
,	O
”	O
ieee	O
trans	O
.	O
on	O
speech	O
and	O
audio	O
processing	B
,	O
vol	O
.	O
13	O
,	O
pp	O
.	O
84–91	O
,	O
2005	O
.	O
[	O
14	O
]	O
kornel	O
laskowski	O
and	O
tanja	O
schultz	O
,	O
“	O
unsupervised	O
learn-	O
ing	O
of	O
overlapped	B
speech	I
model	B
parameters	O
for	O
multichan-	O
nel	O
speech	B
activity	I
detection	I
in	O
meetings	O
,	O
”	O
in	O
icassp	O
2006	O
,	O
toulouse	O
,	O
france	O
,	O
may	O
2006	O
,	O
pp	O
.	O

integrating	O
end	O
-	O
to	O
-	O
end	O
neural	O
and	O
clustering	B
-	O
based	O
diarization	B
:	O
getting	O
the	O
best	O
of	O
both	O
worlds	O
keisuke	O
kinoshita	O
,	O
marc	O
delcroix	O
,	O
naohiro	O
tawara	O
ntt	O
corporation	O
,	O
japan	O
abstract	O
that	O
they	O
can	O
not	O
handle	O
overlapped	B
speech	I
,	O
i.e.	O
,	O
time	B
segments	O
where	O
0	O
more	O
than	O
one	O
person	O
is	O
speaking	O
,	O
because	O
of	O
the	O
way	O
of	O
extracting	O
2	O
recent	O
diarization	B
technologies	O
can	O
be	O
categorized	O
into	O
two	O
ap-	O
speaker	B
embeddings	I
.	O
perhaps	O
surprisingly	O
,	O
even	O
in	O
professional	O
0	O
proaches	O
,	O
i.e.	O
,	O
clustering	B
and	O
end	O
-	O
to	O
-	O
end	O
neural	O
approaches	O
,	O
which	O
meetings	O
,	O
the	O
percentage	B
of	O
overlapped	B
speech	I
is	O
in	O
the	O
order	B
of	O
5	O
to	O
2	O
have	O
different	O
pros	O
and	O
cons	O
.	O
the	O
clustering	B
-	O
based	O
approaches	O
10	O
%	O
,	O
while	O
in	O
informal	O
get	O
-	O
togethers	O
it	O
can	O
easily	O
exceed	O
20	O
%	O
[	O
10	O
]	O
.	O
  	O
assign	O
speaker	B
labels	I
to	O
speech	O
regions	O
by	O
clustering	B
speaker	B
em-	O
t	O
end	O
-	O
to	O
-	O
end	O
neural	O
diarization	B
(	O
eend	O
)	O
has	O
been	O
recently	O
de-	O
c	O
beddings	O
such	O
as	O
x	O
-	O
vectors	O
.	O
while	O
it	O
can	O
be	O
seen	O
as	O
a	O
current	O
state-	O
veloped	O
[	O
11–13	O
]	O
to	O
address	O
the	O
overlapped	B
speech	I
problem	O
.	O
simi-	O
o	O
of	O
-	O
the	O
-	O
art	O
approach	O
that	O
works	O
for	O
various	O
challenging	O
data	B
with	O
larly	O
to	O
the	O
neural	O
source	B
separation	O
algorithms	O
[	O
14	O
,	O
15	O
]	O
,	O
in	O
eend	O
,	O
a	O
6	O
 	O
rtheaastoitnacbanlenorot	O
bhuasntdnleessovaenrdlapacpceudraspcye	O
,	O
eciht	O
hthaast	O
aiscirniteivciatlabdliesaidnvnaanttuargael	O
neural	B
network	I
(	O
nn	O
)	O
receives	O
standard	O
frame	B
-	O
level	B
spectral	O
features	O
2	O
and	O
directly	O
outputs	O
a	O
frame	B
-	O
level	B
speaker	B
activity	O
for	O
each	O
speaker	B
,	O
conversational	O
data	B
.	O
in	O
contrast	O
,	O
the	O
end	O
-	O
to	O
-	O
end	O
neural	O
diarization	B
  	O
no	O
matter	O
whether	O
the	O
input	B
signal	B
contains	O
overlapped	B
speech	I
or	O
  	O
(	O
eend	O
)	O
,	O
which	O
directly	O
predicts	O
diarization	B
labels	O
using	O
a	O
neural	O
]	O
not	O
.	O
while	O
the	O
system	O
is	O
simple	O
and	O
has	O
started	O
outperforming	O
the	O
s	O
network	B
,	O
was	O
devised	O
to	O
handle	O
the	O
overlapped	B
speech	I
.	O
while	O
the	O
conventional	O
clustering	B
-	O
based	O
algorithms	O
[	O
12	O
,	O
13	O
]	O
,	O
it	O
is	O
difﬁcult	O
to	O
eend	O
,	O
which	O
can	O
easily	O
incorporate	O
emerging	O
deep	O
-	O
learning	O
tech-	O
a	O
directly	O
apply	O
the	O
eend	O
systems	O
to	O
long	O
recordings	O
(	O
e.g.	O
,	O
record-	O
nologies	O
,	O
has	O
started	O
outperforming	O
the	O
x	O
-	O
vector	O
clustering	B
approach	O
s.	O
in	O
some	O
realistic	O
database	O
,	O
it	O
is	O
difﬁcult	O
to	O
make	O
it	O
work	O
for	O
long	O
ings	O
longer	O
than	O
10	O
minutes	O
)	O
.	O
the	O
system	O
is	O
designed	O
to	O
operate	O
in	O
a	O
batch	O
processing	B
mode	O
and	O
thus	O
requires	O
a	O
very	O
large	O
computer	B
s	O
recordings	O
(	O
e.g.	O
,	O
recordings	O
longer	O
than	O
10	O
minutes	O
)	O
because	O
of	O
,	O
e.g.	O
,	O
e	O
memory	O
when	O
performing	O
inference	B
with	O
long	O
recordings	O
.	O
besides	O
,	O
its	O
huge	O
memory	O
consumption	O
.	O
block	O
-	O
wise	O
independent	O
process-	O
e	O
aside	O
from	O
the	O
memory	O
issue	O
,	O
the	O
nns	O
in	O
eend	O
has	O
difﬁculty	O
to	O
ing	O
is	O
also	O
difﬁcult	O
because	O
it	O
poses	O
an	O
inter	O
-	O
block	O
label	O
permutation	O
[	O
generalize	O
to	O
unseen	O
very	O
long	O
sequential	O
data	B
,	O
which	O
also	O
ham-	O
  	O
problem	O
,	O
i.e.	O
,	O
an	O
ambiguity	O
of	O
the	O
speaker	B
label	O
assignments	O
between	O
  	O
pers	O
its	O
application	B
to	O
the	O
long	O
recordings	O
.	O
note	O
that	O
,	O
if	O
we	O
segment	B
1	O
blocks	O
.	O
in	O
this	O
paper	O
,	O
we	O
propose	O
a	O
simple	O
but	O
effective	O
hybrid	O
di-	O
the	O
long	O
recordings	O
into	O
small	O
chunks	O
and	O
apply	O
the	O
original	O
eend	O
v	O
arization	O
framework	O
that	O
works	O
with	O
overlapped	B
speech	I
and	O
for	O
long	O
model	B
to	O
each	O
chunk	O
independently	O
,	O
the	O
model	B
inevitably	O
suffers	O
6	O
recordings	O
containing	O
an	O
arbitrary	O
number	O
of	O
speakers	O
.	O
it	O
modiﬁes	O
from	O
the	O
inter	O
-	O
block	O
label	O
permutation	O
problem	O
,	O
i.e.	O
,	O
an	O
ambiguity	O
6	O
the	O
conventional	O
eend	O
framework	O
to	O
output	B
global	O
speaker	B
embed-	O
of	O
the	O
speaker	B
label	O
assignments	O
between	O
chunks	O
.	O
to	O
address	O
this	O
3	O
dings	O
so	O
that	O
speaker	B
clustering	B
can	O
be	O
performed	O
across	O
blocks	O
to	O
3	O
solve	O
the	O
permutation	O
problem	O
.	O
with	O
experiments	O
based	O
on	O
simu-	O
problem	O
(	O
and	O
simultaneously	O
seek	O
for	O
a	O
low	O
-	O
latency	O
solution	O
)	O
,	O
[	O
16	O
]	O
1	O
lated	O
noisy	O
reverberant	O
2-speaker	O
meeting	O
-	O
like	O
data	B
,	O
we	O
show	O
that	O
proposed	O
an	O
nn	O
-	O
based	O
extension	O
of	O
the	O
eend	O
to	O
block	O
-	O
online	O
pro-	O
0	O
.	O
the	O
proposed	O
framework	O
works	O
signiﬁcantly	O
better	O
than	O
the	O
original	O
cessing	O
.	O
the	O
method	B
in	O
[	O
16	O
]	O
ﬁrst	O
tries	O
to	O
ﬁnd	O
single	B
speaker	I
regions	O
,	O
and	O
use	O
them	O
as	O
a	O
guide	O
to	O
assign	O
the	O
speaker	B
labels	I
to	O
the	O
diariza-	O
1	O
eend	O
especially	O
when	O
the	O
input	B
data	B
is	O
long	O
.	O
tion	O
results	B
of	O
future	O
blocks	O
.	O
however	O
,	O
their	O
performance	O
typically	O
0	O
index	O
terms	B
—	O
speaker	B
diarization	I
,	O
neural	B
networks	I
,	O
does	O
not	O
reach	O
that	O
of	O
the	O
original	O
eend	O
.	O
also	O
,	O
more	O
importantly	O
,	O
2	O
the	O
method	B
can	O
not	O
handle	O
an	O
arbitrary	O
number	O
of	O
speakers	O
.	O
:	O
v	O
1	O
.	O
introduction	O
in	O
this	O
paper	O
,	O
we	O
propose	O
a	O
simple	O
but	O
effective	O
hybrid	O
diariza-	O
i	O
tion	O
approach	O
,	O
called	O
eend	O
-	O
vector	O
clustering	B
,	O
by	O
combining	O
the	O
x	O
automatic	O
meeting	O
/	O
conversation	O
analysis	B
is	O
one	O
of	O
the	O
essential	O
tech-	O
best	O
of	O
the	O
clustering	B
-	O
based	O
diarization	B
and	O
the	O
eend	O
.	O
a	O
central	O
r	O
nologies	O
required	O
for	O
realizing	O
futuristic	O
speech	O
applications	O
such	O
as	O
component	O
of	O
the	O
proposed	O
approach	O
is	O
a	O
modiﬁed	O
eend	O
network	B
a	O
communication	B
agents	O
that	O
can	O
follow	O
,	O
respond	O
to	O
,	O
and	O
facilitate	O
our	O
that	O
outputs	O
,	O
in	O
each	O
chunk	O
,	O
not	O
only	O
the	O
diarization	B
results	B
but	O
also	O
conversation	O
.	O
as	O
an	O
important	O
central	O
task	O
for	O
the	O
meeting	O
analysis	B
,	O
global	O
speaker	B
embeddings	I
associated	O
with	O
the	O
diarization	B
results	B
.	O
speaker	B
diarization	I
has	O
been	O
extensively	O
studied	O
[	O
1–3	O
]	O
.	O
the	O
inter	O
-	O
block	O
permutation	O
ambiguity	O
problem	O
can	O
thus	O
be	O
sim-	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
diarization	B
systems	I
that	O
achieve	O
reli-	O
ply	O
solved	O
by	O
clustering	B
the	O
block	O
-	O
level	B
speaker	B
embedding	O
vectors	O
.	O
able	O
performance	O
in	O
many	O
challenges	B
[	O
1	O
,	O
2	O
]	O
is	O
based	O
on	O
clustering	B
this	O
extension	O
thus	O
naturally	O
allows	O
us	O
to	O
combine	O
the	O
advantages	O
of	O
of	O
speaker	B
embeddings	I
(	O
i.e.	O
,	O
speaker	B
identity	O
features	O
)	O
such	O
as	O
i-	O
both	O
clustering	B
and	O
the	O
eend	O
based	O
methods	O
,	O
i.e.	O
it	O
can	O
work	O
with	O
vectors	O
[	O
4	O
]	O
and	O
x	O
-	O
vectors	O
[	O
5	O
]	O
.	O
such	O
clustering	B
-	O
based	O
approaches	O
overlapped	B
speech	I
and	O
deal	O
with	O
long	O
recordings	O
including	O
an	O
arbi-	O
ﬁrst	O
segment	B
a	O
recording	B
into	O
short	O
homogeneous	O
blocks	O
and	O
com-	O
trary	O
number	O
of	O
speakers	O
.	O
in	O
particular	O
,	O
we	O
conﬁrm	O
experimentally	O
pute	O
speaker	B
embeddings	I
for	O
each	O
block	O
assuming	O
that	O
only	O
one	O
that	O
the	O
proposed	O
eend	O
-	O
vector	O
clustering	B
signiﬁcantly	O
outperforms	O
speaker	B
is	O
active	O
in	O
each	O
block	O
.	O
then	O
,	O
speaker	B
embedding	O
vectors	O
the	O
original	O
eend	O
system	O
especially	O
when	O
the	O
recordings	O
are	O
long	O
,	O
are	O
clustered	O
to	O
regroup	O
segments	O
belonging	O
to	O
the	O
same	O
speakers	O
e.g.	O
,	O
more	O
than	O
5	O
minutes	O
,	O
while	O
maintaining	O
the	O
same	O
performance	O
and	O
obtain	O
the	O
diarization	B
results	B
.	O
various	O
speaker	B
embeddings	I
and	O
as	O
the	O
original	O
eend	O
system	O
when	O
the	O
recording	B
is	O
short	O
.	O
clustering	B
techniques	B
have	O
been	O
explored	O
in	O
[	O
6–9	O
]	O
.	O
while	O
these	O
the	O
remainder	O
of	O
this	O
paper	O
is	O
organized	O
as	O
follows	O
.	O
we	O
ﬁrst	O
in-	O
methods	O
can	O
cope	O
with	O
very	O
challenging	O
scenarios	O
[	O
6	O
,	O
7	O
]	O
and	O
work	O
troduce	O
the	O
proposed	O
framework	O
in	O
section	O
2	O
in	O
detail	O
.	O
then	O
,	O
in	O
sec-	O
with	O
an	O
arbitrary	O
number	O
of	O
speakers	O
,	O
there	O
is	O
a	O
clear	O
disadvantage	O
tion	O
3	O
,	O
we	O
evaluate	O
its	O
performance	O
in	O
comparison	O
with	O
the	O
originallineard	O
(	O
s	O
=	O
1	O
,	O
2	O
)	O
,	O
where	O
s	O
is	O
the	O
speaker	B
index	O
within	O
a	O
chunk	O
.	O
s	O
since	O
it	O
is	O
not	O
always	O
guaranteed	O
that	O
the	O
diarization	B
results	B
of	O
a	O
cer-	O
tain	O
speaker	B
are	O
estimated	O
at	O
the	O
same	O
output	B
node	O
,	O
we	O
may	O
have	O
the	O
inter	O
-	O
block	O
label	O
permutation	O
problem	O
in	O
the	O
diarization	B
outputs	O
.	O
as	O
an	O
example	O
,	O
in	O
fig	O
.	O
1	O
,	O
the	O
network	B
lineard	O
estimates	O
the	O
diarization	B
1	O
result	O
of	O
‘	O
speaker	B
a	O
’	O
in	O
the	O
ﬁrst	O
chunk	O
,	O
and	O
that	O
of	O
‘	O
speaker	B
b	O
’	O
in	O
the	O
second	O
chunk	O
.	O
this	O
means	O
that	O
we	O
can	O
not	O
obtain	O
an	O
optimal	O
diariza-	O
tion	O
result	O
simply	O
by	O
stitching	O
the	O
diarization	B
results	B
of	O
a	O
speciﬁc	O
output	B
node	O
across	O
all	O
the	O
chunks	O
.	O
to	O
solve	O
this	O
permutation	O
problem	O
,	O
we	O
simultaneously	O
estimate	O
a	O
speaker	B
embedding	O
corresponding	O
to	O
each	O
diarization	B
result	O
in	O
each	O
chunk	O
.	O
the	O
network	B
to	O
estimate	O
the	O
speaker	B
embeddings	I
are	O
denoted	O
as	O
linears	O
(	O
s	O
=	O
1	O
,	O
2	O
)	O
in	O
fig	O
.	O
1	O
.	O
the	O
speaker	B
embedding	O
extraction	B
s	O
network	B
is	O
optimized	O
through	O
the	O
nn	O
training	O
such	O
that	O
the	O
vectors	O
of	O
the	O
same	B
speaker	I
stay	O
close	O
to	O
each	O
other	O
,	O
while	O
the	O
vectors	O
of	O
different	O
speakers	O
lie	O
far	O
away	O
from	O
each	O
other	O
.	O
this	O
can	O
be	O
seen	O
in	O
the	O
ﬁgure	O
by	O
examining	O
how	O
the	O
embeddings	O
are	O
organized	O
in	O
the	O
speaker	B
embedding	O
space	O
.	O
therefore	O
,	O
after	O
obtaining	O
diarization	B
re-	O
sults	O
for	O
all	O
chunks	O
,	O
by	O
clustering	B
the	O
speaker	B
embeddings	I
given	O
the	O
total	O
number	O
of	O
speakers	O
in	O
the	O
input	B
recording	B
(	O
3	O
in	O
this	O
case	O
)	O
,	O
we	O
can	O
estimate	O
the	O
correct	O
association	O
of	O
the	O
diarization	B
results	B
among	O
chunks	O
.	O
then	O
,	O
ﬁnally	O
,	O
the	O
overall	O
diarization	B
results	B
are	O
obtained	O
by	O
stitching	O
them	O
together	O
based	O
on	O
the	O
embedding	O
clustering	B
result	O
.	O
note	O
that	O
while	O
the	O
proposed	O
framework	O
estimates	O
the	O
diarization	B
results	B
of	O
the	O
ﬁxed	O
number	O
of	O
speakers	O
in	O
a	O
chunk	O
,	O
it	O
can	O
handle	O
a	O
fig	O
.	O
1	O
:	O
schematic	O
diagram	O
of	O
the	O
proposed	O
diarization	B
framework	O
.	O
meeting	O
with	O
an	O
arbitrary	O
number	O
of	O
speakers	O
.	O
the	O
input	B
contains	O
3	O
speakers	O
in	O
total	O
(	O
red	O
,	O
green	O
,	O
and	O
blue	O
speakers	O
for	O
the	O
clustering	B
,	O
we	O
can	O
use	O
any	O
clustering	B
algorithms	O
.	O
how-	O
shown	O
in	O
the	O
waveform	O
in	O
the	O
bottom	O
)	O
,	O
but	O
only	O
at	O
most	O
2	O
speakers	O
ever	O
,	O
it	O
may	O
be	O
preferable	O
if	O
the	O
clustering	B
algorithm	O
is	O
aware	O
of	O
the	O
are	O
actively	O
speaking	O
in	O
each	O
chunk	O
.	O
characteristic	O
of	O
this	O
framework	O
and	O
work	O
with	O
a	O
constraint	O
that	O
the	O
speaker	B
embeddings	I
from	O
a	O
chunk	O
should	O
not	O
belong	O
to	O
the	O
same	B
speaker	I
cluster	O
.	O
in	O
this	O
paper	O
,	O
to	O
incorporate	O
the	O
constraint	O
into	O
the	O
eend	O
to	O
clarify	O
the	O
advantages	O
of	O
the	O
proposed	O
framework	O
.	O
finally	O
,	O
clustering	B
stage	B
,	O
we	O
use	O
a	O
constrained	O
k	O
-	O
means	O
clustering	B
algorithm	O
we	O
conclude	O
the	O
paper	O
in	O
section	O
4	O
.	O
called	O
cop	O
-	O
k	O
-	O
means	O
[	O
18	O
]	O
,	O
which	O
allows	O
us	O
to	O
set	B
cannot	O
-	O
link	O
con-	O
straints	O
between	O
a	O
given	O
pair	O
of	O
embeddings	O
to	O
prevent	O
the	O
pair	O
from	O
2	O
.	O
proposed	O
diarization	B
framework	O
:	O
being	O
assigned	O
to	O
the	O
same	B
speaker	I
cluster	O
.	O
eend	O
-	O
vector	O
clustering	B
2.2	O
.	O
neural	O
diarization	B
with	O
speaker	B
embedding	O
estimation	B
2.1	O
.	O
overall	O
framework	O
this	O
subsection	O
details	O
the	O
nn	O
model	B
in	O
eend	O
-	O
vector	O
clustering	B
to	O
figure	O
1	O
shows	O
a	O
schematic	O
diagram	O
of	O
the	O
proposed	O
eend	O
-	O
vector	O
estimate	O
the	O
diarization	B
results	B
and	O
the	O
speaker	B
embeddings	I
.	O
clustering	B
framework	O
.	O
let	O
us	O
denote	O
the	O
ground	B
-	O
truth	O
diarization	B
label	O
sequence	B
as	O
it	O
ﬁrst	O
segments	O
the	O
input	B
recording	B
into	O
chunks	O
and	O
calculates	O
y	O
=	O
(	O
y	O
|	O
t	O
=	O
1	O
,	O
·	O
·	O
·	O
,	O
t	O
)	O
that	O
corresponds	O
to	O
x	O
.	O
here	O
,	O
the	O
i	O
t	O
,	O
i	O
i	O
a	O
sequence	B
of	O
the	O
input	B
frame	B
features	O
within	O
each	O
chunk	O
,	O
as	O
xi	O
=	O
diarization	B
label	O
y	O
=	O
[	O
y	O
∈	O
{	O
0	O
,	O
1	O
}	O
|	O
s	O
=	O
1	O
,	O
·	O
·	O
·	O
,	O
s	O
]	O
rep-	O
t	O
,	O
i	O
t	O
,	O
i	O
,	O
s	O
local	O
(	O
xt	O
,	O
i	O
|	O
t	O
=	O
1	O
,	O
·	O
·	O
·	O
,	O
t	O
)	O
where	O
i	O
,	O
t	O
and	O
t	O
are	O
the	O
chunk	O
index	O
,	O
the	O
resents	O
a	O
joint	O
activity	O
for	O
s	O
speakers	O
.	O
for	O
example	O
,	O
y	O
=	O
frame	B
index	O
in	O
the	O
chunk	O
and	O
the	O
chunk	O
size1	O
.	O
xt	O
,	O
i	O
∈	O
rk	O
is	O
the	O
k-	O
yt	O
,	O
i	O
,	O
s(cid:48	O
)	O
=	O
1(s	O
(	O
cid:54)=	O
s(cid:48	O
)	O
)	O
indicatelsocbaloth	O
speakers	O
s	O
and	O
s(cid:48	O
)	O
spoket	O
,	O
ia	O
,	O
ts	O
the	O
dimensional	O
input	B
frame	B
feature	O
at	O
the	O
time	B
frame	B
t.	O
in	O
the	O
example	O
time	B
frame	B
t	O
in	O
the	O
chunk	O
i.	O
shown	O
in	O
fig	O
1	O
,	O
the	O
input	B
recording	B
consists	O
of	O
2	O
chunks	O
and	O
contains	O
in	O
the	O
eend	O
framework	O
,	O
the	O
diarization	B
task	O
is	O
formulated	O
as	O
3	O
speakers	O
in	O
total	O
.	O
in	O
the	O
following	O
,	O
we	O
assume	O
that	O
we	O
can	O
ﬁx	O
a	O
multi	O
-	O
label	O
classiﬁcation	O
problem	O
.	O
speciﬁcally	O
,	O
we	O
estimate	O
the	O
the	O
maximum	O
number	O
of	O
active	O
speakers	O
in	O
a	O
chunk	O
,	O
s	O
,	O
to	O
2	O
,	O
local	O
dirarization	O
result	O
of	O
the	O
s	O
-	O
th	O
speaker	B
at	O
each	O
time	B
frame	B
,	O
yˆ	O
,	O
as	O
,	O
t	O
,	O
i	O
,	O
s	O
although	O
the	O
method	B
could	O
be	O
generalized	O
to	O
more	O
speakers	O
or	O
an	O
unknown	O
number	O
of	O
speakers	O
[	O
13	O
]	O
2	O
.	O
(	O
cid:2)h	O
,	O
.	O
.	O
.	O
,	O
h	O
(	O
cid:3	O
)	O
=	O
encoder(x	O
)	O
∈	O
rd×t	O
,	O
based	O
on	O
the	O
hyper	O
-	O
parameter	O
s	O
=	O
2	O
,	O
the	O
network	B
estimates	O
1,i	O
t	O
,	O
i	O
i	O
local	O
diarization	B
results	B
for	O
2	O
speakers	O
in	O
each	O
chunk	O
.	O
in	O
fig	O
.	O
1	O
,	O
the	O
pro-	O
yˆt	O
,	O
i	O
,	O
s	O
=	O
sigmoid(lineards	O
(	O
ht	O
,	O
i	O
)	O
)	O
∈	O
(	O
0	O
,	O
1	O
)	O
cessing	O
for	O
the	O
1st	O
speaker	B
is	O
drawn	O
with	O
black	O
lines	O
and	O
put	O
in	O
the	O
(	O
s	O
=	O
1	O
,	O
.	O
.	O
.	O
,	O
s	O
)	O
,	O
(	O
1	O
)	O
local	O
foreground	O
,	O
while	O
that	O
of	O
the	O
2nd	O
speaker	B
is	O
drawn	O
with	O
grey	O
lines	O
and	O
put	O
in	O
the	O
background	O
.	O
the	O
diarization	B
results	B
are	O
estimated	O
in-	O
where	O
encoder	O
(	O
·	O
)	O
is	O
an	O
encoder	O
such	O
as	O
a	O
multi	O
-	O
head	O
self	O
-	O
attention	O
dependently	O
in	O
each	O
chunk	O
through	O
nns	O
denoted	O
as	O
encoder	O
and	O
nn	O
[	O
12	O
]	O
,	O
which	O
utilizes	O
all	O
the	O
input	B
features	O
x	O
for	O
inference	B
.	O
h	O
i	O
t	O
,	O
i	O
is	O
a	O
d	O
-	O
dimensional	O
internal	O
representation	O
in	O
the	O
nn	O
,	O
lineard	O
(	O
·	O
)	O
:	O
1the	O
chunk	O
size	B
t	O
for	O
estimating	O
speaker	B
embeddings	I
can	O
be	O
advanta-	O
rd	O
→	O
r1	O
is	O
a	O
fully	O
-	O
connected	O
layer	B
to	O
estimate	O
the	O
diarizatiosn	O
re-	O
geously	O
much	O
longer	O
than	O
the	O
homogeneous	O
blocks	O
used	O
in	O
x	O
-	O
vector	O
cluster-	O
sult	O
,	O
and	O
sigmoid	O
(	O
·	O
)	O
is	O
the	O
element	O
-	O
wise	O
sigmoid	O
function	O
.	O
ing	O
since	O
we	O
can	O
handle	O
heterogeneous	O
chunks	O
including	O
more	O
than	O
1	O
speaker	B
.	O
2if	O
we	O
select	O
the	O
chunk	O
size	B
carefully	O
,	O
it	O
is	O
not	O
too	O
difﬁcult	O
to	O
set	B
an	O
ap-	O
now	O
,	O
after	O
estimating	O
the	O
diarization	B
results	B
,	O
for	O
the	O
purpose	O
propriate	O
maximum	O
number	O
of	O
speakers	O
even	O
for	O
practical	O
use	O
cases	O
[	O
17	O
]	O
.	O
of	O
solving	O
the	O
inter	O
-	O
block	O
permutation	O
problem	O
,	O
we	O
estimate	O
thespeaker	O
embedding	O
,	O
eˆ	O
,	O
corresponding	O
to	O
the	O
diarization	B
result	O
of	O
2.3.2	O
.	O
speaker	B
embedding	O
loss	O
i	O
,	O
s	O
the	O
s	O
-	O
th	O
speaker	B
as	O
follows	O
.	O
for	O
the	O
speaker	B
embedding	O
training	O
,	O
we	O
use	O
a	O
loss	O
function	O
that	O
en-	O
zt	O
,	O
i	O
,	O
s	O
=	O
linearss(ht	O
,	O
i	O
)	O
∈	O
rc	O
,	O
courages	O
the	O
embeddings	O
to	O
have	O
small	O
intra	O
-	O
speaker	B
and	O
large	O
inter-	O
t	O
speaker	B
distances	O
.	O
speciﬁcally	O
,	O
we	O
utilize	O
the	O
loss	O
proposed	O
recently	O
z¯	O
=	O
(	O
cid:88	O
)	O
yˆ	O
z	O
,	O
∈	O
rc	O
(	O
2	O
)	O
in	O
[	O
19	O
]	O
,	O
which	O
was	O
shown	O
to	O
be	O
very	O
effective	O
for	O
the	O
speech	O
separa-	O
i	O
,	O
s	O
t	O
,	O
i	O
,	O
s	O
t	O
,	O
i	O
,	O
s	O
t=1	O
tion	O
task	O
.	O
for	O
this	O
loss	O
function	O
,	O
we	O
assume	O
that	O
the	O
training	B
data	I
is	O
z¯	O
annotated	O
with	O
speaker	B
identity	O
labels	O
,	O
i.e.	O
,	O
indices	O
,	O
based	O
on	O
a	O
ﬁnite	O
eˆ	O
=	O
i	O
,	O
s	O
∈	O
rc	O
(	O
s	O
=	O
1	O
,	O
.	O
.	O
.	O
,	O
s	O
)	O
,	O
(	O
3	O
)	O
i	O
,	O
s	O
(	O
cid:107)z¯	O
(	O
cid:107	O
)	O
local	O
set	B
of	O
m	O
training	O
speakers	O
.	O
note	O
,	O
however	O
,	O
that	O
the	O
speaker	B
identity	O
i	O
,	O
s	O
is	O
not	O
required	O
at	O
test	B
time	B
,	O
and	O
that	O
training	O
and	O
test	B
speakers	O
can	O
wrhder→e	O
crics	O
itshea	O
dfuimllyen	O
-	O
csoionnneocftetdhelasypeeratkoeresetmimbaetdedtihneg	O
,	O
sl	O
-	O
thinsepaerassk(e·)r	O
’s	O
:	O
dbiefftehre(ia.bes	O
.	O
,oolupteenssppeeaakkeerricdoenndtiittyioinnsd)i.celsetthσai(cid:63)t	O
c	O
=	O
or(cid:2)reσsi(cid:63)p,1o	O
,	O
n.d	O
.	O
.to	O
,	O
σtih(cid:63),eslpocealr(cid:3)-	O
embedding	O
ei	O
,	O
s	O
,	O
and	O
(	O
cid:107)·(cid:107	O
)	O
is	O
a	O
vector	O
norm	B
.	O
here	O
we	O
chose	O
to	O
estimate	O
mutation	O
of	O
the	O
labels	O
that	O
gives	O
minimum	O
value	O
to	O
eq	O
.	O
(	O
5	O
)	O
,	O
i.e.	O
,	O
φ(cid:63	O
)	O
.	O
the	O
speaker	B
embeddings	I
as	O
weighted	O
sum	O
of	O
frame	B
-	O
level	B
embeddings	O
σ(cid:63	O
)	O
is	O
a	O
subset	O
of	O
the	O
m	O
speaker	B
identity	O
indices	O
.	O
then	O
,	O
the	O
speaker	B
i	O
zt	O
,	O
i	O
,	O
s	O
with	O
weights	O
determined	O
by	O
the	O
diarization	B
results	B
yˆt	O
,	O
i	O
,	O
s	O
,	O
as	O
in	O
embedding	O
loss	O
for	O
chunk	O
i	O
,	O
lspeaker	O
,	O
i	O
,	O
is	O
formulated	O
as	O
follows	O
.	O
eq	O
.	O
(	O
2	O
)	O
.	O
with	O
these	O
operations	O
,	O
we	O
can	O
estimate	O
diarization	B
results	B
aonudt	O
tshpeeaspkeearkeemr	O
beemdbdeindgdsinfgoresatlilmsaltoocralisspeesaseknetrisa.llyththise	O
msaomdeelaws	O
itthhe-	O
l	O
=	O
1	O
s(cid:88)local	O
l	O
(	O
cid:0)σ(cid:63	O
)	O
,	O
eˆ	O
(	O
cid:1	O
)	O
,	O
(	O
6	O
)	O
conventional	O
eend	O
[	O
11	O
]	O
.	O
speaker	B
,	O
i	O
slocal	O
speaker	B
i	O
,	O
s	O
i	O
,	O
s	O
s=1	O
2.3	O
.	O
training	O
objectives	O
where	O
now	O
,	O
we	O
will	O
explain	O
a	O
way	O
to	O
train	O
the	O
model	B
to	O
realize	O
the	O
behav-	O
	O
(	O
cid:16	O
)	O
(	O
cid:16	O
)	O
(	O
cid:17)(cid:17	O
)	O
	O
idoirareizxaptliaoinnerdesiunltss	O
eacntdiosnpe2a.1k.erseimncbeedthdeinngestwsiomruklteasntiemouastelys	O
,	O
booutrhntahte-	O
lspeaker	O
(	O
cid:0)σi(cid:63),s	O
,	O
eˆi	O
,	O
s(cid:1	O
)	O
=	O
−	O
ln	O
	O
(	O
cid:80)emmxp=1	O
e−xdp	O
(	O
−eσdi(cid:63)(,se	O
,	O
meˆi,,seˆi	O
,	O
s	O
)	O
)	O
	O
,	O
(	O
7	O
)	O
ural	O
choice	O
is	O
to	O
use	O
the	O
following	O
multi	O
-	O
task	O
loss	O
.	O
d	O
(	O
e	O
,	O
eˆ	O
)	O
=	O
α(cid:107)e	O
−	O
eˆ	O
(	O
cid:107)2	O
+	O
β	O
,	O
(	O
8)	O
m	O
i	O
,	O
s	O
m	O
i	O
,	O
s	O
l	O
=	O
(	O
1	O
−	O
λ)l	O
+	O
λl	O
,	O
(	O
4	O
)	O
diarization	B
speaker	B
where	O
e	O
is	O
a	O
learnable	O
global	O
speaker	B
embedding	O
dictionary	O
,	O
and	O
e	O
where	O
l	O
is	O
the	O
total	O
loss	O
function	O
to	O
be	O
minimized	O
,	O
l	O
is	O
the	O
m	O
diarization	B
is	O
a	O
learnable	O
global	O
speaker	B
embedding	O
associated	O
with	O
the	O
m	O
-	O
th	O
diarization	B
error	I
loss	O
,	O
l	O
is	O
speaker	B
embedding	O
loss	O
,	O
and	O
λ	O
is	O
a	O
speaker	B
training	O
speaker	B
.	O
eq	O
.	O
(	O
8)	O
is	O
the	O
squared	O
euclidean	O
distance	B
between	O
hyper	O
-	O
parameter	O
to	O
weight	B
the	O
two	O
loss	O
functions	O
.	O
the	O
learnable	O
global	O
speaker	B
embedding	O
and	O
the	O
estimated	O
speaker	B
embedding	O
,	O
which	O
is	O
rescaled	O
with	O
learnable	O
scalar	O
parameters	O
α	O
>	O
2.3.1	O
.	O
diarization	B
loss	O
0	O
and	O
β	O
.	O
eq	O
.	O
(	O
7	O
)	O
is	O
the	O
log	B
softmax	O
over	O
the	O
distances	O
between	O
the	O
es-	O
following	O
[	O
11	O
]	O
,	O
the	O
diariation	O
loss	O
in	O
each	O
chunk	O
is	O
formulated	O
as	O
:	O
timated	O
embedding	O
and	O
the	O
global	O
embeddings	O
,	O
which	O
can	O
be	O
derived	O
from	O
the	O
categorical	O
cross	O
-	O
entropy	O
loss	O
.	O
the	O
loss	O
function	O
l	O
is	O
speaker	B
l	O
,	O
φ(cid:63	O
)	O
=	O
1	O
min	O
(	O
cid:88)t	O
bce	O
(	O
cid:16)lφ	O
,	O
yˆ	O
(	O
cid:17	O
)	O
,	O
(	O
5	O
)	O
formed	O
by	O
collecting	O
b	O
chunks	O
,	O
similarly	O
to	O
ldiarization	O
.	O
diarization	B
,	O
i	O
t	O
slocal	O
φ∈perm(slocal	O
)	O
t=1	O
t	O
,	O
i	O
t	O
,	O
i	O
arizabtiyonmriensiumltisziancgcuthreasteelyloesvsefnunifcttihoenrse	O
,	O
iws	O
eoveexrplaepctpetod	O
espsteiemcaht	O
,	O
eadnid-	O
where	O
perm(s	O
)	O
is	O
the	O
set	B
of	O
all	O
the	O
possible	O
permutations	O
of	O
simultaneously	O
estimate	O
speaker	B
embeddings	I
that	O
are	O
suitable	O
for	O
the	O
local	O
(	O
1	O
,	O
.	O
.	O
.	O
,	O
slocal	O
)	O
,	O
yˆt	O
,	O
i	O
=	O
[	O
yˆt	O
,	O
i,1	O
,	O
.	O
.	O
.	O
,	O
yˆt	O
,	O
i	O
,	O
slocal	O
]	O
∈	O
rslocal	O
,	O
lφt	O
,	O
i	O
is	O
the	O
φ-	O
subsequent	O
clustering	B
process	B
.	O
th	O
permutation	O
of	O
the	O
reference	B
speaker	I
labels	O
,	O
and	O
bce	O
(	O
·	O
,	O
·	O
)	O
is	O
the	O
binary	O
cross	O
-	O
entropy	O
function	O
between	O
the	O
labels	O
and	O
the	O
estimated	O
diarization	B
outputs	O
.	O
φ(cid:63	O
)	O
is	O
the	O
permutation	O
that	O
minimizes	O
the	O
right	O
3	O
.	O
experiments	O
hand	O
side	O
of	O
the	O
eq	O
.	O
(	O
5	O
)	O
.	O
this	O
training	O
scheme	O
called	O
permutation-	O
in	O
this	O
section	O
,	O
we	O
evaluate	O
the	O
effectiveness	O
of	O
the	O
proposed	O
method	B
invariant	O
training	O
has	O
shown	O
to	O
be	O
effective	O
for	O
the	O
neural	O
diarization	B
in	O
comparison	O
with	O
the	O
conventional	O
eend	O
[	O
12	O
]	O
,	O
based	O
on	O
test	B
data	I
[	O
11	O
]	O
,	O
but	O
at	O
the	O
same	O
time	B
,	O
it	O
incurs	O
another	O
problem	O
,	O
i.e.	O
,	O
the	O
inter-	O
including	O
long	O
recordings	O
with	O
a	O
signiﬁcant	O
amount	B
of	O
overlapped	O
block	O
label	O
permutation	O
problem	O
since	O
it	O
clearly	O
allows	O
the	O
speaker	B
speech	O
.	O
comparison	O
with	O
the	O
x	O
-	O
vector	O
clustering	B
is	O
omitted	O
since	O
it	O
labels	O
to	O
permute	O
from	O
chunk	O
to	O
chunk	O
.	O
the	O
diarization	B
loss	O
func-	O
was	O
already	O
shown	O
in	O
[	O
12	O
]	O
that	O
the	O
conventional	O
eend	O
works	O
better	O
tion	O
l	O
is	O
formed	O
by	O
collecting	O
b	O
chunks	O
,	O
i.e.	O
,	O
l	O
=	O
diarization	B
diarization	B
(	O
cid:80)b	O
l	O
,	O
where	O
b	O
is	O
the	O
size	B
of	O
the	O
mini	O
-	O
batch	O
.	O
in	O
case	O
the	O
data	B
contains	O
overlapped	B
speech	I
.	O
i=1	O
diarization	B
,	O
i	O
here	O
,	O
as	O
it	O
was	O
mentioned	O
earlier	O
,	O
s	O
is	O
a	O
hyper	O
-	O
parameter	O
that	O
local	O
has	O
to	O
be	O
appropriately	O
chosen	O
to	O
satisfy	O
(	O
1	O
)	O
slocal	O
≤	O
stotal	O
where	O
3.1	O
.	O
data	B
s	O
is	O
the	O
total	O
number	O
of	O
speakers	O
in	O
the	O
recording	B
,	O
and	O
(	O
2	O
)	O
s	O
total	O
local	O
is	O
always	O
greater	O
than	O
or	O
equal	O
to	O
the	O
maximum	O
number	O
of	O
speakers	O
the	O
training	O
,	O
development	O
,	O
and	O
test	B
data	I
are	O
based	O
on	O
the	O
16	O
khz	O
speaking	O
in	O
a	O
chunk	O
.	O
with	O
an	O
assumption	O
that	O
s	O
is	O
chosen	O
in	O
such	O
librispeech	O
database	O
[	O
20	O
]	O
.	O
to	O
simulate	O
a	O
conversation	O
-	O
like	O
mixture	O
local	O
a	O
way	O
,	O
the	O
diarization	B
labels	O
in	O
the	O
chunk	O
i	O
,	O
y	O
,	O
should	O
be	O
formed	O
as	O
of	O
two	O
speakers	O
,	O
we	O
picked	O
up	O
utterances	B
from	O
randomly	O
selected	O
i	O
a	O
subset	O
of	O
all	O
s	O
speaker	B
’s	O
labels	O
ytotal	O
,	O
i.e.	O
,	O
y	O
⊆	O
ytotal	O
.	O
the	O
two	O
speakers	O
,	O
and	O
generated	O
a	O
noisy	O
reverberant	O
mixture	O
contain-	O
total	O
i	O
i	O
i	O
subset	O
should	O
be	O
chosen	O
appropriately	O
for	O
each	O
chunk	O
such	O
that	O
it	O
ing	O
many	O
utterances	B
per	O
speaker	B
with	O
reasonable	O
silence	B
intervals	O
covers	O
all	O
speakers	O
speaking	O
in	O
the	O
chunk	O
i.	O
if	O
the	O
number	O
of	O
speak-	O
between	O
utterances	B
.	O
for	O
the	O
simulation	O
,	O
we	O
used	O
the	O
algorithm	O
pro-	O
ers	O
speaking	O
in	O
the	O
chunk	O
is	O
smaller	O
than	O
s	O
,	O
we	O
ﬁll	O
y	O
with	O
di-	O
posed	O
in	O
[	O
11	O
]	O
,	O
and	O
set	B
the	O
average	B
silence	B
interval	O
between	O
utterances	B
local	O
i	O
arization	O
label(s	O
)	O
of	O
a	O
virtual	O
(	O
s	O
+	O
1)-th	O
always	O
-	O
silent	O
speaker	B
,	O
at	O
2	O
seconds	B
.	O
noise	O
data	B
was	O
obtained	O
from	O
musan	O
noise	O
data	B
[	O
21	O
]	O
.	O
total	O
i.e.	O
,	O
(	O
y	O
∈	O
{	O
0	O
}	O
|	O
t	O
=	O
1	O
,	O
.	O
.	O
.	O
,	O
t	O
)	O
.	O
the	O
signal	B
-	O
to	O
-	O
noise	O
ratio	O
was	O
sampled	O
randomly	O
for	O
each	O
mixture	O
t	O
,	O
i	O
,	O
stotal+1table	O
1	O
:	O
ders	O
(	O
%	O
)	O
of	O
the	O
conventional	O
eend	O
and	O
the	O
proposed	O
models	B
for	O
each	O
test	B
set	B
that	O
differs	O
in	O
the	O
duration	O
.	O
model	B
chunking	O
clustering	B
test	B
data	I
duration	O
(	O
minutes	O
)	O
3	O
5	O
10	O
20	O
1	O
.	O
eend	O
-	O
n	O
/	O
a	O
7.9	O
8.8	O
9.2	O
n	O
/	O
a	O
2	O
.	O
eend	O
(	O
cid:88	O
)	O
n	O
/	O
a	O
9.9	O
9.9	O
10.2	O
9.9	O
3	O
.	O
proposed	O
-	O
-	O
8.0	O
8.7	O
9.1	O
n	O
/	O
a	O
4	O
.	O
proposed	O
(	O
cid:88	O
)	O
-	O
10.6	O
10.5	O
10.9	O
10.8	O
5	O
.	O
proposed	O
(	O
cid:88	O
)	O
(	O
cid:88	O
)	O
9.1	O
8.2	O
7.9	O
7.7	O
table	O
2	O
:	O
ders	O
(	O
%	O
)	O
of	O
the	O
conventional	O
eend	O
and	O
the	O
proposed	O
eend	O
-	O
vector	O
clustering	B
for	O
each	O
overlap	O
condition	B
.	O
model	B
chunking	O
clustering	B
overlap	O
ratio	O
(	O
%	O
)	O
0	O
-	O
30	O
30	O
-	O
60	O
60	O
-	O
90	O
fig	O
.	O
2	O
:	O
t	O
-	O
sne	O
plot	O
of	O
the	O
test	B
speaker	B
’s	O
embeddings	O
vector	O
eend	O
-	O
-	O
10.5	O
9.4	O
7.1	O
proposed	O
(	O
cid:88	O
)	O
(	O
cid:88	O
)	O
5.4	O
8.3	O
6.6	O
from	O
5	O
,	O
10	O
,	O
15	O
,	O
and	O
20	O
dbs	O
.	O
for	O
reverberation	O
,	O
we	O
used	O
20000	O
im-	O
3.3	O
.	O
results	B
pulse	O
response	O
data	B
in	O
[	O
22	O
]	O
,	O
which	O
simulates	O
various	O
rooms	O
.	O
con-	O
sequently	O
,	O
we	O
obtained	O
a	O
set	B
of	O
training	O
,	O
development	O
,	O
and	O
test	B
data	I
table	O
1	O
shows	O
the	O
results	B
of	O
the	O
conventional	O
eend	O
(	O
1st	O
row	O
)	O
and	O
that	O
contains	O
various	O
overlapping	B
ratios	O
ranging	O
from	O
10	O
to	O
90	O
%	O
.	O
the	O
proposed	O
method	B
(	O
5th	O
row	O
)	O
.	O
the	O
table	O
contains	O
some	O
variants	O
of	O
for	O
the	O
training	O
and	O
development	B
data	I
,	O
we	O
randomly	O
selected	O
these	O
methods	O
to	O
clarify	O
the	O
effectiveness	O
of	O
each	O
component	O
in	O
the	O
utterances	B
from	O
460-hour	O
clean	O
speech	O
training	B
data	I
containing	O
1172	O
proposed	O
model	B
.	O
speakers	O
(	O
m	O
=	O
1172	O
)	O
and	O
generated	O
40000	O
and	O
500	O
mixtures	O
that	O
amount	B
to	O
2774	O
and	O
23	O
hours	B
,	O
respectively	O
.	O
for	O
the	O
test	B
data	I
,	O
we	O
first	O
,	O
by	O
comparing	O
the	O
1st	O
row	O
(	O
conventional	O
eend	O
applied	O
to	O
generated	O
4	O
different	O
sets	O
of	O
data	B
that	O
differ	O
in	O
duration	O
.	O
each	O
test	B
set	B
the	O
entire	O
sequence	B
without	O
chunking	O
)	O
and	O
5th	O
row	O
(	O
the	O
proposed	O
contains	O
500	O
utterances	B
.	O
the	O
average	B
duration	O
of	O
mixtures	O
in	O
each	O
model	B
that	O
processes	O
chunks	O
and	O
performs	O
clustering	B
,	O
i.e.	O
,	O
eend-	O
set	B
is	O
3	O
,	O
5	O
,	O
10	O
,	O
and	O
20	O
minutes	O
,	O
respectively	O
.	O
all	O
the	O
test	B
data	I
were	O
vector	O
clustering	B
)	O
,	O
we	O
can	O
see	O
that	O
,	O
as	O
the	O
duration	O
of	O
the	O
test	B
data	I
generated	O
based	O
on	O
the	O
librispeech	O
test	B
set	B
containing	O
26	O
speakers	O
gets	O
longer	O
,	O
the	O
proposed	O
method	B
becomes	O
increasingly	O
advanta-	O
that	O
were	O
not	O
included	O
in	O
the	O
training	O
and	O
development	B
data	I
.	O
geous	O
.	O
while	O
the	O
conventional	O
eend	O
can	O
not	O
well	O
handle	O
10-	O
and	O
20-minute	O
data	B
because	O
of	O
poor	O
generalization	O
to	O
the	O
long	O
data	B
and	O
the	O
cpu	O
memory	O
constraint	O
,	O
eend	O
-	O
vector	O
clustering	B
can	O
achieve	O
3.2	O
.	O
nn	O
training	O
and	O
hyper	O
-	O
parameters	O
stable	O
diarization	B
performance	O
for	O
such	O
data	B
.	O
interestingly	O
,	O
it	O
tends	O
for	O
the	O
input	B
frame	B
feature	O
,	O
we	O
extracted	O
23-dimensional	O
log	B
-	O
mel-	O
to	O
work	O
better	O
(	O
at	O
least	O
for	O
this	O
data	B
)	O
especially	O
when	O
the	O
duration	O
of	O
ﬁlterbank	O
features	O
with	O
25	O
ms	O
frame	B
length	B
and	O
10	O
ms	O
frame	B
shift	O
.	O
the	O
data	B
is	O
long	O
.	O
it	O
is	O
probably	O
because	O
the	O
number	O
of	O
embeddings	O
for	O
both	O
the	O
proposed	O
method	B
and	O
the	O
conventional	O
eend	O
,	O
the	O
available	O
for	O
the	O
clustering	B
becomes	O
larger	O
as	O
the	O
data	B
gets	O
longer	O
,	O
chunk	O
size	B
t	O
at	O
the	O
training	O
stage	B
was	O
set	B
at	O
500	O
(=	O
50	O
seconds	B
)	O
as	O
in	O
which	O
helps	O
the	O
clustering	B
algorithm	O
ﬁnd	O
better	O
cluster	O
centroids	O
.	O
[	O
12	O
]	O
.	O
therefore	O
,	O
when	O
the	O
training	B
data	I
is	O
longer	O
than	O
50	O
seconds	B
,	O
we	O
now	O
,	O
let	O
us	O
compare	O
the	O
1st	O
row	O
(	O
eend	O
without	O
chunking	O
)	O
and	O
split	O
the	O
input	B
audio	O
into	O
non	O
-	O
overlapping	B
50-second	O
chunks	O
.	O
at	O
the	O
3rd	O
row	O
(	O
the	O
proposed	O
model	B
applied	O
to	O
the	O
entire	O
sequence	B
without	O
inference	B
stage	B
,	O
the	O
conventional	O
eend	O
uses	O
an	O
entire	O
sequence	B
for	O
chunking	O
)	O
.	O
the	O
performance	O
of	O
the	O
proposed	O
model	B
turned	O
out	O
to	O
be	O
inference	B
without	O
chunking	O
.	O
on	O
the	O
other	O
hand	O
,	O
the	O
proposed	O
method	B
almost	O
equal	O
to	O
that	O
of	O
the	O
conventional	O
method	B
in	O
all	O
cases	O
,	O
which	O
segments	O
the	O
input	B
data	B
into	O
50-second	O
non	O
-	O
overlapping	B
chunks	O
,	O
and	O
indicates	O
that	O
the	O
additional	O
speaker	B
loss	O
did	O
not	O
negatively	O
affect	O
the	O
perform	O
diarization	B
as	O
explained	O
in	O
section	O
2.1	O
.	O
diarization	B
capability	O
of	O
the	O
model	B
.	O
the	O
results	B
show	O
that	O
the	O
addi-	O
for	O
both	O
methods	O
,	O
we	O
used	O
the	O
same	O
network	B
architecture	B
as	O
tional	O
speaker	B
loss	O
did	O
not	O
negatively	O
affect	O
the	O
diarization	B
capability	O
[	O
12	O
]	O
.	O
for	O
encoder	O
,	O
we	O
used	O
two	O
multi	O
-	O
head	O
attention	O
blocks	O
with	O
of	O
the	O
model	B
.	O
256	O
attention	O
units	O
containing	O
four	O
heads	O
(	O
d	O
=	O
256).we	O
used	O
the	O
adam	O
optimizer	O
with	O
the	O
learning	O
rate	O
scheduler	O
introduced	O
in	O
[	O
23	O
]	O
.	O
next	O
,	O
let	O
us	O
focus	O
on	O
the	O
comparison	O
between	O
1st/3rd	O
rows	O
the	O
number	O
of	O
warm	O
-	O
up	O
steps	B
used	O
in	O
the	O
learning	O
rate	O
scheduler	O
was	O
(	O
models	B
without	O
chunking	O
)	O
and	O
2nd/4th	O
rows	O
(	O
models	B
with	O
chunk-	O
25000	O
.	O
the	O
batch	O
size	B
b	O
was	O
64	O
.	O
the	O
number	O
of	O
training	O
epochs	O
ing	O
but	O
without	O
clustering	B
)	O
.	O
the	O
performance	O
degradation	O
when	O
was	O
70	O
.	O
the	O
ﬁnal	O
models	B
were	O
obtained	O
by	O
averaging	O
the	O
model	B
using	O
chunking	O
reveals	O
the	O
inter	O
-	O
block	O
label	O
permutation	O
problem	O
.	O
parameters	O
of	O
the	O
last	O
10	O
epochs	O
.	O
we	O
assume	O
this	O
problem	O
may	O
become	O
even	O
more	O
severe	O
when	O
deal-	O
for	O
the	O
proposed	O
method	B
,	O
λ	O
was	O
set	B
at	O
0.01	O
.	O
with	O
an	O
assumption	O
ing	O
with	O
more	O
speakers	O
.	O
with	O
this	O
comparison	O
,	O
we	O
could	O
conﬁrm	O
the	O
that	O
the	O
maximum	O
number	O
of	O
speakers	O
speaking	O
in	O
each	O
chunk	O
is	O
2	O
,	O
effectiveness	O
of	O
the	O
clustering	B
-	O
based	O
diarization	B
result	O
stitching	O
.	O
we	O
set	B
s	O
at	O
2	O
.	O
the	O
dimension	O
of	O
the	O
speaker	B
embedding	O
,	O
c	O
,	O
was	O
local	O
set	B
at	O
256	O
.	O
since	O
the	O
performance	O
of	O
the	O
proposed	O
method	B
slightly	O
overall	O
,	O
we	O
found	O
that	O
,	O
if	O
the	O
test	B
data	I
is	O
shorter	O
than	O
5	O
minutes	O
,	O
changes	O
due	O
to	O
the	O
initialization	O
of	O
the	O
cop	O
-	O
k	O
-	O
means	O
algorithm	O
,	O
we	O
we	O
can	O
apply	O
either	O
the	O
conventional	O
eend	O
or	O
the	O
proposed	O
model	B
to	O
ran	O
the	O
test	B
inference	B
10	O
times	O
with	O
random	O
initialization	O
and	O
ob-	O
the	O
entire	O
sequence	B
(	O
without	O
chunking	O
)	O
to	O
obtain	O
a	O
good	O
diarization	B
tained	O
the	O
averaged	O
results	B
.	O
the	O
standard	O
deviation	O
of	O
the	O
obtained	O
performance	O
.	O
on	O
the	O
other	O
hand	O
,	O
if	O
the	O
data	B
is	O
longer	O
than	O
that	O
,	O
it	O
is	O
diarization	B
error	I
rate	I
(	O
der	O
)	O
was	O
less	O
than	O
0.2	O
%	O
.	O
signiﬁcantly	O
better	O
to	O
use	O
the	O
proposed	O
framework.3.4	O
.	O
detailed	O
analysis	B
dihard	B
challenge	I
,	O
”	O
in	O
proc	O
.	O
interspeech	O
2018	O
,	O
2018	O
,	O
pp	O
.	O
2808–2812	O
.	O
3.4.1	O
.	O
evaluation	B
in	O
terms	B
of	O
overlapping	B
ratio	O
[	O
7	O
]	O
m.	O
diez	O
,	O
f.	O
landini	O
,	O
l.	O
burget	O
,	O
j.	O
rohdin	O
,	O
a.	O
silnova	O
,	O
k.	O
zmo-	O
table	O
2	O
shows	O
the	O
ders	O
in	O
each	O
overlap	O
condition	B
.	O
the	O
results	B
were	O
likova	O
,	O
o.	O
novotny	O
´	O
,	O
k.	O
vesely	O
´	O
,	O
o.	O
glembek	O
,	O
o.	O
plchot	O
,	O
obtained	O
from	O
the	O
test	B
set	B
of	O
10-minute	O
mixtures	O
.	O
since	O
each	O
mixture	O
l.	O
mosˇner	O
,	O
and	O
p.	O
mateˇjka	O
,	O
“	O
but	O
system	O
for	O
dihard	O
speech	O
in	O
the	O
test	B
set	B
differs	O
in	O
the	O
amount	B
of	O
overlapped	B
speech	I
,	O
i.e.	O
,	O
overlap	O
diarization	B
challenge	B
2018	O
,	O
”	O
in	O
proc	O
.	O
interspeech	O
2018	O
,	O
2018	O
,	O
ratio	O
,	O
we	O
categorized	O
the	O
mixtures	O
into	O
several	O
overlap	O
ratio	O
ranges	O
pp	O
.	O
2798–2802	O
.	O
and	O
obtained	O
der	O
in	O
each	O
condition	B
.	O
,	O
to	O
better	O
understand	O
the	O
model	B
behavior	O
.	O
the	O
proposed	O
method	B
is	O
shown	O
to	O
largely	O
outperform	O
the	O
[	O
8	O
]	O
a.	O
zhang	O
,	O
q.	O
wang	O
,	O
z.	O
zhu	O
,	O
j.	O
paisley	O
,	O
and	O
c.	O
wang	O
,	O
“	O
fully	O
conventional	O
eend	O
in	O
all	O
conditions	O
.	O
supervised	O
speaker	B
diarization	I
,	O
”	O
in	O
proc	O
.	O
2019	O
ieee	O
interna-	O
tional	O
conference	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
(	O
icassp	O
)	O
,	O
2019	O
,	O
pp	O
.	O
6301–6305	O
.	O
3.4.2	O
.	O
speaker	B
embedding	O
estimation	B
accuracy	O
[	O
9	O
]	O
x.	O
li	O
,	O
y.	O
zhao	O
,	O
c.	O
luo	O
,	O
and	O
w.	O
zeng	O
,	O
“	O
online	O
speaker	B
diariza-	O
here	O
we	O
also	O
examine	O
whether	O
the	O
speaker	B
embeddings	I
of	O
the	O
test	B
tion	O
with	O
relation	O
network	B
,	O
”	O
2020	O
,	O
arxiv:2009.08162	O
.	O
data	B
is	O
estimated	O
accurately	O
such	O
that	O
they	O
have	O
large	O
inter	O
-	O
speaker	B
[	O
10	O
]	O
t.	O
von	O
neumann	O
and	O
s.	O
araki	O
t.	O
nakatani	O
r.	O
haeb	O
-	O
umbach	O
and	O
small	O
intra	O
-	O
speaker	B
distances	O
.	O
figure	O
2	O
shows	O
the	O
t	O
-	O
sne	O
visual-	O
k.	O
kinoshita	O
,	O
m.	O
delcroix	O
,	O
“	O
all	O
-	O
neural	O
online	O
source	B
separa-	O
ization	O
of	O
the	O
speaker	B
embeddings	I
of	O
the	O
26	O
test	B
speakers	O
.	O
it	O
clearly	O
tion	O
,	O
counting	O
,	O
and	O
diarization	B
for	O
meeting	O
analysis	B
,	O
”	O
in	O
proc	O
.	O
shows	O
distinguished	O
clusters	O
for	O
each	O
speaker	B
,	O
which	O
proves	O
that	O
we	O
2018	O
ieee	O
international	O
conference	O
on	O
acoustics	B
,	O
speech	O
and	O
can	O
estimate	O
the	O
global	O
speaker	B
embeddings	I
accurately	O
even	O
if	O
the	O
signal	B
processing	I
(	O
icassp	O
)	O
,	O
may	O
2019	O
,	O
pp	O
.	O
91–95	O
.	O
input	B
data	B
contains	O
a	O
signiﬁcant	O
amount	B
of	O
overlapped	B
speech	I
.	O
[	O
11	O
]	O
y.	O
fujita	O
,	O
n.	O
kanda	O
,	O
s.	O
horiguchi	O
,	O
k.	O
nagamatsu	O
,	O
and	O
s.	O
watanabe	O
,	O
“	O
end	O
-	O
to	O
-	O
end	O
neural	O
speaker	B
diarization	I
with	O
4	O
.	O
conclusions	O
permutation	O
-	O
free	O
objectives	O
,	O
”	O
in	O
proc	O
.	O
interspeech	O
2019	O
,	O
2019	O
,	O
we	O
proposed	O
a	O
simple	O
but	O
effective	O
diarization	B
framework	O
,	O
eend-	O
pp	O
.	O
4300–4304	O
.	O
vector	O
clustering	B
,	O
that	O
estimates	O
both	O
diarization	B
results	B
and	O
speaker	B
[	O
12	O
]	O
y.	O
fujita	O
,	O
n.	O
kanda	O
,	O
s.	O
horiguchi	O
,	O
y.	O
xue	O
,	O
k.	O
nagamatsu	O
,	O
and	O
embeddings	O
.	O
by	O
utilizing	O
the	O
speaker	B
embeddings	I
,	O
we	O
solved	O
the	O
s.	O
watanabe	O
,	O
“	O
end	O
-	O
to	O
-	O
end	O
neural	O
speaker	B
diarization	I
with	O
self-	O
inter	O
-	O
block	O
label	O
permutation	O
problem	O
.	O
experimental	O
results	B
showed	O
attention	O
,	O
”	O
in	O
proc	O
.	O
ieee	O
asru	O
,	O
2019	O
,	O
pp	O
.	O
296–303	O
.	O
that	O
eend	O
-	O
vector	O
clustering	B
works	O
signiﬁcantly	O
better	O
than	O
the	O
orig-	O
inal	O
eend	O
especially	O
when	O
the	O
input	B
data	B
is	O
long	O
.	O
future	O
work	O
in-	O
[	O
13	O
]	O
s.	O
horiguchi	O
,	O
y.	O
fujita	O
,	O
s.	O
watanabe	O
,	O
y.	O
xue	O
,	O
and	O
k.	O
naga-	O
cludes	O
application	B
of	O
the	O
proposed	O
framework	O
to	O
more	O
challenging	O
matsu	O
,	O
“	O
end	O
-	O
to	O
-	O
end	O
speaker	B
diarization	I
for	O
an	O
unknown	O
num-	O
conditions	O
as	O
well	O
as	O
an	O
extension	O
to	O
a	O
scheme	O
that	O
can	O
handle	O
an	O
ber	O
of	O
speakers	O
with	O
encoder	O
-	O
decoder	O
based	O
attractors	O
,	O
”	O
2020	O
,	O
arbitrary	O
number	O
of	O
speakers	O
within	O
a	O
chunk	O
,	O
e.g.	O
,	O
[	O
13	O
]	O
.	O
arxiv:2005.09921	O
.	O
[	O
14	O
]	O
m.	O
kolbæk	O
,	O
d.	O
yu	O
,	O
z.	O
tan	O
,	O
and	O
j.	O
jensen	O
,	O
“	O
multitalker	O
speech	O
5	O
.	O
references	B
separation	O
with	O
utterance	O
-	O
level	B
permutation	O
invariant	O
training	O
of	O
deep	O
recurrent	O
neural	B
networks	I
,	O
”	O
ieee	O
/	O
acm	O
transactions	O
[	O
1	O
]	O
x.	O
anguera	O
,	O
s.	O
bozonnet	O
,	O
n.	O
evans	O
,	O
c.	O
fredouille	O
,	O
g.	O
fried-	O
on	O
audio	O
,	O
speech	O
,	O
and	O
language	B
processing	I
,	O
vol	O
.	O
25	O
,	O
no	O
.	O
10	O
,	O
land	O
,	O
and	O
o.	O
vinyals	O
,	O
“	O
speaker	B
diarization	I
:	O
a	O
review	O
of	O
recent	O
pp	O
.	O
1901–1913	O
,	O
oct	O
2017	O
.	O
research	B
,	O
”	O
ieee	O
transactions	O
on	O
audio	O
,	O
speech	O
,	O
and	O
language	O
[	O
15	O
]	O
k.	O
kinoshita	O
,	O
l.	O
drude	O
,	O
m.	O
delcroix	O
,	O
and	O
t.	O
nakatani	O
,	O
“	O
lis-	O
processing	B
,	O
vol	O
.	O
20	O
,	O
no	O
.	O
2	O
,	O
pp	O
.	O
356–370	O
,	O
feb	O
2012	O
.	O
tening	O
to	O
each	O
speaker	B
one	O
by	O
one	O
with	O
recurrent	O
selective	O
hear-	O
[	O
2	O
]	O
n.	O
ryant	O
,	O
k.	O
church	O
,	O
c.	O
cieri	O
,	O
a.	O
cristia	O
,	O
j.	O
du	O
,	O
s.	O
ganapathy	O
,	O
ing	O
networks	O
,	O
”	O
in	O
proc	O
.	O
2018	O
ieee	O
international	O
conference	O
and	O
m.	O
liberman	O
,	O
first	O
dihard	B
challenge	I
evaluation	B
plan	I
,	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
(	O
icassp	O
)	O
,	O
april	O
2018	O
,	O
https://zenodo.org/record/1199638	O
.	O
2018	O
,	O
pp	O
.	O
5064–5068	O
.	O
[	O
3	O
]	O
j.	O
carletta	O
,	O
s.	O
ashby	O
,	O
s.	O
bourban	O
,	O
m.	O
flynn	O
,	O
m.	O
guillemot	O
,	O
[	O
16	O
]	O
y.	O
xue	O
,	O
s.	O
horiguchi	O
,	O
y.	O
fujita	O
,	O
s.	O
watanabe	O
,	O
and	O
k.	O
naga-	O
t.	O
hain	O
,	O
j.	O
kadlec	O
,	O
v.	O
karaiskos	O
,	O
w.	O
kraaij	O
,	O
m.	O
kronenthal	O
,	O
matsu	O
,	O
“	O
online	O
end	O
-	O
to	O
-	O
end	O
neural	O
diarization	B
with	O
speaker-	O
g.	O
lathoud	O
,	O
m.	O
lincoln	O
,	O
a.	O
lisowska	O
,	O
i.	O
mccowan	O
,	O
w.	O
post	O
,	O
tracing	O
buffer	O
,	O
”	O
2020	O
,	O
arxiv:2006.02616	O
.	O
d.	O
reidsma	O
,	O
,	O
and	O
p.	O
wellner	O
,	O
“	O
the	O
ami	O
meeting	O
corpus	B
:	O
[	O
17	O
]	O
t.	O
yoshioka	O
,	O
z.	O
chen	O
,	O
c.	O
liu	O
,	O
x.	O
xiao	O
,	O
h.	O
erdogan	O
,	O
and	O
a	O
pre	O
-	O
announcement	O
,	O
”	O
in	O
the	O
second	O
international	O
confer-	O
d.	O
dimitriadis	O
,	O
“	O
low	O
-	O
latency	O
speaker	B
-	O
independent	O
continuous	O
ence	O
on	O
machine	O
learning	O
for	O
multimodal	O
interaction	O
,	O
ser	O
.	O
speech	B
separation	I
,	O
”	O
in	O
proc	O
.	O
2019	O
ieee	O
international	O
confer-	O
mlmi’05	O
,	O
2006	O
,	O
pp	O
.	O
28–39	O
.	O
ence	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
(	O
icassp	O
)	O
,	O
[	O
4	O
]	O
n.	O
dehak	O
,	O
p.	O
kenny	O
,	O
r.	O
dehak	O
,	O
p.	O
dumouchel	O
,	O
,	O
and	O
p.	O
ouel-	O
may	O
2019	O
,	O
pp	O
.	O
6980–6984	O
.	O
let	O
,	O
“	O
front	O
-	O
end	O
factor	B
analysis	I
for	O
speaker	B
veriﬁcation	O
,	O
”	O
ieee	O
[	O
18	O
]	O
k.	O
wagstaff	O
,	O
c.	O
cardie	O
,	O
s.	O
rogers	O
,	O
and	O
s	O
s.	O
schroedl	O
,	O
“	O
con-	O
trans	O
.	O
audio	O
,	O
speech	O
,	O
and	O
language	B
processing	I
,	O
vol	O
.	O
19(4	O
)	O
,	O
strained	O
k	O
-	O
means	O
clustering	B
with	O
background	O
knowledge	B
,	O
”	O
in	O
pp	O
.	O
788–798	O
,	O
2011	O
.	O
proc	O
.	O
18th	O
international	O
conference	O
on	O
machine	O
learning	O
[	O
5	O
]	O
d.	O
snyder	O
,	O
p.	O
ghahremani	O
,	O
d.	O
povey	O
,	O
d.	O
garcia	O
-	O
romero	O
,	O
(	O
icml	O
)	O
,	O
2001	O
.	O
y.	O
carmiel	O
,	O
,	O
and	O
s.	O
khudanpur	O
,	O
“	O
deep	O
neural	B
network	I
-	O
based	O
[	O
19	O
]	O
n.	O
zeghidour	O
and	O
d.	O
grangier	O
,	O
“	O
wavesplit	O
:	O
end	O
-	O
to	O
-	O
end	O
speech	O
speaker	B
embeddings	I
for	O
end	O
-	O
to	O
-	O
end	O
speaker	B
veriﬁcation	O
,	O
”	O
in	O
separation	O
by	O
speaker	B
clustering	B
,	O
”	O
2020	O
,	O
arxiv:2002.08933	O
.	O
proc	O
.	O
ieee	O
spoken	B
language	I
technology	O
workshop	O
,	O
2016	O
.	O
[	O
20	O
]	O
v.	O
panayotov	O
,	O
g.	O
chen	O
,	O
d.	O
povey	O
,	O
and	O
s.	O
khudanpur	O
,	O
“	O
lib-	O
[	O
6	O
]	O
g.	O
sell	O
,	O
d.	O
snyder	O
,	O
a.	O
mccree	O
,	O
d.	O
garcia	O
-	O
romero	O
,	O
j.	O
villalba	O
,	O
rispeech	O
:	O
an	O
asr	B
corpus	B
based	O
on	O
public	O
domain	B
audio	O
books	O
,	O
”	O
m.	O
maciejewski	O
,	O
v.	O
manohar	O
,	O
n.	O
dehak	O
,	O
d.	O
povey	O
,	O
s.	O
watan-	O
in	O
proc	O
.	O
2015	O
ieee	O
international	O
conference	O
on	O
acoustics	B
,	O
abe	O
,	O
and	O
s.	O
khudanpur	O
,	O
“	O
diarization	B
is	O
hard	O
:	O
some	O
experi-	O
speech	O
and	O
signal	B
processing	I
(	O
icassp	O
)	O
,	O
2015	O
,	O
pp	O
.	O
5206	O
–	O
ences	O
and	O
lessons	O
learned	O
for	O
the	O
jhu	O
team	O
in	O
the	O
inaugural	O
5210.[21	O
]	O
d.	O
snyder	O
,	O
g.	O
chen	O
,	O
and	O
d.	O
povey	O
,	O
“	O
musan	O
:	O
a	O
music	O
,	O
speech	O
,	O
and	O
noise	O
corpus	B
,	O
,	O
”	O
2015	O
,	O
arxiv:1510.08484	O
.	O
[	O
22	O
]	O
t.	O
ko	O
,	O
v.	O
peddinti	O
,	O
d.	O
povey	O
,	O
m.	O
l.	O
seltzer	O
,	O
and	O
s.	O
khudanpur	O
,	O
“	O
a	O
study	O
on	O
data	B
augmentation	I
of	O
reverberant	O
speech	O
for	O
robust	O
speech	B
recognition	I
,	O
”	O
in	O
proc	O
.	O
2017	O
ieee	O
international	O
con-	O
ference	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
(	O
icassp	O
)	O
,	O
march	O
2017	O
,	O
pp	O
.	O
5220––5224	O
.	O
[	O
23	O
]	O
a.	O
vaswani	O
,	O
n.	O
shazeer	O
,	O
n.	O
parmar	O
,	O
j.	O
uszkoreit	O
,	O
l.	O
jones	O
,	O
a.	O
n.	O
gomez	O
,	O
l.	O
kaiser	O
,	O
and	O
i.	O
polosukhin	O
,	O
“	O
attention	O
is	O
all	O
you	O
need	O
,	O
”	O
in	O
proc	O
.	O
the	O
thirty-ﬁrst	O
annual	B
conference	I
on	O
neu-	O
ral	O
information	B
processing	B
systems	O
(	O
nips	O
)	O
,	O
2017	O
,	O
pp	O
.	O
5998	O
–	O
–	O

noname	O
manuscript	O
no	O
.	O
(	O
will	O
be	O
inserted	O
by	O
the	O
editor	O
)	O
a	O
tutorial	O
on	O
evaluation	B
metrics	I
for	O
speaker	B
diarization	I
systems	I
supratim	O
tribady	O
·	O
shefali	O
waldekar	O
·	O
a	O
kishore	O
kumar	O
·	O
goutam	O
saha	O
·	O
md	O
sahidullah	O
·	O
received	O
:	O
dd	O
month	O
year	O
/	O
accepted	O
:	O
dd	O
month	O
year	O
abstract	O
in	O
this	O
article	O
,	O
we	O
present	O
a	O
comprehensive	O
review	O
of	O
the	O
evaluation	B
metrics	I
for	O
the	O
sd	O
systems	O
.	O
we	O
demonstrate	O
how	O
they	O
calculate	O
the	O
evaluation	B
metrics	I
from	O
the	O
ground	B
truth	I
and	O
the	O
system	O
-	O
generated	O
output	B
.	O
here	O
,	O
diﬀer-	O
ent	O
errors	B
are	O
considered	O
in	O
each	O
evaluation	B
metrics	I
,	O
such	O
as	O
speaker	B
error	O
,	O
false	B
alarm	I
,	O
and	O
missed	O
speech	O
with	O
the	O
help	O
of	O
ground	B
truth	I
and	O
system	O
out-	O
put	O
.	O
we	O
explain	O
the	O
importance	O
of	O
diﬀerent	O
error	O
terms	B
for	O
computing	O
these	O
evaluation	B
metrics	I
for	O
sd	O
with	O
the	O
help	O
of	O
case	O
studies	O
.	O
the	O
limitations	O
of	O
diﬀerent	O
evaluation	B
metrics	I
are	O
brieﬂy	O
explained	O
in	O
this	O
article	O
.	O
finally	O
,	O
we	O
discuss	O
the	O
formulation	O
of	O
new	O
or	O
diﬀerent	O
evaluation	B
metric	B
for	O
evaluation	B
of	O
sd	O
systems	O
.	O
keywords	O
diarization	B
error	I
rate	I
(	O
der	O
)	O
·	O
jaccard	B
error	I
rate	O
(	O
jer	O
)	O
·	O
rich	B
transcription	I
time	B
marked	O
(	O
rttm	O
)	O
·	O
speaker	B
diarization	I
(	O
sd	O
)	O
·	O
speaker	B
indexing	O
·	O
un	O
-	O
partitioned	O
evaluation	B
map	O
(	O
uem	O
)	O
supratim	O
tribady	O
department	O
of	O
electronics	O
&	O
electrical	O
communication	B
engineering	O
,	O
iit	O
kharagpur	O
e	O
-	O
mail	O
:	O
supratimtribedy96@gmail.com	O
shefali	O
waldekar	O
department	O
of	O
electronics	O
&	O
electrical	O
communication	B
engineering	O
,	O
iit	O
kharagpur	O
e	O
-	O
mail	O
:	O
shefaliw@ece.iitkgp.ernet.in	O
a	O
kishore	O
kumar	O
department	O
of	O
electronics	O
&	O
electrical	O
communication	B
engineering	O
,	O
iit	O
kharagpur	O
e	O
-	O
mail	O
:	O
kishore@iitkgp.ac.in	O
goutam	O
saha	O
department	O
of	O
electronics	O
&	O
electrical	O
communication	B
engineering	O
,	O
iit	O
kharagpur	O
e	O
-	O
mail	O
:	O
gsaha@ece.iitkgp.ac.in	O
md	O
sahidullah	O
universit´e	O
de	O
lorraine	O
,	O
cnrs	O
,	O
inria	O
,	O
loria	O
,	O
f-54000	O
,	O
nancy	O
,	O
france	O
e	O
-	O
mail	O
:	O
md.sahidullah@inria.fr2	O
supratim	O
tribady	O
et	O
al	O
.	O
1	O
introduction	O
speaker	B
diarization	I
(	O
sd	O
)	O
(	O
also	O
known	O
as	O
speaker	B
indexing	O
(	O
wilcox	O
and	O
kim-	O
ber	O
,	O
1997	O
)	O
)	O
aims	O
to	O
solve	O
the	O
problem	O
“	O
who	O
spoke	O
when	O
”	O
for	O
a	O
given	O
speech	B
signal	I
(	O
anguera	O
et	O
al	O
.	O
,	O
2012	O
)	O
.	O
it	O
mainly	O
involves	O
dividing	O
a	O
speech	B
signal	I
into	O
segments	O
followed	O
by	O
grouping	O
of	O
the	O
homogeneous	O
segments	O
based	O
on	O
speaker	B
similarity	B
indexing	O
.	O
sd	O
has	O
many	O
practical	O
applications	O
,	O
such	O
as	O
automatic	O
video	O
captioning	O
(	O
song	O
et	O
al	O
.	O
,	O
2018	O
)	O
,	O
automatic	O
transcript	O
generation	O
for	O
spo-	O
ken	O
conversations	O
(	O
bentley	O
et	O
al	O
.	O
,	O
2018	O
)	O
,	O
smart	O
speaker	B
technology	O
(	O
bentley	O
et	O
al	O
.	O
,	O
2018	O
)	O
,	O
etc	O
.	O
in	O
the	O
present	O
period	O
with	O
a	O
growing	O
number	O
of	O
broadcast-	O
ing	O
and	O
online	O
meeting	O
,	O
sd	O
could	O
play	O
a	O
key	O
role	O
in	O
creating	O
transcripts	B
for	O
content	O
summarization	O
and	O
sentiment	O
analysis	B
in	O
natural	O
language	B
processing	I
application	B
(	O
tiwary	O
and	O
siddiqui	O
,	O
2008	O
)	O
.	O
most	O
of	O
the	O
studies	O
conducted	O
in	O
sd	O
research	B
focus	O
on	O
three	O
kinds	O
of	O
audio	O
-	O
data	B
:	O
(	O
i	O
)	O
broadcast	O
news	O
audio	O
where	O
speech	O
data	B
are	O
usually	O
collected	O
from	O
radio	O
and	O
tv	O
programs	O
containing	O
com-	O
mercial	O
breaks	O
and	O
music	O
(	O
wachob	O
,	O
1992	O
)	O
,	O
(	O
ii	O
)	O
meeting	O
audio	O
where	O
multiple	O
people	O
are	O
involved	O
in	O
a	O
conversation	O
(	O
mieczakowski	O
et	O
al	O
.	O
)	O
,	O
and	O
(	O
iii	O
)	O
audio-	O
data	B
from	O
telephone	O
conversation	O
(	O
elvins	O
et	O
al	O
.	O
,	O
2003	O
)	O
.	O
however	O
,	O
studies	O
on	O
sd	O
are	O
also	O
conducted	O
with	O
dihard	O
corpora	B
which	O
consists	O
of	O
a	O
wide	O
variety	O
of	O
audio	O
-	O
data	B
collected	O
from	O
a	O
number	O
of	O
real	O
-	O
world	O
conditions	O
(	O
ryant	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O
the	O
main	O
challenge	B
in	O
sd	O
system	O
arises	O
due	O
to	O
diﬀerent	O
practical	O
problems	O
,	O
which	O
mainly	O
includes	O
domain	B
mismatch	O
because	O
of	O
diﬀerent	O
acoustic	O
environ-	O
ment	O
(	O
himawan	O
et	O
al	O
.	O
,	O
2018	O
)	O
,	O
incorrect	O
detection	B
of	O
speakers	O
in	O
multi	O
-	O
speaker	B
speech	B
recognition	I
from	O
unsegmented	O
recordings	O
(	O
watanabe	O
et	O
al	O
.	O
,	O
2020	O
)	O
,	O
and	O
improper	O
evaluation	B
of	O
the	O
metrics	O
during	O
overlapping	B
of	O
speakers	O
in	O
a	O
con-	O
versation	O
(	O
vipperla	O
et	O
al	O
.	O
,	O
2012	O
)	O
.	O
the	O
system	O
should	O
be	O
strong	O
enough	O
to	O
deal	O
with	O
multiple	O
speakers	O
during	O
overlapping	B
.	O
the	O
main	O
aim	O
of	O
this	O
work	O
is	O
to	O
review	O
the	O
evaluation	B
metrics	I
for	O
sd	O
sys-	O
tem	O
.	O
evaluation	B
metrics	I
play	O
a	O
very	O
important	O
role	O
in	O
determining	O
the	O
best	O
system	O
,	O
based	O
on	O
the	O
various	O
shortcomings	O
of	O
the	O
diarization	B
process	B
.	O
the	O
se-	O
lection	O
of	O
an	O
evaluation	B
metric	B
decides	O
the	O
system	O
performance	O
in	O
diﬀerent	O
ad-	O
versarial	O
conditions	O
.	O
an	O
important	O
aspect	O
of	O
the	O
evaluation	B
metric	B
is	O
the	O
capa-	O
bility	O
to	O
distinguish	O
among	O
various	O
systems	O
.	O
several	O
metrics	O
are	O
used	O
to	O
check	O
the	O
performance	O
of	O
the	O
speech	O
processing	B
systems	O
,	O
like	O
for	O
automatic	O
speaker	B
veriﬁcation	O
equal	O
error	B
rate	I
(	O
eer	B
)	O
is	O
used	O
(	O
jyh	O
-	O
min	O
cheng	O
and	O
hsiao	O
-	O
chuan	O
wang	O
,	O
2004	O
)	O
,	O
for	O
acoustic	O
scene	O
classiﬁcation	O
the	O
standard	O
is	O
accuracy	O
(	O
valenti	O
et	O
al	O
.	O
,	O
2016	O
)	O
,	O
f1	O
score	B
is	O
used	O
for	O
sound	O
event	O
detection	B
(	O
kong	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
metrics	O
such	O
as	O
unweighted	O
average	B
recall	O
(	O
uar	O
)	O
is	O
used	O
for	O
emotion	O
recog-	O
nition	O
evaluation	B
(	O
gamage	O
et	O
al	O
.	O
,	O
2017	O
)	O
,	O
and	O
min	O
t	O
-	O
dcf	O
is	O
used	O
for	O
detecting	O
spooﬁng	O
countermeasures	O
(	O
kinnunen	O
et	O
al	O
.	O
,	O
2020),word	O
error	B
rate	I
(	O
wer	O
)	O
is	O
the	O
primary	O
evaluation	B
metric	B
for	O
automatic	O
speech	B
recognition	I
(	O
galibert	O
,	O
2013	O
)	O
,	O
etc	O
.	O
these	O
are	O
some	O
evaluation	B
metrics	I
used	O
for	O
checking	O
the	O
perfor-	O
mance	O
of	O
the	O
systems	O
for	O
the	O
respective	O
domain	B
.	O
similarly	O
,	O
diarization	B
error	I
rate	I
and	O
jaccard	B
error	I
rate	O
are	O
the	O
two	O
widely	O
used	O
evaluation	B
metric	B
,	O
used	O
to	O
check	O
the	O
performance	O
of	O
the	O
sd	O
system	O
.	O
diarization	B
error	I
rate	I
,	O
remainsa	O
tutorial	O
on	O
evaluation	B
metrics	I
for	O
speaker	B
diarization	I
systems	I
3	O
the	O
principal	O
evaluation	B
metric	B
in	O
this	O
area	O
which	O
was	O
introduced	O
by	O
national	O
institute	O
of	O
standards	O
and	O
technology	O
(	O
nist	O
)	O
in	O
the	O
rich	O
transcriptions	B
(	O
rt	O
)	O
evaluations1	O
in	O
the	O
year	O
2000	O
.	O
jaccard	B
error	I
rate	O
,	O
a	O
metric	B
introduced	O
for	O
sec-	O
ond	O
dihard	O
diarization	B
challenge	B
,	O
2019	O
23	O
that	O
is	O
based	O
on	O
the	O
jaccard	O
index	O
(	O
ryant	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
in	O
this	O
article	O
,	O
we	O
review	O
diﬀerent	O
metrics	O
used	O
for	O
the	O
evaluation	B
of	O
sd	O
system	O
.	O
we	O
mainly	O
analyse	O
two	O
widely	O
used	O
evaluation	B
metric	B
known	O
as	O
der	O
and	O
jer	O
,	O
for	O
synthetically	O
prepared	O
ground	B
-	O
truth	O
and	O
predicted	O
output	B
.	O
we	O
discuss	O
the	O
limitations	O
of	O
the	O
currently	O
used	O
evaluation	B
metrics	I
and	O
brieﬂy	O
discuss	O
how	O
to	O
develop	O
a	O
new	O
reliable	O
metric	B
for	O
the	O
evaluation	B
of	O
sd	O
systems	O
.	O
the	O
rest	O
of	O
the	O
paper	O
is	O
organized	O
as	O
follows	O
.	O
in	O
section	O
2	O
,	O
we	O
present	O
a	O
brief	O
overview	O
of	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
sd	O
system	O
.	O
in	O
section	O
3	O
,	O
we	O
present	O
the	O
case	O
studies	O
with	O
two	O
evaluation	B
metrics	I
mainly	O
der	O
and	O
jer	O
along	O
with	O
some	O
other	O
clustering	B
metrics	O
.	O
in	O
section	O
4	O
,	O
we	O
prepared	O
synthetic	O
data	B
in	O
the	O
form	O
of	O
reference	B
ground	B
truth	I
and	O
system	O
predicted	O
labels	O
and	O
calculated	O
the	O
der	O
and	O
jer	O
.	O
and	O
lastly	O
,	O
in	O
section	O
5	O
,	O
and	O
section	O
6	O
we	O
will	O
discuss	O
the	O
limitations	O
of	O
der	O
and	O
jer	O
,	O
and	O
also	O
give	O
overview	O
regarding	O
development	O
of	O
new	O
evaluation	B
metrics	I
.	O
2	O
an	O
overview	O
of	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
speaker	B
diarization	I
system	I
sd	O
is	O
one	O
of	O
the	O
diﬀerent	O
ways	O
of	O
processing	B
done	O
on	O
audio	O
signals	B
(	O
anguera	O
et	O
al	O
.	O
,	O
2012	O
)	O
.	O
a	O
sd	O
system	O
usually	O
consists	O
of	O
several	O
components	B
.	O
the	O
ﬁrst	O
important	O
component	O
is	O
a	O
voice	O
activity	O
detector	O
(	O
vad	O
)	O
(	O
moattar	O
and	O
homay-	O
ounpour	O
,	O
2009	O
)	O
,	O
which	O
separates	O
the	O
speech	B
segments	I
from	O
the	O
non	O
-	O
speech	B
segments	I
in	O
an	O
audio	O
-	O
data	B
.	O
then	O
it	O
applies	O
a	O
speech	O
based	O
segmentation	B
tech-	O
nique	O
to	O
split	O
the	O
speech	O
regions	O
into	O
diﬀerent	O
small	O
segments	O
(	O
tritschler	O
and	O
gopinath	O
,	O
1999	O
)	O
.	O
after	O
segmentation	B
speaker	B
embeddings4	O
are	O
extracted	O
.	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
speaker	B
diarization	I
systems	I
rely	O
on	O
speaker	B
embeddings	I
(	O
cyrta	O
et	O
al	O
.	O
,	O
2017	O
)	O
for	O
speaker	B
similarity	B
measure	O
(	O
sell	O
and	O
garcia	O
-	O
romero	O
,	O
2014	O
)	O
.	O
in	O
the	O
following	O
step	O
,	O
it	O
uses	O
a	O
clustering	B
technique	B
for	O
clustering	B
the	O
segments	O
into	O
disjoint	O
speakers	O
.	O
finally	O
,	O
re	O
-	O
segmentation	B
is	O
used	O
for	O
further	O
frame	B
-	O
level	B
reﬁnement	O
of	O
speaker	B
diarization	I
output	B
(	O
sell	O
and	O
garcia	O
-	O
romero	O
,	O
2015	O
)	O
.	O
fig	O
1	O
illustrates	O
the	O
diﬀerent	O
components	B
of	O
the	O
sd	O
system.4	O
supratim	O
tribady	O
et	O
al	O
.	O
input	B
speech	O
voice	O
activity	B
detection	I
input	B
speech	O
without	O
silence	B
segmentation	B
overlapped	O
or	O
non	O
-	O
overlapped	O
segments	O
speaker	B
embeddings	I
x	O
-	O
vector	O
or	O
i	O
-	O
vector	O
speaker	B
similarity	B
measure	O
similarity	B
matrix	O
computed	O
with	O
plda	B
clustering	B
a	O
b	O
c	O
ahc	O
with	O
threshold=1.5	O
re	O
-	O
segmentation	B
diarization	B
output	B
a	O
b	O
c	O
fig	O
.	O
1	O
this	O
ﬁgure	O
tells	O
about	O
the	O
standard	O
sd	O
structure	O
with	O
multiple	O
modules	O
.	O
a	O
raw	O
audio	O
recording	B
of	O
a	O
conversation	O
is	O
given	O
as	O
an	O
input	B
,	O
after	O
that	O
speech	O
part	O
of	O
the	O
signal	B
is	O
extracted	O
or	O
separated	O
from	O
the	O
non	O
-	O
speech	O
part	O
of	O
the	O
audio	O
signal	B
.	O
the	O
speech	O
part	O
of	O
the	O
audio	O
signal	B
is	O
segmented	O
into	O
small	O
segments	O
from	O
which	O
speaker	B
embeddings	I
(	O
i-	O
vector	O
or	O
x	O
-	O
vector	O
)	O
are	O
extracted	O
.	O
the	O
speaker	B
similarity	B
is	O
measured	O
and	O
computed	O
from	O
the	O
speaker	B
embeddings	I
and	O
ﬁnally	O
,	O
based	O
on	O
the	O
similarity	B
measure	O
the	O
speaker	B
embeddings	I
are	O
clustered	O
using	O
agglomerative	O
hierarchical	O
clustering	B
with	O
a	O
threshold	B
of	O
1.5	O
which	O
assigns	O
similar	O
speaker	B
segments	I
to	O
a	O
global	O
speaker	B
i	O
d	O
.	O
after	O
clustering	B
,	O
again	O
it	O
is	O
re	O
-	O
segmented	O
and	O
ﬁnally	O
a	O
timeline	O
showing	O
diarization	B
output	B
audio	O
is	O
found.a	O
tutorial	O
on	O
evaluation	B
metrics	I
for	O
speaker	B
diarization	I
systems	I
5	O
0	O
sec	O
1	O
sec	O
2	O
sec	O
3	O
sec	O
4	O
sec	O
5	O
sec	O
6	O
sec	O
7	O
sec	O
8	O
sec	O
9	O
sec	O
a	O
a	O
a	O
a	O
b	O
b	O
b	O
bb	O
b	O
ground	B
truth	I
c	O
c	O
c	O
d	O
d	O
d	O
d	O
d	O
p	O
p	O
p	O
q	O
q	O
q	O
q	O
q	O
system	O
output	B
r	O
r	O
r	O
r	O
s	O
s	O
s	O
p	O
q	O
q	O
q	O
speaker	B
error	O
r	O
r	O
r	O
s	O
s	O
p	O
false	B
alarm	I
q	O
r	O
s	O
p	O
missed	O
speech	O
q	O
q	O
s	O
s	O
s	O
fig	O
.	O
2	O
synthetic	O
ground	B
truth	I
and	O
system	O
predicted	O
labels	O
to	O
illustrate	O
diﬀerent	O
types	O
of	O
error	O
.	O
here	O
green	O
speaker	B
labels	I
indicate	O
the	O
reference	B
ground	B
truth	I
,	O
yellow	O
color	O
speaker	B
la-	O
bels	O
indicates	O
system	O
predicted	O
speaker	B
labels	I
and	O
blue	O
color	O
speaker	B
labels	I
indicates	O
speaker	B
error	O
,	O
false	B
alarm	I
and	O
missed	O
speech	O
3	O
evaluation	B
metrics	I
for	O
speaker	B
diarization	I
der	O
and	O
jer	O
,	O
are	O
used	O
to	O
measure	O
the	O
performance	O
of	O
a	O
sd	O
system	O
.	O
for	O
speech	O
regions	O
,	O
the	O
diarization	B
system	O
speciﬁes	O
the	O
locations	O
of	O
speaker	B
labels	I
to	O
each	O
homogeneous	O
segment	B
of	O
speech	O
.	O
der	O
and	O
jer	O
provides	O
a	O
convenient	O
way	O
to	O
compare	O
diﬀerent	O
diarization	B
approaches	O
.	O
the	O
diﬀerence	O
or	O
error	O
gen-	O
erated	O
by	O
a	O
system	O
in	O
diarizing	O
a	O
speech	O
,	O
that	O
is	O
by	O
comparing	O
the	O
error	O
from	O
1	O
http://www.xavieranguera.com/phdthesis/node147.html#nis	O
rt	O
eval	O
plan	O
2006	O
2	O
https://signalprocessingsociety.org/publications-resources/data-challenges/second-	O
dihard	O
-	O
speech	O
-	O
diarization	B
-	O
challenge	B
3	O
dihard	O
ii	O
is	O
the	O
second	O
in	O
a	O
series	O
of	O
diarization	B
challenges	B
focusing	O
on	O
”	O
hard	O
”	O
diariza-	O
tion	O
;	O
that	O
is	O
,	O
sd	O
for	O
challenging	O
recordings	O
where	O
there	O
is	O
an	O
expectation	O
that	O
the	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
will	O
fare	O
poorly	O
https://coml.lscp.ens.fr/dihard/index.html	O
4	O
speaker	B
embeddings	I
are	O
representation	O
of	O
speech	B
segments	I
created	O
with	O
deep	O
neural	O
network.6	O
supratim	O
tribady	O
et	O
al	O
.	O
the	O
ground	B
truth	I
(	O
reference	B
truth	O
)	O
rich	B
transcription	I
time	B
marked	O
(	O
rttm	O
)	O
,	O
and	O
system	O
predicted	O
or	O
system	O
-	O
generated	O
rttm	O
using	O
an	O
unpartioned	O
for-	O
mat	O
evaluation	B
(	O
uem	O
)	O
ﬁle	O
,	O
which	O
is	O
used	O
to	O
specify	O
the	O
scoring	O
within	O
each	O
recording	B
.	O
so	O
,	O
the	O
motivation	O
will	O
be	O
to	O
decrease	O
the	O
der	O
and	O
jer	O
,	O
in	O
case	O
of	O
output	B
rttm	O
which	O
will	O
help	O
to	O
improve	O
the	O
sd	O
system	O
and	O
to	O
match	O
the	O
relative	O
speaker	B
labels	I
and	O
location	O
of	O
speaker	B
boundaries	B
from	O
reference	B
rttm	O
compared	O
to	O
output	B
predicted	O
rttm	O
.	O
the	O
evaluation	B
metrics	I
are	O
gen-	O
erated	O
with	O
the	O
help	O
of	O
some	O
ﬁles	O
such	O
as	O
reference	B
rttm	O
,	O
system	O
rttm	O
and	O
uem	O
ﬁles	O
.	O
the	O
der	O
of	O
the	O
system	O
can	O
be	O
over	O
100	O
%	O
,	O
whereas	O
the	O
jer	O
of	O
the	O
system	O
can	O
not	O
exceed	O
over	O
100	O
%	O
(	O
anguera	O
et	O
al	O
.	O
,	O
2005	O
)	O
.	O
the	O
rttm	O
ﬁles	O
are	O
space	O
-	O
delimited	O
text	O
ﬁles	O
containing	O
one	O
turn	O
per	O
line	O
,	O
each	O
line	O
containing	O
ten	O
ﬁelds	O
whereas	O
uem	O
ﬁles	O
are	O
used	O
to	O
specify	O
the	O
scoring	O
regions	O
within	O
each	O
audio	O
recording	B
.	O
the	O
uem	O
ﬁle	O
contains	O
a	O
line	O
with	O
four	O
space	O
-	O
delimited	O
ﬁelds	O
for	O
each	O
scoring	O
region	O
.	O
for	O
speech	O
regions	O
,	O
the	O
diarization	B
system	O
spec-	O
iﬁes	O
the	O
locations	O
of	O
speaker	B
labels	I
,	O
to	O
each	O
homogeneous	O
segment	B
of	O
speech	O
.	O
computation	O
of	O
an	O
error	B
rate	I
requires	O
describing	O
what	O
are	O
the	O
errors	B
present	O
.	O
the	O
various	O
types	O
of	O
error	O
in	O
the	O
evaluation	B
metrics	I
of	O
the	O
sd	O
system	O
are	O
:	O
speaker	B
error	O
:	O
speaker	B
error	O
corresponds	O
to	O
the	O
percentage	B
of	O
scored	O
time	B
that	O
a	O
reference	B
speaker	I
is	O
assigned	O
to	O
a	O
wrong	O
speaker	B
in	O
the	O
output	B
reference	B
speaker	I
labels	O
.	O
speaker	B
error	O
is	O
mainly	O
a	O
diarization	B
system	O
error	O
.	O
speaker	B
error	O
is	O
assigned	O
within	O
a	O
speech	O
region	O
,	O
and	O
it	O
does	O
not	O
account	O
for	O
speaker	B
errors	B
in	O
overlapping	B
regions	O
,	O
or	O
any	O
other	O
error	O
coming	O
from	O
non	O
-	O
speech	O
frames	O
.	O
false	B
alarm	I
speech	O
:	O
false	B
alarm	I
speech	O
corresponds	O
to	O
the	O
percentage	B
of	O
a	O
scored	O
time	B
,	O
that	O
a	O
non	O
-	O
speech	O
part	O
is	O
incorrectly	O
labelled	O
as	O
a	O
speech	O
region	O
in	O
system	O
-	O
generated	O
output	B
.	O
missed	O
speech	O
:	O
missed	O
speech	O
corresponds	O
to	O
the	O
percentage	B
of	O
a	O
scored	O
time	B
,	O
that	O
a	O
speech	O
part	O
is	O
incorrectly	O
labelled	O
as	O
a	O
non	O
-	O
speech	O
part	O
in	O
system-	O
generated	O
output	B
.	O
3.1	O
diarization	B
error	I
rate	I
it	O
is	O
the	O
most	O
commonly	O
used	O
metric	B
in	O
the	O
sd	O
system	O
.	O
to	O
compute	O
der	O
,	O
an	O
optimal	O
one	O
-	O
to	O
-	O
one	O
mapping	O
of	O
reference	B
speakers	O
to	O
system	O
output	B
speakers	O
is	O
determined	O
.	O
the	O
der	O
is	O
then	O
the	O
sum	O
of	O
the	O
per	O
speakers	O
false	B
alarm	I
time	B
,	O
miss	B
time	B
and	O
speaker	B
error	O
time	B
that	O
is	O
not	O
matched	O
to	O
the	O
reference	B
speaker	I
divided	O
by	O
total	O
speech	O
time	B
in	O
an	O
audio	O
ﬁle	O
.	O
it	O
is	O
measured	O
as	O
the	O
fraction	O
of	O
time	B
that	O
is	O
not	O
attributed	O
correctly	O
to	O
a	O
speaker	B
or	O
non	O
-	O
speech	O
.	O
error	O
+	O
fa	O
+	O
miss	B
der	O
=	O
(	O
1	O
)	O
total	O
here	O
total	O
refers	O
to	O
the	O
duration	O
of	O
the	O
union	O
of	O
reference	B
and	O
system	B
speaker	I
segments	O
and	O
if	O
the	O
reference	B
speaker	I
was	O
not	O
paired	O
with	O
a	O
system	B
speaker	I
,	O
it	O
is	O
the	O
duration	O
of	O
all	O
reference	B
speaker	I
segments.a	O
tutorial	O
on	O
evaluation	B
metrics	I
for	O
speaker	B
diarization	I
systems	I
7	O
in	O
fig	O
.	O
2	O
,	O
a	O
synthetic	O
speaker	B
label	O
has	O
been	O
generated	O
to	O
show	O
the	O
diﬀer-	O
ent	O
errors	B
generated	O
in	O
a	O
sd	O
system	O
.	O
in	O
order	B
to	O
check	O
the	O
speaker	B
mapping	O
between	O
the	O
reference	B
speaker	I
and	O
system	B
speaker	I
output	B
,	O
der	O
uses	O
hun-	O
garian	O
algorithm	O
and	O
weighted	O
-	O
bipartite	O
graph	O
matching	O
algorithm	O
.	O
using	O
hungarian	O
algorithm	O
and	O
weighted	O
-	O
bipartite	O
graph	O
matching	O
we	O
have	O
found	O
the	O
reference	B
speaker	I
a	O
is	O
mapped	O
with	O
system	B
speaker	I
r	O
,	O
reference	B
speaker	I
b	O
is	O
mapped	O
with	O
system	B
speaker	I
p	O
,	O
reference	B
speaker	I
c	O
is	O
mapped	O
with	O
system	B
speaker	I
s	O
and	O
reference	B
speaker	I
d	O
is	O
mapped	O
with	O
system	B
speaker	I
q.	O
in	O
table	O
1	O
,	O
diﬀerent	O
types	O
of	O
error	O
that	O
are	O
generated	O
in	O
the	O
synthetic	O
speaker	B
labels	I
are	O
shown	O
in	O
fig.2	O
.	O
time	B
frame	B
reference	B
speaker	I
system	O
output	B
error	O
0	O
-	O
1	O
second	O
a	O
,	O
c	O
q	O
,	O
s	O
1	O
speaker	B
error	O
1	O
-	O
2	O
second	O
a	O
,	O
b	O
,	O
d	O
p	O
,	O
r	O
1	O
missed	O
speech	O
2	O
-	O
3	O
second	O
a	O
p	O
,	O
r	O
1	O
false	B
alarm	I
3	O
-	O
4	O
second	O
b	O
q	O
1	O
speaker	B
error	O
4	O
-	O
5	O
second	O
b	O
,	O
c	O
,	O
d	O
r	O
1	O
speaker	B
error	O
,	O
2	O
missed	O
speech	O
5	O
-	O
6	O
second	O
b	O
,	O
d	O
q	O
1	O
missed	O
speech	O
6	O
-	O
7	O
second	O
a	O
,	O
d	O
q	O
,	O
r	O
no	O
error	O
7	O
-	O
8	O
second	O
b	O
,	O
c	O
p	O
,	O
s	O
no	O
error	O
8	O
-	O
9	O
second	O
d	O
q	O
,	O
s	O
1	O
false	B
alarm	I
table	O
1	O
demonstration	O
of	O
diﬀerent	O
types	O
of	O
error	O
present	O
in	O
diﬀerent	O
time	B
frames	O
for	O
the	O
synthetically	O
prepared	O
data	B
in	O
fig.2	O
3.2	O
goodman	O
-	O
kruskal	O
tau	O
(	O
gkt	O
)	O
gkt	O
(	O
zarghami	O
et	O
al	O
.	O
,	O
2009	O
)	O
is	O
an	O
unbalanced	O
measure	O
which	O
was	O
discovered	O
by	O
goodman	O
and	O
kruskal	O
in	O
1954	O
.	O
for	O
a	O
reference	B
speaker	I
label	O
’	O
ref	O
’	O
and	O
a	O
system	B
speaker	I
label	O
’	O
sys	O
’	O
,	O
gkt(ref	O
,	O
sys	O
)	O
correlates	O
to	O
the	O
fraction	O
of	O
change	B
in	O
sys	O
that	O
can	O
be	O
explained	O
by	O
ref	O
.	O
therefore	O
,	O
gkt(sys	O
,	O
ref	O
)	O
is	O
1	O
when	O
ref	O
is	O
exactly	O
predictive	O
compared	O
to	O
sys	O
and	O
is	O
0	O
when	O
ref	O
is	O
not	O
predictive	O
compared	O
to	O
sys	O
in	O
system	O
-	O
output	B
.	O
3.3	O
conditional	O
entropy	O
another	O
evaluation	B
metric	B
,	O
which	O
reports	O
four	O
information	B
theoretic	O
measures	O
.	O
–	O
h(x	O
—	O
y	O
)	O
:	O
conditional	O
entropy	O
in	O
bits	O
of	O
the	O
reference	B
speaker	I
label	O
when	O
system	B
speaker	I
label	O
is	O
present	O
.	O
–	O
h(y	O
—	O
x	O
)	O
:	O
conditional	O
entropy	O
in	O
bits	O
of	O
the	O
system	B
speaker	I
label	O
when	O
reference	B
speaker	I
label	O
is	O
present	O
.	O
–	O
mi	O
:	O
mutual	O
information	B
in	O
bits	O
between	O
reference	B
and	O
system	B
speaker	I
labels.8	O
supratim	O
tribady	O
et	O
al	O
.	O
–	O
nmi	O
:	O
normalized	O
mutual	O
information	B
between	O
the	O
reference	B
and	O
system	B
speaker	I
labels	O
.	O
here	O
,	O
x	O
refers	O
to	O
the	O
sequence	B
of	O
true	O
frame	B
-	O
wise	O
speaker	B
labels	I
whereas	O
y	O
refers	O
to	O
the	O
sequence	B
of	O
hypothesized	O
speaker	B
labels	I
.	O
nmi	O
is	O
basically	O
derived	O
from	O
mi	O
after	O
being	O
normalized	O
in	O
the	O
interval	O
between	O
0	O
to	O
1	O
.	O
3.4	O
purity	O
,	O
coverage	O
and	O
clustering	B
metrics	O
apart	O
from	O
der	O
and	O
jer	O
,	O
purity	O
(	O
cettolo	O
,	O
2000	O
)	O
and	O
coverage	O
(	O
gauvain	O
et	O
al	O
.	O
,	O
1998	O
)	O
also	O
provide	O
a	O
convenient	O
way	O
to	O
compare	O
between	O
systems	O
of	O
diﬀerent	O
diarization	B
approaches	O
.	O
it	O
is	O
usually	O
not	O
suﬃcient	O
to	O
understand	O
the	O
type	O
of	O
error	O
executed	O
by	O
the	O
system	O
.	O
to	O
understand	O
the	O
type	O
of	O
error	O
performed	O
by	O
the	O
system	O
,	O
purity	O
and	O
coverage	O
play	O
a	O
key	O
role	O
to	O
judge	O
the	O
behaviour	O
of	O
the	O
system	O
.	O
a	O
fourth	O
approach	O
or	O
evaluation	B
metrics	I
to	O
check	O
the	O
performance	O
of	O
the	O
system	O
uses	O
both	O
the	O
reference	B
and	O
system	O
output	B
labels	O
.	O
each	O
recording	B
is	O
converted	O
to	O
a	O
sequence	B
of	O
10	O
msec	O
out	O
of	O
which	O
is	O
a	O
single	B
speaker	I
label	O
is	O
assigned	O
to	O
the	O
following	O
cases	O
:	O
–	O
frame	B
containing	O
no	O
speech	O
–	O
frame	B
containing	O
speech	O
from	O
a	O
single	B
speaker	I
–	O
frame	B
containing	O
overlapping	B
speech	I
b	O
-	O
cubed	O
precision	O
,	O
recall	O
,	O
and	O
f1	O
:	O
the	O
b	O
-	O
cubed	O
precision	O
for	O
a	O
single	O
frame	B
assigned	O
speaker	B
s	O
in	O
the	O
reference	B
diarization	B
and	O
c	O
in	O
the	O
system	O
diarization	B
is	O
the	O
proportion	O
of	O
frames	O
assigned	O
c	O
that	O
are	O
also	O
assigned	O
s.	O
similarly	O
,	O
the	O
b	O
-	O
cubed	O
recall	O
for	O
a	O
frame	B
is	O
the	O
proportion	O
of	O
all	O
frames	O
assigned	O
s	O
that	O
are	O
also	O
assigned	O
c.	O
the	O
overall	O
precision	O
and	O
recall	O
,	O
then	O
,	O
are	O
just	O
the	O
mean	O
of	O
the	O
frame	B
-	O
level	B
precision	O
and	O
recall	O
measures	O
and	O
the	O
overall	O
f-1	O
their	O
harmonic	O
mean	O
.	O
3.5	O
speaker	B
error	B
rate	I
when	O
speech	O
or	O
non	O
-	O
speech	B
segments	I
do	O
not	O
play	O
an	O
important	O
role	O
in	O
the	O
ex-	O
periment	O
,	O
then	O
the	O
standard	O
speaker	B
error	B
rate	I
(	O
ser	O
)	O
comes	O
into	O
play	O
,	O
which	O
does	O
not	O
include	O
speech	O
or	O
non	O
-	O
speech	O
errors	B
.	O
speaker	B
error	B
rate	I
(	O
ser	O
)	O
corre-	O
sponds	O
to	O
the	O
amount	B
of	O
scored	O
time	B
when	O
a	O
reference	B
speaker	I
in	O
the	O
ground	B
truth	I
is	O
mapped	O
to	O
a	O
wrong	O
speaker	B
in	O
the	O
output	B
speaker	B
labels	I
(	O
aronowitz	O
,	O
2010	O
)	O
.	O
speaker	B
error	B
rate	I
(	O
ser	O
)	O
is	O
only	O
assigned	O
for	O
speech	O
regions	O
,	O
and	O
it	O
does	O
not	O
account	O
for	O
speaker	B
errors	B
in	O
the	O
non	O
-	O
speech	O
part	O
.	O
for	O
the	O
evalua-	O
tion	O
of	O
two	O
-	O
speaker	B
segmentation	I
task	O
,	O
speaker	B
error	B
rate	I
(	O
ser	O
)	O
is	O
computed	O
according	O
to	O
the	O
standard	O
nist	O
protocol	O
5	O
.	O
5	O
http://www.itl.nist.gov/iad/mig/tests/sre/2002/spkrsegeval-v07.pla	O
tutorial	O
on	O
evaluation	B
metrics	I
for	O
speaker	B
diarization	I
systems	I
9	O
3.6	O
jaccard	B
error	I
rate	O
in	O
addition	O
to	O
the	O
principal	O
metric	B
,	O
the	O
jer	O
is	O
based	O
on	O
the	O
jaccard	O
index	O
,	O
which	O
is	O
a	O
similarity	B
measure	O
used	O
to	O
evaluate	O
the	O
output	B
of	O
speaker	B
segmenta-	O
tion	O
.	O
jer	O
was	O
newly	O
introduced	O
in	O
the	O
second	O
dihard	O
diarization	B
challenge	B
as	O
another	O
evaluation	B
metric	B
along	O
with	O
der	O
(	O
ryant	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
the	O
jer	O
calculates	O
the	O
missed	O
speech	O
and	O
false	B
alarm	I
speech	O
for	O
each	O
individual	O
speaker	B
.	O
an	O
optimal	O
mapping	O
between	O
reference	B
speakers	O
and	O
system	O
output	B
speakers	O
is	O
determined	O
.	O
the	O
jaccard	O
index	O
is	O
computed	O
,	O
for	O
each	O
such	O
speaker	B
pairs	O
.	O
the	O
jer	O
is	O
deﬁned	O
as	O
1	O
minus	O
the	O
average	B
of	O
these	O
speaker	B
pair	O
scores	O
.	O
more	O
speciﬁcally	O
,	O
“	O
n	O
“	O
reference	B
speakers	O
and	O
“	O
m	O
“	O
system	O
speakers	O
are	O
as-	O
sumed	O
from	O
the	O
ground	B
truth	I
and	O
system	O
predicted	O
output	B
.	O
an	O
optimal	O
map-	O
ping	O
between	O
speakers	O
is	O
determined	O
using	O
the	O
hungarian	O
algorithm	O
7	O
(	O
jonker	O
and	O
volgenant	O
,	O
1986	O
)	O
so	O
that	O
each	O
reference	B
speaker	I
is	O
paired	O
with	O
at	O
most	O
one	O
system	B
speaker	I
and	O
each	O
system	B
speaker	I
with	O
at	O
most	O
one	O
reference	B
speaker	I
(	O
bell	O
and	O
dee	O
,	O
2016	O
)	O
.	O
then	O
,	O
for	O
each	O
reference	B
speaker	I
“	O
ref	O
“	O
the	O
speaker	B
-	O
speciﬁc	O
jaccard	B
error	I
rate	O
is	O
“	O
(	O
fa	O
+	O
miss)/total	O
“	O
,	O
where	O
“	O
total	O
“	O
denotes	O
the	O
duration	O
of	O
the	O
union	O
of	O
reference	B
and	O
system	B
speaker	I
segments	O
;	O
if	O
the	O
reference	B
speaker	I
was	O
not	O
paired	O
with	O
a	O
system	B
speaker	I
,	O
it	O
is	O
the	O
duration	O
of	O
all	O
reference	B
speaker	I
segments	O
-	O
“	O
fa	O
“	O
is	O
the	O
total	O
system	B
speaker	I
time	B
not	O
attributed	O
to	O
the	O
reference	B
speaker	I
;	O
if	O
the	O
reference	B
speaker	I
was	O
not	O
paired	O
with	O
a	O
system	B
speaker	I
,	O
it	O
is	O
0	O
-	O
“	O
miss	B
“	O
is	O
the	O
total	O
reference	B
speaker	I
time	B
not	O
attributed	O
to	O
the	O
system	B
speaker	I
;	O
if	O
the	O
reference	B
speaker	I
was	O
not	O
paired	O
with	O
a	O
system	B
speaker	I
,	O
it	O
is	O
equal	O
to	O
“	O
total“.the	O
jaccard	B
error	I
rate	O
is	O
the	O
average	B
of	O
the	O
speaker	B
-	O
speciﬁc	O
jaccard	B
error	I
rate	O
.	O
jer	O
and	O
der	O
are	O
highly	O
correlated	O
with	O
the	O
jer	O
typically	O
being	O
higher	O
,	O
especially	O
in	O
recordings	O
where	O
one	O
or	O
more	O
speakers	O
is	O
particularly	O
dominant	O
.	O
when	O
a	O
ith	O
speaker	B
from	O
reference	B
output	B
corresponds	O
to	O
the	O
jth	O
speaker	B
in	O
fa	O
+	O
miss	B
jer	O
=	O
i	O
i	O
.	O
(	O
2	O
)	O
i	O
union	O
of	O
ref	O
+	O
system	O
i	O
j	O
1	O
n	O
x	O
overall	O
=	O
jer	O
(	O
3	O
)	O
jer	O
n	O
i	O
i=1	O
here	O
n	O
refers	O
to	O
number	O
of	O
speakers	O
present	O
in	O
the	O
conversation	O
.	O
4	O
examples	O
demonstrating	O
the	O
computation	O
of	O
evaluation	B
metrics	I
in	O
this	O
section	O
,	O
we	O
demonstrate	O
with	O
examples	O
how	O
evaluation	B
metrics	I
are	O
computed	O
from	O
the	O
ground	B
-	O
truth	O
and	O
system	O
predicted	O
output	B
.	O
for	O
better	O
understanding	O
of	O
the	O
computation	O
process	B
,	O
we	O
show	O
each	O
intermediate	O
steps	B
.	O
we	O
considered	O
ﬁve	O
diﬀerent	O
examples	O
as	O
summarized	O
in	O
table	O
.	O
all	O
the	O
speech	O
recordings	O
are	O
nine	O
seconds	B
in	O
length.10	O
supratim	O
tribady	O
et	O
al	O
.	O
{	O
#	O
refspk	O
,	O
#	O
sysspk	O
}	O
example	O
1	O
{	O
1	O
,	O
1	O
}	O
example	O
2	O
{	O
2	O
,	O
2	O
}	O
example	O
3	O
{	O
4	O
,	O
4	O
}	O
example	O
4	O
{	O
4	O
,	O
3	O
}	O
example	O
5	O
{	O
3	O
,	O
4	O
}	O
table	O
2	O
summary	O
of	O
the	O
ﬁve	O
examples	O
for	O
the	O
computation	O
of	O
der	O
and	O
jer	O
.	O
here	O
refspk	O
denotes	O
the	O
number	O
speakers	O
in	O
reference	B
(	O
or	O
ground	B
-	O
truth	O
)	O
and	O
sys	O
denotes	O
the	O
number	O
spk	O
of	O
speakers	O
in	O
system	O
output	B
.	O
4.1	O
example	O
1	O
in	O
this	O
example	O
(	O
as	O
shown	O
in	O
fig	O
.	O
3	O
)	O
,	O
we	O
show	O
how	O
the	O
der	O
and	O
jer	O
are	O
com-	O
puted	O
for	O
single	B
speaker	I
in	O
both	O
ground	B
-	O
truth	O
and	O
system	O
predicted	O
output	B
.	O
0	O
sec	O
1	O
sec	O
2	O
sec	O
3	O
sec	O
4	O
sec	O
5	O
sec	O
6	O
sec	O
7	O
sec	O
8	O
sec	O
9	O
sec	O
ground	B
truth	I
a	O
a	O
a	O
a	O
a	O
a	O
system	O
output	B
p	O
p	O
p	O
p	O
speaker	B
error	O
false	B
alarm	I
p	O
p	O
missed	O
speech	O
p	O
p	O
p	O
p	O
fig	O
.	O
3	O
synthetic	O
ground	B
truth	I
and	O
system	O
predicted	O
labels	O
and	O
illustration	O
diﬀerent	O
types	O
of	O
error	O
for	O
example	O
1	O
.	O
the	O
green	O
boxes	O
indicate	O
the	O
reference	B
ground	B
truth	I
,	O
yellow	O
boxes	O
indicate	O
system	O
predicted	O
speaker	B
labels	I
and	O
cyan	O
boxes	O
indicates	O
speaker	B
error	O
,	O
false	B
alarm	I
and	O
missed	O
speech.a	O
tutorial	O
on	O
evaluation	B
metrics	I
for	O
speaker	B
diarization	I
systems	I
11	O
example	O
1	O
in	O
order	B
to	O
compute	O
the	O
der	O
,	O
we	O
ﬁrst	O
need	O
to	O
compute	O
the	O
three	O
basic	O
errors	B
:	O
speaker	B
error	O
,	O
false	B
alarm	I
and	O
missed	O
speech	O
as	O
shown	O
in	O
eq	O
.	O
1	O
.	O
in	O
this	O
case	O
,	O
we	O
have	O
no	O
speaker	B
error	O
as	O
the	O
single	B
speaker	I
in	O
ground-	O
truth	O
(	O
i.e.	O
,	O
speaker	B
a	O
)	O
is	O
paired	O
with	O
the	O
single	B
speaker	I
in	O
predicted	O
output	B
(	O
i.e.	O
,	O
speaker	B
p	O
)	O
.	O
we	O
observe	O
two	O
seconds	B
of	O
false	B
alarm	I
due	O
and	O
four	O
seconds	B
missed	O
speech	O
as	O
shown	O
in	O
fig	O
.	O
3	O
.	O
in	O
this	O
case	O
,	O
the	O
total	O
amount	B
of	O
speech	O
for	O
ground	B
-	O
truth	O
speaker	B
is	O
six	O
seconds	B
.	O
therefore	O
,	O
the	O
der	O
for	O
example	O
1	O
will	O
be	O
,	O
0	O
+	O
2	O
+	O
4	O
der	O
=	O
×	O
100	O
%	O
=	O
100	O
%	O
.	O
ex1	O
6	O
in	O
jer	O
computation	O
,	O
ﬁrst	O
speaker	B
correspondence	O
between	O
each	O
of	O
the	O
reference	B
speakers	O
and	O
system	O
output	B
is	O
computed	O
with	O
hungarian	O
al-	O
gorithm	O
.	O
then	O
we	O
compute	O
individual	O
jers	O
for	O
each	O
reference	B
speakers	O
as	O
shown	O
in	O
eq	O
.	O
3	O
.	O
finally	O
,	O
overall	O
jer	O
is	O
computed	O
by	O
taking	O
average	B
of	O
the	O
individual	O
jers	O
.	O
in	O
this	O
example	O
,	O
we	O
have	O
single	B
speaker	I
in	O
both	O
reference	B
and	O
system	O
output	B
.	O
therefore	O
,	O
the	O
overall	O
jer	O
is	O
computed	O
as	O
,	O
fa	O
+	O
miss	B
2	O
+	O
4	O
jer	O
=	O
jer	O
=	O
a	O
a	O
=	O
×	O
100	O
%	O
=	O
75	O
%	O
ex1	O
a	O
∪(a	O
,	O
p	O
)	O
812	O
supratim	O
tribady	O
et	O
al	O
.	O
4.2	O
example	O
2	O
in	O
fig	O
.	O
4	O
,	O
we	O
demonstrate	O
the	O
evaluation	B
metric	B
computation	O
for	O
two	O
speakers	O
in	O
both	O
ground	B
-	O
truth	O
and	O
system	O
predicted	O
output	B
in	O
a	O
recording	B
of	O
9	O
seconds	B
.	O
0	O
sec	O
1	O
sec	O
2	O
sec	O
3	O
sec	O
4	O
sec	O
5	O
sec	O
6	O
sec	O
7	O
sec	O
8	O
sec	O
9	O
sec	O
0	O
sec	O
1	O
sec	O
2	O
sec	O
3	O
sec	O
4	O
sec	O
5	O
sec	O
6	O
sec	O
7	O
sec	O
8	O
sec	O
a	O
a	O
a	O
a	O
a	O
a	O
ground	B
truth	I
b	O
b	O
b	O
b	O
b	O
b	O
p	O
p	O
p	O
p	O
p	O
p	O
system	O
output	B
q	O
q	O
q	O
q	O
q	O
speaker	B
error	O
p	O
false	B
alarm	I
q	O
p	O
missed	O
speech	O
q	O
q	O
fig	O
.	O
4	O
synthetic	O
ground	B
truth	I
and	O
system	O
predicted	O
labels	O
and	O
illustration	O
diﬀerent	O
types	O
of	O
error	O
for	O
example	O
2	O
.	O
the	O
green	O
boxes	O
indicate	O
the	O
reference	B
ground	B
truth	I
,	O
yellow	O
boxes	O
indicate	O
system	O
predicted	O
speaker	B
labels	I
and	O
cyan	O
boxes	O
indicates	O
speaker	B
error	O
,	O
false	B
alarm	I
and	O
missed	O
speech.a	O
tutorial	O
on	O
evaluation	B
metrics	I
for	O
speaker	B
diarization	I
systems	I
13	O
example	O
2	O
for	O
example	O
2	O
,	O
we	O
observe	O
two	O
seconds	B
of	O
false	B
alarm	I
,	O
two	O
seconds	B
of	O
missed	O
speech	O
,	O
and	O
no	O
speaker	B
error	O
as	O
shown	O
in	O
fig	O
.	O
4	O
.	O
we	O
also	O
compute	O
the	O
total	O
amount	B
of	O
speech	O
spoken	O
by	O
two	O
speakers	O
in	O
reference	B
is	O
12	O
seconds	B
.	O
therefore	O
,	O
we	O
can	O
compute	O
der	O
as	O
,	O
0	O
+	O
2	O
+	O
3	O
der	O
=	O
×	O
100	O
%	O
=	O
41.66	O
%	O
.	O
ex2	O
12	O
now	O
to	O
compute	O
the	O
jer	O
,	O
we	O
ﬁrst	O
need	O
to	O
ﬁnd	O
the	O
speaker	B
corre-	O
spondence	O
.	O
using	O
hungarian	O
algorithm	O
,	O
we	O
have	O
found	O
that	O
reference	B
speaker	I
a	O
pairs	O
with	O
system	O
predicted	O
speaker	B
p	O
and	O
reference	B
speaker	I
b	O
pairs	O
with	O
system	O
predicted	O
speaker	B
q.	O
then	O
,	O
we	O
can	O
compute	O
the	O
jers	O
of	O
individual	O
referene	O
speakers	O
as	O
,	O
fa	O
+	O
miss	B
1	O
+	O
1	O
jer	O
=	O
a	O
a	O
=	O
×	O
100	O
%	O
=	O
28.57	O
%	O
.	O
a	O
∪(a	O
,	O
p	O
)	O
7	O
fa	O
+	O
miss	B
2	O
+	O
1	O
jer	O
=	O
b	O
b	O
=	O
×	O
100	O
%	O
=	O
42.86	O
%	O
.	O
b	O
∪(b	O
,	O
q	O
)	O
7	O
therefore	O
,	O
the	O
overall	O
jer	O
will	O
be	O
,	O
1	O
h	O
i	O
jer	O
=	O
28.57	O
+	O
42.86	O
×	O
100	O
%	O
=	O
35.71	O
%	O
.	O
ex2	O
2	O
4.3	O
example	O
3	O
in	O
fig	O
.	O
5	O
,	O
we	O
demonstrate	O
the	O
evaluation	B
metric	B
computation	O
for	O
four	O
speakers	O
in	O
both	O
ground	B
-	O
truth	O
and	O
system	O
predicted	O
output	B
in	O
a	O
recording	B
of	O
9	O
seconds.14	O
supratim	O
tribady	O
et	O
al	O
.	O
0	O
sec	O
1	O
sec	O
2	O
sec	O
3	O
sec	O
4	O
sec	O
5	O
sec	O
6	O
sec	O
7	O
sec	O
8	O
sec	O
9	O
sec	O
a	O
a	O
a	O
a	O
b	O
b	O
ground	B
truth	I
c	O
c	O
d	O
p	O
system	O
output	B
q	O
q	O
q	O
r	O
r	O
s	O
s	O
s	O
q	O
speaker	B
error	O
r	O
s	O
r	O
false	B
alarm	I
s	O
p	O
missed	O
speech	O
r	O
fig	O
.	O
5	O
synthetic	O
ground	B
truth	I
and	O
system	O
predicted	O
labels	O
and	O
illustration	O
diﬀerent	O
types	O
of	O
error	O
for	O
example	O
3	O
.	O
the	O
green	O
boxes	O
indicate	O
the	O
reference	B
ground	B
truth	I
,	O
yellow	O
boxes	O
indicate	O
system	O
predicted	O
speaker	B
labels	I
and	O
cyan	O
boxes	O
indicates	O
speaker	B
error	O
,	O
false	B
alarm	I
and	O
missed	O
speech	O
.	O
example	O
3	O
for	O
example	O
3	O
,	O
we	O
observe	O
two	O
seconds	B
of	O
false	B
alarm	I
,	O
two	O
seconds	B
of	O
missed	O
speech	O
,	O
and	O
three	O
seconds	B
of	O
speaker	B
error	O
as	O
shown	O
in	O
fig	O
.	O
5	O
.	O
we	O
also	O
compute	O
the	O
total	O
amount	B
of	O
speech	O
spoken	O
by	O
four	O
speakers	O
in	O
reference	B
is	O
nine	O
seconds	B
.	O
therefore	O
,	O
we	O
can	O
compute	O
der	O
as	O
,	O
3	O
+	O
2	O
+	O
2	O
der	O
=	O
×	O
100	O
%	O
=	O
77.77	O
%	O
.	O
ex3	O
9	O
now	O
to	O
compute	O
the	O
jer	O
,	O
we	O
ﬁrst	O
need	O
to	O
ﬁnd	O
the	O
speaker	B
corre-	O
spondence	O
.	O
using	O
hungarian	O
algorithm	O
,	O
we	O
have	O
found	O
that	O
reference	B
speaker	I
a	O
pairs	O
with	O
system	O
predicted	O
speaker	B
p	O
,	O
reference	B
speaker	I
b	O
pairs	O
with	O
system	O
predicted	O
speaker	B
r	O
,	O
reference	B
speaker	I
c	O
pairs	O
with	O
system	O
predicted	O
speaker	B
q	O
and	O
reference	B
speaker	I
d	O
pairs	O
with	O
system	O
predicted	O
speaker	B
s.	O
then	O
,	O
we	O
can	O
compute	O
the	O
jers	O
of	O
individual	O
reference	B
speakers	O
as	O
,	O
fa	O
+	O
miss	B
3	O
+	O
0	O
3	O
jer	O
=	O
a	O
a	O
=	O
=	O
×	O
100	O
%	O
=	O
75.00	O
%	O
.	O
a	O
∪(a	O
,	O
p	O
)	O
4	O
4	O
fa	O
+	O
miss	B
2	O
+	O
2	O
4	O
jer	O
=	O
b	O
b	O
=	O
=	O
×	O
100	O
%	O
=	O
100.00	O
%	O
.	O
b	O
∪(b	O
,	O
q	O
)	O
4	O
4	O
fa	O
+	O
miss	B
0	O
+	O
1	O
1	O
jer	O
=	O
c	O
c	O
=	O
=	O
×	O
100	O
%	O
=	O
33.33	O
%	O
.	O
c	O
∪(c	O
,	O
r	O
)	O
3	O
3	O
fa	O
+	O
miss	B
0	O
+	O
2	O
2	O
jer	O
=	O
d	O
d	O
=	O
=	O
×	O
100	O
%	O
=	O
66.66	O
%	O
.	O
d	O
∪(d	O
,	O
s	O
)	O
3	O
3	O
therefore	O
,	O
the	O
overall	O
jer	O
will	O
be	O
,	O
1	O
jer	O
=	O
[	O
jer	O
+	O
jer	O
+	O
jer	O
+	O
jer	O
]	O
.	O
(	O
4	O
)	O
ex3	O
n	O
a	O
b	O
c	O
d	O
1	O
jer	O
=	O
[	O
75.00	O
+	O
100.00	O
+	O
33.33	O
+	O
66.66	O
]	O
×	O
100	O
%	O
=	O
68.74	O
%	O
..	O
ex3	O
4a	O
tutorial	O
on	O
evaluation	B
metrics	I
for	O
speaker	B
diarization	I
systems	I
15	O
0	O
sec	O
1	O
sec	O
2	O
sec	O
3	O
sec	O
4	O
sec	O
5	O
sec	O
6	O
sec	O
7	O
sec	O
8	O
sec	O
9	O
sec	O
a	O
a	O
a	O
a	O
ground	B
truth	I
cb	O
c	O
b	O
d	O
p	O
p	O
system	O
output	B
q	O
q	O
r	O
r	O
r	O
p	O
speaker	B
error	O
false	B
alarm	I
r	O
p	O
missed	O
speech	O
r	O
d	O
fig	O
.	O
6	O
synthetic	O
ground	B
truth	I
and	O
system	O
predicted	O
labels	O
and	O
illustration	O
diﬀerent	O
types	O
of	O
error	O
for	O
example	O
4	O
.	O
the	O
green	O
boxes	O
indicate	O
the	O
reference	B
ground	B
truth	I
,	O
yellow	O
boxes	O
indicate	O
system	O
predicted	O
speaker	B
labels	I
and	O
cyan	O
boxes	O
indicates	O
speaker	B
error	O
,	O
false	B
alarm	I
and	O
missed	O
speech	O
4.4	O
example	O
4	O
:	O
in	O
fig	O
.	O
6	O
,	O
we	O
demonstrate	O
the	O
evaluation	B
metric	B
computation	O
for	O
four	O
speakers	O
in	O
both	O
ground	B
-	O
truth	O
and	O
system	O
predicted	O
output	B
in	O
a	O
recording	B
of	O
9	O
seconds.16	O
supratim	O
tribady	O
et	O
al	O
.	O
example	O
4	O
in	O
example	O
4	O
,	O
we	O
observe	O
one	O
second	O
of	O
false	B
alarm	I
,	O
three	O
seconds	B
of	O
missed	O
speech	O
and	O
one	O
second	O
of	O
speaker	B
error	O
as	O
shown	O
in	O
fig	O
.	O
6	O
.	O
we	O
also	O
compute	O
the	O
total	O
amount	B
of	O
speech	O
spoken	O
by	O
four	O
speakers	O
in	O
reference	B
is	O
9	O
seconds	B
.	O
therefore	O
,	O
we	O
can	O
compute	O
the	O
der	O
as	O
,	O
3	O
+	O
1	O
+	O
1	O
der	O
=	O
×	O
100	O
%	O
=	O
55.56	O
%	O
.	O
ex4	O
9	O
now	O
to	O
compute	O
the	O
jers	O
,	O
we	O
ﬁrst	O
need	O
to	O
ﬁnd	O
the	O
speaker	B
corre-	O
spondence	O
.	O
using	O
hungarian	O
algorithm	O
,	O
we	O
have	O
found	O
that	O
reference	B
speaker	I
a	O
pairs	O
with	O
system	O
predicted	O
speaker	B
r	O
,	O
reference	B
speaker	I
b	O
pairs	O
with	O
system	O
predicted	O
speaker	B
p	O
,	O
reference	B
speaker	I
c	O
pairs	O
with	O
system	O
predicted	O
speaker	B
q.	O
then	O
,	O
we	O
can	O
compute	O
the	O
jers	O
of	O
indi-	O
vidual	O
reference	B
speakers	O
as	O
,	O
fa	O
+	O
miss	B
2	O
+	O
1	O
3	O
jer	O
=	O
a	O
a	O
=	O
=	O
×	O
100	O
%	O
=	O
60.00	O
%	O
.	O
a	O
∪(a	O
,	O
q	O
)	O
5	O
5	O
fa	O
+	O
miss	B
1	O
+	O
1	O
2	O
jer	O
=	O
b	O
b	O
=	O
=	O
×	O
100	O
%	O
=	O
66.667	O
%	O
.	O
b	O
∪(b	O
,	O
r	O
)	O
3	O
3	O
fa	O
+	O
miss	B
0	O
+	O
0	O
0	O
jer	O
=	O
c	O
c	O
=	O
=	O
×	O
100	O
%	O
=	O
0.00	O
%	O
.	O
c	O
∪(c	O
,	O
p	O
)	O
5	O
5	O
fa	O
+	O
miss	B
0	O
+	O
1	O
1	O
jer	O
=	O
d	O
d	O
=	O
=	O
×	O
100	O
%	O
=	O
100.00	O
%	O
.	O
d	O
∪(d	O
,	O
d	O
)	O
1	O
1	O
so	O
,	O
the	O
overall	O
jer	O
will	O
be	O
,	O
1	O
jer	O
=	O
[	O
jer	O
+	O
jer	O
+	O
jer	O
+	O
jer	O
]	O
.	O
(	O
5	O
)	O
ex4	O
n	O
a	O
b	O
c	O
d	O
1	O
jer	O
=	O
[	O
60.00	O
+	O
66.667	O
+	O
0.00	O
+	O
100.00	O
]	O
×	O
100	O
%	O
=	O
56.67	O
%	O
..	O
ex4	O
4	O
4.5	O
example	O
5	O
:	O
in	O
fig	O
.	O
7	O
,	O
we	O
demonstrate	O
the	O
evaluation	B
metric	B
computation	O
for	O
four	O
speakers	O
in	O
both	O
ground	B
-	O
truth	O
and	O
system	O
predicted	O
output	B
in	O
a	O
recording	B
of	O
8	O
seconds.a	O
tutorial	O
on	O
evaluation	B
metrics	I
for	O
speaker	B
diarization	I
systems	I
17	O
0	O
sec	O
1	O
sec	O
2	O
sec	O
3	O
sec	O
4	O
sec	O
5	O
sec	O
6	O
sec	O
7	O
sec	O
8	O
sec	O
0	O
sec	O
1	O
sec	O
2	O
sec	O
3	O
sec	O
4	O
sec	O
5	O
sec	O
6	O
sec	O
7	O
sec	O
8	O
sec	O
a	O
a	O
a	O
ground	B
truth	I
b	O
c	O
c	O
p	O
p	O
q	O
q	O
q	O
system	O
output	B
r	O
s	O
p	O
q	O
speaker	B
error	O
false	B
alarm	I
r	O
s	O
s	O
missed	O
speech	O
fig	O
.	O
7	O
synthetic	O
ground	B
truth	I
and	O
system	O
predicted	O
labels	O
and	O
illustration	O
diﬀerent	O
types	O
of	O
error	O
for	O
example	O
5	O
.	O
the	O
green	O
boxes	O
indicate	O
the	O
reference	B
ground	B
truth	I
,	O
yellow	O
boxes	O
indicate	O
system	O
predicted	O
speaker	B
labels	I
and	O
cyan	O
boxes	O
indicates	O
speaker	B
error	O
,	O
false	B
alarm	I
and	O
missed	O
speech	O
example	O
5	O
in	O
example	O
5	O
,	O
we	O
observe	O
one	O
second	O
of	O
false	B
alarm	I
,	O
two	O
seconds	B
of	O
missed	O
speech	O
and	O
two	O
seconds	B
of	O
speaker	B
error	O
as	O
shown	O
in	O
fig	O
.	O
6	O
.	O
we	O
also	O
compute	O
the	O
total	O
amount	B
of	O
speech	O
spoken	O
by	O
four	O
speakers	O
in	O
reference	B
is	O
6	O
seconds	B
.	O
therefore	O
,	O
we	O
can	O
compute	O
the	O
der	O
as	O
,	O
2	O
+	O
2	O
+	O
1	O
der	O
=	O
×	O
100	O
%	O
=	O
83.33	O
%	O
.	O
ex5	O
6	O
now	O
to	O
compute	O
the	O
jers	O
,	O
we	O
ﬁrst	O
need	O
to	O
ﬁnd	O
the	O
speaker	B
corre-	O
spondence	O
.	O
using	O
hungarian	O
algorithm	O
,	O
we	O
have	O
found	O
that	O
reference	B
speaker	I
a	O
pairs	O
with	O
system	O
predicted	O
speaker	B
q	O
,	O
reference	B
speaker	I
b	O
pairs	O
with	O
system	O
predicted	O
speaker	B
s	O
and	O
reference	B
speaker	I
c	O
pairs	O
with	O
system	O
predicted	O
speaker	B
p.	O
then	O
,	O
we	O
can	O
compute	O
the	O
jers	O
of	O
individual	O
reference	B
speakers	O
as	O
,	O
fa	O
+	O
miss	B
1	O
+	O
1	O
2	O
jer	O
=	O
a	O
a	O
=	O
=	O
×	O
100	O
%	O
=	O
50.00	O
%	O
.	O
a	O
∪(a	O
,	O
r	O
)	O
4	O
4	O
fa	O
+	O
miss	B
1	O
+	O
3	O
4	O
jer	O
=	O
b	O
b	O
=	O
=	O
×	O
100	O
%	O
=	O
100.00	O
%	O
.	O
b	O
∪(b	O
,	O
q	O
)	O
4	O
4	O
fa	O
+	O
miss	B
1	O
+	O
1	O
2	O
jer	O
=	O
c	O
c	O
=	O
=	O
×	O
100	O
%	O
=	O
67.66	O
%	O
.	O
c	O
∪(c	O
,	O
p	O
)	O
3	O
3	O
here	O
,	O
speaker	B
d	O
is	O
only	O
present	O
in	O
the	O
system	O
generated	O
speaker	B
labels	I
.	O
so	O
,	O
it	O
will	O
not	O
be	O
considered	O
for	O
calculation	O
of	O
jer	O
in	O
case	O
of	O
speaker	B
d.	O
so	O
,	O
the	O
overall	O
jer	O
will	O
be	O
,	O
1	O
jer	O
=	O
[	O
jer	O
+	O
jer	O
+	O
jer	O
]	O
.	O
(	O
6	O
)	O
ex5	O
n	O
a	O
b	O
c	O
1	O
jer	O
=	O
[	O
50.00	O
+	O
100.00	O
+	O
67.66	O
]	O
×	O
100	O
%	O
=	O
72.22	O
%	O
..	O
ex5	O
418	O
supratim	O
tribady	O
et	O
al	O
.	O
5	O
limitations	O
of	O
the	O
existing	O
evaluation	B
metrics	I
der	O
and	O
jer	O
one	O
of	O
the	O
current	O
existing	O
evaluation	B
metrics	I
in	O
the	O
ﬁeld	O
of	O
sd	O
.	O
there	O
are	O
various	O
drawbacks	O
of	O
the	O
existing	O
evaluation	B
metrics	I
.	O
according	O
to	O
the	O
formulae	O
of	O
the	O
der	O
,	O
the	O
denominator	O
part	O
”	O
total	O
”	O
is	O
the	O
duration	O
of	O
all	O
reference	B
speaker	I
segments	O
,	O
but	O
it	O
does	O
not	O
include	O
the	O
system	O
-	O
speaker	B
segments	I
for	O
calculation	O
of	O
the	O
error	B
rate	I
.	O
if	O
there	O
is	O
a	O
data	B
imbalance	O
of	O
two	O
or	O
more	O
speakers	O
in	O
terms	B
of	O
duration	O
of	O
the	O
active	O
speaker	B
in	O
a	O
conversation	O
in	O
reference	B
speaker	I
level	B
,	O
then	O
irrespective	O
of	O
the	O
system	O
-	O
generated	O
speaker	B
levels	O
it	O
will	O
produce	O
a	O
good	O
result	O
which	O
in	O
turn	O
will	O
give	O
less	O
der	O
,	O
which	O
is	O
not	O
correct	O
will	O
respect	O
to	O
the	O
ground	B
scenario	O
.	O
der	O
has	O
no	O
upper	O
limit	O
,	O
as	O
it	O
can	O
exceed	O
100	O
%	O
.	O
after	O
that	O
jer	O
was	O
introduced	O
in	O
the	O
dihard	O
ii	O
challenge	B
,	O
2019	O
which	O
also	O
has	O
some	O
drawbacks	O
.	O
the	O
drawback	O
for	O
upperlimit	O
in	O
der	O
is	O
solved	O
in	O
the	O
jer	O
,	O
as	O
it	O
can	O
not	O
exceed	O
more	O
than	O
100	O
%	O
.	O
the	O
jer	O
is	O
used	O
to	O
calculate	O
the	O
error	B
rate	I
from	O
the	O
weighted	O
average	B
of	O
each	O
individual	O
speaker	B
present	O
in	O
a	O
conversation	O
.	O
it	O
performs	O
speaker	B
correspondence	O
using	O
the	O
hungarian	O
algorithm	O
.	O
but	O
from	O
our	O
experiments	O
,	O
we	O
see	O
that	O
these	O
speaker	B
correspondence	O
does	O
not	O
reﬂect	O
actual	O
speaker	B
mapping	O
for	O
the	O
calculation	O
of	O
jer	O
during	O
the	O
overlapping	B
of	O
more	O
than	O
two	O
active	O
speakers	O
.	O
der	O
and	O
jer	O
gives	O
the	O
overall	O
error	B
rate	I
of	O
an	O
audio	O
ﬁle	O
,	O
but	O
it	O
does	O
not	O
provide	O
the	O
error	B
rate	I
of	O
each	O
segment	B
-	O
wise	O
speaker	B
boundaries	B
of	O
each	O
speaker	B
,	O
which	O
might	O
be	O
helpful	O
to	O
analyse	O
and	O
reduce	O
the	O
overall	O
der	O
and	O
jer	O
of	O
the	O
entire	O
audio	O
ﬁle	O
.	O
systems	O
which	O
do	O
not	O
consider	O
overlapping	B
will	O
always	O
acknowledge	O
the	O
considerable	O
amount	B
of	O
error	O
.	O
ignoring	O
the	O
overlappings	O
decreases	O
overall	O
jaccard	B
error	I
rate	O
,	O
but	O
it	O
does	O
not	O
portray	O
the	O
actual	O
scenario	O
of	O
the	O
number	O
of	O
speakers	O
present	O
in	O
the	O
conversation	O
,	O
and	O
the	O
actual	O
identity	O
of	O
the	O
speaker	B
error	O
,	O
false	B
alarm	I
and	O
missed	O
speech	O
.	O
in	O
case	O
of	O
synthetically	O
prepared	O
data	B
from	O
fig	O
.	O
5	O
,	O
there	O
is	O
an	O
overlapping	B
of	O
speaker	B
b	O
and	O
speaker	B
c	O
and	O
in	O
the	O
system	O
output	B
only	O
speaker	B
q	O
is	O
present	O
,	O
but	O
the	O
system	O
considered	O
it	O
as	O
speaker	B
r	O
instead	O
of	O
speaker	B
q.	O
so	O
,	O
to	O
get	O
the	O
minimum	O
jer	O
,	O
the	O
system	O
is	O
considering	O
speaker	B
r	O
instead	O
of	O
speaker	B
q.	O
the	O
main	O
challenge	B
of	O
implementing	O
the	O
metric	B
is	O
establishing	O
the	O
mapping	O
between	O
reference	B
speaker	I
i	O
d	O
and	O
system	O
-	O
generated	O
speaker	B
i	O
d	O
.	O
these	O
are	O
the	O
major	O
limitations	O
of	O
the	O
der	O
and	O
jer	O
.	O
6	O
proposal	O
for	O
new	O
evaluation	B
metrics	I
one	O
of	O
the	O
new	O
ﬁndings	O
from	O
our	O
experiments	O
is	O
the	O
importance	O
of	O
using	O
a	O
correct	O
evaluation	B
metric	B
for	O
sd	O
system	O
.	O
the	O
existing	O
evaluation	B
metrics	I
or	O
the	O
evaluation	B
tools	O
are	O
reaching	O
the	O
limits	O
under	O
certain	O
conditions	O
,	O
so	O
there	O
is	O
a	O
need	O
to	O
build	O
and	O
generalize	O
new	O
metric	B
for	O
evaluation	B
and	O
rebuild	O
it	O
based	O
on	O
their	O
application	B
to	O
make	O
them	O
usable	O
under	O
the	O
new	O
challenges	B
and	O
conditions	O
along	O
with	O
making	O
it	O
comparable	O
with	O
the	O
previous	O
results	B
.	O
though	O
,	O
it	O
is	O
very	O
diﬃcult	O
to	O
deﬁne	O
a	O
precise	O
point	O
in	O
time	B
boundaries	B
about	O
when	O
a	O
speaker	B
starts	O
or	O
stop	O
,	O
especially	O
when	O
overlapping	B
speech	I
is	O
present	O
,	O
it	O
is	O
better	O
to	O
build	O
a	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
evaluation	B
metric	B
which	O
will	O
detect	O
a	O
proper	O
errora	O
tutorial	O
on	O
evaluation	B
metrics	I
for	O
speaker	B
diarization	I
systems	I
19	O
during	O
the	O
speaker	B
overlappings	O
.	O
a	O
new	O
evaluation	B
metrics	I
should	O
be	O
developed	O
to	O
give	O
segment	B
-	O
wise	O
errors	B
between	O
speaker	B
labels	I
of	O
reference	B
ground	B
truth	I
and	O
system	O
-	O
generated	O
speaker	B
labels	I
thereby	O
properly	O
detecting	O
speaker	B
errors	B
.	O
the	O
evaluation	B
metric	B
should	O
also	O
detect	O
errors	B
during	O
speaker	B
overlappings	O
,	O
such	O
as	O
speaker	B
error	O
,	O
missed	O
speech	O
and	O
false	B
alarm	I
and	O
denoting	O
it	O
for	O
the	O
respective	O
speakers	O
.	O
the	O
new	O
evaluation	B
metrics	I
should	O
calculate	O
the	O
der	O
and	O
jer	O
with	O
respect	O
to	O
the	O
system	O
generated	O
speaker	B
labels	I
irrespective	O
of	O
calculating	O
it	O
concerning	O
to	O
generate	O
optimum	O
der	O
and	O
jer	O
.	O
7	O
conclusions	O
following	O
on	O
from	O
the	O
previous	O
study	O
,	O
we	O
draw	O
diﬀerent	O
conclusions	O
on	O
the	O
evaluation	B
metrics	I
for	O
sd	O
system	O
.	O
due	O
to	O
the	O
increased	O
used	O
of	O
online	O
meetings	O
,	O
and	O
smart	O
speakers	O
,	O
sd	O
has	O
become	O
very	O
important	O
.	O
the	O
der	O
and	O
jer	O
is	O
still	O
a	O
relevant	O
evaluation	B
metric	B
used	O
to	O
measure	O
the	O
standard	O
of	O
a	O
diarization	B
system	O
,	O
with	O
much	O
more	O
composite	O
setup	B
including	O
:	O
–	O
cross	O
-	O
show	O
diarization	B
,	O
where	O
re	O
-	O
occurring	O
speakers	O
in	O
multiple	O
shows	O
have	O
to	O
be	O
acknowledged	O
.	O
–	O
speaker	B
overlappings	O
,	O
where	O
multiple	O
speakers	O
speak	O
concurrently	O
.	O
more	O
eminently	O
,	O
we	O
described	O
the	O
implementation	O
method	B
along	O
with	O
the	O
al-	O
gorithms	O
to	O
ensure	O
a	O
better	O
understanding	O
of	O
the	O
evaluation	B
metric	B
.	O
these	O
evaluation	B
metrics	I
serve	O
as	O
an	O
important	O
parameter	O
for	O
checking	O
the	O
overall	O
performance	O
of	O
the	O
system	O
.	O
appendix	O
a	O
:	O
speaker	B
correspondence	O
hungarian	O
algorithm	O
:	O
the	O
hungarian	O
method	B
is	O
a	O
combinational	O
optimization	O
algorithm	O
that	O
solves	O
the	O
speaker	B
correspondence	O
assignment	O
issue	O
.	O
in	O
this	O
section	O
,	O
we	O
explore	O
the	O
working	O
of	O
the	O
hungarian	O
algorithm	O
which	O
is	O
used	O
to	O
compute	O
the	O
best	O
matches	O
between	O
ground	B
-	O
truth	O
speaker	B
sequence	B
and	O
system	O
output	B
sequence	B
of	O
speakers	O
.	O
here	O
,	O
we	O
will	O
demonstrate	O
the	O
calculation	O
of	O
jer	O
for	O
speaker	B
correspondence	O
with	O
the	O
help	O
of	O
hungarian	O
algorithm	O
for	O
example	O
3	O
in	O
the	O
fig	O
.	O
5	O
.	O
the	O
jer	O
is	O
calculated	O
for	O
all	O
possible	O
cases	O
or	O
conditions	O
.	O
in	O
our	O
case	O
,	O
we	O
calculate	O
for	O
all	O
possible	O
combinations	O
thereby	O
mapping	O
from	O
one	O
speaker	B
in	O
reference	B
speaker	I
sequence	B
to	O
another	O
speaker	B
in	O
system	O
-	O
speaker	B
sequence	B
.	O
after	O
calculating	O
the	O
jer	O
,	O
we	O
put	O
the	O
values	B
in	O
the	O
matrix	O
corresponding	O
to	O
the	O
speaker	B
levels	O
and	O
then	O
we	O
go	O
for	O
the	O
calculation	O
of	O
the	O
optimal	O
value	O
of	O
jer	O
.	O
in	O
example	O
3	O
,	O
there	O
are	O
four	O
speakers	O
in	O
the	O
ground	B
-	O
truth	O
(	O
i.e.	O
,	O
speaker	B
a	O
,	O
speaker	B
b	O
,	O
speaker	B
c	O
and	O
speaker	B
d	O
)	O
and	O
four	O
system	B
speaker	I
output	B
(	O
i.e.	O
speaker	B
p	O
,	O
speaker	B
q	O
,	O
speaker	B
r	O
,	O
and	O
speaker	B
s	O
)	O
.	O
so	O
,	O
using	O
the	O
hungarian	O
algorithmwe	O
will	O
explain	O
the	O
speaker	B
correspondence	O
in	O
case	O
of	O
jer	O
calcula-	O
tion	O
.	O
the	O
matrix	O
below	O
shows	O
the	O
cost	B
of	O
assigning	O
a	O
speaker	B
from	O
reference20	O
supratim	O
tribady	O
et	O
al	O
.	O
reference	B
speaker	I
sequence	B
speaker	B
a	O
speaker	B
b	O
speaker	B
c	O
speaker	B
d	O
system	B
speaker	I
sequence	B
speaker	B
p	O
speaker	B
q	O
speaker	B
r	O
speaker	B
s	O
speaker	B
level	B
to	O
a	O
speaker	B
in	O
the	O
system	B
speaker	I
level	B
.	O
the	O
main	O
objective	O
is	O
to	O
minimize	O
the	O
total	O
jer	O
in	O
the	O
system	O
.	O
speaker	B
p	O
q	O
r	O
s	O
a	O
0.750	O
0.833	O
0.800	O
1.000	O
b	O
1.000	O
0.750	O
1.000	O
0.750	O
c	O
1.000	O
0.330	O
0.660	O
1.000	O
d	O
1.000	O
1.000	O
1.000	O
0.660	O
step	O
1	O
:	O
substraction	O
of	O
row	O
minima	O
from	O
each	O
row	O
.	O
speaker	B
p	O
q	O
r	O
s	O
a	O
0.000	O
0.083	O
0.050	O
0.250	O
b	O
0.250	O
0.000	O
0.250	O
0.000	O
c	O
0.670	O
0.000	O
0.330	O
0.670	O
d	O
0.340	O
0.340	O
0.340	O
0.000	O
step	O
2	O
:	O
substraction	O
of	O
column	O
minima	O
from	O
each	O
column	O
speaker	B
p	O
q	O
r	O
s	O
a	O
0.000	O
0.083	O
0.000	O
0.250	O
b	O
0.250	O
0.000	O
0.2000	O
0.000	O
c	O
0.670	O
0.000	O
0.280	O
0.670	O
d	O
0.340	O
0.340	O
0.290	O
0.000	O
step	O
3	O
:	O
covering	O
all	O
the	O
zero	O
rows	O
and	O
columns	O
with	O
minimum	O
number	O
of	O
lines	O
.	O
speaker	B
p	O
q	O
r	O
s	O
a	O
0.000	O
0.083	O
0.000	O
0.250	O
b	O
0.250	O
0.000	O
0.200	O
0.000	O
c	O
0.670	O
0.000	O
0.280	O
0.670	O
d	O
0.340	O
0.340	O
0.290	O
0.000	O
step	O
4	O
:	O
creating	O
additional	O
zeros	O
in	O
the	O
matrix	O
.	O
for	O
example	O
,	O
we	O
ﬁnd	O
the	O
smallest	O
number	O
from	O
all	O
uncovered	O
rows	O
and	O
columns	O
and	O
substract	O
it	O
from	O
all	O
uncovered	O
elements	O
and	O
add	O
it	O
to	O
all	O
elements	O
that	O
are	O
covered	O
by	O
boxes	O
twice.a	O
tutorial	O
on	O
evaluation	B
metrics	I
for	O
speaker	B
diarization	I
systems	I
21	O
speaker	B
p	O
q	O
r	O
s	O
a	O
0.000	O
0.283	O
0.000	O
0.450	O
b	O
0.050	O
0.000	O
0.000	O
0.000	O
c	O
0.470	O
0.000	O
0.080	O
0.670	O
d	O
0.140	O
0.340	O
0.090	O
0.000	O
now	O
in	O
order	B
to	O
cover	O
all	O
the	O
minimum	O
number	O
of	O
zero	O
rows	O
and	O
columns	O
,	O
we	O
return	O
to	O
step	O
3	O
.	O
step	O
3	O
:	O
again	O
,	O
covering	O
all	O
the	O
rows	O
and	O
columns	O
with	O
minimum	O
number	O
of	O
zeros	O
.	O
speaker	B
p	O
q	O
r	O
s	O
a	O
0.000	O
0.283	O
0.000	O
0.480	O
b	O
0.050	O
0.000	O
0.000	O
0.000	O
c	O
0.470	O
0.000	O
0.080	O
0.670	O
d	O
0.140	O
0.340	O
0.090	O
0.000	O
now	O
in	O
order	B
to	O
cover	O
all	O
the	O
minimum	O
number	O
of	O
zero	O
rows	O
and	O
columns	O
,	O
we	O
return	O
to	O
step	O
3	O
.	O
step	O
5	O
:	O
therefore	O
,	O
the	O
zeros	O
in	O
each	O
row	O
shows	O
optimal	O
assignment	O
.	O
speaker	B
p	O
q	O
r	O
s	O
a	O
0.000	O
0.283	O
0.000	O
0.450	O
b	O
0.050	O
0.000	O
0.000	O
0.000	O
c	O
0.470	O
0.000	O
0.080	O
0.670	O
d	O
0.140	O
0.340	O
0.090	O
0.000	O
step	O
6	O
:	O
now	O
,	O
corresponding	O
to	O
the	O
optimal	O
matrix	O
for	O
cost	B
function	O
.	O
speaker	B
p	O
q	O
r	O
s	O
a	O
0.750	O
0.833	O
0.800	O
1.000	O
b	O
1.000	O
0.750	O
1.000	O
0.750	O
c	O
1.000	O
0.330	O
0.660	O
1.000	O
d	O
1.000	O
1.000	O
1.000	O
0.660	O
hence	O
,	O
the	O
optimal	O
jaccard	B
error	I
rate	O
value	O
will	O
be	O
:	O
1	O
jer	O
=	O
[	O
0.750	O
+	O
1.000	O
+	O
0.330	O
+	O
0.660	O
]	O
×	O
100	O
%	O
=	O
68.73	O
%	O
.	O
min	O
4	O
(	O
7	O
)	O
hence	O
,	O
using	O
hungarian	O
algorithm	O
we	O
found	O
the	O
speaker	B
correspondence	O
between	O
reference	B
speaker	I
sequence	B
and	O
system	O
-	O
speaker	B
sequence	B
.	O
speaker	B
a	O
→speaker	O
p	O
speaker	B
b	O
→speaker	O
r	O
speaker	B
c	O
→speaker	O
q	O
speaker	B
d	O
→speaker	O
s22	O
supratim	O
tribady	O
et	O
al	O
.	O
references	B
x.	O
anguera	O
,	O
c.	O
woofers	O
,	O
j.	O
hernando	O
,	O
speaker	B
diarization	I
for	O
multi	O
-	O
party	O
meetings	O
using	O
acoustic	O
fusion	O
,	O
in	O
ieee	O
workshop	O
on	O
automatic	O
speech	B
recognition	I
and	O
understanding	O
,	O
2005	O
.	O
,	O
ieee	O
,	O
2005	O
,	O
pp	O
.	O
426–431	O
.	O
ieee	O
x.	O
anguera	O
,	O
s.	O
bozonnet	O
,	O
n.	O
evans	O
,	O
c.	O
fredouille	O
,	O
g.	O
friedland	O
,	O
o.	O
vinyals	O
,	O
speaker	B
diarization	I
:	O
a	O
review	O
of	O
recent	O
research	B
.	O
ieee	O
transactions	O
on	O
au-	O
dio	O
,	O
speech	O
,	O
and	O
language	B
processing	I
20(2	O
)	O
,	O
356–370	O
(	O
2012	O
)	O
h.	O
aronowitz	O
,	O
unsupervised	O
compensation	O
of	O
intra	O
-	O
session	O
intra	O
-	O
speaker	B
variability	O
for	O
speaker	B
diarization	I
.	O
,	O
in	O
odyssey	O
,	O
2010	O
,	O
p.	O
25	O
j.	O
bell	O
,	O
h.m	O
.	O
dee	O
,	O
the	O
subset	O
-	O
matched	O
jaccard	O
index	O
for	O
evaluation	B
of	O
seg-	O
mentation	O
for	O
plant	O
images	O
.	O
arxiv	O
preprint	O
arxiv:1611.06880	O
(	O
2016	O
)	O
f.	O
bentley	O
,	O
c.	O
luvogt	O
,	O
m.	O
silverman	O
,	O
r.	O
wirasinghe	O
,	O
b.	O
white	O
,	O
d.	O
lottridge	O
,	O
understanding	O
the	O
long	O
-	O
term	O
use	O
of	O
smart	O
speaker	B
assistants	O
.	O
proceedings	O
of	O
the	O
acm	O
on	O
interactive	O
,	O
mobile	O
,	O
wearable	O
and	O
ubiquitous	O
technologies	O
2(3	O
)	O
,	O
1–24	O
(	O
2018	O
)	O
m.	O
cettolo	O
,	O
segmentation	B
,	O
classiﬁcation	O
and	O
clustering	B
of	O
an	O
italian	O
broadcast	O
news	O
corpus	B
,	O
in	O
proc	O
.	O
of	O
riao	O
,	O
citeseer	O
,	O
2000	O
.	O
citeseer	O
p.	O
cyrta	O
,	O
t.	O
trzcin´ski	O
,	O
w.	O
stokowiec	O
,	O
speaker	B
diarization	I
using	O
deep	O
recur-	O
rent	O
convolutional	O
neural	B
networks	I
for	O
speaker	B
embeddings	I
,	O
in	O
international	O
conference	O
on	O
information	B
systems	O
architecture	B
and	O
technology	O
,	O
springer	O
,	O
2017	O
,	O
pp	O
.	O
107–117	O
.	O
springer	O
t.t	O
.	O
elvins	O
,	O
r.t	O
.	O
fassett	O
,	O
p.	O
shinn	O
,	O
system	O
and	O
method	B
for	O
gathering	O
,	O
person-	O
alized	O
rendering	O
,	O
and	O
secure	O
telephonic	O
transmission	O
of	O
audio	O
data	B
(	O
google	O
patents	O
,	O
2003	O
)	O
.	O
us	O
patent	O
6,529,586	O
o.	O
galibert	O
,	O
methodologies	O
for	O
the	O
evaluation	B
of	O
speaker	B
diarization	I
and	O
auto-	O
matic	O
speech	B
recognition	I
in	O
the	O
presence	B
of	O
overlapping	B
speech	I
.	O
,	O
in	O
inter-	O
speech	O
,	O
2013	O
,	O
pp	O
.	O
1131–1134	O
k.w	O
.	O
gamage	O
,	O
v.	O
sethu	O
,	O
e.	O
ambikairajah	O
,	O
salience	O
based	O
lexical	O
features	O
for	O
emotion	O
recognition	O
,	O
in	O
2017	O
ieee	O
international	O
conference	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
(	O
icassp	O
)	O
,	O
ieee	O
,	O
2017	O
,	O
pp	O
.	O
5830–5834	O
.	O
ieee	O
j.-l	O
.	O
gauvain	O
,	O
l.f	O
.	O
lamel	O
,	O
g.	O
adda	O
,	O
partitioning	O
and	O
transcription	B
of	O
broad-	O
cast	O
news	O
data	B
,	O
in	O
fifth	O
international	O
conference	O
on	O
spoken	B
language	I
pro-	O
cessing	O
,	O
1998	O
i.	O
himawan	O
,	O
m.h	O
.	O
rahman	O
,	O
s.	O
sridharan	O
,	O
c.	O
fookes	O
,	O
a.	O
kanagasundaram	O
,	O
in-	O
vestigating	O
deep	O
neural	B
networks	I
for	O
speaker	B
diarization	I
in	O
the	O
dihard	O
chal-	O
lenge	O
,	O
in	O
2018	O
ieee	O
spoken	B
language	I
technology	O
workshop	O
(	O
slt	O
)	O
,	O
ieee	O
,	O
2018	O
,	O
pp	O
.	O
1029–1035	O
.	O
ieee	O
r.	O
jonker	O
,	O
t.	O
volgenant	O
,	O
improving	O
the	O
hungarian	O
assignment	O
algorithm	O
.	O
op-	O
erations	O
research	B
letters	O
5(4	O
)	O
,	O
171–175	O
(	O
1986	O
)	O
jyh	O
-	O
min	O
cheng	O
,	O
hsiao	O
-	O
chuan	O
wang	O
,	O
a	O
method	B
of	O
estimating	O
the	O
equal	O
error	B
rate	I
for	O
automatic	O
speaker	B
veriﬁcation	O
,	O
in	O
2004	O
international	O
symposium	O
on	O
chinese	O
spoken	B
language	I
processing	B
,	O
2004	O
,	O
pp	O
.	O
285–288	O
t.	O
kinnunen	O
,	O
h.	O
delgado	O
,	O
n.	O
evans	O
,	O
k.a	O
.	O
lee	O
,	O
v.	O
vestman	O
,	O
a.	O
nautsch	O
,	O
m.	O
todisco	O
,	O
x.	O
wang	O
,	O
m.	O
sahidullah	O
,	O
j.	O
yamagishi	O
,	O
et	O
al	O
.	O
,	O
tandem	O
assessment	O
of	O
spooﬁng	O
countermeasures	O
and	O
automatic	O
speaker	B
veriﬁcation	O
:	O
fundamen	O
-	O
a	O
tutorial	O
on	O
evaluation	B
metrics	I
for	O
speaker	B
diarization	I
systems	I
23	O
tals	O
.	O
ieee	O
/	O
acm	O
transactions	O
on	O
audio	O
,	O
speech	O
,	O
and	O
language	B
processing	I
(	O
2020	O
)	O
q.	O
kong	O
,	O
y.	O
xu	O
,	O
i.	O
sobieraj	O
,	O
w.	O
wang	O
,	O
m.d	O
.	O
plumbley	O
,	O
sound	O
event	O
detection	B
and	O
time	B
–	O
frequency	B
segmentation	B
from	O
weakly	O
labelled	O
data	B
.	O
ieee	O
/	O
acm	O
transactions	O
on	O
audio	O
,	O
speech	O
,	O
and	O
language	B
processing	I
27(4	O
)	O
,	O
777–787	O
(	O
2019	O
)	O
a.	O
mieczakowski	O
,	O
j.	O
goodman	O
-	O
deane	O
,	O
j.	O
patmore	O
,	O
j.	O
clarkson	O
,	O
conversations	O
,	O
conferencing	O
and	O
collaboration	O
m.h	O
.	O
moattar	O
,	O
m.m	O
.	O
homayounpour	O
,	O
a	O
simple	O
but	O
eﬃcient	O
real	O
-	O
time	B
voice	O
activity	B
detection	I
algorithm	O
,	O
in	O
2009	O
17th	O
european	O
signal	B
processing	I
con-	O
ference	O
,	O
ieee	O
,	O
2009	O
,	O
pp	O
.	O
2549–2553	O
.	O
ieee	O
n.	O
ryant	O
,	O
k.	O
church	O
,	O
c.	O
cieri	O
,	O
a.	O
cristia	O
,	O
j.	O
du	O
,	O
s.	O
ganapathy	O
,	O
m.	O
liberman	O
,	O
first	O
dihard	B
challenge	I
evaluation	B
plan	I
.	O
2018	O
,	O
tech	O
.	O
rep	O
.	O
(	O
2018	O
)	O
n.	O
ryant	O
,	O
k.	O
church	O
,	O
c.	O
cieri	O
,	O
a.	O
cristia	O
,	O
j.	O
du	O
,	O
s.	O
ganapathy	O
,	O
m.	O
liberman	O
,	O
the	O
second	O
dihard	O
diarization	B
challenge	B
:	O
dataset	O
,	O
task	O
,	O
and	O
baselines	O
.	O
arxiv	O
preprint	O
arxiv:1906.07839	O
(	O
2019	O
)	O
g.	O
sell	O
,	O
d.	O
garcia	O
-	O
romero	O
,	O
speaker	B
diarization	I
with	O
plda	B
i	O
-	O
vector	O
scoring	O
and	O
unsupervised	O
calibration	O
,	O
in	O
2014	O
ieee	O
spoken	B
language	I
technology	O
workshop	O
(	O
slt	O
)	O
,	O
ieee	O
,	O
2014	O
,	O
pp	O
.	O
413–417	O
.	O
ieee	O
g.	O
sell	O
,	O
d.	O
garcia	O
-	O
romero	O
,	O
diarization	B
resegmentation	B
in	O
the	O
factor	B
analysis	I
subspace	O
,	O
in	O
2015	O
ieee	O
international	O
conference	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
(	O
icassp	O
)	O
,	O
ieee	O
,	O
2015	O
,	O
pp	O
.	O
4794–4798	O
.	O
ieee	O
j.	O
song	O
,	O
y.	O
guo	O
,	O
l.	O
gao	O
,	O
x.	O
li	O
,	O
a.	O
hanjalic	O
,	O
h.t	O
.	O
shen	O
,	O
from	O
deterministic	O
to	O
generative	O
:	O
multimodal	O
stochastic	O
rnns	O
for	O
video	O
captioning	O
.	O
ieee	O
transac-	O
tions	O
on	O
neural	B
networks	I
and	O
learning	O
systems	O
30(10	O
)	O
,	O
3047–3058	O
(	O
2018	O
)	O
u.	O
tiwary	O
,	O
t.	O
siddiqui	O
,	O
natural	O
language	B
processing	I
and	O
information	B
retrieval	O
(	O
oxford	O
university	O
press	O
,	O
inc	O
.	O
,	O
?	O
?	O
?	O
,	O
2008	O
)	O
a.	O
tritschler	O
,	O
r.a	O
.	O
gopinath	O
,	O
improved	O
speaker	B
segmentation	I
and	O
segments	O
clustering	B
using	O
the	O
bayesian	O
information	B
criterion	B
,	O
in	O
sixth	O
european	O
con-	O
ference	O
on	O
speech	B
communication	I
and	O
technology	O
,	O
1999	O
m.	O
valenti	O
,	O
a.	O
diment	O
,	O
g.	O
parascandolo	O
,	O
s.	O
squartini	O
,	O
t.	O
virtanen	O
,	O
dcase	O
2016	O
acoustic	O
scene	O
classiﬁcation	O
using	O
convolutional	O
neural	B
networks	I
,	O
in	O
proc	O
.	O
workshop	O
detection	B
classif	O
.	O
acoust	O
.	O
scenes	O
events	O
,	O
2016	O
,	O
pp	O
.	O
95–99	O
r.	O
vipperla	O
,	O
j.t	O
.	O
geiger	O
,	O
s.	O
bozonnet	O
,	O
d.	O
wang	O
,	O
n.	O
evans	O
,	O
b.	O
schuller	O
,	O
g.	O
rigoll	O
,	O
speech	O
overlap	B
detection	I
and	O
attribution	O
using	O
convolutive	O
non-	O
negative	O
sparse	O
coding	O
,	O
in	O
2012	O
ieee	O
international	O
conference	O
on	O
acous-	O
tics	O
,	O
speech	O
and	O
signal	B
processing	I
(	O
icassp	O
)	O
,	O
ieee	O
,	O
2012	O
,	O
pp	O
.	O
4181–4184	O
.	O
ieee	O
d.e	O
.	O
wachob	O
,	O
method	B
and	O
apparatus	O
for	O
providing	O
demographically	O
targeted	O
television	O
commercials	O
(	O
google	O
patents	O
,	O
1992	O
)	O
.	O
us	O
patent	O
5,155,591	O
s.	O
watanabe	O
,	O
m.	O
mandel	O
,	O
j.	O
barker	O
,	O
e.	O
vincent	O
,	O
chime-6	O
challenge	B
:	O
tackling	O
multispeaker	O
speech	B
recognition	I
for	O
unsegmented	O
recordings	O
.	O
arxiv	O
preprint	O
arxiv:2004.09249	O
(	O
2020	O
)	O
l.d	O
.	O
wilcox	O
,	O
d.g	O
.	O
kimber	O
,	O
unsupervised	O
speaker	B
clustering	B
for	O
automatic	O
speaker	B
indexing	O
of	O
recorded	O
audio	O
data	B
(	O
google	O
patents	O
,	O
1997	O
)	O
.	O
us	O
patent	O
5,659,66224	O
supratim	O
tribady	O
et	O
al	O
.	O
a.	O
zarghami	O
,	O
s.	O
fazeli	O
,	O
n.	O
dokoohaki	O
,	O
m.	O
matskin	O
,	O
social	O
trust	O
-	O
aware	O
recom-	O
mendation	O
system	O
:	O
a	O
t	O
-	O
index	O
approach	O
,	O
in	O
2009	O
ieee	O
/	O
wic	O
/	O
acm	O
interna-	O
tional	O
joint	O
conference	O
on	O
web	O
intelligence	O
and	O
intelligent	O
agent	O
technol-	O
ogy	O
,	O
vol	O
.	O
3	O
,	O
ieee	O
,	O
2009	O
,	O
pp	O
.	O
85–90	O

ieee	O
transactions	O
on	O
audio	O
,	O
speech	O
,	O
and	O
language	B
processing	I
,	O
vol	O
.	O
14	O
,	O
no	O
.	O
5	O
,	O
september	O
2006	O
1557	O
an	O
overview	O
of	O
automatic	O
speaker	B
diarization	I
systems	I
sue	O
e.	O
tranter	O
,	O
member	O
,	O
ieee	O
and	O
douglas	O
a.	O
reynolds	O
,	O
senior	O
member	O
,	O
ieee	O
abstract	O
—	O
audio	O
diarization	B
is	O
the	O
process	B
of	O
annotating	O
an	O
input	B
audio	O
channel	O
with	O
information	B
that	O
attributes	O
(	O
possibly	O
overlapping	B
)	O
temporal	O
regions	O
of	O
signal	B
energy	O
to	O
their	O
speciﬁc	O
sources	O
.	O
these	O
sources	O
can	O
include	O
particular	O
speakers	O
,	O
music	O
,	O
background	B
noise	I
sources	O
,	O
and	O
other	O
signal	B
source	B
/	O
channel	O
char-	O
acteristics	O
.	O
diarization	B
can	O
be	O
used	O
for	O
helping	O
speech	B
recognition	I
,	O
facilitating	O
the	O
searching	O
and	O
indexing	O
of	O
audio	O
archives	O
,	O
and	O
increasing	O
the	O
richness	O
of	O
automatic	O
transcriptions	B
,	O
making	O
them	O
more	O
readable	O
.	O
in	O
this	O
paper	O
,	O
we	O
provide	O
an	O
overview	O
of	O
the	O
approaches	O
currently	O
used	O
in	O
a	O
key	O
area	O
of	O
audio	O
diarization	B
,	O
fig	O
.	O
1	O
.	O
example	O
of	O
audio	O
diarization	B
on	O
broadcast	O
news	O
.	O
annotated	O
namely	O
speaker	B
diarization	I
,	O
and	O
discuss	O
their	O
relative	O
merits	O
phenomena	O
may	O
include	O
different	O
structural	O
regions	O
such	O
as	O
commercials	O
,	O
and	O
limitations	O
.	O
performances	O
using	O
the	O
different	O
techniques	B
are	O
different	O
acoustic	O
events	O
such	O
as	O
music	O
or	O
noise	O
,	O
and	O
different	O
speakers	O
.	O
(	O
color	O
compared	O
within	O
the	O
framework	O
of	O
the	O
speaker	B
diarization	I
task	O
in	O
version	O
available	O
online	O
at	O
http://ieeexplore.ieee.org	O
.	O
)	O
the	O
darpa	O
ears	O
rich	B
transcription	I
evaluations	O
.	O
we	O
also	O
look	O
at	O
how	O
the	O
techniques	B
are	O
being	O
introduced	O
into	O
real	O
broadcast	O
news	O
systems	O
and	O
their	O
portability	O
to	O
other	O
domains	O
and	O
tasks	O
such	O
as	O
in	O
general	O
,	O
a	O
spoken	O
document	O
is	O
a	O
single	O
-	O
channel	O
recording	B
meetings	O
and	O
speaker	B
veriﬁcation	O
.	O
that	O
consists	O
of	O
multiple	O
audio	O
sources	O
.	O
audio	O
sources	O
may	O
be	O
index	O
terms	B
—	O
speaker	B
diarization	I
,	O
speaker	B
segmentation	I
and	O
different	O
speakers	O
,	O
music	O
segments	O
,	O
types	O
of	O
noise	O
,	O
etc	O
.	O
for	O
clustering	B
.	O
example	O
,	O
a	O
broadcast	O
news	O
program	O
consists	O
of	O
speech	O
from	O
different	O
speakers	O
as	O
well	O
as	O
music	O
segments	O
,	O
commercials	O
,	O
and	O
sounds	O
used	O
to	O
segue	O
into	O
reports	O
(	O
see	O
fig	O
.	O
1	O
)	O
.	O
audio	O
diarization	B
i.	O
introduction	O
is	O
deﬁned	O
as	O
the	O
task	O
of	O
marking	O
and	O
categorising	O
the	O
audio	O
t	O
he	O
continually	O
decreasing	O
cost	B
of	O
and	O
increasing	O
ac-	O
sources	O
within	O
a	O
spoken	O
document	O
.	O
the	O
types	O
and	O
details	O
of	O
cess	O
to	O
processing	B
power	O
,	O
storage	O
capacity	O
,	O
and	O
network	B
the	O
audio	O
sources	O
are	O
application	B
speciﬁc	O
.	O
at	O
the	O
simplest	O
,	O
bandwidth	O
is	O
facilitating	O
the	O
amassing	O
of	O
large	O
volumes	O
of	O
diarization	B
is	O
speech	O
versus	O
nonspeech	O
,	O
where	O
nonspeech	O
is	O
audio	O
,	O
including	O
broadcasts	O
,	O
voice	O
mails	O
,	O
meetings	O
and	O
other	O
a	O
general	O
class	O
consisting	O
of	O
music	O
,	O
silence	B
,	O
noise	O
,	O
etc	O
.	O
,	O
that	O
“	O
spoken	O
documents	O
.	O
”	O
there	O
is	O
a	O
growing	O
need	O
to	O
apply	O
au-	O
need	O
not	O
be	O
broken	O
out	O
by	O
type	O
.	O
a	O
more	O
complicated	O
diariza-	O
tomatic	O
human	O
language	O
technologies	O
to	O
allow	O
efﬁcient	O
and	O
tion	O
would	O
further	O
mark	O
where	O
speaker	B
changes	O
occur	O
in	O
the	O
effective	O
searching	O
,	O
indexing	O
,	O
and	O
accessing	O
of	O
these	O
informa-	O
detected	O
speech	O
and	O
associate	O
segments	O
of	O
speech	O
(	O
a	O
segment	B
is	O
tion	O
sources	O
.	O
extracting	O
the	O
words	B
being	O
spoken	O
in	O
the	O
audio	O
a	O
section	O
of	O
speech	O
bounded	O
by	O
nonspeech	O
or	O
speaker	B
change	I
using	O
speech	B
recognition	I
technology	O
provides	O
a	O
sound	O
base	O
points	O
)	O
coming	O
from	O
the	O
same	B
speaker	I
.	O
this	O
is	O
usually	O
referred	O
for	O
these	O
tasks	O
,	O
but	O
the	O
transcripts	B
are	O
often	O
hard	O
to	O
read	O
and	O
to	O
as	O
speaker	B
diarization	I
(	O
a.k.a	O
.	O
“	O
who	O
spoke	O
when	O
”	O
)	O
or	O
speaker	B
do	O
not	O
capture	O
all	O
the	O
information	B
contained	O
within	O
the	O
audio	O
.	O
segmentation	B
and	O
clustering	B
and	O
is	O
the	O
focus	O
of	O
most	O
current	O
other	O
technologies	O
are	O
needed	O
to	O
extract	O
meta	O
-	O
data	B
which	O
can	O
research	B
efforts	O
in	O
audio	O
diarization	B
.	O
this	O
paper	O
discusses	O
the	O
make	O
the	O
transcripts	B
more	O
readable	O
and	O
provide	O
context	O
and	O
techniques	B
commonly	O
used	O
for	O
speaker	B
diarization	I
,	O
which	O
information	B
beyond	O
a	O
simple	O
word	B
sequence	B
.	O
speaker	B
turns	O
and	O
allows	O
searching	O
audio	O
by	O
speaker	B
,	O
makes	O
transcripts	B
easier	O
sentence	O
boundaries	B
are	O
examples	O
of	O
such	O
meta	O
-	O
data	B
,	O
both	O
of	O
to	O
read	O
,	O
and	O
provides	O
information	B
which	O
could	O
be	O
used	O
within	O
which	O
help	O
provide	O
a	O
richer	O
transcription	B
of	O
the	O
audio	O
,	O
making	O
speaker	B
adaptation	O
in	O
speech	B
recognition	I
systems	O
.	O
other	O
audio	O
transcripts	B
more	O
readable	O
and	O
potentially	O
helping	O
with	O
other	O
diarization	B
tasks	O
,	O
such	O
as	O
explicitly	O
detecting	O
the	O
presence	B
of	O
tasks	O
such	O
as	O
summarization	O
,	O
parsing	O
,	O
or	O
machine	O
translation	O
.	O
music	O
(	O
e.g.	O
,	O
[	O
2	O
]	O
)	O
,	O
helping	O
ﬁnd	O
the	O
structure	O
of	O
a	O
broadcast	O
pro-	O
gram	O
(	O
e.g.	O
,	O
[	O
3	O
]	O
)	O
,	O
or	O
locating	O
commercials	O
to	O
eliminate	O
unwanted	O
manuscript	O
received	O
october	O
11	O
,	O
2005	O
;	O
revised	O
april	O
25	O
,	O
2006	O
.	O
this	O
work	O
audio	O
(	O
e.g.	O
,	O
[	O
4	O
]	O
)	O
,	O
also	O
have	O
many	O
potential	O
beneﬁts	O
but	O
fall	O
was	O
supported	O
by	O
the	O
defense	O
advanced	O
research	B
projects	O
agency	O
under	O
grant	O
outside	O
the	O
scope	O
of	O
this	O
paper	O
.	O
mda972	O
-	O
02	O
-	O
1	O
-	O
0013	O
and	O
in	O
part	O
by	O
air	O
force	O
contract	O
fa8721	O
-	O
05-c-0002	O
.	O
there	O
are	O
three	O
primary	O
domains	O
which	O
have	O
been	O
used	O
for	O
opinions	O
,	O
interpretations	O
,	O
conclusions	O
,	O
and	O
recommendations	O
are	O
those	O
of	O
the	O
authors	O
and	O
are	O
not	O
necessarily	O
endorsed	O
by	O
the	O
u.s	O
.	O
government	O
.	O
this	O
paper	O
speaker	B
diarization	I
research	B
and	O
development	O
:	O
broadcast	O
news	O
is	O
based	O
on	O
the	O
icassp	O
2005	O
hlt	O
special	O
session	O
paper	O
(	O
philadelphia	O
,	O
pa	O
)	O
.	O
audio	O
,	O
recorded	O
meetings	O
,	O
and	O
telephone	O
conversations	O
.	O
the	O
the	O
associate	O
editor	O
coordinating	O
the	O
review	O
of	O
this	O
manuscript	O
and	O
approving	O
data	B
from	O
these	O
domains	O
differs	O
in	O
the	O
quality	B
of	O
the	O
recordings	O
it	O
for	O
publication	O
was	O
dr	O
.	O
john	O
makhoul	O
.	O
s.	O
tranter	O
is	O
with	O
the	O
engineering	O
department	O
,	O
cambridge	O
university	O
,	O
cam-	O
(	O
bandwidth	O
,	O
microphones	O
,	O
noise	O
)	O
,	O
the	O
amount	B
and	O
types	O
of	O
bridge	O
cb2	O
1pz	O
,	O
u.k	O
.	O
(	O
e	O
-	O
mail	O
:	O
sej28@eng.cam.ac.uk	O
)	O
.	O
nonspeech	O
sources	O
,	O
the	O
number	O
of	O
speakers	O
,	O
the	O
durations	O
and	O
d.	O
reynolds	O
is	O
with	O
the	O
lincoln	O
laboratory	O
,	O
massachusetts	O
institute	O
of	O
tech-	O
sequencing	O
of	O
speaker	B
turns	O
,	O
and	O
the	O
style	O
/	O
spontaneity	O
of	O
the	O
nology	O
,	O
lexington	O
,	O
ma	O
02420	O
-	O
9185	O
usa	O
(	O
e	O
-	O
mail	O
:	O
dar@ll.mit.edu	O
)	O
.	O
digital	O
object	O
identiﬁer	O
10.1109	O
/	O
tasl.2006.878256	O
speech	O
.	O
each	O
domain	B
presents	O
unique	O
diarization	B
challenges	B
,	O
1558	O
-	O
7916/$20.00	O
©	O
2006	O
ieee1558	O
ieee	O
transactions	O
on	O
audio	O
,	O
speech	O
,	O
and	O
language	B
processing	I
,	O
vol	O
.	O
14	O
,	O
no	O
.	O
5	O
,	O
september	O
2006	O
although	O
often	O
high	O
-	O
level	B
system	O
techniques	B
tend	O
to	O
generalize	O
well	O
over	O
several	O
domains	O
[	O
5	O
]	O
,	O
[	O
6	O
]	O
.	O
the	O
nist	O
rich	O
transcrip-	O
tion	O
speaker	B
evaluations	O
[	O
7	O
]	O
have	O
primarily	O
used	O
both	O
broadcast	O
news	O
and	O
meeting	O
data	B
,	O
whereas	O
the	O
nist	O
speaker	B
recognition	O
evaluations	O
[	O
8	O
]	O
have	O
primarily	O
used	O
conversational	O
telephone	B
speech	I
with	O
summed	O
sides	O
(	O
a.k.a	O
two	O
-	O
wire	O
)	O
.	O
the	O
diarization	B
task	O
is	O
also	O
deﬁned	O
by	O
the	O
amount	B
of	O
speciﬁc	O
prior	O
knowledge	B
allowed	O
.	O
there	O
may	O
be	O
speciﬁc	O
prior	O
knowl-	O
edge	O
via	O
example	O
speech	O
from	O
the	O
speakers	O
in	O
the	O
audio	O
,	O
such	O
as	O
in	O
a	O
recording	B
of	O
a	O
regular	O
staff	O
meeting	O
.	O
the	O
task	O
then	O
be-	O
comes	O
more	O
like	O
speaker	B
detection	B
or	O
tracking	O
tasks	O
[	O
9	O
]	O
.	O
spe-	O
ciﬁc	O
prior	O
knowledge	B
could	O
also	O
be	O
example	O
speech	O
from	O
just	O
a	O
few	O
of	O
the	O
speakers	O
such	O
as	O
common	O
anchors	O
on	O
particular	O
news	O
stations	O
,	O
or	O
knowledge	B
of	O
the	O
number	O
of	O
speakers	O
in	O
the	O
audio	O
,	O
perhaps	O
for	O
a	O
teleconference	O
over	O
a	O
known	O
number	O
of	O
lines	O
,	O
or	O
maybe	O
the	O
structure	O
of	O
the	O
audio	O
recording	B
(	O
e.g.	O
,	O
music	O
followed	O
fig	O
.	O
2	O
.	O
prototypical	O
diarization	B
system	O
.	O
most	O
diarization	B
systems	I
have	O
by	O
story	O
)	O
.	O
most	O
of	O
this	O
prior	O
knowledge	B
has	O
been	O
used	O
to	O
improve	O
components	B
to	O
perform	O
speech	B
detection	I
,	O
gender	O
and/or	O
bandwidth	O
diarization	B
performance	O
although	O
not	O
all	O
of	O
it	O
has	O
proved	O
beneﬁ-	O
segmentation	B
,	O
speaker	B
segmentation	I
,	O
speaker	B
clustering	B
,	O
and	O
ﬁnal	O
cial	O
within	O
current	O
systems	O
.	O
[	O
10	O
]	O
.	O
however	O
,	O
for	O
a	O
more	O
portable	O
resegmentation	B
or	O
boundary	O
reﬁnement	O
.	O
speaker	B
diarization	I
system	I
,	O
it	O
is	O
desired	O
to	O
operate	O
without	O
any	O
speciﬁc	O
prior	O
knowledge	B
of	O
the	O
audio	O
.	O
this	O
is	O
the	O
general	O
task	O
speech	O
/	O
nonspeech	O
models	B
such	O
as	O
in	O
[	O
11	O
]	O
,	O
while	O
[	O
12	O
]	O
is	O
similar	O
deﬁnition	O
used	O
in	O
the	O
rich	B
transcription	I
diarization	B
evaluations	O
,	O
but	O
four	O
speech	O
models	B
are	O
used	O
for	O
the	O
possible	O
gender	O
/	O
band-	O
where	O
only	O
the	O
broadcaster	O
and	O
date	O
of	O
broadcast	O
are	O
known	O
in	O
width	O
combinations	O
.	O
noise	O
and	O
music	O
are	O
explicitly	O
modeled	O
in	O
addition	O
to	O
having	O
the	O
audio	O
data	B
and	O
we	O
adopt	O
this	O
scenario	O
[	O
13]–[15	O
]	O
which	O
have	O
classes	O
for	O
speech	O
,	O
music	O
,	O
noise	O
,	O
speech	O
when	O
discussing	O
speaker	B
diarization	I
systems	I
.	O
music	O
,	O
and	O
speech	O
noise	O
,	O
while	O
[	O
16	O
]	O
and	O
[	O
17	O
]	O
use	O
wideband	O
the	O
aim	O
of	O
this	O
paper	O
is	O
to	O
provide	O
an	O
overview	O
of	O
current	O
speech	O
,	O
narrowband	O
speech	O
,	O
music	O
and	O
speech	O
music	O
.	O
the	O
speaker	B
diarization	I
approaches	O
and	O
to	O
discuss	O
performance	O
and	O
extra	O
speech	O
xx	O
models	B
are	O
used	O
to	O
help	O
minimize	O
the	O
false	O
potential	O
applications	O
.	O
in	O
section	O
ii	O
,	O
we	O
outline	O
the	O
general	O
rejection	O
of	O
speech	O
occurring	O
in	O
the	O
presence	B
of	O
music	O
or	O
noise	O
,	O
framework	O
of	O
diarization	B
systems	I
and	O
discuss	O
different	O
im-	O
and	O
this	O
data	B
is	O
subsequently	O
reclassiﬁed	O
as	O
speech.the	O
classes	O
plementations	O
of	O
the	O
key	O
components	B
within	O
current	O
systems	O
.	O
can	O
also	O
be	O
broken	O
down	O
further	O
,	O
as	O
in	O
[	O
18	O
]	O
,	O
which	O
has	O
eight	O
performance	O
is	O
measured	O
in	O
terms	B
of	O
the	O
diarization	B
error	I
rate	I
models	B
in	O
total	O
,	O
ﬁve	O
for	O
nonspeech	O
(	O
music	O
,	O
laughter	O
,	O
breath	O
,	O
(	O
der	O
)	O
using	O
the	O
darpa	O
ears	O
rich	B
transcription	I
fall	O
2004	O
lip	O
-	O
smack	O
,	O
and	O
silence	B
)	O
and	O
three	O
for	O
speech	O
(	O
vowels	O
and	O
nasals	O
,	O
(	O
rt-04f	O
)	O
speaker	B
diarization	I
evaluation	B
data	B
.	O
section	O
iv	O
looks	O
fricatives	O
,	O
and	O
obstruents	O
)	O
.	O
at	O
the	O
use	O
of	O
these	O
methods	O
in	O
real	O
applications	O
and	O
the	O
future	O
when	O
operating	O
on	O
unsegmented	O
audio	O
,	O
viterbi	O
segmenta-	O
directions	O
for	O
diarization	B
research	B
.	O
tion	O
,	O
(	O
single	O
pass	O
or	O
iterative	O
with	O
optional	O
adaptation	O
)	O
using	O
the	O
models	B
is	O
employed	O
to	O
identify	O
speech	O
regions	O
.	O
if	O
an	O
initial	O
seg-	O
ii	O
.	O
diarization	B
system	O
framework	O
mentation	O
is	O
already	O
available	O
(	O
for	O
example	O
,	O
the	O
ordering	O
of	O
the	O
key	O
components	B
may	O
allow	O
change	B
point	B
detection	I
before	O
non-	O
in	O
this	O
section	O
,	O
we	O
review	O
the	O
key	O
subtasks	O
used	O
to	O
build	O
cur-	O
speech	O
removal	O
)	O
,	O
each	O
segment	B
is	O
individually	O
classiﬁed	O
.	O
min-	O
rent	O
speaker	B
diarization	I
systems	I
.	O
most	O
diarization	B
systems	I
per-	O
imum	O
length	B
constraints	O
[	O
11	O
]	O
,	O
[	O
18	O
]	O
and	O
heuristic	O
smoothing	O
rules	O
form	O
these	O
tasks	O
separately	O
,	O
although	O
it	O
is	O
possible	O
to	O
perform	O
[	O
12	O
]	O
,	O
[	O
15	O
]	O
may	O
also	O
be	O
applied	O
.	O
an	O
alternative	O
approach	O
which	O
some	O
of	O
the	O
stages	O
jointly	O
(	O
for	O
example	O
speaker	B
segmentation	I
does	O
not	O
use	O
viterbi	O
decoding	O
,	O
but	O
instead	O
a	O
best	O
model	B
search	O
and	O
clustering	B
)	O
and	O
the	O
ordering	O
of	O
the	O
stages	O
often	O
varies	O
from	O
with	O
morphological	O
rules	O
is	O
described	O
in	O
[	O
19	O
]	O
.	O
system	O
to	O
system	O
.	O
a	O
prototypical	O
combination	O
of	O
the	O
key	O
com-	O
silence	B
can	O
be	O
removed	O
in	O
this	O
early	O
stage	B
,	O
using	O
a	O
phone	O
rec-	O
ponents	O
of	O
a	O
diarization	B
system	O
is	O
shown	O
in	O
fig	O
.	O
2	O
.	O
for	O
each	O
task	O
,	O
ognizer	O
(	O
as	O
in	O
[	O
17	O
]	O
)	O
or	O
energy	O
constraint	O
,	O
or	O
in	O
a	O
ﬁnal	O
stage	B
pro-	O
we	O
provide	O
a	O
brief	O
description	O
of	O
the	O
common	O
approaches	O
em-	O
cessing	O
using	O
a	O
word	B
recognizer	O
(	O
as	O
in	O
[	O
14	O
]	O
)	O
or	O
energy	O
constraint	O
ployed	O
and	O
some	O
of	O
the	O
issues	O
in	O
applying	O
them	O
.	O
(	O
as	O
in	O
the	O
mit	O
system	O
for	O
rt-03	O
[	O
20	O
]	O
)	O
.	O
regions	O
which	O
contain	O
commercials	O
and	O
thus	O
are	O
of	O
no	O
interest	O
for	O
the	O
ﬁnal	O
output	B
can	O
a.	O
speech	B
detection	I
also	O
be	O
automatically	O
detected	O
and	O
removed	O
at	O
this	O
early	O
stage	B
the	O
aim	O
of	O
this	O
step	O
is	O
to	O
ﬁnd	O
the	O
regions	O
of	O
speech	O
in	O
the	O
[	O
4	O
]	O
,	O
[	O
20	O
]	O
audio	O
stream	O
.	O
depending	O
on	O
the	O
domain	B
data	B
being	O
used	O
,	O
non-	O
for	O
broadcast	O
news	O
audio	O
,	O
speech	B
detection	I
performance	O
is	O
speech	O
regions	O
to	O
be	O
discarded	O
can	O
consist	O
of	O
many	O
acoustic	O
phe-	O
typically	O
less	O
than	O
1	O
%	O
miss	B
(	O
speech	O
in	O
reference	B
but	O
not	O
in	O
the	O
nomena	O
such	O
as	O
silence	B
,	O
music	O
,	O
room	O
noise	O
,	O
background	B
noise	I
,	O
hypothesis	B
)	O
and	O
1%–2	O
%	O
false	B
alarm	I
(	O
speech	O
in	O
the	O
hypothesis	B
or	O
cross	O
-	O
talk	O
.	O
but	O
not	O
in	O
the	O
reference	B
)	O
,	O
whereas	O
for	O
meeting	O
audio	O
,	O
the	O
ﬁgures	O
the	O
general	O
approach	O
used	O
is	O
maximum	O
-	O
likelihood	B
classi-	O
are	O
typically	O
around	O
1	O
%	O
higher	O
for	O
both	O
.	O
when	O
the	O
speech	O
detec-	O
ﬁcation	O
with	O
gaussian	O
mixture	O
models	B
(	O
gmms	O
)	O
trained	O
on	O
tion	O
phase	O
is	O
run	O
early	O
in	O
a	O
system	O
,	O
or	O
the	O
output	B
is	O
required	O
for	O
labeled	O
training	B
data	I
,	O
although	O
different	O
class	O
models	B
can	O
be	O
further	O
processing	B
such	O
as	O
for	O
transcription	B
,	O
it	O
is	O
more	O
impor-	O
used	O
,	O
such	O
as	O
multistate	O
hmms	O
.	O
the	O
simplest	O
system	O
uses	O
just	O
tant	O
to	O
minimize	O
speech	O
miss	B
than	O
false	B
alarm	I
rates	B
,	O
since	O
thetranter	O
and	O
reynolds	O
:	O
overview	O
of	O
automatic	O
speaker	B
diarisation	O
systems	O
1559	O
former	O
are	O
unrecoverable	O
errors	B
in	O
most	O
systems	O
.	O
however	O
,	O
the	O
distance	B
metric	B
.	O
the	O
peaks	B
in	O
the	O
distance	B
function	O
are	O
then	O
der	O
,	O
used	O
to	O
evaluate	O
speaker	B
diarization	I
performance	O
,	O
treats	O
found	O
and	O
deﬁne	O
the	O
change	B
points	O
if	O
their	O
absolute	O
value	O
ex-	O
both	O
forms	O
of	O
error	O
equally	O
.	O
ceeds	O
a	O
predetermined	O
threshold	B
chosen	O
on	O
development	B
data	I
.	O
for	O
telephone	O
audio	O
,	O
typically	O
some	O
form	O
of	O
standard	O
en-	O
smoothing	O
the	O
distance	B
distribution	O
or	O
eliminating	O
the	O
smaller	O
ergy	O
/	O
spectrum	B
-	O
based	O
speech	B
activity	I
detection	I
is	O
used	O
since	O
of	O
neighboring	O
peaks	B
within	O
a	O
certain	O
minimum	O
duration	O
pre-	O
nonspeech	O
tends	O
to	O
be	O
silence	B
or	O
noise	O
sources	O
,	O
although	O
the	O
vents	O
the	O
system	O
overgenerating	O
change	B
points	O
at	O
true	O
bound-	O
gmm	O
approach	O
has	O
also	O
been	O
successful	O
in	O
this	O
domain	B
with	O
aries	O
.	O
single	O
gaussians	O
are	O
generally	O
preferred	O
to	O
gmms	O
due	O
to	O
single	O
-	O
channel	O
[	O
21	O
]	O
or	O
cross	O
-	O
channel	O
[	O
22	O
]	O
classes	O
.	O
for	O
meeting	O
the	O
simpliﬁed	O
distance	B
calculations	O
.	O
typical	O
window	O
sizes	O
are	O
audio	O
,	O
the	O
nonspeech	O
can	O
be	O
from	O
a	O
variety	O
of	O
noise	O
sources	O
,	O
1–2	O
or	O
2–5	O
s	O
when	O
using	O
a	O
diagonal	O
or	O
full	O
covariance	O
gaussian	O
,	O
like	O
paper	O
shufﬂing	O
,	O
coughing	O
,	O
laughing	O
,	O
etc	O
.	O
and	O
energy	O
-	O
based	O
respectively	O
.	O
as	O
with	O
bic	B
,	O
the	O
window	O
length	B
constrains	O
the	O
de-	O
methods	O
do	O
not	O
currently	O
work	O
well	O
for	O
distant	O
microphones	O
tection	O
of	O
short	O
turns	O
.	O
[	O
23	O
]	O
,	O
[	O
24	O
]	O
,	O
so	O
using	O
a	O
simple	O
pretrained	O
speech	O
/	O
nonspeech	O
gmm	O
since	O
the	O
change	B
point	B
detection	I
often	O
only	O
provides	O
an	O
initial	O
is	O
generally	O
preferred	O
[	O
6	O
]	O
,	O
[	O
25	O
]	O
,	O
[	O
23	O
]	O
.	O
an	O
interesting	O
alternative	O
base	O
segmentation	B
for	O
diarization	B
systems	I
,	O
which	O
will	O
be	O
clus-	O
uses	O
a	O
gmm	O
,	O
built	O
on	O
the	O
normalized	O
energy	O
coefﬁcients	O
of	O
tered	O
and	O
often	O
resegmented	O
later	O
,	O
being	O
able	O
to	O
run	O
the	O
change	B
the	O
test	B
data	I
,	O
to	O
determine	O
how	O
much	O
nonspeech	O
to	O
reject	O
[	O
24	O
]	O
,	O
point	B
detection	I
very	O
fast	O
(	O
typically	O
less	O
than	O
0.01	O
for	O
a	O
di-	O
while	O
preliminary	O
work	O
in	O
[	O
6	O
]	O
shows	O
potential	O
for	O
the	O
future	O
for	O
agonal	O
covariance	O
system	O
)	O
is	O
often	O
more	O
important	O
than	O
any	O
per-	O
a	O
new	O
energy	O
-	O
based	O
method	B
.	O
when	O
supported	O
,	O
multiple	O
channel	O
formance	O
degradation	O
.	O
in	O
fact	O
,	O
[	O
11	O
]	O
and	O
[	O
19	O
]	O
found	O
no	O
signiﬁcant	O
meeting	O
audio	O
can	O
be	O
used	O
to	O
help	O
speech	B
activity	I
detection	I
performance	O
degradation	O
when	O
using	O
a	O
simple	O
initial	O
uniform	O
[	O
26	O
]	O
.	O
this	O
problem	O
is	O
felt	O
to	O
be	O
so	O
important	O
in	O
the	O
meetings	O
segmentation	B
within	O
their	O
systems	O
.	O
domain	B
that	O
a	O
separate	O
evaluation	B
for	O
speech	B
activity	I
detection	I
both	O
change	B
detection	I
techniques	B
require	O
a	O
detection	B
was	O
introduced	O
in	O
the	O
spring	O
2005	O
rich	B
transcription	I
meeting	O
threshold	B
to	O
be	O
empirically	O
tuned	O
for	O
changes	O
in	O
audio	O
type	O
and	O
evaluation	B
[	O
27	O
]	O
.	O
features	O
.	O
tuning	O
the	O
change	B
detector	O
is	O
a	O
tradeoff	O
between	O
the	O
desires	O
to	O
have	O
long	O
,	O
pure	O
segments	O
to	O
aid	O
in	O
initializing	O
the	O
b.	O
change	B
detection	I
clustering	B
stage	B
,	O
and	O
minimizing	O
missed	O
change	B
points	O
which	O
the	O
aim	O
of	O
this	O
step	O
is	O
to	O
ﬁnd	O
points	O
in	O
the	O
audio	O
stream	O
produce	O
contaminations	O
in	O
the	O
clustering	B
.	O
likely	O
to	O
be	O
change	B
points	O
between	O
audio	O
sources	O
.	O
if	O
the	O
input	B
alternatively	O
,	O
or	O
in	O
addition	O
,	O
a	O
word	B
or	O
phone	O
decoding	O
step	O
to	O
this	O
stage	B
is	O
the	O
unsegmented	O
audio	O
stream	O
,	O
then	O
the	O
change	B
with	O
heuristic	O
rules	O
may	O
be	O
used	O
to	O
help	O
ﬁnd	O
putative	O
speaker	B
detection	B
looks	O
for	O
both	O
speaker	B
and	O
speech	O
/	O
nonspeech	O
change	B
change	B
points	O
such	O
as	O
in	O
[	O
18	O
]	O
and	O
the	O
cambridge	O
1998–2003	O
points	O
.	O
if	O
a	O
speech	O
detector	O
or	O
gender	O
/	O
bandwidth	O
classiﬁer	O
has	O
systems	O
[	O
16	O
]	O
,	O
[	O
20	O
]	O
.	O
however	O
,	O
this	O
approach	O
can	O
over	O
-	O
segment	B
been	O
run	O
ﬁrst	O
,	O
then	O
the	O
change	B
detector	O
looks	O
for	O
speaker	B
change	I
the	O
speech	O
data	B
and	O
requires	O
some	O
additional	O
merging	O
or	O
clus-	O
points	O
within	O
each	O
speech	B
segment	I
.	O
tering	O
to	O
form	O
viable	O
speech	B
segments	I
,	O
and	O
can	O
miss	B
boundaries	B
two	O
main	O
approaches	O
have	O
been	O
used	O
for	O
change	B
detection	I
.	O
in	O
fast	O
speaker	B
interchanges	O
if	O
relying	O
on	O
the	O
presence	B
of	O
silence	B
they	O
both	O
involve	O
looking	O
at	O
adjacent	O
windows	O
of	O
data	B
and	O
or	O
gender	O
changes	O
between	O
speakers	O
.	O
calculating	O
a	O
distance	B
metric	B
between	O
the	O
two	O
,	O
then	O
deciding	O
c.	O
gender	O
/	O
bandwidth	O
classiﬁcation	O
whether	O
the	O
windows	O
originate	O
from	O
the	O
same	O
or	O
a	O
different	O
source	B
.	O
the	O
differences	O
between	O
them	O
lie	O
in	O
the	O
choice	O
of	O
dis-	O
the	O
aim	O
of	O
this	O
stage	B
is	O
to	O
partition	O
the	O
segments	O
into	O
tance	O
metric	B
and	O
thresholding	O
decisions	O
.	O
common	O
groupings	O
of	O
gender	O
(	O
male	O
or	O
female	O
)	O
and	O
bandwidth	O
the	O
ﬁrst	O
general	O
approach	O
used	O
for	O
change	B
detection	I
,	O
used	O
(	O
low	O
-	O
bandwidth	O
:	O
narrow	O
-	O
band	O
/	O
telephone	O
or	O
high	O
-	O
bandwidth	O
:	O
in	O
[	O
15	O
]	O
,	O
is	O
a	O
variation	O
on	O
the	O
bayesian	O
information	B
criterion	B
studio	O
)	O
.	O
this	O
is	O
done	O
to	O
reduce	O
the	O
load	O
on	O
subsequent	O
clus-	O
(	O
bic	B
)	O
technique	B
introduced	O
in	O
[	O
28	O
]	O
.	O
this	O
technique	B
searches	O
for	O
tering	O
,	O
provide	O
more	O
ﬂexibility	O
in	O
clustering	B
settings	O
(	O
for	O
change	B
points	O
within	O
a	O
window	O
using	O
a	O
penalized	O
likelihood	B
example	O
female	O
speakers	O
may	O
have	O
different	O
optimal	O
parameter	O
ratio	O
test	B
of	O
whether	O
the	O
data	B
in	O
the	O
window	O
is	O
better	O
modeled	O
settings	O
to	O
male	O
speakers	O
)	O
,	O
and	O
supply	O
more	O
side	O
information	B
by	O
a	O
single	O
distribution	O
(	O
no	O
change	B
point	O
)	O
or	O
two	O
different	O
dis-	O
about	O
the	O
speakers	O
in	O
the	O
ﬁnal	O
output	B
.	O
if	O
the	O
partitioning	O
can	O
tributions	O
(	O
change	B
point	O
)	O
.	O
if	O
a	O
change	B
is	O
found	O
,	O
the	O
window	O
is	O
be	O
done	O
very	O
accurately	O
and	O
assuming	O
no	O
speaker	B
appears	O
in	O
reset	O
to	O
the	O
change	B
point	O
and	O
the	O
search	O
restarted	O
.	O
if	O
no	O
change	B
the	O
same	O
broadcast	O
in	O
different	O
classes	O
(	O
for	O
example	O
both	O
in	O
point	O
is	O
found	O
,	O
the	O
window	O
is	O
increased	O
and	O
the	O
search	O
is	O
redone	O
.	O
the	O
studio	O
and	O
via	O
a	O
prerecorded	O
ﬁeld	O
report	O
)	O
then	O
performing	O
some	O
of	O
the	O
issues	O
in	O
applying	O
the	O
bic	B
change	B
detector	O
are	O
as	O
this	O
partitioning	O
early	O
on	O
in	O
the	O
system	O
can	O
also	O
help	O
improve	O
follows	O
.	O
1	O
)	O
it	O
has	O
high	O
miss	B
rates	B
on	O
detecting	O
short	O
turns	O
(	O
2–5	O
performance	O
while	O
reducing	O
the	O
computational	O
load	O
[	O
33	O
]	O
.	O
the	O
s	O
)	O
,	O
so	O
can	O
be	O
problematic	O
to	O
use	O
on	O
fast	O
interchange	O
speech	O
like	O
potential	O
drawback	O
in	O
this	O
partitioning	O
stage	B
,	O
however	O
,	O
is	O
if	O
conversations	O
.	O
2	O
)	O
the	O
full	O
search	O
implementation	O
is	O
computa-	O
a	O
subset	O
of	O
a	O
speaker	B
’s	O
segments	O
is	O
misclassiﬁed	O
the	O
errors	B
tionally	O
expensive	O
(	O
order	B
)	O
,	O
so	O
most	O
systems	O
employ	O
some	O
can	O
be	O
unrecoverable	O
,	O
although	O
it	O
is	O
possible	O
to	O
allow	O
these	O
form	O
of	O
computation	O
reductions	O
(	O
e.g.	O
,	O
[	O
29	O
]	O
)	O
.	O
classiﬁcations	O
to	O
change	B
in	O
a	O
subsequent	O
resegmentation	B
stage	B
,	O
a	O
second	O
technique	B
used	O
ﬁrst	O
in	O
[	O
30	O
]	O
and	O
later	O
in	O
[	O
13	O
]	O
,	O
[	O
17	O
]	O
,	O
such	O
as	O
in	O
[	O
19	O
]	O
.	O
and	O
[	O
31	O
]	O
uses	O
ﬁxed	O
-	O
length	B
windows	O
and	O
represents	O
each	O
window	O
classiﬁcation	O
for	O
both	O
gender	O
and	O
bandwidth	O
is	O
typically	O
by	O
a	O
gaussian	O
and	O
the	O
distance	B
between	O
them	O
by	O
the	O
gaussian	O
done	O
using	O
maximum	O
-	O
likelihood	B
classiﬁcation	O
with	O
gmms	O
divergence	O
(	O
symmetric	O
kl-2	O
distance	B
)	O
.	O
the	O
step	O
-	O
by	O
-	O
step	O
im-	O
trained	O
on	O
labeled	O
training	B
data	I
.	O
either	O
two	O
classiﬁers	O
are	O
run	O
plementation	O
in	O
[	O
19	O
]	O
and	O
system	O
for	O
telephone	O
audio	O
in	O
[	O
32	O
]	O
(	O
one	O
for	O
gender	O
and	O
one	O
for	O
bandwidth	O
)	O
or	O
joint	O
models	B
for	O
are	O
similar	O
but	O
use	O
the	O
generalized	O
log	B
likelihood	B
ratio	I
as	O
the	O
gender	O
and	O
bandwidth	O
are	O
used	O
.	O
this	O
can	O
be	O
done	O
either	O
in1560	O
ieee	O
transactions	O
on	O
audio	O
,	O
speech	O
,	O
and	O
language	B
processing	I
,	O
vol	O
.	O
14	O
,	O
no	O
.	O
5	O
,	O
september	O
2006	O
conjunction	O
with	O
the	O
speech	O
/	O
nonspeech	O
detection	B
process	B
or	O
parent	O
cluster	O
in	O
the	O
penalty	O
factor	B
represents	O
a	O
“	O
local	O
”	O
after	O
the	O
initial	O
segmentation	B
.	O
bandwidth	O
classiﬁcation	O
can	O
also	O
bic	B
decision	O
,	O
i.e.	O
,	O
just	O
considering	O
the	O
clusters	O
being	O
combined	O
.	O
be	O
done	O
using	O
a	O
test	B
on	O
the	O
ratio	O
of	O
spectral	O
energy	O
above	O
and	O
this	O
has	O
been	O
shown	O
to	O
perform	O
better	O
than	O
the	O
corresponding	O
below	O
4	O
khz	O
.	O
an	O
alternative	O
method	B
of	O
gender	O
classiﬁcation	O
,	O
“	O
global	O
”	O
bic	B
implementation	O
which	O
uses	O
the	O
number	O
of	O
frames	O
used	O
in	O
[	O
17	O
]	O
,	O
aligns	O
the	O
word	B
recognition	O
output	B
of	O
a	O
fast	O
asr	B
in	O
the	O
whole	O
show	O
instead	O
[	O
20	O
]	O
,	O
[	O
31	O
]	O
,	O
[	O
36	O
]	O
.	O
system	O
with	O
gender	O
dependent	O
models	B
and	O
assigns	O
the	O
most	O
slight	O
variations	O
of	O
this	O
technique	B
have	O
also	O
been	O
used	O
.	O
for	O
likely	O
gender	O
to	O
each	O
segment	B
.	O
this	O
has	O
a	O
high	O
accuracy	O
but	O
is	O
example	O
,	O
the	O
system	O
described	O
in	O
[	O
18	O
]	O
uses	O
essentially	O
the	O
local	O
unnecessarily	O
computationally	O
expensive	O
if	O
a	O
speech	O
recogni-	O
bic	B
score	B
(	O
with	O
the	O
number	O
of	O
parameters	O
term	O
incorporated	O
tion	O
output	B
is	O
not	O
already	O
available	O
and	O
segments	O
ideally	O
should	O
within	O
the	O
penalty	O
weight	B
)	O
,	O
but	O
sets	O
different	O
thresholds	O
for	O
po-	O
be	O
of	O
a	O
reasonable	O
size	B
(	O
typically	O
between	O
1	O
and	O
30	O
s	O
)	O
.	O
gender	O
tential	O
boundaries	B
occurring	O
during	O
speech	O
or	O
nonspeech	O
,	O
moti-	O
classiﬁcation	O
error	B
rates	I
are	O
around	O
1%–2	O
%	O
and	O
bandwidth	O
vated	O
by	O
an	O
observation	O
that	O
most	O
true	O
speaker	B
change	I
points	O
classiﬁcation	O
error	B
rates	I
are	O
around	O
3%–5	O
%	O
for	O
broadcast	O
news	O
occurred	O
during	O
nonspeech	O
regions	O
.	O
a	O
further	O
example	O
,	O
used	O
audio	O
.	O
in	O
the	O
system	O
described	O
in	O
[	O
11	O
]	O
and	O
[	O
37	O
]	O
removes	O
the	O
need	O
for	O
tuning	O
the	O
penalty	O
weight	B
on	O
development	B
data	I
,	O
by	O
ensuring	O
d.	O
clustering	B
that	O
the	O
number	O
of	O
parameters	O
in	O
the	O
merged	O
and	O
separate	O
distributions	O
are	O
equal	O
,	O
although	O
the	O
base	O
number	O
of	O
gaussians	O
the	O
purpose	O
of	O
this	O
stage	B
is	O
to	O
associate	O
or	O
cluster	O
segments	O
and	O
,	O
hence	O
,	O
number	O
of	O
free	O
parameters	O
needs	O
to	O
be	O
chosen	O
care-	O
from	O
the	O
same	B
speaker	I
together	O
.	O
the	O
clustering	B
ideally	O
produces	O
fully	O
for	O
optimal	O
effect	O
.	O
alternatives	O
to	O
the	O
penalty	O
term	O
,	O
such	O
as	O
one	O
cluster	O
for	O
each	O
speaker	B
in	O
the	O
audio	O
with	O
all	O
segments	O
from	O
using	O
a	O
constant	O
[	O
38	O
]	O
,	O
the	O
weighted	O
sum	O
of	O
the	O
number	O
of	O
clus-	O
a	O
given	O
speaker	B
in	O
a	O
single	O
cluster	O
.	O
the	O
predominant	O
approach	O
ters	O
and	O
number	O
of	O
segments	O
[	O
13	O
]	O
,	O
or	O
a	O
penalized	O
determinant	O
used	O
in	O
diarization	B
systems	I
is	O
hierarchical	O
,	O
agglomerative	O
clus-	O
of	O
the	O
within	O
-	O
cluster	O
dispersion	O
matrix	O
[	O
34	O
]	O
,	O
[	O
39	O
]	O
have	O
also	O
had	O
tering	O
with	O
a	O
bic	B
based	O
stopping	O
criterion	B
[	O
28	O
]	O
consisting	O
of	O
the	O
moderate	O
success	O
,	O
but	O
the	O
bic	B
method	B
has	O
generally	O
superseded	O
following	O
steps	B
:	O
these	O
.	O
adding	O
a	O
viterbi	O
resegmentation	B
between	O
multiple	O
itera-	O
0	O
)	O
initialize	O
leaf	O
clusters	O
of	O
tree	O
with	O
speech	B
segments	I
;	O
tions	O
of	O
clustering	B
[	O
31	O
]	O
or	O
within	O
a	O
single	O
iteration	O
[	O
11	O
]	O
has	O
also	O
1	O
)	O
compute	O
pair	O
-	O
wise	O
distances	O
between	O
each	O
cluster	O
;	O
been	O
used	O
to	O
increase	O
performance	O
at	O
the	O
penalty	O
of	O
increased	O
2	O
)	O
merge	O
closest	O
clusters	O
;	O
computational	O
cost	B
.	O
3	O
)	O
update	O
distances	O
of	O
remaining	O
clusters	O
to	O
new	O
cluster	O
;	O
an	O
alternative	O
approach	O
described	O
in	O
[	O
40	O
]	O
uses	O
a	O
euclidean	O
4	O
)	O
iterate	O
steps	B
1)–3	O
)	O
until	O
stopping	O
criterion	B
is	O
met	O
.	O
distance	B
between	O
map	O
-	O
adapted	O
gmms	O
and	O
notes	O
this	O
is	O
highly	O
the	O
clusters	O
are	O
generally	O
represented	O
by	O
a	O
single	O
full	O
covari-	O
correlated	O
with	O
a	O
monte	O
carlo	O
estimation	B
of	O
the	O
gaussian	O
di-	O
ance	O
gaussian	O
[	O
5	O
]	O
,	O
[	O
12	O
]	O
,	O
[	O
15	O
]	O
,	O
[	O
17	O
]	O
,	O
[	O
31	O
]	O
,	O
[	O
34	O
]	O
,	O
but	O
gmms	O
have	O
vergence	O
(	O
symmetric	O
kl-2	O
)	O
distance	B
while	O
also	O
being	O
an	O
upper	O
also	O
been	O
used	O
[	O
11	O
]	O
,	O
[	O
19	O
]	O
,	O
[	O
35	O
]	O
,	O
sometimes	O
being	O
built	O
using	O
bound	O
to	O
it	O
.	O
the	O
stopping	O
criterion	B
uses	O
a	O
ﬁxed	O
threshold	B
,	O
chosen	O
mean	O
-	O
only	O
map	O
adaptation	O
of	O
a	O
gmm	O
of	O
the	O
entire	O
test	B
ﬁle	O
on	O
the	O
development	B
data	I
,	O
on	O
the	O
distance	B
metric	B
.	O
the	O
perfor-	O
to	O
each	O
cluster	O
for	O
increased	O
robustness	O
.	O
the	O
standard	O
distance	B
mance	O
is	O
comparable	O
to	O
the	O
more	O
conventional	O
bic	B
method	B
.	O
metric	B
between	O
clusters	O
is	O
the	O
generalized	O
likelihood	B
ratio	I
a	O
further	O
method	B
described	O
in	O
[	O
15	O
]	O
uses	O
“	O
proxy	O
”	O
speakers	O
.	O
(	O
glr	O
)	O
.	O
it	O
is	O
possible	O
to	O
use	O
other	O
representations	O
or	O
distance	B
a	O
set	B
of	O
proxy	O
models	B
is	O
applied	O
to	O
map	O
segments	O
into	O
a	O
vector	O
metrics	O
,	O
but	O
these	O
have	O
been	O
found	O
the	O
most	O
successful	O
within	O
space	O
,	O
then	O
a	O
euclidean	O
distance	B
metric	B
and	O
an	O
ad	O
hoc	O
occu-	O
the	O
bic	B
clustering	B
framework	O
.	O
the	O
stopping	O
criterion	B
compares	O
pancy	O
stopping	O
criterion	B
are	O
used	O
,	O
but	O
the	O
overall	O
clustering	B
the	O
bic	B
statistic	O
from	O
the	O
two	O
clusters	O
being	O
considered	O
,	O
and	O
framework	O
remains	O
the	O
same	O
.	O
the	O
proxy	O
models	B
can	O
be	O
built	O
,	O
with	O
that	O
of	O
the	O
parent	O
cluster	O
,	O
,	O
should	O
they	O
be	O
merged	O
,	O
the	O
by	O
adapting	O
a	O
universal	O
background	O
model	B
(	O
ubm	O
)	O
such	O
as	O
a	O
formulation	O
being	O
for	O
the	O
full	O
covariance	O
gaussian	O
case	O
128	O
mixture	O
gmm	O
to	O
the	O
test	B
data	I
segments	O
themselves	O
,	O
thus	O
making	O
the	O
system	O
portable	O
to	O
different	O
shows	O
and	O
domains	O
while	O
still	O
giving	O
consistent	O
performance	O
gain	O
over	O
the	O
bic	B
method	B
.	O
regardless	O
of	O
the	O
clustering	B
employed	O
,	O
the	O
stopping	O
crite-	O
rion	O
is	O
critical	O
to	O
good	O
performance	O
and	O
depends	O
on	O
how	O
the	O
output	B
is	O
to	O
be	O
used	O
.	O
under	O
-	O
clustering	B
fragments	O
speaker	B
data	B
over	O
several	O
clusters	O
,	O
while	O
over	O
-	O
clustering	B
produces	O
contam-	O
inated	O
clusters	O
containing	O
speech	O
from	O
several	O
speakers	O
.	O
for	O
where	O
is	O
the	O
number	O
of	O
free	O
parameters	O
,	O
the	O
number	O
of	O
indexing	O
information	B
by	O
speaker	B
,	O
both	O
are	O
suboptimal	O
.	O
how-	O
frames	O
,	O
the	O
covariance	O
matrix	O
,	O
and	O
the	O
dimension	O
of	O
the	O
ever	O
,	O
when	O
using	O
cluster	O
output	B
to	O
assist	O
in	O
speaker	B
adaptation	O
feature	O
vector	O
.	O
(	O
see	O
,	O
e.g.	O
,	O
[	O
20	O
]	O
for	O
a	O
more	O
complete	O
derivation	O
.	O
)	O
of	O
speech	B
recognition	I
models	B
,	O
under	O
-	O
clustering	B
may	O
be	O
suit-	O
if	O
the	O
pair	O
of	O
clusters	O
are	O
best	O
described	O
by	O
a	O
single	O
full	O
covari-	O
able	O
when	O
a	O
speaker	B
occurs	O
in	O
multiple	O
acoustic	O
environments	O
ance	O
gaussian	O
,	O
the	O
will	O
be	O
low	O
,	O
whereas	O
if	O
there	O
are	O
two	O
and	O
over	O
-	O
clustering	B
may	O
be	O
advantageous	O
in	O
aggregating	O
speech	O
separate	O
distributions	O
,	O
implying	O
two	O
speakers	O
,	O
the	O
will	O
be	O
from	O
similar	O
speakers	O
or	O
acoustic	O
environments	O
.	O
high	O
.	O
for	O
each	O
step	O
,	O
the	O
pair	O
of	O
clusters	O
with	O
the	O
lowest	O
is	O
e.	O
joint	O
segmentation	B
and	O
clustering	B
merged	O
and	O
the	O
statistics	B
are	O
recalculated	O
.	O
the	O
process	B
is	O
gener-	O
ally	O
stopped	O
when	O
the	O
lowest	O
is	O
greater	O
than	O
a	O
speciﬁed	O
an	O
alternative	O
approach	O
to	O
running	O
segmentation	B
and	O
clus-	O
threshold	B
,	O
usually	O
0	O
.	O
the	O
use	O
of	O
the	O
number	O
of	O
frames	O
in	O
the	O
tering	O
stages	O
separately	O
is	O
to	O
use	O
an	O
integrated	O
scheme	O
.	O
this	O
wastranter	O
and	O
reynolds	O
:	O
overview	O
of	O
automatic	O
speaker	B
diarisation	O
systems	O
1561	O
ﬁrst	O
done	O
in	O
[	O
13	O
]	O
by	O
employing	O
a	O
viterbi	O
decode	O
between	O
iter-	O
mean	O
and	O
variance	O
normalization	O
[	O
15	O
]	O
and	O
feature	O
warping	O
[	O
44	O
]	O
ations	O
of	O
agglomerative	O
clustering	B
,	O
but	O
an	O
initial	O
segmentation	B
using	O
a	O
sliding	O
window	O
of	O
3	O
s	O
[	O
14	O
]	O
,	O
[	O
17	O
]	O
.	O
the	O
latter	O
method	B
had	O
stage	B
was	O
still	O
required	O
.	O
a	O
more	O
recent	O
completely	O
integrated	O
previously	O
been	O
found	O
by	O
one	O
study	O
to	O
be	O
more	O
effective	O
than	O
scheme	O
,	O
based	O
on	O
an	O
evolutive	O
-	O
hmm	O
(	O
e	O
-	O
hmm	O
)	O
where	O
detected	O
other	O
standard	O
normalization	O
techniques	B
on	O
a	O
speaker	B
veriﬁca-	O
speakers	O
help	O
inﬂuence	O
both	O
the	O
detection	B
of	O
other	O
speakers	O
and	O
tion	O
task	O
on	O
cellular	O
data	B
[	O
45	O
]	O
.	O
in	O
[	O
17	O
]	O
,	O
it	O
was	O
found	O
the	O
fea-	O
the	O
speaker	B
boundaries	B
,	O
was	O
introduced	O
in	O
[	O
41	O
]	O
and	O
developed	O
ture	O
normalization	O
was	O
necessary	O
to	O
get	O
signiﬁcant	O
gain	O
from	O
in	O
[	O
19	O
]	O
and	O
[	O
42	O
]	O
.	O
the	O
recording	B
is	O
represented	O
by	O
an	O
ergodic	O
the	O
cluster	O
recombination	O
technique	B
.	O
hmm	O
in	O
which	O
each	O
state	O
represents	O
a	O
speaker	B
and	O
the	O
tran-	O
when	O
the	O
clusters	O
are	O
merged	O
,	O
a	O
new	O
speaker	B
model	B
can	O
be	O
sitions	O
model	B
the	O
changes	O
between	O
speakers	O
.	O
the	O
initial	O
hmm	O
trained	O
with	O
the	O
combined	O
data	B
and	O
distances	O
updated	O
(	O
as	O
in	O
[	O
14	O
]	O
contains	O
only	O
one	O
state	O
and	O
represents	O
all	O
of	O
the	O
data	B
.	O
in	O
each	O
it-	O
and	O
[	O
17	O
]	O
)	O
or	O
standard	O
clustering	B
rules	O
can	O
be	O
used	O
with	O
a	O
static	O
eration	O
,	O
a	O
short	O
speech	B
segment	I
assumed	O
to	O
come	O
from	O
a	O
nonde-	O
distance	B
matrix	O
(	O
as	O
in	O
[	O
15	O
]	O
)	O
.	O
this	O
recombination	O
can	O
be	O
viewed	O
tected	O
speaker	B
is	O
selected	O
and	O
used	O
to	O
build	O
a	O
new	O
speaker	B
model	B
as	O
fusing	O
intra-	O
and	O
inter-	O
[	O
43	O
]	O
audio	O
ﬁle	O
speaker	B
clustering	B
tech-	O
by	O
bayesian	O
adaptation	O
of	O
a	O
ubm	O
.	O
a	O
state	O
is	O
then	O
added	O
to	O
the	O
niques	O
.	O
on	O
the	O
rt-04f	O
evaluation	B
it	O
was	O
found	O
that	O
this	O
stage	B
hmm	O
to	O
reﬂect	O
this	O
new	O
speaker	B
,	O
and	O
the	O
transitions	O
probabili-	O
signiﬁcantly	O
improves	O
performance	O
,	O
with	O
further	O
improvements	B
ties	O
are	O
modiﬁed	O
accordingly	O
.	O
a	O
new	O
segmentation	B
is	O
then	O
gen-	O
being	O
obtained	O
subsequently	O
by	O
using	O
a	O
variable	O
prior	O
iterative	O
erated	O
from	O
a	O
viterbi	O
decode	O
of	O
the	O
data	B
with	O
the	O
new	O
hmm	O
,	O
and	O
map	O
approach	O
for	O
adapting	O
the	O
ubms	O
,	O
and	O
building	O
new	O
ubms	O
each	O
model	B
is	O
adapted	O
using	O
the	O
new	O
segmentation	B
.	O
this	O
reseg-	O
including	O
all	O
of	O
the	O
test	B
data	I
[	O
17	O
]	O
.	O
mentation	O
phase	O
is	O
repeated	O
until	O
the	O
speaker	B
labels	I
no	O
longer	O
change	B
.	O
the	O
process	B
of	O
adding	O
new	O
speakers	O
is	O
repeated	O
until	O
g.	O
resegmentation	B
there	O
is	O
no	O
gain	O
in	O
terms	B
of	O
comparable	O
likelihood	B
or	O
there	O
is	O
no	O
the	O
last	O
stage	B
found	O
in	O
many	O
diarization	B
systems	I
is	O
a	O
reseg-	O
data	B
left	O
to	O
form	O
a	O
new	O
speaker	B
.	O
the	O
main	O
advantages	O
of	O
this	O
in-	O
mentation	O
of	O
the	O
audio	O
via	O
viterbi	O
decoding	O
(	O
with	O
or	O
without	O
it-	O
tegrated	O
approach	O
are	O
to	O
use	O
all	O
the	O
information	B
at	O
each	O
step	O
and	O
erations	O
)	O
using	O
the	O
ﬁnal	O
cluster	O
models	B
and	O
nonspeech	O
models	B
.	O
to	O
allow	O
the	O
use	O
of	O
speaker	B
recognition	O
-	O
based	O
techniques	B
,	O
like	O
the	O
purpose	O
of	O
this	O
stage	B
is	O
to	O
reﬁne	O
the	O
original	O
segment	B
bound-	O
bayesian	O
adaptation	O
of	O
the	O
speaker	B
models	B
from	O
a	O
ubm	O
.	O
aries	O
and/or	O
to	O
ﬁll	O
in	O
short	O
segments	O
that	O
may	O
have	O
been	O
removed	O
for	O
more	O
robust	O
processing	B
in	O
the	O
clustering	B
stage	B
.	O
filtering	O
the	O
f.	O
cluster	O
recombination	O
segment	B
boundaries	B
using	O
a	O
word	B
or	O
phone	O
recognizer	O
output	B
in	O
this	O
relatively	O
recent	O
approach	O
[	O
31	O
]	O
,	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
can	O
also	O
help	O
reduce	O
the	O
false	B
alarm	I
component	O
of	O
the	O
error	B
rate	I
speaker	B
recognition	O
modeling	O
and	O
matching	O
techniques	B
are	O
[	O
31	O
]	O
.	O
used	O
as	O
a	O
secondary	O
stage	B
for	O
combining	O
clusters	O
.	O
the	O
signal	B
processing	I
and	O
modeling	O
used	O
in	O
the	O
clustering	B
stage	B
of	O
sec-	O
h.	O
finding	O
identities	O
tion	O
ii	O
-	O
d	O
are	O
usually	O
simple	O
:	O
no	O
channel	O
compensation	O
,	O
such	O
as	O
rasta	O
,	O
since	O
we	O
wish	O
to	O
take	O
advantage	O
of	O
common	O
channel	O
although	O
current	O
diarization	B
systems	I
are	O
only	O
evaluated	O
using	O
characteristics	B
among	O
a	O
speaker	B
’s	O
segments	O
,	O
and	O
limited	O
param-	O
“	O
relative	O
”	O
speaker	B
labels	I
(	O
such	O
as	O
“	O
spkr1	O
”	O
)	O
,	O
it	O
is	O
often	O
possible	O
to	O
eter	O
distribution	O
models	B
,	O
since	O
the	O
model	B
needs	O
to	O
work	O
with	O
ﬁnd	O
the	O
true	O
identities	O
of	O
the	O
speakers	O
(	O
such	O
as	O
“	O
ted	O
koppel	O
”	O
)	O
.	O
small	O
amounts	O
of	O
data	B
in	O
the	O
clusters	O
at	O
the	O
start	O
.	O
this	O
can	O
be	O
achieved	O
by	O
a	O
variety	O
of	O
methods	O
,	O
such	O
as	O
building	O
with	O
cluster	O
recombination	O
,	O
clustering	B
is	O
run	O
to	O
under	O
-	O
cluster	O
speaker	B
models	B
for	O
people	O
who	O
are	O
likely	O
to	O
be	O
in	O
the	O
news	O
the	O
audio	O
but	O
still	O
produce	O
clusters	O
with	O
a	O
reasonable	O
amount	B
of	O
broadcasts	O
(	O
such	O
as	O
prominent	O
politicians	O
or	O
main	O
news	O
anchors	O
speech	O
s	O
.	O
a	O
ubm	O
is	O
built	O
on	O
training	B
data	I
to	O
represent	O
and	O
reporters	O
)	O
and	O
including	O
these	O
models	B
in	O
the	O
speaker	B
clus-	O
general	O
speakers	O
.	O
both	O
static	O
and	O
delta	O
coefﬁcients	O
are	O
used	O
and	O
tering	O
stage	B
or	O
running	O
speaker	B
-	O
tracking	O
systems	O
.	O
feature	O
normalization	O
is	O
applied	O
to	O
help	O
reduce	O
the	O
effect	O
of	O
the	O
an	O
alternative	O
approach	O
,	O
introduced	O
in	O
[	O
46	O
]	O
,	O
uses	O
linguistic	O
in-	O
acoustic	O
environment	O
.	O
maximum	O
a	O
posteriori	O
(	O
map	O
)	O
adaptation	O
formation	O
contained	O
within	O
the	O
transcriptions	B
to	O
predict	O
the	O
pre-	O
(	O
usually	O
mean	O
-	O
only	O
)	O
is	O
then	O
applied	O
on	O
each	O
cluster	O
from	O
the	O
vious	O
,	O
current	O
,	O
or	O
next	O
speaker	B
.	O
rules	O
are	O
deﬁned	O
based	O
on	O
cat-	O
ubm	O
to	O
form	O
a	O
single	O
model	B
per	O
cluster	O
.	O
the	O
cross	O
likelihood	B
egory	O
and	O
word	B
n	O
-	O
grams	O
chosen	O
from	O
the	O
training	B
data	I
,	O
and	O
are	O
ratio	O
(	O
clr	O
)	O
between	O
any	O
two	O
given	O
clusters	O
is	O
deﬁned	O
[	O
31	O
]	O
,	O
[	O
43	O
]	O
then	O
applied	O
sequentially	O
on	O
the	O
test	B
data	I
until	O
the	O
speaker	B
names	O
have	O
been	O
found	O
.	O
blocking	O
rules	O
are	O
used	O
to	O
stop	O
rules	O
ﬁring	O
in	O
certain	O
contexts	O
,	O
for	O
example	O
,	O
the	O
sequence	B
“	O
[	O
name	O
]	O
reports	O
”	O
assigns	O
the	O
next	O
speaker	B
to	O
be	O
[	O
name	O
]	O
unless	O
is	O
the	O
word	B
“	O
that	O
.	O
”	O
an	O
extension	O
of	O
this	O
system	O
described	O
in	O
[	O
47	O
]	O
,	O
learns	O
many	O
rules	O
where	O
is	O
the	O
average	B
likelihood	B
per	O
frame	B
of	O
data	B
and	O
their	O
associated	O
probability	B
of	O
being	O
correct	O
automatically	O
given	O
the	O
model	B
.	O
the	O
pair	O
of	O
clusters	O
with	O
the	O
highest	O
clr	O
from	O
the	O
training	B
data	I
and	O
then	O
applies	O
these	O
simultaneously	O
on	O
is	O
merged	O
and	O
a	O
new	O
model	B
is	O
created	O
.	O
the	O
process	B
is	O
repeated	O
the	O
test	B
data	I
using	O
probabilistic	O
combination	O
.	O
using	O
automatic	O
until	O
the	O
highest	O
clr	O
is	O
below	O
a	O
predeﬁned	O
threshold	B
chosen	O
transcriptions	B
and	O
automatically	O
found	O
speaker	B
turns	O
naturally	O
from	O
development	B
data	I
.	O
because	O
of	O
the	O
computational	O
load	O
at	O
degrades	O
performance	O
but	O
potentially	O
85	O
%	O
of	O
the	O
time	B
can	O
be	O
this	O
stage	B
,	O
each	O
gender	O
/	O
bandwidth	O
combination	O
is	O
usually	O
pro-	O
correctly	O
assigned	O
to	O
the	O
true	O
speaker	B
identity	O
using	O
this	O
method	B
.	O
cessed	O
separately	O
,	O
which	O
also	O
allows	O
more	O
appropriate	O
ubms	O
to	O
although	O
primarily	O
used	O
for	O
identifying	O
the	O
speaker	B
names	O
be	O
used	O
for	O
each	O
case	O
.	O
given	O
a	O
set	B
of	O
speaker	B
clusters	O
,	O
this	O
technique	B
can	O
associate	O
the	O
different	O
types	O
of	O
feature	O
normalization	O
have	O
been	O
used	O
with	O
same	O
name	O
for	O
more	O
than	O
one	O
input	B
cluster	O
and	O
,	O
therefore	O
,	O
could	O
this	O
process	B
,	O
namely	O
rasta-ﬁltered	O
cepstra	O
with	O
10-s	O
feature	O
be	O
thought	O
of	O
as	O
a	O
high	O
-	O
level	B
cluster	O
-	O
combination	O
stage.1562	O
ieee	O
transactions	O
on	O
audio	O
,	O
speech	O
,	O
and	O
language	B
processing	I
,	O
vol	O
.	O
14	O
,	O
no	O
.	O
5	O
,	O
september	O
2006	O
i.	O
combining	O
different	O
diarization	B
methods	O
then	O
scored	O
against	O
reference	B
“	O
ground	B
-	O
truth	O
”	O
speaker	B
segmenta-	O
tion	O
which	O
is	O
generated	O
using	O
the	O
rules	O
given	O
in	O
[	O
52	O
]	O
.	O
since	O
the	O
combining	O
methods	O
used	O
in	O
different	O
diarization	B
systems	I
hypothesis	B
speaker	B
labels	I
are	O
relative	O
,	O
they	O
must	O
be	O
matched	O
ap-	O
could	O
potentially	O
improve	O
performance	O
over	O
the	O
best	O
single	O
propriately	O
to	O
the	O
true	O
speaker	B
names	O
in	O
the	O
reference	B
.	O
to	O
accom-	O
diarization	B
system	O
.	O
it	O
has	O
been	O
shown	O
that	O
the	O
word	B
error	B
rate	I
plish	O
this	O
,	O
a	O
one	O
-	O
to	O
-	O
one	O
mapping	O
of	O
the	O
reference	B
speaker	I
ids	O
to	O
(	O
wer	O
)	O
of	O
an	O
automatic	O
speech	O
recognizer	O
can	O
be	O
consistently	O
the	O
hypothesis	B
speaker	B
ids	O
is	O
performed	O
so	O
as	O
to	O
maximize	O
the	O
reduced	O
when	O
combining	O
multiple	O
segmentations	O
even	O
if	O
the	O
in-	O
total	O
overlap	O
of	O
the	O
reference	B
and	O
(	O
corresponding	O
)	O
mapped	O
hy-	O
dividual	O
segmentations	O
themselves	O
do	O
not	O
offer	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
pothesis	O
speakers	O
.	O
speaker	B
diarization	I
performance	O
is	O
then	O
ex-	O
performance	O
in	O
either	O
der	O
or	O
resulting	O
wer	O
[	O
48	O
]	O
.	O
indeed	O
,	O
it	O
pressed	O
in	O
terms	B
of	O
the	O
miss	B
(	O
speaker	B
in	O
reference	B
but	O
not	O
in	O
seems	O
that	O
diversity	O
between	O
the	O
segmentation	B
methods	O
is	O
just	O
hypothesis	B
)	O
,	O
false	B
alarm	I
(	O
speaker	B
in	O
hypothesis	B
but	O
not	O
in	O
refer-	O
as	O
important	O
as	O
the	O
segmentation	B
quality	B
when	O
being	O
combined	O
.	O
ence	O
)	O
,	O
and	O
speaker	B
-	O
error	O
(	O
mapped	O
reference	B
speaker	I
is	O
not	O
the	O
it	O
is	O
expected	O
that	O
gains	O
in	O
der	O
are	O
also	O
possible	O
by	O
combining	O
same	O
as	O
the	O
hypothesized	O
speaker	B
)	O
rates	B
.	O
the	O
overall	O
der	O
is	O
the	O
different	O
diarization	B
modules	O
or	O
systems	O
.	O
sum	O
of	O
these	O
three	O
components	B
.	O
a	O
complete	O
description	O
of	O
the	O
several	O
methods	O
of	O
combining	O
aspects	O
of	O
different	O
diariza-	O
evaluation	B
measure	O
and	O
scoring	O
software	O
implementing	O
it	O
can	O
be	O
tion	O
systems	O
have	O
been	O
tried	O
,	O
for	O
example	O
the	O
“	O
hybridization	O
”	O
found	O
at	O
http://nist.gov/speech/tests/rt/rt2004/fall	O
.	O
or	O
“	O
piped	O
”	O
clips	O
/	O
lia	O
systems	O
of	O
[	O
35	O
]	O
and	O
[	O
49	O
]	O
and	O
the	O
“	O
plug	O
it	O
should	O
be	O
noted	O
that	O
this	O
measure	O
is	O
time	B
-	O
weighted	O
,	O
so	O
the	O
and	O
play	O
”	O
cued	O
/	O
mit	O
-	O
ll	O
system	O
of	O
[	O
20	O
]	O
which	O
both	O
combine	O
der	O
is	O
primarily	O
driven	O
by	O
(	O
relatively	O
few	O
)	O
loquacious	O
speakers	O
components	B
of	O
different	O
systems	O
together	O
.	O
a	O
more	O
integrated	O
and	O
it	O
is	O
,	O
therefore	O
,	O
more	O
important	O
to	O
get	O
the	O
main	O
speakers	O
merging	O
method	B
is	O
described	O
in	O
[	O
49	O
]	O
,	O
while	O
[	O
35	O
]	O
describes	O
a	O
way	O
complete	O
and	O
correct	O
than	O
to	O
accurately	O
ﬁnd	O
speakers	O
who	O
do	O
not	O
of	O
using	O
the	O
2002	O
nist	O
speaker	B
segmentation	I
error	O
metric	B
to	O
speak	O
much	O
.	O
this	O
scenario	O
models	B
some	O
tasks	O
,	O
such	O
as	O
tracking	O
ﬁnd	O
regions	O
in	O
two	O
inputs	O
which	O
agree	O
and	O
then	O
uses	O
these	O
to	O
anchor	O
speakers	O
in	O
broadcast	O
news	O
for	O
text	O
summarization	O
,	O
but	O
train	O
potentially	O
more	O
accurate	O
speaker	B
models	B
.	O
these	O
systems	O
there	O
may	O
be	O
other	O
tasks	O
(	O
such	O
as	O
for	O
speaker	B
adaptation	O
within	O
generally	O
produce	O
performance	O
gains	O
,	O
but	O
tend	O
to	O
place	O
some	O
re-	O
automatic	O
transcription	B
,	O
or	O
ascertaining	O
the	O
opinions	O
of	O
several	O
striction	O
on	O
the	O
systems	O
being	O
combined	O
,	O
such	O
as	O
the	O
required	O
ar-	O
speakers	O
in	O
a	O
quick	O
debate	O
)	O
for	O
which	O
it	O
is	O
less	O
appropriate	O
.	O
the	O
chitecture	O
or	O
equalizing	O
the	O
number	O
of	O
speakers	O
.	O
an	O
alternative	O
same	O
formulation	O
can	O
be	O
modiﬁed	O
to	O
be	O
speaker	B
weighted	O
in-	O
approach	O
introduced	O
in	O
[	O
50	O
]	O
uses	O
a	O
“	O
cluster	O
voting	O
”	O
technique	B
to	O
stead	O
of	O
time	B
weighted	O
if	O
necessary	O
,	O
but	O
this	O
is	O
not	O
discussed	O
compare	O
the	O
output	B
of	O
arbitrary	O
diarization	B
systems	I
,	O
maintaining	O
here	O
.	O
the	O
utility	O
of	O
either	O
weighting	O
depends	O
on	O
the	O
application	B
areas	O
of	O
agreement	O
and	O
voting	O
using	O
conﬁdences	O
or	O
an	O
external	O
of	O
the	O
diarization	B
output	B
.	O
judging	O
scheme	O
in	O
areas	O
of	O
conﬂict	O
.	O
j.	O
sequential	O
speaker	B
clustering	B
b.	O
data	B
for	O
some	O
applications	O
,	O
it	O
can	O
be	O
important	O
to	O
produce	O
speaker	B
the	O
rt-04f	O
speaker	B
diarization	I
data	B
consists	O
of	O
one	O
30-min	O
labels	O
immediately	O
without	O
collecting	O
all	O
of	O
the	O
potential	O
data	B
extract	O
from	O
12	O
different	O
u.s	O
.	O
broadcast	O
news	O
shows	O
.	O
these	O
were	O
from	O
a	O
particular	O
scenario	O
,	O
for	O
example	O
real	O
-	O
time	B
captioning	O
of	O
derived	O
from	O
tv	O
shows	O
:	O
three	O
from	O
abc	O
,	O
three	O
from	O
cnn	O
,	O
two	O
a	O
broadcast	O
news	O
show	O
.	O
this	O
constraint	O
prevents	O
the	O
standard	O
hi-	O
from	O
cnbc	O
,	O
two	O
from	O
pbs	O
,	O
one	O
from	O
cspan	O
,	O
and	O
one	O
from	O
erarchical	O
clustering	B
techniques	B
being	O
used	O
,	O
and	O
instead	O
requires	O
wbn	O
.	O
the	O
style	O
of	O
show	O
varied	O
from	O
a	O
set	B
of	O
lectures	O
from	O
a	O
few	O
the	O
clustering	B
to	O
be	O
performed	O
sequentially	O
or	O
online	O
.	O
an	O
elegant	O
speakers	O
(	O
cspan	O
)	O
to	O
rapid	O
headline	O
news	O
reporting	O
(	O
cnn	O
head-	O
solution	O
to	O
this	O
,	O
described	O
in	O
[	O
34	O
]	O
,	O
takes	O
the	O
segments	O
in	O
turn	O
and	O
line	O
news	O
)	O
.	O
details	O
of	O
the	O
exact	O
composition	O
of	O
the	O
data	B
sets	O
can	O
decides	O
if	O
they	O
match	O
any	O
of	O
the	O
existing	O
speaker	B
clusters	O
using	O
be	O
found	O
in	O
[	O
52	O
]	O
.	O
thresholds	O
on	O
distance	B
metrics	O
based	O
on	O
the	O
generalized	O
likeli-	O
hood	O
ratio	O
and	O
a	O
penalized	O
within	O
-	O
cluster	O
dispersion	O
.	O
if	O
a	O
match	O
c.	O
results	B
is	O
found	O
,	O
the	O
statistics	B
of	O
the	O
matched	O
cluster	O
are	O
updated	O
using	O
the	O
results	B
from	O
the	O
main	O
diarization	B
techniques	B
are	O
shown	O
the	O
new	O
segment	B
information	B
,	O
whereas	O
if	O
no	O
match	O
is	O
found	O
,	O
the	O
in	O
fig	O
.	O
3	O
.	O
using	O
a	O
top	O
-	O
down	O
clustering	B
approach	O
with	O
full	O
segment	B
starts	O
a	O
new	O
speaker	B
cluster	O
.	O
this	O
process	B
is	O
much	O
faster	O
covariance	O
models	B
,	O
arithmetic	O
harmonic	O
sphericity	O
(	O
ahs	O
)	O
than	O
the	O
conventional	O
hierarchical	O
approach	O
,	O
particularly	O
when	O
distance	B
metric	B
and	O
bic	B
stopping	O
criterion	B
gave	O
a	O
der	O
of	O
be-	O
there	O
are	O
a	O
large	O
number	O
of	O
initial	O
segments	O
,	O
and	O
has	O
been	O
used	O
tween	O
20.5	O
%	O
and	O
22.5	O
%	O
[	O
38	O
]	O
.	O
the	O
corresponding	O
performance	O
for	O
both	O
ﬁnding	O
speaker	B
turns	O
[	O
34	O
]	O
and	O
for	O
speaker	B
adaptation	O
on	O
the	O
six	O
-	O
show	O
rt	O
diarization	B
development	B
data	I
sets	O
ranged	O
within	O
a	O
real	O
-	O
time	B
speech	B
recognition	I
framework	O
[	O
51	O
]	O
.	O
from	O
15.9	O
%	O
to	O
26.9	O
%	O
,	O
showing	O
that	O
the	O
top	O
-	O
down	O
method	B
seems	O
more	O
unpredictable	O
than	O
the	O
agglomerative	O
method	B
.	O
iii	O
.	O
evaluation	B
of	O
performance	O
this	O
is	O
thought	O
to	O
be	O
because	O
the	O
initial	O
clusters	O
contain	O
many	O
in	O
this	O
section	O
we	O
brieﬂy	O
describe	O
the	O
nist	O
rt-04f	O
speaker	B
speakers	O
and	O
segments	O
may	O
thus	O
be	O
assigned	O
incorrectly	O
early	O
diarization	B
evaluation	B
and	O
present	O
the	O
results	B
when	O
using	O
the	O
key	O
on	O
,	O
leading	O
to	O
an	O
unrecoverable	O
error	O
.	O
in	O
contrast	O
,	O
the	O
agglom-	O
techniques	B
discussed	O
in	O
this	O
paper	O
on	O
the	O
rt-04f	O
diarization	B
erative	O
scheme	O
grows	O
clusters	O
from	O
the	O
original	O
segments	O
and	O
evaluation	B
data	B
.	O
should	O
not	O
contain	O
impure	O
multispeaker	O
clusters	O
until	O
very	O
late	O
in	O
the	O
clustering	B
process	B
.	O
the	O
agglomerative	O
clustering	B
a.	O
speaker	B
diarization	I
error	O
measure	O
bic	B
-	O
based	O
scheme	O
got	O
around	O
17%–18	O
%	O
der	O
[	O
11	O
]	O
,	O
[	O
15	O
]	O
,	O
a	O
system	O
hypothesizes	O
a	O
set	B
of	O
speaker	B
segments	I
each	O
of	O
[	O
17	O
]	O
,	O
[	O
31	O
]	O
,	O
with	O
viterbi	O
resegmentation	B
between	O
each	O
step	O
which	O
consists	O
of	O
a	O
(	O
relative	O
)	O
speaker	B
-	O
id	O
label	O
such	O
as	O
“	O
mspkr1	O
”	O
providing	O
a	O
slight	O
beneﬁt	O
to	O
16.4	O
%	O
[	O
11	O
]	O
.	O
further	O
improvements	B
or	O
“	O
fspkr2	O
”	O
and	O
the	O
corresponding	O
start	O
and	O
end	O
times	O
.	O
this	O
is	O
to	O
around	O
13	O
%	O
were	O
made	O
using	O
clr	O
cluster	O
recombinationtranter	O
and	O
reynolds	O
:	O
overview	O
of	O
automatic	O
speaker	B
diarisation	O
systems	O
1563	O
fig	O
.	O
5	O
.	O
accessing	O
broadcast	O
news	O
audio	O
from	O
automatically	O
derived	O
speaker	B
names	O
via	O
a	O
wavesurfer	O
plug	O
-	O
in	O
.	O
(	O
color	O
version	O
available	O
online	O
at	O
fig	O
.	O
3	O
.	O
ders	O
for	O
different	O
methods	O
on	O
the	O
rt-04f	O
evaluation	B
data	B
.	O
each	O
http://ieeexplore.ieee.org	O
.	O
)	O
dot	O
represents	O
a	O
different	O
version	O
of	O
a	O
system	O
built	O
using	O
the	O
indicated	O
core	O
technique	B
.	O
e	O
-	O
hmm	O
not	O
tuned	O
on	O
the	O
u.s	O
.	O
broadcast	O
news	O
development	O
sets	O
.	O
(	O
color	O
version	O
available	O
online	O
at	O
http://ieeexplore.ieee.org	O
.	O
)	O
reducing	O
this	O
variability	O
is	O
a	O
source	B
of	O
ongoing	O
work	O
.	O
certain	O
techniques	B
or	O
parameter	O
settings	O
can	O
perform	O
better	O
for	O
different	O
styles	O
of	O
show	O
.	O
systems	O
may	O
potentially	O
be	O
improved	O
by	O
ei-	O
ther	O
automatically	O
detecting	O
the	O
type	O
of	O
show	O
and	O
modifying	O
the	O
choice	O
of	O
techniques	B
or	O
parameters	O
accordingly	O
,	O
or	O
by	O
com-	O
bining	O
different	O
systems	O
directly	O
as	O
discussed	O
in	O
section	O
ii	O
-	O
a	O
.	O
iv	O
.	O
conclusion	O
and	O
future	O
directions	O
there	O
has	O
been	O
tremendous	O
progress	O
in	O
task	O
deﬁnition	O
,	O
data	B
availability	O
,	O
scoring	O
measures	O
,	O
and	O
technical	O
approaches	O
for	O
speaker	B
diarization	I
over	O
recent	O
years	O
.	O
the	O
methods	O
used	O
in	O
broadcast	O
news	O
diarization	B
are	O
now	O
being	O
deployed	O
across	O
other	O
domains	O
,	O
for	O
example	O
,	O
improving	O
speaker	B
recognition	O
perfor-	O
mance	O
using	O
multispeaker	O
train	O
and	O
test	B
data	I
in	O
conversational	O
telephone	B
speech	I
[	O
15	O
]	O
and	O
ﬁnding	O
speakers	O
within	O
meeting	O
data	B
[	O
6	O
]	O
,	O
[	O
23]–[25	O
]	O
,	O
[	O
53	O
]	O
.	O
the	O
latter	O
sometimes	O
contains	O
an	O
additional	O
stage	B
when	O
multiple	O
microphones	O
are	O
present	O
to	O
either	O
select	O
the	O
most	O
prominent	O
microphone	O
[	O
53	O
]	O
or	O
to	O
weight	B
the	O
audio	O
signal	B
from	O
multiple	O
microphones	O
to	O
form	O
a	O
single	O
“	O
superior	O
”	O
signal	B
before	O
further	O
processing	B
[	O
6	O
]	O
,	O
[	O
24	O
]	O
.	O
different	O
methods	O
fig	O
.	O
4	O
.	O
der	O
per	O
show	O
for	O
the	O
system	O
with	O
lowest	O
der	O
.	O
there	O
is	O
a	O
large	O
for	O
obtaining	O
these	O
channel	O
weights	O
have	O
been	O
tried	O
including	O
variability	O
between	O
the	O
different	O
styles	O
of	O
show	O
.	O
(	O
color	O
version	O
available	O
online	O
equal	O
weighting	O
[	O
6	O
]	O
,	O
[	O
24	O
]	O
,	O
using	O
signal	B
-	O
to	O
-	O
noise	O
ratio	O
estimates	O
at	O
http://ieeexplore.ieee.org	O
.	O
)	O
[	O
6	O
]	O
,	O
[	O
24	O
]	O
,	O
using	O
the	O
correlation	O
between	O
different	O
channels	B
[	O
6	O
]	O
,	O
and	O
“	O
delay	O
-	O
and	O
-	O
sum	O
”	O
beamforming	O
[	O
6	O
]	O
.	O
however	O
,	O
the	O
other	O
and	O
resegmentation	B
[	O
15	O
]	O
.	O
the	O
clr	O
cluster	O
recombination	O
stage	B
components	B
of	O
the	O
systems	O
generally	O
match	O
those	O
used	O
in	O
which	O
included	O
feature	O
warping	O
produced	O
a	O
further	O
reduction	O
broadcast	O
news	O
with	O
only	O
the	O
pretrained	O
models	B
and	O
in	O
some	O
to	O
around	O
8.5%–9.5	O
%	O
[	O
14	O
]	O
,	O
[	O
17	O
]	O
,	O
and	O
using	O
the	O
whole	O
of	O
the	O
cases	O
parameters	O
being	O
changed	O
to	O
reﬂect	O
the	O
new	O
domain	B
.	O
rt-04f	O
evaluation	B
data	B
in	O
the	O
ubm	O
build	O
of	O
the	O
clr	O
cluster	O
indeed	O
,	O
[	O
6	O
]	O
is	O
working	O
toward	O
the	O
goal	O
of	O
complete	O
portability	O
recombination	O
stage	B
gave	O
a	O
ﬁnal	O
performance	O
of	O
6.9	O
%	O
[	O
17	O
]	O
.	O
between	O
domains	O
by	O
trying	O
to	O
remove	O
domain	B
-	O
speciﬁc	O
models	B
the	O
proxy	O
model	B
technique	B
performed	O
better	O
than	O
the	O
equiva-	O
and	O
parameters	O
completely	O
.	O
lent	O
bic	B
stages	O
,	O
giving	O
14.1	O
%	O
initially	O
and	O
11.0	O
%	O
after	O
clr	O
other	O
tasks	O
,	O
such	O
as	O
ﬁnding	O
true	O
speaker	B
identities	O
(	O
see	O
sec-	O
cluster	O
recombination	O
and	O
resegmentation	B
[	O
15	O
]	O
.	O
the	O
e	O
-	O
hmm	O
tion	O
ii	O
-	O
h	O
)	O
or	O
speaker	B
tracking	O
(	O
e.g.	O
,	O
in	O
[	O
54	O
]	O
)	O
are	O
increasingly	O
system	O
,	O
despite	O
not	O
being	O
tuned	O
on	O
the	O
u.s	O
.	O
broadcast	O
news	O
using	O
diarization	B
output	B
as	O
a	O
starting	O
point	O
and	O
performance	O
is	O
development	O
sets	O
,	O
gave	O
16.1	O
%	O
der	O
.	O
approaching	O
a	O
level	B
where	O
it	O
can	O
be	O
considered	O
“	O
useful	O
”	O
for	O
real	O
for	O
the	O
system	O
with	O
the	O
lowest	O
der	O
,	O
the	O
per	O
-	O
show	O
results	B
are	O
human	O
interaction	O
.	O
given	O
in	O
fig	O
.	O
4	O
.	O
typical	O
of	O
most	O
systems	O
,	O
there	O
is	O
a	O
large	O
vari-	O
additions	O
to	O
applications	O
which	O
display	O
audio	O
and	O
optionally	O
ability	O
in	O
performance	O
over	O
the	O
shows	O
,	O
reﬂecting	O
the	O
variability	O
transcriptions	B
,	O
such	O
as	O
wavesurfer1	O
(	O
see	O
fig	O
.	O
5	O
)	O
or	O
transcriber2	O
in	O
the	O
number	O
of	O
speakers	O
,	O
the	O
dominance	O
of	O
speakers	O
,	O
and	O
the	O
style	O
and	O
structure	O
of	O
the	O
speech	O
.	O
most	O
of	O
the	O
variability	O
is	O
from	O
1wavesurfer	O
is	O
available	O
from	O
www.speech.kth.se/wavesurfer	O
the	O
speaker	B
error	O
component	O
due	O
to	O
over	O
or	O
under	O
clustering	B
.	O
2transcriber	O
is	O
available	O
from	O
http://trans.sourceforge.net/1564	O
ieee	O
transactions	O
on	O
audio	O
,	O
speech	O
,	O
and	O
language	B
processing	I
,	O
vol	O
.	O
14	O
,	O
no	O
.	O
5	O
,	O
september	O
2006	O
[	O
6	O
]	O
x.	O
anguera	O
,	O
c.	O
wooters	O
,	O
b.	O
peskin	O
,	O
and	O
m.	O
aguiló	O
,	O
“	O
robust	B
speaker	I
segmentation	B
for	O
meetings	O
:	O
the	O
icsi	O
-	O
sri	O
spring	O
2005	O
diarization	B
system	O
,	O
”	O
in	O
proc	O
.	O
machine	O
learning	O
for	O
multimodal	O
interaction	O
work-	O
shop	O
(	O
mlmi	O
)	O
,	O
edinburgh	O
,	O
u.k	O
.	O
,	O
jul	O
.	O
2005	O
,	O
pp	O
.	O
402–414	O
.	O
[	O
7	O
]	O
benchmark	O
tests	O
:	O
rich	B
transcription	I
(	O
rt	O
)	O
.	O
nist	O
.	O
[	O
online	O
]	O
.	O
available	O
:	O
http://www.nist.gov/speech/tests/rt/	O
[	O
8	O
]	O
benchmark	O
tests	O
:	O
speaker	B
recognition	O
.	O
nist	O
.	O
[	O
online	O
]	O
.	O
available	O
:	O
http://www.nist.gov/speech/tests/spk/	O
[	O
9	O
]	O
a.	O
martin	O
and	O
m.	O
przybocki	O
,	O
“	O
speaker	B
recognition	O
in	O
a	O
multi	O
-	O
speaker	B
environment	O
,	O
”	O
in	O
proc	O
.	O
eur	O
.	O
conf	O
.	O
speech	O
commun	O
.	O
technol	O
.	O
,	O
vol	O
.	O
2	O
,	O
aal-	O
borg	O
,	O
denmark	O
,	O
sep	O
.	O
2001	O
,	O
pp	O
.	O
787–790	O
.	O
[	O
10	O
]	O
d.	O
moraru	O
,	O
l.	O
besacier	O
,	O
and	O
e.	O
castelli	O
,	O
“	O
using	O
a	O
-	O
priori	O
information	B
for	O
speaker	B
diarization	I
,	O
”	O
in	O
proc	O
.	O
odyssey	O
speaker	B
and	O
language	O
recogni-	O
tion	O
workshop	O
,	O
toledo	O
,	O
spain	O
,	O
may	O
2004	O
,	O
pp	O
.	O
355–362	O
.	O
[	O
11	O
]	O
c.	O
wooters	O
,	O
j.	O
fung	O
,	O
b.	O
peskin	O
,	O
and	O
x.	O
anguera	O
,	O
“	O
toward	O
robust	B
speaker	I
segmentation	B
:	O
the	O
icsi	O
-	O
sri	O
fall	O
2004	O
diarization	B
system	O
,	O
”	O
in	O
proc	O
.	O
fall	O
2004	O
rich	B
transcription	I
workshop	O
(	O
rt-04	O
)	O
,	O
palisades	O
,	O
ny	O
,	O
nov	O
.	O
2004	O
,	O
[	O
online	O
]	O
.	O
available	O
:	O
http://www.icsi.berkeley.edu/cgi-	O
fig	O
.	O
6	O
.	O
diarization	B
information	B
,	O
including	O
automatically	O
found	O
speaker	B
bin	O
/	O
pubs	O
/	O
publication.pl?id=000100	O
.	O
identities	O
,	O
being	O
used	O
in	O
the	O
“	O
transcriber	O
”	O
tool	O
to	O
improve	O
readability	O
[	O
12	O
]	O
p.	O
nguyen	O
,	O
l.	O
rigazio	O
,	O
y.	O
moh	O
,	O
and	O
j.	O
c.	O
junqua	O
.	O
rich	B
transcription	I
and	O
facilitate	O
searching	O
by	O
speaker	B
.	O
(	O
color	O
version	O
available	O
online	O
at	O
2002	O
site	O
report	O
.	O
panasonic	O
speech	O
technology	O
laboratory	O
(	O
pstl	O
)	O
.	O
pre-	O
http://ieeexplore.ieee.org	O
.	O
)	O
sented	O
at	O
proc	O
.	O
rich	B
transcription	I
workshop	O
(	O
rt-02	O
)	O
.	O
[	O
online	O
]	O
.	O
avail-	O
able	O
:	O
http://www.nist.gov/speech/tests/rt/rt2002/presentations/rt02.pdf	O
(	O
see	O
fig	O
.	O
6	O
)	O
,	O
and	O
the	O
inclusion	O
in	O
complete	O
retrieval	O
systems	O
such	O
[	O
13	O
]	O
j.-l	O
.	O
gauvain	O
,	O
l.	O
lamel	O
,	O
and	O
g.	O
adda	O
,	O
“	O
partitioning	O
and	O
transcription	B
of	O
as	O
rough	O
’	O
n	O
’	O
ready	O
[	O
55	O
]	O
and	O
speechfind	O
[	O
56	O
]	O
allow	O
users	O
to	O
broadcast	O
news	O
data	B
,	O
”	O
in	O
proc	O
.	O
int	O
.	O
conf	O
.	O
spoken	O
lang	O
.	O
process	B
.	O
,	O
vol	O
.	O
4	O
,	O
sydney	O
,	O
australia	O
,	O
dec	O
.	O
1998	O
,	O
pp	O
.	O
1335–1338	O
.	O
see	O
the	O
current	O
speaker	B
information	B
,	O
understand	O
the	O
general	O
ﬂow	O
[	O
14	O
]	O
x.	O
zhu	O
,	O
c.	O
barras	O
,	O
s.	O
meignier	O
,	O
and	O
j.-l	O
.	O
gauvain	O
,	O
“	O
combining	O
of	O
speakers	O
throughout	O
the	O
broadcast	O
,	O
or	O
search	O
for	O
a	O
particular	O
speaker	B
identiﬁcation	O
and	O
bic	B
for	O
speaker	B
diarization	I
,	O
”	O
in	O
proc	O
.	O
eur	O
.	O
speaker	B
within	O
the	O
audio	O
.	O
experiments	O
are	O
also	O
underway	O
to	O
as-	O
conf	O
.	O
speech	O
commun	O
.	O
technol	O
.	O
,	O
lisbon	O
,	O
portugal	O
,	O
sep	O
.	O
2005	O
,	O
pp	O
.	O
2441–2444	O
.	O
certain	O
if	O
additional	O
tasks	O
,	O
such	O
as	O
the	O
process	B
of	O
annotating	O
data	B
,	O
[	O
15	O
]	O
d.	O
a.	O
reynolds	O
and	O
p.	O
torres	O
-	O
carrasquillo	O
,	O
“	O
the	O
mit	O
lincoln	O
labora-	O
can	O
be	O
facilitated	O
using	O
diarization	B
output	B
.	O
tory	O
rt-04f	O
diarization	B
systems	I
:	O
applications	O
to	O
broadcast	O
audio	O
and	O
the	O
diarization	B
tasks	O
of	O
the	O
future	O
will	O
cover	O
a	O
wider	O
scope	O
telephone	O
conversations	O
,	O
”	O
in	O
proc	O
.	O
fall	O
2004	O
rich	B
transcription	I
work-	O
shop	O
(	O
rt-04	O
)	O
,	O
palisades	O
,	O
ny	O
,	O
nov	O
.	O
2004	O
.	O
than	O
currently	O
,	O
both	O
in	O
terms	B
of	O
the	O
amount	B
of	O
data	B
(	O
hundreds	O
of	O
[	O
16	O
]	O
t.	O
hain	O
,	O
s.	O
e.	O
johnson	O
,	O
a.	O
tuerk	O
,	O
p.	O
c.	O
woodland	O
,	O
and	O
s.	O
j.	O
young	O
.	O
hours	B
)	O
and	O
information	B
required	O
(	O
speaker	B
identity	O
,	O
speaker	B
char-	O
segment	B
generation	O
and	O
clustering	B
in	O
the	O
htk	O
broadcast	O
news	O
tran-	O
acteristics	O
,	O
or	O
potentially	O
even	O
emotion	O
)	O
.	O
current	O
techniques	B
and	O
scription	O
system	O
.	O
presented	O
at	O
proc	O
.	O
1998	O
darpa	O
broadcast	O
news	O
transcription	B
and	O
understanding	O
workshop	O
.	O
[	O
online	O
]	O
.	O
available	O
:	O
toolkits	O
(	O
for	O
example	O
,	O
alize	O
[	O
57	O
]	O
)	O
will	O
provide	O
a	O
ﬁrm	O
base	O
to	O
http://mi.eng.cam.ac.uk/reports/abstracts/hain_darpa98.html	O
start	O
from	O
,	O
but	O
new	O
methods	O
,	O
particularly	O
combining	O
informa-	O
[	O
17	O
]	O
r.	O
sinha	O
,	O
s.	O
e.	O
tranter	O
,	O
m.	O
j.	O
f.	O
gales	O
,	O
and	O
p.	O
c.	O
woodland	O
,	O
“	O
the	O
tion	O
from	O
many	O
different	O
approaches	O
(	O
as	O
is	O
currently	O
done	O
in	O
cambridge	O
university	O
march	O
2005	O
speaker	B
diarization	I
system	I
,	O
”	O
in	O
proc	O
.	O
eur	O
.	O
conf	O
.	O
speech	O
commun	O
.	O
technol	O
.	O
,	O
lisbon	O
,	O
portugal	O
,	O
sep	O
.	O
the	O
speaker	B
recognition	O
ﬁeld	O
[	O
58	O
]	O
)	O
will	O
need	O
to	O
be	O
developed	O
to	O
2005	O
,	O
pp	O
.	O
2437–2440	O
.	O
allow	O
diarization	B
to	O
be	O
maximally	O
beneﬁcial	O
to	O
real	O
users	O
and	O
po-	O
[	O
18	O
]	O
d.	O
liu	O
and	O
f.	O
kubala	O
,	O
“	O
fast	O
speaker	B
change	I
detection	B
for	O
broadcast	O
tential	O
downstream	O
processing	B
such	O
as	O
machine	O
translation	O
and	O
news	O
transcription	B
and	O
indexing	O
,	O
”	O
in	O
proc	O
.	O
eur	O
.	O
conf	O
.	O
speech	O
commun	O
.	O
technol	O
.	O
,	O
vol	O
.	O
iii	O
,	O
budapest	O
,	O
hungary	O
,	O
sep	O
.	O
1999	O
,	O
pp	O
.	O
parsing	O
.	O
additionally	O
,	O
further	O
development	O
of	O
tools	O
to	O
allow	O
user	O
1031–1034	O
.	O
interactions	O
with	O
diarization	B
output	B
for	O
speciﬁc	O
jobs	O
will	O
help	O
[	O
19	O
]	O
s.	O
meignier	O
,	O
d.	O
moraru	O
,	O
c.	O
fredouille	O
,	O
j.-f	O
.	O
bonastre	O
,	O
and	O
l.	O
besacier	O
,	O
focus	O
the	O
research	B
to	O
contribute	O
to	O
high	O
-	O
utility	O
human	O
language	O
“	O
step	O
-	O
by	O
-	O
step	O
and	O
integrated	O
approaches	O
in	O
broadcast	O
news	O
speaker	B
di-	O
arization	O
,	O
”	O
comput	O
.	O
speech	O
lang	O
.	O
,	O
no	O
.	O
20	O
,	O
pp	O
.	O
303–330	O
,	O
sep	O
.	O
2005	O
,	O
to	O
technology	O
.	O
be	O
published	O
.	O
[	O
20	O
]	O
s.	O
e.	O
tranter	O
and	O
d.	O
a.	O
reynolds	O
,	O
“	O
speaker	B
diarization	I
for	O
broadcast	O
acknowledgment	O
news	O
,	O
”	O
in	O
proc	O
.	O
odyssey	O
speaker	B
and	O
language	O
recognition	O
workshop	O
,	O
toledo	O
,	O
spain	O
,	O
jun	O
.	O
2004	O
,	O
pp	O
.	O
337–344	O
.	O
the	O
authors	O
would	O
like	O
to	O
thank	O
c.	O
barras	O
,	O
j.-f	O
.	O
bonastre	O
,	O
c.	O
[	O
21	O
]	O
s.	O
e.	O
tranter	O
,	O
k.	O
yu	O
,	O
g.	O
evermann	O
,	O
and	O
p.	O
c.	O
woodland	O
,	O
“	O
generating	O
fredouille	O
,	O
p.	O
nguyen	O
,	O
p.	O
torres	O
-	O
carrasquillo	O
,	O
and	O
c.	O
wooters	O
and	O
evaluating	O
segmentations	O
for	O
automatic	O
speech	B
recognition	I
of	O
con-	O
versational	O
telephone	B
speech	I
,	O
”	O
in	O
proc	O
.	O
icassp	O
,	O
vol	O
.	O
i	O
,	O
montreal	O
,	O
qc	O
,	O
for	O
their	O
help	O
in	O
the	O
construction	O
of	O
this	O
paper	O
.	O
canada	O
,	O
may	O
2004	O
,	O
pp	O
.	O
753–756	O
.	O
[	O
22	O
]	O
d.	O
liu	O
and	O
f.	O
kubala	O
,	O
“	O
a	O
cross	O
-	O
channel	O
modeling	O
approach	O
for	O
au-	O
references	B
tomatic	O
segmentation	B
of	O
conversational	O
telephone	B
speech	I
,	O
”	O
in	O
proc	O
.	O
ieee	O
asru	O
workshop	O
,	O
st	O
.	O
thomas	O
,	O
u.s	O
.	O
virgin	O
islands	O
,	O
dec	O
.	O
2003	O
,	O
pp	O
.	O
[	O
1	O
]	O
d.	O
a.	O
reynolds	O
and	O
p.	O
torres	O
-	O
carrasquillo	O
,	O
“	O
approaches	O
and	O
applica-	O
333–338	O
.	O
tions	O
of	O
audio	O
diarization	B
,	O
”	O
in	O
proc	O
.	O
ieee	O
int	O
.	O
conf	O
.	O
acoust	O
.	O
,	O
speech	O
,	O
[	O
23	O
]	O
d.	O
a.	O
van	O
leeuwan	O
,	O
“	O
the	O
tno	O
speaker	B
diarization	I
system	I
for	O
nist	O
signal	B
process	B
.	O
,	O
vol	O
.	O
v	O
,	O
philadelphia	O
,	O
pa	O
,	O
mar	O
.	O
2005	O
,	O
pp	O
.	O
953–956	O
.	O
rt05s	O
meeting	O
data	B
,	O
”	O
in	O
proc	O
.	O
machine	O
learning	O
for	O
multimodal	O
[	O
2	O
]	O
j.	O
saunders	O
,	O
“	O
real	O
-	O
time	B
discrimination	O
of	O
broadcast	O
speech	O
/	O
music	O
,	O
”	O
in	O
interaction	O
workshop	O
(	O
mlmi	O
)	O
,	O
edinburgh	O
,	O
uk	O
,	O
jul	O
.	O
2005	O
,	O
pp	O
.	O
proc	O
.	O
ieee	O
int	O
.	O
conf	O
.	O
acoust	O
.	O
,	O
speech	O
,	O
signal	B
process	B
.	O
,	O
vol	O
.	O
ii	O
,	O
atlanta	O
,	O
440–449	O
.	O
ga	O
,	O
may	O
1996	O
,	O
pp	O
.	O
993–996	O
.	O
[	O
24	O
]	O
d.	O
istrate	O
,	O
c.	O
fredouille	O
,	O
s.	O
meignier	O
,	O
l.	O
besacier	O
,	O
and	O
j.-f	O
.	O
bonastre	O
,	O
[	O
3	O
]	O
z.	O
liu	O
,	O
y.	O
wang	O
,	O
and	O
t.	O
chen	O
,	O
“	O
audio	O
feature	O
extraction	B
and	O
analysis	B
“	O
nist	O
rt’05	O
evaluation	B
:	O
preprocessing	O
techniques	B
and	O
speaker	B
diariza-	O
for	O
scene	O
segmentation	B
and	O
classiﬁcation	O
,	O
”	O
j.	O
vlsi	O
signal	B
process	B
.	O
syst	O
.	O
,	O
tion	O
on	O
multiple	O
microphone	O
meetings	O
,	O
”	O
in	O
proc	O
.	O
machine	O
learning	O
for	O
vol	O
.	O
20	O
,	O
no	O
.	O
1–2	O
,	O
pp	O
.	O
61–79	O
,	O
oct	O
.	O
1998	O
.	O
multimodal	O
interaction	O
workshop	O
(	O
mlmi	O
)	O
,	O
edinburgh	O
,	O
u.k	O
.	O
,	O
jul	O
.	O
2005	O
,	O
[	O
4	O
]	O
s.	O
e.	O
johnson	O
and	O
p.	O
c.	O
woodland	O
,	O
“	O
a	O
method	B
for	O
direct	O
audio	O
search	O
pp	O
.	O
428–439	O
.	O
with	O
applications	O
to	O
indexing	O
and	O
retrieval	O
,	O
”	O
in	O
proc	O
.	O
ieee	O
int	O
.	O
conf	O
.	O
[	O
25	O
]	O
s.	O
cassidy	O
,	O
“	O
the	O
macquarie	O
speaker	B
diarization	I
system	I
for	O
rt05s	O
,	O
”	O
in	O
acoust	O
.	O
,	O
speech	O
,	O
signal	B
process	B
.	O
,	O
vol	O
.	O
3	O
,	O
istanbul	O
,	O
turkey	O
,	O
jun	O
.	O
2000	O
,	O
pp	O
.	O
proc	O
.	O
nist	O
spring	O
rich	B
transcription	I
evaluation	B
workshop	O
(	O
rt-05s	O
)	O
,	O
1427–1430	O
.	O
edinburgh	O
,	O
uk	O
,	O
jul	O
.	O
2005	O
.	O
[	O
5	O
]	O
y.	O
moh	O
,	O
p.	O
nguyen	O
,	O
and	O
j.-c	O
.	O
junqua	O
,	O
“	O
toward	O
domain	B
independent	O
clus-	O
[	O
26	O
]	O
t.	O
pfau	O
,	O
d.	O
ellis	O
,	O
and	O
a.	O
stolcke	O
,	O
“	O
multispeaker	O
speech	B
activity	I
detection	I
tering	O
,	O
”	O
in	O
proc	O
.	O
ieee	O
int	O
.	O
conf	O
.	O
acoust	O
.	O
,	O
speech	O
,	O
signal	B
process	B
.	O
,	O
vol	O
.	O
for	O
the	O
icsi	O
meeting	O
recorder	O
,	O
”	O
in	O
proc	O
.	O
ieee	O
asru	O
workshop	O
,	O
trento	O
,	O
ii	O
,	O
china	O
,	O
apr	O
.	O
2003	O
,	O
pp	O
.	O
85–88	O
.	O
italy	O
,	O
dec	O
.	O
2001	O
,	O
pp	O
.	O
107–110.tranter	O
and	O
reynolds	O
:	O
overview	O
of	O
automatic	O
speaker	B
diarisation	O
systems	O
1565	O
[	O
27	O
]	O
j.	O
g.	O
fiscus	O
,	O
n.	O
radde	O
,	O
j.	O
s.	O
garofolo	O
,	O
a.	O
le	O
,	O
j.	O
ajot	O
,	O
and	O
c.	O
laprun	O
,	O
[	O
47	O
]	O
s.	O
e.	O
tranter	O
,	O
“	O
who	O
really	O
spoke	O
when?—finding	O
speaker	B
turns	O
and	O
“	O
the	O
rich	B
transcription	I
2005	O
spring	O
meeting	O
recogntion	O
evaluation	B
,	O
”	O
in	O
identities	O
in	O
audio	O
,	O
”	O
in	O
proc	O
.	O
ieee	O
int	O
.	O
conf	O
.	O
acoust	O
.	O
,	O
speech	O
,	O
signal	B
proc	O
.	O
machine	O
learning	O
for	O
multimodal	O
interaction	O
workshop	O
(	O
mlmi	O
)	O
,	O
process	B
.	O
,	O
vol	O
.	O
i	O
,	O
toulouse	O
,	O
france	O
,	O
may	O
2006	O
,	O
pp	O
.	O
1013–1016	O
.	O
edinburgh	O
,	O
uk	O
,	O
jul	O
.	O
2005	O
,	O
pp	O
.	O
369–389	O
.	O
[	O
48	O
]	O
m.	O
j.	O
f.	O
gales	O
,	O
d.	O
y.	O
kim	O
,	O
p.	O
c.	O
woodland	O
,	O
h.	O
y.	O
chan	O
,	O
d.	O
mrva	O
,	O
r.	O
sinha	O
,	O
[	O
28	O
]	O
s.	O
s.	O
chen	O
and	O
p.	O
s.	O
gopalakrishnam	O
,	O
“	O
speaker	B
,	O
environment	O
and	O
s.	O
e.	O
tranter	O
,	O
“	O
progress	O
in	O
the	O
cu	O
-	O
htk	O
transcription	B
system	O
,	O
”	O
ieee	O
and	O
channel	O
change	B
detection	I
and	O
clustering	B
via	O
the	O
bayesian	O
trans	O
.	O
audio	O
,	O
speech	O
,	O
lang	O
,	O
process	B
.	O
,	O
vol	O
.	O
14	O
,	O
no	O
.	O
5	O
,	O
pp	O
.	O
1511–1523	O
,	O
sep	O
.	O
information	B
criterion	B
,	O
”	O
in	O
proc	O
.	O
1998	O
darpa	O
broadcast	O
news	O
2006	O
.	O
transcription	B
and	O
understanding	O
workshop	O
,	O
lansdowne	O
,	O
va	O
,	O
1998	O
,	O
[	O
49	O
]	O
d.	O
moraru	O
,	O
s.	O
meignier	O
,	O
c.	O
fredouille	O
,	O
l.	O
besacier	O
,	O
and	O
j.-f	O
.	O
bonastre	O
,	O
pp	O
.	O
127–132	O
.	O
“	O
the	O
elisa	O
consortium	O
approaches	O
in	O
speaker	B
segmentation	I
during	O
the	O
[	O
29	O
]	O
b.	O
zhou	O
and	O
j.	O
hansen	O
,	O
“	O
unsupervised	O
audio	O
stream	O
segmentation	B
nist	O
2003	O
rich	B
transcription	I
evaluation	B
,	O
”	O
in	O
proc	O
.	O
ieee	O
int	O
.	O
conf	O
.	O
and	O
clustering	B
via	O
the	O
bayesian	O
information	B
criterion	B
,	O
”	O
in	O
proc	O
.	O
int	O
.	O
acoust	O
.	O
,	O
speech	O
,	O
signal	B
process	B
.	O
,	O
vol	O
.	O
1	O
,	O
montreal	O
,	O
qc	O
,	O
canada	O
,	O
may	O
conf	O
.	O
spoken	B
language	I
process	B
.	O
,	O
vol	O
.	O
3	O
,	O
beijing	O
,	O
china	O
,	O
oct	O
.	O
2000	O
,	O
pp	O
.	O
2004	O
,	O
pp	O
.	O
373–376	O
.	O
714–717	O
.	O
[	O
50	O
]	O
s.	O
e.	O
tranter	O
,	O
“	O
two	O
-	O
way	O
cluster	O
voting	O
to	O
improve	O
speaker	B
diarization	I
[	O
30	O
]	O
m.	O
a.	O
siegler	O
,	O
u.	O
jain	O
,	O
b.	O
raj	O
,	O
and	O
r.	O
m.	O
stern	O
,	O
“	O
automatic	O
segmenta-	O
performance	O
,	O
”	O
in	O
proc	O
.	O
ieee	O
int	O
.	O
conf	O
.	O
acoust	O
.	O
,	O
speech	O
,	O
signal	B
process	B
.	O
,	O
tion	O
,	O
classiﬁcation	O
and	O
clustering	B
of	O
broadcast	O
news	O
,	O
”	O
in	O
proc	O
.	O
darpa	O
vol	O
.	O
i	O
,	O
philadelphia	O
,	O
pa	O
,	O
mar	O
.	O
2005	O
,	O
pp	O
.	O
753–756	O
.	O
speech	B
recognition	I
workshop	O
,	O
chantilly	O
,	O
va	O
,	O
feb	O
.	O
1997	O
,	O
pp	O
.	O
97–99	O
.	O
[	O
51	O
]	O
d.	O
liu	O
,	O
d.	O
kiecza	O
,	O
a.	O
srivastava	O
,	O
and	O
f.	O
kubala	O
,	O
“	O
online	O
speaker	B
adap-	O
[	O
31	O
]	O
c.	O
barras	O
,	O
x.	O
zhu	O
,	O
s.	O
meignier	O
,	O
and	O
j.-l	O
.	O
gauvain	O
,	O
“	O
improving	O
speaker	B
tation	O
and	O
tracking	O
for	O
real	O
-	O
time	B
speech	B
recognition	I
,	O
”	O
in	O
proc	O
.	O
eur	O
.	O
conf	O
.	O
diarization	B
,	O
”	O
in	O
proc	O
.	O
fall	O
rich	B
transcription	I
workshop	O
(	O
rt-04	O
)	O
,	O
speech	O
commun	O
.	O
technol	O
.	O
,	O
lisbon	O
,	O
portugal	O
,	O
sep	O
.	O
2005	O
,	O
pp	O
.	O
281–284	O
.	O
palisades	O
,	O
ny	O
,	O
nov	O
.	O
2004	O
,	O
[	O
online	O
]	O
.	O
available	O
:	O
http://www.limsi.fr/in-	O
[	O
52	O
]	O
j.	O
g.	O
fiscus	O
,	O
j.	O
s.	O
garofolo	O
,	O
a.	O
le	O
,	O
a.	O
f.	O
martin	O
,	O
d.	O
s.	O
pallett	O
,	O
m.	O
a.	O
dividu	O
/	O
barras	O
/	O
publis	O
/	O
rt04f_diarization.pdf	O
.	O
przybocki	O
,	O
and	O
g.	O
sanders	O
,	O
“	O
results	B
of	O
the	O
fall	O
2004	O
stt	O
and	O
mde	O
[	O
32	O
]	O
a.	O
e.	O
rosenberg	O
,	O
a.	O
gorin	O
,	O
z.	O
liu	O
,	O
and	O
s.	O
parthasarathy	O
,	O
“	O
unsupervised	O
evaluation	B
,	O
”	O
in	O
proc	O
.	O
fall	O
2004	O
rich	B
transcription	I
workshop	O
(	O
rt-04	O
)	O
,	O
speaker	B
segmentation	I
of	O
telephone	O
conversations	O
,	O
”	O
in	O
proc	O
.	O
int	O
.	O
conf	O
.	O
palisades	O
,	O
ny	O
,	O
nov	O
.	O
2004	O
.	O
spoken	B
language	I
process	B
.	O
,	O
denver	O
,	O
co	O
,	O
sep	O
.	O
2002	O
,	O
pp	O
.	O
565–568	O
.	O
[	O
53	O
]	O
q.	O
jin	O
,	O
k.	O
laskowski	O
,	O
t.	O
schultz	O
,	O
and	O
a.	O
waibel	O
,	O
“	O
speaker	B
segmenta-	O
[	O
33	O
]	O
s.	O
meignier	O
,	O
d.	O
moraru	O
,	O
c.	O
fredouille	O
,	O
l.	O
besacier	O
,	O
and	O
j.-f	O
.	O
bonastre	O
,	O
tion	O
and	O
clustering	B
in	O
meetings	O
,	O
”	O
in	O
proc	O
.	O
icassp	O
meeting	O
recogni-	O
“	O
beneﬁts	O
of	O
prior	O
acoustic	O
segmentation	B
for	O
automatic	O
speaker	B
segmen-	O
tion	O
workshop	O
,	O
montreal	O
,	O
qc	O
,	O
canada	O
,	O
may	O
2004	O
,	O
[	O
online	O
]	O
.	O
available	O
:	O
tation	O
,	O
”	O
in	O
proc	O
.	O
ieee	O
int	O
.	O
conf	O
.	O
acoust	O
.	O
,	O
speech	O
,	O
signal	B
process	B
.	O
,	O
vol	O
.	O
i	O
,	O
http://isl.ira.uka.de/publications/schultzjin_nist04.pdf	O
.	O
montreal	O
,	O
qc	O
,	O
canada	O
,	O
may	O
2004	O
,	O
pp	O
.	O
397–400	O
.	O
[	O
54	O
]	O
d.	O
istrate	O
,	O
n.	O
schefﬂer	O
,	O
c.	O
fredouille	O
,	O
and	O
j.-f	O
.	O
bonastre	O
,	O
“	O
broadcast	O
[	O
34	O
]	O
d.	O
liu	O
and	O
f.	O
kubala	O
,	O
“	O
online	O
speaker	B
clustering	B
,	O
”	O
in	O
proc	O
.	O
ieee	O
int	O
.	O
news	O
speaker	B
tracking	O
for	O
ester	O
2005	O
campaign	O
,	O
”	O
in	O
proc	O
.	O
eur	O
.	O
conf	O
.	O
conf	O
.	O
acoust	O
.	O
,	O
speech	O
,	O
signal	B
process	B
.	O
,	O
vol	O
.	O
i	O
,	O
hong	O
kong	O
,	O
china	O
,	O
apr	O
.	O
speech	O
commun	O
.	O
technol	O
.	O
,	O
lisbon	O
,	O
portugal	O
,	O
sep	O
.	O
2005	O
,	O
pp	O
.	O
2445–2448	O
.	O
2003	O
,	O
pp	O
.	O
572–575	O
.	O
[	O
55	O
]	O
f.	O
kubala	O
,	O
s.	O
colbath	O
,	O
d.	O
liu	O
,	O
a.	O
srivastava	O
,	O
and	O
j.	O
makhoul	O
,	O
“	O
integrated	O
[	O
35	O
]	O
d.	O
moraru	O
,	O
s.	O
meignier	O
,	O
l.	O
besacier	O
,	O
j.-f	O
.	O
bonastre	O
,	O
and	O
i.	O
technologies	O
for	O
indexing	O
spoken	B
language	I
,	O
”	O
commun	O
.	O
acm	O
,	O
vol	O
.	O
43	O
,	O
no	O
.	O
magrin	O
-	O
chagnolleau	O
.	O
the	O
elisa	O
consortium	O
approaches	O
in	O
speaker	B
2	O
,	O
pp	O
.	O
48–56	O
,	O
feb	O
.	O
2000	O
.	O
segmentation	B
during	O
the	O
nist	O
2002	O
speaker	B
recognition	O
evaluation	B
.	O
[	O
56	O
]	O
j.	O
h.	O
l.	O
hansen	O
,	O
r.	O
huang	O
,	O
b.	O
z.	O
m.	O
seadle	O
,	O
j.	O
j.	O
r.	O
deller	O
,	O
a.	O
r.	O
gurijala	O
,	O
presented	O
at	O
proc	O
.	O
ieee	O
int	O
.	O
conf	O
.	O
acoust	O
.	O
,	O
speech	O
,	O
signal	B
process	B
..	O
m.	O
kurimo	O
,	O
and	O
p.	O
angkititrakul	O
,	O
“	O
speechﬁnd	O
:	O
advances	O
in	O
spoken	O
doc-	O
[	O
online	O
]	O
.	O
available	O
:	O
http://www.lia.univ-avignon.fr/ﬁch_art/339-mor-	O
ument	O
retrieval	O
for	O
a	O
national	O
gallery	O
of	O
the	O
spoken	O
word	B
,	O
”	O
ieee	O
trans	O
.	O
icassp2003.pdf	O
speech	O
audio	O
process	B
.	O
,	O
vol	O
.	O
13	O
,	O
no	O
.	O
5	O
,	O
pp	O
.	O
712–730	O
,	O
sep	O
.	O
2005	O
.	O
[	O
36	O
]	O
m.	O
cettolo	O
,	O
“	O
segmentation	B
,	O
classiﬁcation	O
and	O
clustering	B
of	O
an	O
[	O
57	O
]	O
j.	O
f.	O
bonastre	O
,	O
f.	O
wils	O
,	O
and	O
s.	O
meignier	O
,	O
“	O
alize	O
:	O
a	O
free	O
toolkit	O
for	O
speaker	B
italian	O
corpus	B
,	O
”	O
in	O
proc	O
.	O
recherche	O
d’information	O
assisté	O
par	O
or-	O
recogntion	O
,	O
”	O
in	O
proc	O
.	O
ieee	O
int	O
.	O
conf	O
.	O
acoust	O
.	O
,	O
speech	O
,	O
signal	B
process	B
.	O
,	O
dinateur	O
(	O
riao	O
)	O
,	O
paris	O
,	O
france	O
,	O
apr	O
.	O
2000	O
,	O
[	O
online	O
]	O
.	O
available	O
:	O
vol	O
.	O
i	O
,	O
philadelphia	O
,	O
pa	O
,	O
mar	O
.	O
2005	O
,	O
pp	O
.	O
737–740	O
.	O
http://munst.itc.it/people/cettolo/papers/riao00a.ps.gz	O
.	O
[	O
58	O
]	O
d.	O
reynolds	O
,	O
w.	O
andrews	O
,	O
j.	O
campbell	O
,	O
j.	O
navratil	O
,	O
b.	O
peskin	O
,	O
a.	O
adami	O
,	O
[	O
37	O
]	O
j.	O
ajmera	O
and	O
c.	O
wooters	O
,	O
“	O
a	O
robust	B
speaker	I
clustering	B
algorithm	O
,	O
”	O
q.	O
jin	O
,	O
d.	O
klusacek	O
,	O
j.	O
abramson	O
,	O
r.	O
mihaescu	O
,	O
j.	O
godfrey	O
,	O
d.	O
jones	O
,	O
in	O
proc	O
.	O
ieee	O
asru	O
workshop	O
,	O
st	O
thomas	O
,	O
u.s	O
.	O
virgin	O
islands	O
,	O
nov	O
.	O
and	O
b.	O
xiang	O
,	O
“	O
the	O
supersid	O
project	O
:	O
exploiting	O
high	O
-	O
level	B
informa-	O
2003	O
,	O
pp	O
.	O
411–416	O
.	O
tion	O
for	O
high	O
-	O
accuracy	O
speaker	B
recognition	O
,	O
”	O
in	O
proc	O
.	O
ieee	O
int	O
.	O
conf	O
.	O
[	O
38	O
]	O
s.	O
e.	O
tranter	O
,	O
m.	O
j.	O
f.	O
gales	O
,	O
r.	O
sinha	O
,	O
s.	O
umesh	O
,	O
and	O
p.	O
c.	O
wood-	O
acoust	O
.	O
,	O
speech	O
,	O
signal	B
process	B
.	O
,	O
vol	O
.	O
iv	O
,	O
hong	O
kong	O
,	O
china	O
,	O
apr	O
.	O
2003	O
,	O
land	O
,	O
“	O
the	O
development	O
of	O
the	O
cambridge	O
university	O
rt-04	O
diarization	B
pp	O
.	O
784–787	O
.	O
system	O
,	O
”	O
in	O
proc	O
.	O
fall	O
2004	O
rich	B
transcription	I
workshop	O
(	O
rt-04	O
)	O
,	O
pal-	O
isades	O
,	O
ny	O
,	O
nov	O
.	O
2004	O
,	O
[	O
online	O
]	O
.	O
available	O
:	O
http://mi.eng.cam.ac.uk/re-	O
ports	O
/	O
abstracts	O
/	O
tranter_rt04.html	O
.	O
sue	O
e.	O
tranter	O
(	O
m’04	O
)	O
received	O
the	O
m.eng	O
.	O
degree	O
[	O
39	O
]	O
h.	O
jin	O
,	O
f.	O
kubala	O
,	O
and	O
r.	O
schwartz	O
,	O
“	O
automatic	O
speaker	B
clustering	B
,	O
”	O
in	O
in	O
engineering	O
science	O
,	O
specializing	O
in	O
information	B
proc	O
.	O
darpa	O
speech	B
recognition	I
workshop	O
,	O
chantilly	O
,	O
va	O
,	O
feb	O
.	O
1997	O
,	O
engineering	O
,	O
from	O
the	O
university	O
of	O
oxford	O
,	O
oxford	O
,	O
pp	O
.	O
108–111	O
.	O
u.k	O
.	O
,	O
in	O
1996	O
and	O
the	O
m.phil	O
.	O
degree	O
in	O
computer	B
[	O
40	O
]	O
m.	O
ben	O
,	O
m.	O
betser	O
,	O
f.	O
bimbot	O
,	O
and	O
g.	O
gravier	O
,	O
“	O
speaker	B
diarization	I
using	O
speech	O
and	O
language	B
processing	I
from	O
the	O
university	O
bottom	O
-	O
up	O
clustering	B
based	O
on	O
a	O
parameter	O
-	O
derived	O
distance	B
between	O
of	O
cambridge	O
,	O
cambridge	O
,	O
u.k	O
.	O
,	O
in	O
1997	O
.	O
adapted	O
gmms	O
,	O
”	O
in	O
proc	O
.	O
int	O
.	O
conf	O
.	O
spoken	B
language	I
processing	B
,	O
jeju	O
following	O
this	O
,	O
she	O
worked	O
as	O
a	O
research	B
assistant	O
island	O
,	O
korea	O
,	O
oct	O
.	O
2004	O
,	O
pp	O
.	O
2329–2332	O
.	O
on	O
multimedia	O
document	O
retrieval	O
at	O
the	O
university	O
[	O
41	O
]	O
s.	O
meignier	O
,	O
j.-f	O
.	O
bonastre	O
,	O
c.	O
fredouille	O
,	O
and	O
t.	O
merlin	O
,	O
“	O
evolutive	O
of	O
cambridge	O
until	O
2000	O
,	O
and	O
then	O
on	O
nonlinear	O
con-	O
hmm	O
for	O
multispeaker	O
tracking	O
system	O
,	O
”	O
in	O
proc	O
.	O
ieee	O
int	O
.	O
conf	O
.	O
trol	O
theory	O
at	O
the	O
university	O
of	O
oxford	O
.	O
since	O
2002	O
acoust	O
.	O
,	O
speech	O
,	O
signal	B
process	B
.	O
,	O
vol	O
.	O
ii	O
,	O
istanbul	O
,	O
turkey	O
,	O
jun	O
.	O
2000	O
,	O
she	O
has	O
been	O
a	O
research	B
associate	O
on	O
the	O
effective	O
pp	O
.	O
1201–1204	O
.	O
affordable	O
reusable	O
speech	O
-	O
to	O
-	O
text	O
(	O
ears	O
)	O
project	O
at	O
the	O
university	O
of	O
cam-	O
[	O
42	O
]	O
s.	O
meignier	O
,	O
j.-f	O
.	O
bonastre	O
,	O
and	O
s.	O
igounet	O
,	O
“	O
e	O
-	O
hmm	O
approach	O
for	O
bridge	O
,	O
specializing	O
in	O
speaker	B
segmentation	I
and	O
clustering	B
.	O
learning	O
and	O
adapting	O
sound	O
models	B
for	O
speaker	B
indexing	O
,	O
”	O
in	O
proc	O
.	O
odyssey	O
speaker	B
and	O
language	O
recognition	O
workshop	O
,	O
crete	O
,	O
greece	O
,	O
jun	O
.	O
2001	O
,	O
pp	O
.	O
175–180	O
.	O
douglas	O
reynolds	O
(	O
sm’98	O
)	O
received	O
the	O
b.e.e	O
.	O
de-	O
[	O
43	O
]	O
d.	O
reynolds	O
,	O
e.	O
singer	O
,	O
b.	O
carlson	O
,	O
j.	O
o’leary	O
,	O
j.	O
mclaughlin	O
,	O
and	O
m.	O
gree	O
(	O
with	O
highest	O
honors	O
)	O
and	O
the	O
ph.d	O
.	O
degree	O
in	O
zissman	O
,	O
“	O
blind	O
clustering	B
of	O
speech	O
utterances	B
based	O
on	O
speaker	B
and	O
electrical	O
engineering	O
,	O
both	O
from	O
the	O
georgia	O
insti-	O
language	O
characteristics	B
,	O
”	O
in	O
proc	O
.	O
int	O
.	O
conf	O
.	O
spoken	B
language	I
process	B
.	O
,	O
tute	O
of	O
technology	O
,	O
atlanta	O
.	O
vol	O
.	O
7	O
,	O
sydney	O
,	O
australia	O
,	O
dec	O
.	O
1998	O
,	O
pp	O
.	O
3193–3196	O
.	O
he	O
joined	O
the	O
speech	O
systems	O
technology	O
group	O
[	O
44	O
]	O
j.	O
pelecanos	O
and	O
s.	O
sridharan	O
,	O
“	O
feature	O
warping	O
for	O
robust	B
speaker	I
ver-	O
(	O
now	O
the	O
information	B
systems	O
technology	O
group	O
)	O
,	O
iﬁcation	O
,	O
”	O
in	O
proc	O
.	O
odyssey	O
speaker	B
and	O
language	O
recognition	O
work-	O
lincoln	O
laboratory	O
,	O
massachusetts	O
institute	O
of	O
tech-	O
shop	O
,	O
crete	O
,	O
greece	O
,	O
jun	O
.	O
2001	O
,	O
pp	O
.	O
213–218	O
.	O
nology	O
,	O
cambridge	O
,	O
in	O
1992	O
.	O
currently	O
,	O
he	O
is	O
a	O
se-	O
[	O
45	O
]	O
c.	O
barras	O
and	O
j.-l	O
.	O
gauvain	O
,	O
“	O
feature	O
and	O
score	B
normalization	O
for	O
nior	O
member	O
of	O
technical	O
staff	O
and	O
his	O
research	B
in-	O
speaker	B
veriﬁcation	O
of	O
cellular	O
data	B
,	O
”	O
in	O
proc	O
.	O
ieee	O
int	O
.	O
conf	O
.	O
acoust	O
.	O
,	O
terests	O
include	O
robust	B
speaker	I
and	O
language	O
identiﬁ-	O
speech	O
,	O
signal	B
process	B
.	O
,	O
vol	O
.	O
ii	O
,	O
hong	O
kong	O
,	O
china	O
,	O
apr	O
.	O
2003	O
,	O
pp	O
.	O
cation	O
and	O
veriﬁcation	O
,	O
speech	B
recognition	I
,	O
and	O
gen-	O
49–52	O
.	O
eral	O
problems	O
in	O
signal	B
classiﬁcation	O
and	O
clustering	B
.	O
[	O
46	O
]	O
l.	O
canseco	O
-	O
rodriguez	O
,	O
l.	O
lamel	O
,	O
and	O
j.-l	O
.	O
gauvain	O
,	O
“	O
speaker	B
diariza-	O
douglas	O
is	O
a	O
senior	O
member	O
of	O
ieee	O
signal	B
processing	I
society	O
and	O
a	O
co-	O
tion	O
from	O
speech	O
transcripts	B
,	O
”	O
in	O
proc	O
.	O
int	O
.	O
conf	O
.	O
spoken	B
language	I
founder	O
and	O
member	O
of	O
the	O
steering	O
committee	O
of	O
the	O
odyssey	O
speaker	B
recog-	O
process	B
.	O
,	O
jeju	O
island	O
,	O
korea	O
,	O
oct	O
.	O
2004	O
,	O
pp	O
.	O
1272–1275	O
.	O
nition	O

interspeech	O
2011	O
plda	B
-	O
based	O
clustering	B
for	O
speaker	B
diarization	I
of	O
broadcast	O
streams	O
jan	O
silovsky	O
,	O
jan	O
prazak	O
,	O
petr	O
cerva	O
,	O
jindrich	O
zdansky	O
,	O
jan	O
nouza	O
institute	O
of	O
information	B
technology	O
and	O
electronics	O
,	O
faculty	O
of	O
mechatronics	O
,	O
technical	O
university	O
of	O
liberec	O
,	O
czech	O
republic	O
{	O
jan.silovsky,jan.prazak,petr.cerva,jindrich.zdansky,jan.nouza}@tul.cz	O
abstract	O
multiple	O
observations	O
(	O
speech	B
segments	I
in	O
our	O
case	O
)	O
.	O
in	O
con-	O
trast	O
,	O
traditional	O
speaker	B
recognition	O
methods	O
usually	O
handle	O
this	O
paper	O
presents	O
two	O
approaches	O
to	O
speaker	B
clustering	B
based	O
multiple	O
segments	O
by	O
merging	O
them	O
into	O
one	O
segment	B
,	O
or	O
equiv-	O
on	O
probabilistic	O
linear	O
discriminant	B
analysis	I
(	O
plda	B
)	O
in	O
the	O
alently	O
by	O
summation	O
of	O
statistics	B
derived	O
for	O
each	O
segment	B
.	O
speaker	B
diarization	I
task	O
.	O
we	O
refer	O
to	O
the	O
approaches	O
as	O
the	O
multifold	O
-	O
plda	B
approach	O
and	O
the	O
onefold	O
-	O
plda	B
approach	O
.	O
2	O
.	O
speaker	B
diarization	I
system	I
for	O
both	O
approaches	O
,	O
simple	O
factor	B
analysis	I
model	B
is	O
employed	O
to	O
extract	O
low	O
-	O
dimensional	O
representation	O
of	O
a	O
sequence	B
of	O
our	O
speaker	B
diarization	I
system	I
consists	O
of	O
three	O
basic	O
modules	O
.	O
acoustic	O
feature	O
vectors	O
–	O
so	O
called	O
i	O
-	O
vectors	O
–	O
and	O
these	O
i-	O
first	O
,	O
after	O
feature	O
vectors	O
are	O
extracted	O
,	O
speech	B
activity	I
detec-	O
vectors	O
are	O
modeled	O
using	O
the	O
plda	B
model	B
.	O
further	O
,	O
two	O
-	O
stage	B
tion	O
(	O
sad	O
)	O
is	O
applied	O
.	O
then	O
,	O
speaker	B
change	I
points	O
are	O
detected	O
clustering	B
with	O
bayesian	O
information	B
criterion	B
(	O
bic	B
)	O
based	O
ap-	O
by	O
a	O
speaker	B
segmentation	I
module	O
.	O
finally	O
,	O
segments	O
of	O
the	O
proach	O
applied	O
in	O
the	O
ﬁrst	O
stage	B
and	O
the	O
plda	B
-	O
based	O
approach	O
same	O
speakers	O
are	O
clustered	O
and	O
speaker	B
diarization	I
is	O
provided	O
.	O
in	O
the	O
second	O
stage	B
is	O
examined	O
.	O
we	O
carried	O
out	O
our	O
experiments	O
all	O
components	B
of	O
the	O
system	O
use	O
classic	O
mel	O
-	O
frequency	B
cep-	O
using	O
the	O
cost278	O
multilingual	O
broadcast	O
news	O
database	O
.	O
the	O
stral	O
coefﬁcient	O
(	O
mfcc	O
)	O
features	O
.	O
best	O
evaluated	O
system	O
yielded	O
42	O
%	O
relative	O
improvement	O
of	O
the	O
the	O
speech	B
activity	I
detector	O
has	O
two	O
parts	O
-	O
an	O
energy	O
based	B
speaker	I
error	B
rate	I
over	O
a	O
baseline	B
bic	B
-	O
based	O
system	O
.	O
detector	O
with	O
an	O
adaptive	O
threshold	B
and	O
a	O
gaussian	O
mixture	O
index	O
terms	B
:	O
speaker	B
diarization	I
,	O
plda	B
,	O
clustering	B
,	O
i	O
-	O
vectors	O
model	B
(	O
gmm	O
)	O
based	O
detector	O
.	O
the	O
aim	O
of	O
the	O
former	O
is	O
to	O
re-	O
move	O
silent	O
parts	O
from	O
the	O
signal	B
,	O
while	O
the	O
latter	O
does	O
the	O
same	O
for	O
other	O
non	O
-	O
speech	O
events	O
(	O
especially	O
for	O
music	O
and	O
noise	O
)	O
.	O
1	O
.	O
introduction	O
the	O
aim	O
of	O
the	O
speaker	B
segmentation	I
module	O
is	O
to	O
ﬁnd	O
speaker	B
diarization	I
is	O
the	O
process	B
of	O
partitioning	O
an	O
input	B
audio	O
speaker	B
change	I
points	O
in	O
previously	O
identiﬁed	O
speech	B
segments	I
.	O
data	B
into	O
homogeneous	O
segments	O
according	O
to	O
a	O
speciﬁc	O
speaker	B
for	O
that	O
purpose	O
,	O
we	O
use	O
method	B
based	O
on	O
the	O
bayesian	O
in-	O
identity	O
(	O
it	O
solves	O
the	O
”	O
who	O
spoke	O
when	O
”	O
task	O
)	O
and	O
it	O
is	O
a	O
useful	O
formation	O
criterion	B
(	O
bic	B
)	O
introduced	O
in	O
[	O
5	O
]	O
.	O
this	O
technique	B
preprocessing	O
step	O
in	O
speech	O
or	O
speaker	B
recognition	O
and	O
for	O
in-	O
searches	O
for	O
one	O
change	B
point	O
within	O
an	O
adaptive	O
(	O
variable-	O
dexing	O
of	O
audio	O
archives	O
.	O
it	O
can	O
also	O
improve	O
the	O
readability	O
of	O
length	B
)	O
window	O
that	O
moves	O
subsequently	O
through	O
all	O
the	O
speech	O
automatic	O
transcriptions	B
.	O
an	O
inherent	O
part	O
of	O
a	O
speaker	B
diariza-	O
segments	O
.	O
tion	O
system	O
is	O
a	O
clustering	B
module	O
.	O
the	O
aim	O
of	O
clustering	B
is	O
to	O
the	O
clustering	B
module	O
uses	O
bottom	O
-	O
up	O
clustering	B
(	O
a.k.a	O
.	O
hi-	O
group	O
segments	O
of	O
the	O
same	B
speaker	I
together	O
.	O
in	O
this	O
paper	O
,	O
we	O
erarchical	O
agglomerative	O
clustering	B
)	O
which	O
is	O
predominant	O
ap-	O
investigate	O
two	O
clustering	B
approaches	O
based	O
on	O
the	O
probabilistic	O
proach	O
for	O
speaker	B
clustering	B
.	O
first	O
,	O
a	O
similarity	B
measure	O
be-	O
linear	O
discriminant	B
analysis	I
(	O
plda	B
)	O
.	O
tween	O
all	O
pairs	O
of	O
speech	B
segments	I
is	O
computed	O
.	O
next	O
,	O
until	O
the	O
stopping	O
criterion	B
is	O
met	O
,	O
the	O
most	O
similar	O
pair	O
of	O
speech	O
seg-	O
the	O
plda	B
was	O
initially	O
introduced	O
for	O
the	O
face	O
recogni-	O
ments	O
(	O
clusters	O
)	O
is	O
iteratively	O
merged	O
into	O
a	O
new	O
cluster	O
and	O
the	O
tion	O
task	O
[	O
1	O
]	O
and	O
it	O
was	O
recently	O
successfully	O
applied	O
in	O
the	O
similarity	B
measure	O
between	O
the	O
new	O
cluster	O
and	O
all	O
remaining	O
speaker	B
detection	B
task	O
in	O
the	O
nist	O
2010	O
speaker	B
recognition	O
speech	B
segments	I
(	O
clusters	O
)	O
is	O
recomputed	O
.	O
evaluation	B
(	O
sre	O
)	O
[	O
2	O
]	O
.	O
compared	O
to	O
the	O
face	O
recognition	O
task	O
based	O
on	O
comparison	O
of	O
two	O
images	O
of	O
a	O
deﬁned	O
resolution	O
,	O
speaker	B
recognition	O
operates	O
with	O
observations	O
(	O
sequences	O
of	O
3	O
.	O
clustering	B
methods	O
feature	O
vectors	O
)	O
of	O
variable	O
length	B
and	O
thus	O
a	O
projection	O
to	O
a	O
3.1	O
.	O
bic	B
-	O
based	O
clustering	B
ﬁxed	O
-	O
dimensional	O
feature	O
vector	O
must	O
be	O
performed	O
.	O
we	O
ap-	O
ply	O
a	O
simple	O
factor	B
analysis	I
model	B
to	O
extract	O
low	O
-	O
dimensional	O
probably	O
the	O
most	O
popular	O
clustering	B
similarity	B
measure	O
is	O
a	O
representation	O
of	O
audio	O
segments	O
using	O
so	O
called	O
i	O
-	O
vectors	O
as	O
metric	B
based	O
on	O
the	O
bic	B
[	O
5	O
]	O
.	O
the	O
bic	B
-	O
based	O
criterion	B
compares	O
proposed	O
by	O
[	O
3	O
]	O
.	O
the	O
bic	B
statistic	O
of	O
clusters	O
g1	O
and	O
g2	O
with	O
the	O
bic	B
statistic	O
of	O
our	O
motivation	O
for	O
utilization	O
of	O
plda	B
stems	O
from	O
the	O
fol-	O
the	O
cluster	O
g	O
which	O
is	O
formed	O
by	O
merging	O
of	O
the	O
g1	O
and	O
the	O
g2	O
.	O
lowing	O
reasons	O
.	O
first	O
,	O
the	O
plda	B
model	B
provides	O
separation	O
we	O
apply	O
a	O
local	O
bic	B
measure	O
which	O
is	O
deﬁned	O
as	O
of	O
speaker	B
-	O
speciﬁc	O
and	O
nuisance	O
variability	O
.	O
further	O
,	O
plda	B
provides	O
implicitly	O
symmetric	O
scoring	O
.	O
when	O
deciding	O
about	O
δbic(g1	O
,	O
g2	O
)	O
=	O
(	O
n1	O
+	O
n2)log	O
|σ|	O
−	O
n1log	O
|σ1|	O
(	O
1	O
)	O
whether	O
two	O
segments	O
share	O
the	O
same	O
identity	O
or	O
not	O
,	O
traditional	O
−	O
n2log	O
|σ2|	O
−	O
αp	O
speaker	B
recognition	O
methods	O
usually	O
employ	O
a	O
speaker	B
model	B
,	O
where	O
n	O
is	O
the	O
number	O
of	O
frames	O
,	O
σ	O
is	O
the	O
full	O
covariance	O
ma-	O
trained	O
using	O
one	O
of	O
the	O
segments	O
,	O
which	O
is	O
scored	O
against	O
trix	O
of	O
the	O
data	B
and	O
p	O
is	O
the	O
penalty	O
the	O
other	O
segment	B
.	O
cross	O
score	B
is	O
computed	O
for	O
swapped	O
seg-	O
(	O
cid:2	O
)	O
(	O
cid:3	O
)	O
ments	O
[	O
4	O
]	O
and	O
symmetric	O
score	B
is	O
then	O
obtained	O
as	O
average	B
of	O
1	O
1	O
both	O
scores	O
.	O
finally	O
,	O
the	O
plda	B
model	B
supports	O
operation	O
with	O
p	O
=	O
2	O
d	O
+	O
2	O
d(d	O
+	O
1	O
)	O
log(n1	O
+	O
n2	O
)	O
(	O
2	O
)	O
copyright	O
©	O
2011	O
isca	O
2909	O
28-	O
31	O
august	O
2011	O
,	O
florence	O
,	O
italywhere	O
d	O
is	O
the	O
dimension	O
of	O
feature	O
vectors	O
and	O
α	O
is	O
a	O
penalty	O
nz[0	O
,	O
i	O
]	O
.	O
please	O
note	O
that	O
the	O
term	O
v	O
ys	O
depends	O
only	O
on	O
the	O
weight	B
.	O
identity	O
of	O
the	O
speaker	B
and	O
not	O
on	O
the	O
particular	O
segment	B
.	O
in	O
the	O
clustering	B
process	B
,	O
two	O
clusters	O
with	O
the	O
lowest	O
the	O
model	B
represented	O
by	O
eq	O
.	O
(	O
4	O
)	O
can	O
be	O
expressed	O
in	O
terms	B
δbic	O
value	O
are	O
merged	O
together	O
.	O
if	O
a	O
minimal	O
distance	B
be-	O
of	O
conditional	O
probability	B
as	O
follows	O
:	O
tween	O
any	O
pair	O
of	O
clusters	O
is	O
higher	O
than	O
a	O
certain	O
threshold	B
λ	O
(	O
typically	O
zero	O
)	O
,	O
the	O
stopping	O
criterion	B
is	O
met	O
.	O
p(xs	O
,	O
j|ys	O
,	O
zs	O
,	O
j	O
,	O
θ	O
)	O
=	O
nx[μ	O
+	O
v	O
ys	O
+	O
u	O
zs	O
,	O
j	O
,	O
σ	O
]	O
(	O
5	O
)	O
where	O
θ	O
represents	O
the	O
set	B
of	O
parameters	O
{	O
μ	O
,	O
v	O
,	O
u	O
,	O
σ	O
}	O
that	O
are	O
3.2	O
.	O
i	O
-	O
vectors	O
extraction	B
estimated	O
using	O
the	O
expectation	O
maximization	O
(	O
em	O
)	O
algorithm	O
on	O
the	O
background	O
data	B
.	O
these	O
parameters	O
remain	O
ﬁxed	O
during	O
before	O
we	O
can	O
approach	O
plda	B
-	O
based	O
clustering	B
,	O
a	O
ﬁxed-	O
the	O
recognition	O
phase	O
.	O
dimensional	O
representation	O
of	O
a	O
segment	B
of	O
variable	O
length	B
must	O
in	O
recognition	O
,	O
we	O
aim	O
to	O
compute	O
the	O
likelihood	B
of	O
the	O
ob-	O
be	O
extracted	O
.	O
we	O
employ	O
a	O
simple	O
factor	B
analysis	I
model	B
as	O
pro-	O
served	O
data	B
.	O
considering	O
the	O
clustering	B
task	O
,	O
evaluation	B
of	O
the	O
posed	O
by	O
[	O
3	O
]	O
.	O
let	O
’s	O
assume	O
a	O
gmm	O
trained	O
on	O
data	B
pooled	O
from	O
many	O
speakers	O
.	O
this	O
model	B
is	O
typically	O
referred	O
to	O
as	O
the	O
uni-	O
likelihood	B
p(x1	O
...	O
n	O
)	O
that	O
n	O
observations	O
x1	O
...	O
n	O
share	O
the	O
same	O
identity	O
is	O
particularly	O
of	O
our	O
interest	O
.	O
combining	O
the	O
plda	B
versal	O
background	O
model	B
(	O
ubm	O
)	O
.	O
the	O
term	O
supervector	O
is	O
used	O
generative	O
models	B
for	O
all	O
n	O
observations	O
sharing	O
the	O
identity	O
y	O
to	O
refer	O
to	O
a	O
high	O
-	O
dimensional	O
vector	O
obtained	O
by	O
concatenation	O
of	O
mean	O
vectors	O
of	O
components	B
of	O
a	O
gmm	O
.	O
let	O
s	O
be	O
a	O
supervec-	O
we	O
get	O
a	O
compound	O
model	B
:	O
tor	O
representing	O
a	O
speech	B
segment	I
.	O
the	O
speaker	B
-	O
and	O
segment-	O
⎡	O
⎤	O
speciﬁc	O
supervector	O
for	O
j’th	O
segment	B
of	O
a	O
speaker	B
s	O
is	O
deﬁned	O
⎡	O
⎤	O
⎡	O
⎤	O
⎡	O
⎤	O
y	O
⎡	O
⎤	O
using	O
the	O
generative	O
model	B
⎢⎢	O
xx12	O
⎥⎥	O
⎢⎢μμ⎥⎥	O
⎢⎢vv	O
u0	O
u0	O
..	O
..	O
..	O
00	O
⎥⎥	O
⎢⎢⎢	O
zz1	O
⎥⎥⎥	O
⎢⎢	O
(	O
cid:2)(cid:2)12	O
⎥⎥	O
ss	O
,	O
j	O
=	O
m	O
+	O
t	O
xs	O
,	O
j	O
(	O
3	O
)	O
⎢⎣	O
...	O
⎥⎦	O
=	O
⎢⎣	O
...	O
⎥⎦	O
+	O
⎢⎣	O
...	O
...	O
...	O
.	O
.	O
.	O
...	O
⎥⎦	O
⎢⎢⎣	O
..	O
2	O
⎥⎥⎦	O
+	O
⎢⎣	O
...	O
⎥⎦	O
.	O
where	O
m	O
is	O
the	O
speaker	B
-	O
and	O
segment	B
-	O
independent	O
supervector	O
xn	O
μ	O
v	O
0	O
0	O
.	O
.	O
.	O
u	O
z	O
(	O
cid:2)n	O
n	O
(	O
obtained	O
from	O
the	O
ubm	O
)	O
,	O
the	O
t	O
is	O
a	O
rectangular	O
matrix	O
of	O
low	O
(	O
6	O
)	O
rank	O
and	O
xs	O
,	O
j	O
is	O
a	O
random	O
vector	O
having	O
standard	O
normal	O
distri-	O
which	O
we	O
can	O
rewrite	O
as	O
:	O
bution	O
n	O
[	O
0	O
,	O
i	O
]	O
.	O
the	O
matrix	O
t	O
deﬁnes	O
a	O
total	O
variability	O
space	O
and	O
components	B
of	O
the	O
vector	O
x	O
are	O
the	O
total	O
factor	B
loadings	O
.	O
x(cid:2	O
)	O
=	O
μ(cid:2	O
)	O
+	O
aw	O
+	O
(	O
cid:2)(cid:2	O
)	O
(	O
7	O
)	O
following	O
the	O
terminology	O
of	O
[	O
3	O
]	O
we	O
refer	O
to	O
the	O
vector	O
x	O
as	O
the	O
because	O
p(w	O
)	O
=	O
nw[0	O
,	O
i	O
]	O
,	O
the	O
likelihood	B
of	O
the	O
compound	O
i	O
-	O
vector	O
.	O
model	B
is	O
given	O
as	O
:	O
a	O
projection	O
from	O
a	O
sequence	B
of	O
feature	O
vectors	O
represent-	O
ing	O
a	O
speech	B
segment	I
to	O
the	O
i	O
-	O
vector	O
space	O
is	O
provided	O
by	O
com-	O
p(x1	O
...	O
n	O
)	O
=	O
p(x(cid:2	O
)	O
)	O
=	O
nx(cid:2)[μ(cid:2	O
)	O
,	O
aat	O
+	O
σ(cid:2	O
)	O
]	O
(	O
8)	O
putation	O
of	O
a	O
maximum	O
a	O
posterior	O
(	O
map	O
)	O
point	O
estimate	O
of	O
where	O
σ(cid:2	O
)	O
is	O
block	O
diagonal	O
matrix	O
whose	O
diagonal	O
blocks	O
are	O
the	O
total	O
factor	B
loadings	O
based	O
on	O
zero	O
-	O
and	O
ﬁrst	O
-	O
order	B
sufﬁcient	O
σ	O
.	O
eq	O
.	O
8	O
thus	O
represents	O
the	O
likelihood	B
that	O
the	O
segments	O
rep-	O
statistics	B
gathered	O
employing	O
the	O
ubm	O
[	O
6	O
]	O
.	O
having	O
a	O
ﬁxed-	O
dimensional	O
representation	O
we	O
can	O
apply	O
the	O
plda	B
.	O
motivated	O
resented	O
by	O
i	O
-	O
vectors	O
{	O
x1	O
,	O
.	O
.	O
.	O
xn	O
}	O
all	O
share	O
the	O
same	O
identity	O
.	O
please	O
note	O
that	O
no	O
point	O
estimates	O
of	O
hidden	O
variables	O
y	O
or	O
by	O
[	O
3	O
]	O
which	O
deals	O
with	O
application	B
of	O
cosine	O
distance	B
scoring	O
for	O
speaker	B
recognition	O
using	O
i	O
-	O
vectors	O
,	O
we	O
apply	O
unit	O
length	B
{	O
z1	O
,	O
.	O
.	O
.	O
zn	O
}	O
are	O
used	O
for	O
the	O
likelihood	B
computation	O
,	O
instead	O
the	O
hidden	O
variables	O
are	O
integrated	O
out	O
[	O
1	O
]	O
.	O
normalization	O
of	O
i	O
-	O
vectors	O
.	O
3.4	O
.	O
multifold	O
-	O
plda	B
approach	O
3.3	O
.	O
probabilistic	O
linear	O
discriminant	B
analysis	I
in	O
the	O
multifold	O
-	O
plda	B
approach	O
,	O
a	O
cluster	O
is	O
represented	O
by	O
a	O
now	O
we	O
put	O
aside	O
the	O
assumption	O
of	O
i	O
-	O
vectors	O
having	O
distribu-	O
tion	O
n	O
[	O
0	O
,	O
i	O
]	O
and	O
consider	O
another	O
factor	B
analysis	I
model	B
that	O
set	B
of	O
i	O
-	O
vectors	O
corresponding	O
to	O
the	O
segments	O
assigned	O
to	O
the	O
aims	O
to	O
separate	O
speaker	B
-	O
speciﬁc	O
and	O
nuisance	O
variability	O
in	O
the	O
cluster	O
.	O
let	O
x(g	O
)	O
=	O
{	O
x(1g	O
..	O
).j(g	O
)	O
}	O
be	O
the	O
set	B
of	O
j(g	O
)	O
i	O
-	O
vectors	O
i	O
-	O
vector	O
space	O
.	O
the	O
plda	B
model	B
deﬁnes	O
generation	O
process	B
of	O
representing	O
a	O
cluster	O
g	O
and	O
x(cid:2)(g	O
)	O
a	O
compound	O
vector	O
formed	O
the	O
i	O
-	O
vector	O
x	O
as	O
by	O
concatenation	O
of	O
the	O
i	O
-	O
vectors	O
.	O
in	O
the	O
clustering	B
process	B
,	O
we	O
s	O
,	O
j	O
aim	O
to	O
compare	O
the	O
likelihood	B
of	O
two	O
competing	O
models	B
.	O
un-	O
xs	O
,	O
j	O
=	O
μ	O
+	O
v	O
ys	O
+	O
u	O
zs	O
,	O
j	O
+	O
(	O
cid:2)s	O
,	O
j	O
(	O
4	O
)	O
der	O
the	O
ﬁrst	O
model	B
m0	O
,	O
clusters	O
belong	O
to	O
different	O
speakers	O
and	O
thus	O
they	O
have	O
different	O
speaker	B
factor	B
loadings	O
y	O
and	O
y	O
.	O
where	O
μ	O
is	O
the	O
overall	O
speaker	B
-	O
and	O
segment	B
-	O
independent	O
mean	O
while	O
under	O
the	O
second	O
model	B
m1	O
,	O
two	O
clusters	O
belo1ng	O
to	O
th2e	O
of	O
the	O
vectors	O
in	O
the	O
training	O
dataset	O
,	O
columns	O
of	O
the	O
matrix	O
v	O
same	B
speaker	I
and	O
thus	O
have	O
the	O
same	B
speaker	I
factor	B
loadings	O
y.	O
deﬁne	O
bases	O
for	O
the	O
subspace	O
where	O
the	O
speaker	B
-	O
speciﬁc	O
vari-	O
the	O
criterion	B
used	O
to	O
decide	O
whether	O
the	O
data	B
are	O
more	O
likely	O
ability	O
resides	O
(	O
the	O
columns	O
are	O
referred	O
to	O
as	O
eigenvoices	O
)	O
and	O
represented	O
by	O
the	O
model	B
with	O
a	O
shared	O
identity	O
or	O
by	O
the	O
model	B
columns	O
of	O
the	O
matrix	O
u	O
deﬁne	O
bases	O
for	O
the	O
nuisance	O
variabil-	O
with	O
different	O
identities	O
is	O
based	O
on	O
the	O
log	B
-	O
likelihood	B
ratio	I
:	O
ity	O
subspace	O
(	O
the	O
columns	O
are	O
referred	O
to	O
as	O
eigenchannels1	O
)	O
.	O
the	O
term	O
(	O
cid:2)s	O
,	O
j	O
represents	O
unexplained	O
residual	O
variability	O
which	O
llr	O
=	O
log	B
p(x(cid:2)(1	O
)	O
,	O
x(cid:2)(2)|m1	O
)	O
(	O
9	O
)	O
is	O
deﬁned	O
by	O
the	O
diagonal	O
covariance	O
matrix	O
σ	O
.	O
the	O
com-	O
p(x(cid:2)(1	O
)	O
,	O
x(cid:2)(2)|m0	O
)	O
ponents	O
of	O
the	O
vector	O
y	O
are	O
the	O
eigenvoice	O
factor	B
loadings	O
and	O
components	B
of	O
the	O
vsector	O
z	O
are	O
the	O
eigenchannel	O
fac-	O
because	O
the	O
variables	O
y1	O
and	O
y2	O
are	O
independent	O
under	O
the	O
tor	O
loadings	O
.	O
both	O
loadings	O
vectosr	O
,	O
js	O
are	O
assumed	O
to	O
have	O
stan-	O
model	B
m0	O
,	O
the	O
likelihood	B
can	O
be	O
broken	O
down	O
into	O
dard	O
normal	O
distribution	O
,	O
i.e.	O
p(ys	O
)	O
=	O
ny[0	O
,	O
i	O
]	O
and	O
p(zs	O
,	O
j	O
)	O
=	O
p(x(cid:2)(1	O
)	O
,	O
x(cid:2)(2)|m0	O
)	O
=	O
p(x(cid:2)(1)|m0)p(x(cid:2)(2)|m0	O
)	O
(	O
10	O
)	O
1we	O
adopt	O
the	O
terminology	O
used	O
in	O
speaker	B
recognition	O
where	O
chan-	O
the	O
likelihood	B
for	O
the	O
model	B
m1	O
is	O
given	O
as	O
follows	O
:	O
nel	O
variability	O
is	O
usually	O
supposed	O
to	O
represent	O
not	O
only	O
variance	O
be-	O
tween	O
telephone	O
and	O
microphone	O
speech	O
but	O
all	O
the	O
nuisance	O
variability	O
.	O
p(x(cid:2)(1	O
)	O
,	O
x(cid:2)(2)|m1	O
)	O
=	O
p(x(cid:2)|m1	O
)	O
(	O
11	O
)	O
2910where	O
x(cid:2	O
)	O
is	O
formed	O
by	O
concatenation	O
of	O
vectors	O
x(cid:2)(1	O
)	O
and	O
x(cid:2)(2	O
)	O
.	O
fa	O
reﬂects	O
the	O
amount	B
of	O
non	O
-	O
speech	B
segments	I
that	O
were	O
rec-	O
likelihoods	O
on	O
the	O
right	O
-	O
hand	O
side	O
of	O
eqs	O
.	O
(	O
10	O
)	O
and	O
(	O
11	O
)	O
cor-	O
ognized	O
as	O
speech	O
and	O
the	O
miss	B
reﬂects	O
the	O
amount	B
of	O
speech	O
respond	O
to	O
models	B
with	O
a	O
single	O
identity	O
and	O
are	O
computed	O
ac-	O
segments	O
that	O
were	O
recognized	O
as	O
non	O
-	O
speech	O
.	O
because	O
all	O
our	O
cording	O
to	O
(	O
8)	O
.	O
evaluated	O
systems	O
share	O
the	O
same	O
sad	O
and	O
speaker	B
segmen-	O
in	O
the	O
clustering	B
process	B
,	O
the	O
two	O
clusters	O
with	O
the	O
highest	O
tation	O
modules	O
,	O
we	O
use	O
the	O
spke	O
as	O
the	O
primary	O
metric	B
.	O
the	O
llr	O
value	O
are	O
merged	O
together	O
.	O
if	O
a	O
maximum	O
llr	O
value	O
for	O
nist	O
scoring	O
tool2	O
was	O
employed	O
to	O
compute	O
the	O
metrics	O
for	O
any	O
pair	O
of	O
clusters	O
is	O
lower	O
than	O
a	O
certain	O
threshold	B
λ	O
,	O
estimated	O
our	O
experiments	O
.	O
likewise	O
in	O
[	O
8	O
]	O
,	O
a	O
forgiveness	O
collar	O
of	O
0.25	O
s	O
on	O
the	O
development	B
data	I
,	O
the	O
stopping	O
criterion	B
is	O
met	O
.	O
(	O
both	O
+	O
and	O
-	O
)	O
was	O
not	O
scored	O
around	O
each	O
boundary	O
.	O
3.5	O
.	O
onefold	O
-	O
plda	B
approach	O
4.3	O
.	O
baseline	B
system	I
in	O
the	O
onefold	O
-	O
plda	B
approach	O
,	O
a	O
cluster	O
is	O
represented	O
by	O
a	O
sin-	O
the	O
sad	O
achieved	O
fa	O
of	O
0.8	O
%	O
and	O
miss	B
of	O
3.2	O
%	O
.	O
we	O
found	O
gle	O
i	O
-	O
vector	O
.	O
sufﬁcient	O
statistics	B
gathered	O
employing	O
the	O
ubm	O
that	O
higher	O
value	O
of	O
the	O
miss	B
is	O
caused	O
by	O
inaccuracy	O
of	O
refer-	O
for	O
each	O
segment	B
assigned	O
to	O
the	O
cluster	O
are	O
summed	O
together	O
ence	O
annotations	O
.	O
the	O
average	B
length	B
of	O
speech	B
segments	I
after	O
and	O
a	O
map	O
point	O
estimate	O
of	O
the	O
total	O
factor	B
loadings	O
extracted	O
segmentation	B
was	O
3.6	O
s.	O
based	O
on	O
these	O
summed	O
statistics	B
.	O
although	O
,	O
compared	O
to	O
the	O
the	O
baseline	B
system	I
employs	O
the	O
bic	B
-	O
based	O
clustering	B
ap-	O
multifold	O
-	O
plda	B
system	O
,	O
an	O
i	O
-	O
vector	O
must	O
be	O
extracted	O
every	O
proach	O
.	O
first	O
,	O
performance	O
for	O
different	O
values	B
of	O
the	O
bic	B
time	B
a	O
new	O
cluster	O
is	O
formed	O
,	O
the	O
onefold	O
-	O
plda	B
system	O
is	O
less	O
penalty	O
weight	B
α	O
was	O
evaluated	O
.	O
we	O
found	O
that	O
the	O
systems	O
computational	O
expensive	O
as	O
only	O
one	O
i	O
-	O
vector	O
per	O
a	O
cluster	O
par-	O
using	O
a	O
value	O
of	O
the	O
stopping	O
threshold	B
λ	O
estimated	O
on	O
the	O
de-	O
ticipates	O
in	O
the	O
likelihood	B
computation	O
.	O
velopment	O
data	B
yielded	O
better	O
performance	O
than	O
the	O
systems	O
op-	O
likewise	O
in	O
the	O
multifold	O
approach	O
,	O
the	O
clustering	B
process	B
erating	O
with	O
zero	O
value	O
of	O
the	O
threshold	B
.	O
the	O
best	O
performance	O
is	O
driven	O
by	O
the	O
llr	O
values	B
between	O
clusters	O
.	O
was	O
provided	O
by	O
the	O
system	O
using	O
penalty	O
weight	B
α	O
of	O
4.0	O
and	O
the	O
stopping	O
threshold	B
λ	O
of	O
1268.8	O
.	O
the	O
system	O
achieved	O
spke	O
4	O
.	O
experiments	O
and	O
results	B
of	O
24.9	O
%	O
which	O
corresponds	O
to	O
the	O
der	O
of	O
28.9	O
%	O
.	O
these	O
results	B
are	O
considered	O
as	O
baseline	B
.	O
4.1	O
.	O
datasets	B
4.4	O
.	O
plda	B
system	O
training	B
data	I
experiments	O
were	O
carried	O
out	O
using	O
the	O
cost278	O
multilingual	O
pan	O
-	O
european	O
broadcast	O
news	O
database	O
[	O
7	O
]	O
.	O
the	O
database	O
com-	O
the	O
ubm	O
with	O
1024	O
components	B
was	O
trained	O
using	O
data	B
from	O
prises	O
broadcast	O
news	O
recordings	O
in	O
9	O
languages	O
.	O
authors	O
of	O
the	O
1007	O
speakers	O
(	O
2530	O
segments	O
,	O
11.5	O
hours	B
)	O
.	O
the	O
total	O
variabil-	O
database	O
have	O
divided	O
the	O
data	B
for	O
each	O
language	O
into	O
a	O
training	O
ity	O
space	O
was	O
estimated	O
using	O
a	O
subset	O
of	O
the	O
ubm	O
training	B
data	I
set	B
(	O
containing	O
about	O
two	O
hours	B
)	O
and	O
a	O
test	B
set	B
(	O
containing	O
about	O
resulting	O
from	O
the	O
condition	B
of	O
minimal	O
length	B
of	O
a	O
segment	B
of	O
one	O
hour	O
)	O
.	O
3	O
seconds	B
and	O
using	O
at	O
most	O
eight	O
segments	O
per	O
speaker	B
.	O
this	O
we	O
divided	O
the	O
data	B
into	O
three	O
datasets	B
.	O
the	O
ﬁrst	O
set	B
con-	O
resulted	O
in	O
2050	O
segments	O
(	O
10.2	O
hours	B
)	O
from	O
909	O
speakers	O
.	O
the	O
tained	O
all	O
cost278	O
croatian	O
,	O
czech	O
,	O
hungarian	O
,	O
portuguese	O
eigenvoices	O
and	O
eigenchannels	O
were	O
jointly	O
estimated	O
[	O
1	O
]	O
using	O
and	O
slovak	O
training	B
data	I
giving	O
in	O
total	O
11.5	O
hours	B
of	O
audio	O
.	O
this	O
data	B
from	O
speakers	O
for	O
which	O
at	O
least	O
three	O
segments	O
of	O
mini-	O
set	B
was	O
used	O
for	O
training	O
of	O
the	O
ubm	O
and	O
estimation	B
of	O
the	O
total	O
mal	O
length	B
of	O
3	O
seconds	B
are	O
available	O
,	O
in	O
total	O
1528	O
segments	O
variability	O
space	O
and	O
parameters	O
of	O
the	O
plda	B
model	B
.	O
the	O
sec-	O
(	O
7.5	O
hours	B
)	O
from	O
280	O
speakers	O
were	O
used	O
.	O
the	O
average	B
length	B
ond	O
set	B
,	O
consisting	O
of	O
13	O
shows	O
of	O
various	O
lengths	O
(	O
in	O
the	O
range	O
of	O
segments	O
used	O
in	O
training	O
is	O
17.8	O
s.	O
for	O
training	O
of	O
all	O
sub-	O
from	O
8.5	O
to	O
53.8	O
minutes	O
)	O
drawn	O
also	O
from	O
the	O
cost278	O
train-	O
spaces	O
,	O
we	O
employed	O
the	O
em	O
-	O
algorithm	O
proposed	O
by	O
[	O
9	O
]	O
which	O
ing	O
data	B
giving	O
in	O
total	O
5.89	O
hours	B
,	O
was	O
used	O
as	O
the	O
development	O
performs	O
both	O
maximum	O
likelihood	B
and	O
minimum	O
divergence	O
set	B
for	O
tuning	O
of	O
system	O
parameters	O
.	O
particularly	O
for	O
estimation	B
update	O
at	O
each	O
iteration	O
.	O
of	O
segmentation	B
and	O
clustering	B
stopping	O
thresholds	O
.	O
finally	O
,	O
the	O
third	O
set	B
was	O
used	O
as	O
the	O
test	B
set	B
in	O
our	O
experiments	O
.	O
the	O
set	B
4.5	O
.	O
multifold	O
-	O
plda	B
system	O
consisted	O
of	O
15	O
shows	O
of	O
various	O
lengths	O
(	O
in	O
the	O
range	O
from	O
4.1	O
various	O
conﬁgurations	O
were	O
examined	O
differing	O
in	O
the	O
num-	O
to	O
53.2	O
minutes	O
)	O
drawn	O
from	O
the	O
cost278	O
test	B
data	I
giving	O
in	O
ber	O
of	O
gaussians	O
in	O
the	O
ubm	O
,	O
dimension	O
of	O
the	O
total	O
variabil-	O
total	O
6.34	O
hours	B
.	O
the	O
development	O
and	O
test	B
data	I
were	O
limited	O
ity	O
space	O
and	O
the	O
number	O
of	O
eigenvoices	O
and	O
eigenchannels	O
in	O
to	O
5	O
languages	O
:	O
belgian	O
dutch	O
,	O
czech	O
,	O
hungarian	O
,	O
slovenian	O
the	O
plda	B
model	B
.	O
table	O
1	O
shows	O
results	B
for	O
two	O
best	O
perform-	O
and	O
slovak	O
.	O
the	O
streams	O
in	O
cost278	O
corpus	B
contain	O
also	O
com-	O
ing	O
conﬁgurations	O
.	O
the	O
ubm	O
with	O
256	O
gaussians	O
was	O
used	O
mercials	O
which	O
are	O
not	O
annotated	O
.	O
the	O
commercials	O
were	O
thus	O
to	O
extract	O
the	O
sufﬁcient	O
statistics	B
in	O
both	O
cases	O
.	O
although	O
non-	O
removed	O
from	O
the	O
streams	O
used	O
in	O
development	O
and	O
test	B
sets	O
.	O
symmetric	O
numbers	O
of	O
eigenvoices	O
and	O
eigenchannels	O
were	O
also	O
examined	O
,	O
symmetric	O
conﬁgurations	O
always	O
yielded	O
better	O
per-	O
4.2	O
.	O
evaluation	B
metrics	I
formance	O
.	O
the	O
system	O
employing	O
400-dimensional	O
i	O
-	O
vectors	O
performance	O
of	O
diarization	B
systems	I
is	O
usually	O
evaluated	O
by	O
the	O
and	O
the	O
plda	B
model	B
with	O
200	O
eigenvoices	O
and	O
200	O
eigenchan-	O
diarization	B
error	I
rate	I
(	O
der	O
)	O
as	O
the	O
primary	O
metric	B
.	O
the	O
der	O
nels	O
yielded	O
36	O
%	O
reduction	O
of	O
the	O
spke	O
.	O
was	O
deﬁned	O
by	O
the	O
national	O
institute	O
of	O
standards	O
and	O
technol-	O
ogy	O
(	O
nist	O
)	O
[	O
8	O
]	O
and	O
it	O
can	O
be	O
decomposed	O
as	O
:	O
table	O
1	O
:	O
results	B
for	O
the	O
multifold	O
-	O
plda	B
system	O
.	O
der	O
=	O
sp	O
ke	O
+	O
f	O
a	O
+	O
miss	B
(	O
12	O
)	O
rk(t	O
)	O
rk(v	O
)	O
rk(u	O
)	O
spke	O
[	O
%	O
]	O
rel	O
.	O
impr	O
.	O
[	O
%	O
]	O
where	O
the	O
spke	O
represents	O
the	O
speaker	B
error	B
rate	I
,	O
the	O
fa	O
is	O
the	O
300	O
150	O
150	O
17.2	O
30.9	O
speech	O
false	B
alarm	I
error	B
rate	I
and	O
the	O
miss	B
is	O
the	O
missed	O
speech	O
400	O
200	O
200	O
15.9	O
36.1	O
error	B
rate	I
.	O
the	O
spke	O
reﬂects	O
the	O
amount	B
of	O
speech	O
data	B
that	O
is	O
attributed	O
to	O
a	O
wrong	O
speaker	B
given	O
the	O
optimum	O
speaker	B
map-	O
ping	O
between	O
a	O
system	O
output	B
and	O
a	O
reference	B
diarization	B
.	O
the	O
2http://itl.nist.gov/iad/mig/tests/rt/2006-spring/code/md-eval-v21.pl	O
29114.6	O
.	O
onefold	O
-	O
plda	B
system	O
rations	O
from	O
table	O
1	O
.	O
better	O
performance	O
was	O
yielded	O
by	O
the	O
larger	O
system	O
.	O
for	O
the	O
bic	B
penalty	O
weight	B
of	O
2.5	O
,	O
the	O
system	O
table	O
2	O
summarizes	O
results	B
for	O
the	O
best	O
performing	O
setups	O
of	O
the	O
achieved	O
spke	O
of	O
14.7	O
%	O
(	O
41	O
%	O
relative	O
reduction	O
)	O
.	O
compared	O
onefold	O
-	O
plda	B
system	O
(	O
again	O
the	O
ubm	O
with	O
256	O
gaussians	O
was	O
to	O
the	O
onefold	O
-	O
plda	B
system	O
,	O
the	O
multifold	O
-	O
plda	B
seems	O
to	O
employed	O
)	O
and	O
shows	O
that	O
the	O
system	O
also	O
outperforms	O
the	O
base-	O
provide	O
better	O
performance	O
for	O
more	O
under	O
-	O
clustered	O
segments	O
line	O
system	O
.	O
however	O
,	O
the	O
performance	O
improvement	O
is	O
of	O
much	O
which	O
corresponds	O
to	O
the	O
performance	O
of	O
both	O
systems	O
in	O
the	O
smaller	O
extent	O
compared	O
to	O
the	O
multifold	O
-	O
plda	B
system	O
.	O
we	O
at-	O
one	O
-	O
stage	B
clustering	B
scenario	O
.	O
however	O
,	O
two	O
-	O
stage	B
clustering	B
tribute	O
this	O
to	O
the	O
loss	O
of	O
information	B
caused	O
by	O
summation	O
of	O
scenario	O
improves	O
performance	O
for	O
both	O
systems	O
.	O
the	O
sufﬁcient	O
statistics	B
.	O
in	O
case	O
that	O
the	O
clusters	O
belonging	O
to	O
the	O
same	B
speaker	I
are	O
merged	O
together	O
,	O
we	O
obtain	O
a	O
better	O
estimate	O
5	O
.	O
conclusions	O
of	O
i	O
-	O
vector	O
components	B
by	O
virtue	O
of	O
summation	O
of	O
the	O
statistics	B
over	O
the	O
clusters	O
since	O
the	O
summation	O
averages	O
out	O
the	O
intra-	O
in	O
this	O
paper	O
we	O
have	O
described	O
our	O
speaker	B
diarization	I
sys-	O
speaker	B
variability	O
.	O
in	O
contrast	O
,	O
when	O
two	O
clusters	O
belonging	O
to	O
tem	O
and	O
presented	O
two	O
speaker	B
clustering	B
approaches	O
based	O
on	O
different	O
speakers	O
are	O
merged	O
,	O
we	O
obtain	O
an	O
i	O
-	O
vector	O
belonging	O
the	O
plda	B
.	O
the	O
system	O
using	O
the	O
ﬁrst	O
approach	O
,	O
denoted	O
as	O
to	O
a	O
synthesized	O
identity	O
.	O
this	O
seems	O
to	O
have	O
more	O
impact	O
than	O
the	O
multifold	O
-	O
plda	B
system	O
,	O
outperformed	O
the	O
baseline	B
system	I
a	O
contamination	O
of	O
a	O
set	B
of	O
i	O
-	O
vectors	O
representing	O
a	O
cluster	O
by	O
based	O
on	O
the	O
bic	B
relatively	O
by	O
36	O
%	O
in	O
terms	B
of	O
speaker	B
er-	O
i	O
-	O
vector	O
belonging	O
to	O
a	O
different	O
speaker	B
which	O
would	O
occur	O
in	O
ror	O
rate	O
.	O
the	O
onefold	O
-	O
plda	B
system	O
based	O
on	O
the	O
second	O
pre-	O
case	O
of	O
the	O
multifold	O
-	O
plda	B
system	O
.	O
sented	O
approach	O
yielded	O
12	O
%	O
performance	O
improvement	O
over	O
the	O
baseline	B
.	O
we	O
argue	O
that	O
the	O
i	O
-	O
vectors	O
representing	O
the	O
speech	B
segments	I
can	O
not	O
be	O
estimated	O
reliably	O
for	O
short	O
segments	O
and	O
table	O
2	O
:	O
results	B
for	O
the	O
onefold	O
-	O
plda	B
system	O
.	O
employ	O
two	O
-	O
stage	B
clustering	B
.	O
the	O
ﬁrst	O
stage	B
uses	O
bic	B
-	O
based	O
rk(t	O
)	O
rk(v	O
)	O
rk(u	O
)	O
spke	O
[	O
%	O
]	O
rel	O
.	O
impr	O
.	O
[	O
%	O
]	O
clustering	B
to	O
under	O
-	O
cluster	O
the	O
segments	O
and	O
plda	B
-	O
based	O
clus-	O
tering	O
is	O
performed	O
at	O
the	O
second	O
stage	B
.	O
signiﬁcant	O
effect	O
of	O
the	O
300	O
100	O
100	O
22.5	O
9.6	O
two	O
-	O
stage	B
clustering	B
was	O
observed	O
particularly	O
for	O
the	O
onefold-	O
300	O
150	O
150	O
21.8	O
12.4	O
plda	B
system	O
.	O
the	O
onefold	O
-	O
plda	B
system	O
used	O
in	O
two	O
-	O
stage	B
400	O
200	O
200	O
23.0	O
7.6	O
clustering	B
scenario	O
achieved	O
the	O
best	O
overall	O
speaker	B
error	B
rate	I
of	O
14.5	O
%	O
which	O
corresponds	O
to	O
42	O
%	O
relative	O
improvement	O
over	O
the	O
baseline	B
error	B
rate	I
of	O
24.9	O
%	O
.	O
4.7	O
.	O
two	O
-	O
stage	B
clustering	B
we	O
hypothesize	O
that	O
the	O
map	O
point	O
estimate	O
of	O
the	O
total	O
fac-	O
6	O
.	O
acknowledgements	O
tor	O
loadings	O
(	O
i	O
-	O
vectors	O
)	O
for	O
segments	O
of	O
short	O
duration	O
can	O
not	O
be	O
the	O
research	B
described	O
in	O
this	O
paper	O
was	O
supported	O
by	O
estimated	O
reliably	O
which	O
may	O
harm	O
the	O
clustering	B
process	B
par-	O
the	O
technology	O
agency	O
of	O
the	O
czech	O
republic	O
(	O
project	O
no	O
.	O
ticularly	O
at	O
early	O
phases	O
.	O
this	O
problem	O
relates	O
at	O
various	O
extent	O
ta01011204	O
)	O
and	O
by	O
the	O
czech	O
science	O
foundation	O
-	O
gacr	O
to	O
both	O
plda	B
-	O
based	O
systems	O
.	O
to	O
cope	O
with	O
the	O
problem	O
we	O
em-	O
(	O
project	O
no	O
.	O
p103/11	O
/	O
p499	O
)	O
.	O
ploy	O
two	O
-	O
stage	B
clustering	B
.	O
in	O
the	O
ﬁrst	O
stage	B
,	O
we	O
use	O
bic	B
-	O
based	O
clustering	B
with	O
zero	O
value	O
of	O
the	O
stopping	O
threshold	B
λ	O
and	O
value	O
7	O
.	O
references	B
of	O
the	O
bic	B
penalty	O
weight	B
α	O
set	B
so	O
as	O
to	O
under	O
-	O
cluster	O
the	O
seg-	O
ments	O
.	O
in	O
the	O
next	O
stage	B
the	O
plda	B
-	O
based	O
clustering	B
is	O
applied	O
.	O
[	O
1	O
]	O
s.	O
prince	O
and	O
j.	O
elder	O
,	O
“	O
probabilistic	O
linear	O
discriminant	B
analysis	I
table	O
3	O
shows	O
achieved	O
results	B
.	O
for	O
inferences	O
about	O
identity	O
,	O
”	O
in	O
proceedings	O
iccv	O
2007	O
,	O
rio	O
de	O
janeiro	O
,	O
brazil	O
,	O
october	O
2007	O
.	O
[	O
2	O
]	O
n.	O
brummer	O
,	O
l.	O
burget	O
,	O
p.	O
kenny	O
,	O
p.	O
mateˇjka	O
,	O
e.	O
v.	O
de	O
,	O
m.	O
karaﬁa´t	O
,	O
table	O
3	O
:	O
results	B
for	O
two	O
-	O
stage	B
clustering	B
.	O
m.	O
kockmann	O
,	O
o.	O
glembek	O
,	O
o.	O
plchot	O
,	O
d.	O
baum	O
,	O
and	O
m.	O
senous-	O
sauoi	O
,	O
“	O
abc	O
system	O
description	O
for	O
nist	O
sre	O
2010	O
,	O
”	O
in	O
proc	O
.	O
multifold	O
-	O
plda	B
system	O
onefold	O
-	O
plda	B
system	O
nist	O
2010	O
speaker	B
recognition	O
evaluation	B
.	O
brno	O
university	O
of	O
bic	B
α	O
spke	O
rel	O
.	O
impr	O
.	O
bic	B
α	O
spke	O
rel	O
.	O
impr	O
.	O
technology	O
,	O
2010	O
,	O
pp	O
.	O
1–20	O
.	O
[	O
%	O
]	O
[	O
%	O
]	O
[	O
%	O
]	O
[	O
%	O
]	O
[	O
3	O
]	O
n.	O
dehak	O
,	O
p.	O
kenny	O
,	O
r.	O
dehak	O
,	O
p.	O
dumouchel	O
,	O
and	O
p.	O
ouellet	O
,	O
rk(t	O
)	O
=	O
300	O
,	O
rk(v	O
)	O
=	O
150	O
,	O
rk(u	O
)	O
=	O
150	O
“	O
front	O
-	O
end	O
factor	B
analysis	I
for	O
speaker	B
veriﬁcation	O
,	O
”	O
audio	O
,	O
speech	O
,	O
and	O
language	B
processing	I
,	O
ieee	O
transactions	O
on	O
,	O
vol	O
.	O
19	O
,	O
no	O
.	O
4	O
,	O
2.0	O
17.0	O
31.7	O
2.0	O
19.2	O
22.9	O
pp	O
.	O
788	O
–	O
798	O
,	O
may	O
2011	O
.	O
2.5	O
18.3	O
26.5	O
2.5	O
16.0	O
35.7	O
[	O
4	O
]	O
x.	O
zhu	O
,	O
c.	O
barras	O
,	O
s.	O
meignier	O
,	O
and	O
j.-l	O
.	O
gauvain	O
,	O
“	O
combining	O
3.0	O
18.9	O
24.1	O
3.0	O
14.5	O
41.8	O
speaker	B
identiﬁcation	O
and	O
bic	B
for	O
speaker	B
diarization	I
,	O
”	O
in	O
inter-	O
rk(t	O
)	O
=	O
400	O
,	O
rk(v	O
)	O
=	O
200	O
,	O
rk(u	O
)	O
=	O
200	O
speech’05	O
,	O
isca	O
,	O
lisbon	O
,	O
september	O
2005	O
.	O
2.0	O
14.9	O
40.2	O
2.0	O
19.0	O
23.7	O
[	O
5	O
]	O
s.	O
chen	O
and	O
p.	O
gopalakrishnan	O
,	O
“	O
speaker	B
,	O
environment	O
and	O
channel	O
2.5	O
14.7	O
41.0	O
2.5	O
16.6	O
33.3	O
change	B
detection	I
and	O
clustering	B
via	O
the	O
bayesian	O
information	B
crite-	O
3.0	O
15.1	O
39.4	O
3.0	O
16.9	O
32.1	O
rion	O
,	O
”	O
in	O
proceedings	O
1998	O
darpa	O
broadcast	O
news	O
transcription	B
and	O
understanding	O
workshop	O
,	O
1998	O
,	O
pp	O
.	O
127–132	O
.	O
[	O
6	O
]	O
p.	O
kenny	O
,	O
g.	O
boulianne	O
,	O
and	O
p.	O
dumouchel	O
,	O
“	O
eigenvoice	O
modeling	O
signiﬁcant	O
effect	O
of	O
the	O
two	O
-	O
stage	B
clustering	B
scenario	O
was	O
with	O
sparse	O
training	B
data	I
,	O
”	O
ieee	O
trans	O
.	O
processing	B
,	O
vol	O
.	O
13	O
,	O
may	O
observed	O
particularly	O
for	O
the	O
onefold	O
-	O
plda	B
system	O
.	O
all	O
eval-	O
2005	O
.	O
uated	O
setups	O
of	O
the	O
system	O
provided	O
performance	O
improve-	O
[	O
7	O
]	O
a.	O
vandecatseye	O
et	O
al	O
.	O
,	O
“	O
the	O
cost278	O
pan	O
-	O
european	O
broadcast	O
ment	O
.	O
the	O
system	O
employing	O
300-dimensional	O
i	O
-	O
vectors	O
and	O
news	O
database	O
,	O
”	O
2004	O
,	O
pp	O
.	O
873–876	O
.	O
the	O
plda	B
model	B
with	O
150	O
eigenvoices	O
and	O
150	O
eigenchannels	O
[	O
8	O
]	O
nist	O
,	O
“	O
the	O
2009	O
(	O
rt-09	O
)	O
rich	B
transcription	I
meeting	O
recognition	O
achieved	O
the	O
best	O
overall	O
spke	O
of	O
14.5	O
%	O
(	O
42	O
%	O
relative	O
reduc-	O
evaluation	B
plan	I
,	O
”	O
2009	O
.	O
tion	O
)	O
for	O
the	O
bic	B
penalty	O
weight	B
of	O
3.0	O
used	O
at	O
the	O
ﬁrst	O
stage	B
.	O
[	O
9	O
]	O
n.	O
brummer	O
,	O
“	O
the	O
em	O
algorithm	O
and	O
minimum	O
diver-	O
for	O
the	O
multifold	O
-	O
plda	B
system	O
,	O
rather	O
minor	O
effect	O
of	O
the	O
gence	O
,	O
”	O
october	O
2009	O
,	O
unpublished	O
.	O
[	O
online	O
]	O
.	O
available	O
:	O
two	O
-	O
stage	B
clustering	B
was	O
observed	O
for	O
both	O
system	O
’s	O
conﬁgu-	O

see	O
discussions	O
,	O
stats	O
,	O
and	O
author	O
profiles	O
for	O
this	O
publication	O
at	O
:	O
https://www.researchgate.net/publication/221480626	O
the	O
detection	B
of	O
overlapping	B
speech	I
with	O
prosodic	B
features	I
for	O
speaker	B
diarization	I
.	O
conference	O
paper	O
·	O
january	O
2011	O
source	B
:	O
dblp	O
citations	O
reads	O
22	O
470	O
2	O
authors	O
:	O
martin	O
zelenák	O
javier	O
hernando	O
universitat	O
politècnica	O
de	O
catalunya	O
universitat	O
politècnica	O
de	O
catalunya	O
7	O
publications	O
   	O
91	O
citations	O
    	O
251	O
publications	O
   	O
2,167	O
citations	O
    	O
see	O
profile	O
see	O
profile	O
some	O
of	O
the	O
authors	O
of	O
this	O
publication	O
are	O
also	O
working	O
on	O
these	O
related	O
projects	O
:	O
deep	O
networks	O
for	O
speaker	B
recognition	O
view	O
project	O
harmonic	O
decomposition	O
applied	O
to	O
automatic	O
speech	B
recognition	I
(	O
columbo	O
)	O
view	O
project	O
all	O
content	O
following	O
this	O
page	O
was	O
uploaded	O
by	O
javier	O
hernando	O
on	O
18	O
april	O
2014	O
.	O
the	O
user	O
has	O
requested	O
enhancement	O
of	O
the	O
downloaded	O
file.interspeech	O
2011	O
the	O
detection	B
of	O
overlapping	B
speech	I
with	O
prosodic	B
features	I
for	O
speaker	B
diarization	I
martin	O
zelena	O
´	O
k	O
,	O
javier	O
hernando	O
universitat	O
polite`cnica	O
de	O
catalunya	O
,	O
barcelona	O
,	O
spain	O
{	O
martin.zelenak,javier.hernando}@upc.edu	O
abstract	O
ing	O
,	O
but	O
experiments	O
were	O
performed	O
on	O
artiﬁcially	O
overlapped	B
speech	I
.	O
overlapping	B
speech	I
is	O
responsible	O
for	O
a	O
certain	O
amount	B
of	O
er-	O
in	O
[	O
8	O
]	O
the	O
authors	O
presented	O
a	O
system	O
,	O
which	O
exploits	O
cross-	O
rors	O
produced	O
by	O
standard	O
speaker	B
diarization	I
systems	I
in	O
meet-	O
correlation	O
-	O
based	O
spatial	O
features	O
for	O
overlapping	B
speech	I
detec-	O
ing	O
environment	O
.	O
we	O
are	O
investigating	O
a	O
set	B
of	O
prosody	O
-	O
based	O
tion	O
in	O
a	O
multi	O
-	O
microphone	O
environment	O
.	O
in	O
this	O
paper	O
,	O
we	O
shift	O
long	O
-	O
term	O
features	O
as	O
a	O
potential	O
complement	O
to	O
our	O
overlap	O
de-	O
our	O
focus	O
back	O
to	O
single	O
distant	O
microphone	O
scenario	O
and	O
pro-	O
tection	O
system	O
relying	O
on	O
short	O
-	O
term	O
spectral	O
parameters	O
.	O
the	O
pose	O
the	O
use	O
of	O
several	O
long	O
-	O
term	O
prosody	O
-	O
based	O
features	O
for	O
most	O
relevant	O
features	O
are	O
selected	O
in	O
a	O
two	O
-	O
step	O
process	B
.	O
they	O
the	O
detection	B
of	O
overlapping	B
speech	I
.	O
we	O
believe	O
that	O
they	O
may	O
are	O
ﬁrstly	O
evaluated	O
and	O
sorted	O
according	O
to	O
mrmr	O
criterion	B
act	O
complementary	O
to	O
the	O
short	O
-	O
term	O
spectral	O
features	O
.	O
the	O
set	B
and	O
then	O
the	O
optimal	O
number	O
is	O
determined	O
by	O
iterative	O
wrapper	O
of	O
the	O
most	O
appropriate	O
prosodic	B
features	I
is	O
determined	O
from	O
approach	O
.	O
we	O
show	O
that	O
the	O
addition	O
of	O
prosodic	B
features	I
de-	O
the	O
candidate	O
set	B
in	O
a	O
two	O
-	O
step	O
process	B
.	O
in	O
the	O
ﬁrst	O
step	O
,	O
the	O
creased	O
overlap	B
detection	I
error	O
.	O
detected	O
overlap	O
segments	O
are	O
features	O
are	O
sorted	O
according	O
to	O
minimal	O
-	O
redundancy	O
-	O
maximal-	O
used	O
in	O
speaker	B
diarization	I
to	O
recover	O
missed	O
speech	O
by	O
assign-	O
relevance	O
(	O
mrmr	O
)	O
criterion	B
and	O
then	O
,	O
in	O
the	O
second	O
step	O
,	O
a	O
stan-	O
ing	O
multiple	O
speaker	B
labels	I
and	O
to	O
increase	O
the	O
purity	O
of	O
speaker	B
dard	O
wrapper	O
selection	O
method	B
is	O
applied	O
.	O
clusters	O
.	O
our	O
speaker	B
diarization	I
system	I
assigns	O
multiple	O
speaker	B
la-	O
index	O
terms	B
:	O
overlapping	B
speech	I
detection	B
,	O
prosody	O
,	O
feature	O
bels	O
for	O
the	O
obtained	O
overlap	O
regions	O
in	O
order	B
to	O
decrease	O
the	O
selection	O
,	O
speaker	B
diarization	I
missed	O
speech	O
error	O
.	O
overlap	O
segments	O
can	O
also	O
be	O
used	O
to	O
indi-	O
cate	O
data	B
which	O
should	O
not	O
be	O
used	O
for	O
model	B
building	O
with	O
the	O
1	O
.	O
introduction	O
aim	O
of	O
a	O
purer	O
clustering	B
.	O
the	O
experiments	O
were	O
conducted	O
on	O
human	O
conversation	O
often	O
includes	O
certain	O
amount	B
of	O
overlap-	O
the	O
ami	O
meeting	O
corpus	B
.	O
ping	O
speech	O
.	O
several	O
works	O
identiﬁed	O
these	O
speciﬁc	O
conversa-	O
this	O
paper	O
is	O
organized	O
as	O
follows	O
.	O
overlap	B
detection	I
sys-	O
tion	O
events	O
as	O
a	O
challenge	B
for	O
many	O
automatic	O
human	O
language	O
tem	O
is	O
described	O
in	O
section	O
2	O
.	O
the	O
candidate	O
prosodic	B
features	I
technologies	O
[	O
1	O
,	O
2	O
]	O
.	O
one	O
of	O
these	O
technologies	O
is	O
speaker	B
di-	O
and	O
feature	O
selection	O
process	B
is	O
discussed	O
in	O
section	O
3	O
.	O
speaker	B
arization	O
,	O
which	O
,	O
given	O
a	O
recording	B
,	O
strives	O
to	O
answer	O
the	O
ques-	O
diarization	B
system	O
and	O
its	O
improvements	B
are	O
brieﬂy	O
outlined	O
in	O
tion	O
“	O
who	O
spoke	O
when	O
?	O
”	O
without	O
any	O
prior	O
knowledge	B
about	O
section	O
4	O
.	O
experimental	O
results	B
and	O
conclusions	O
are	O
given	O
in	O
the	O
speakers	O
.	O
the	O
problem	O
is	O
that	O
conventional	O
diarization	B
sys-	O
section	O
5	O
and	O
6	O
,	O
respectively	O
.	O
tems	O
assign	O
only	O
one	O
speaker	B
label	O
per	O
segment	B
and	O
,	O
conse-	O
quently	O
,	O
miss	B
speech	O
from	O
overlapping	B
speakers	O
.	O
furthermore	O
,	O
2	O
.	O
overlapping	B
speech	I
detection	B
it	O
is	O
reasonable	O
to	O
assume	O
that	O
overlapping	B
speech	I
included	O
into	O
the	O
baseline	B
overlap	B
detection	I
system	O
,	O
which	O
was	O
presented	O
in	O
the	O
training	B
data	I
of	O
a	O
single	O
-	O
speaker	B
model	B
can	O
lead	O
to	O
some	O
[	O
8	O
]	O
,	O
relies	O
on	O
a	O
number	O
of	O
spectral	O
-	O
based	O
features	O
.	O
first	O
param-	O
level	B
of	O
corruption	O
of	O
the	O
models	B
.	O
eter	O
kind	O
is	O
the	O
cepstrum	O
,	O
thus	O
12	O
mfccs	O
were	O
extracted	O
ev-	O
prosody	O
describes	O
the	O
rhythm	O
,	O
intonation	O
and	O
stress	O
of	O
ery	O
10	O
ms	O
over	O
a	O
window	O
of	O
30	O
ms	O
.	O
next	O
,	O
assuming	O
that	O
lin-	O
speech	O
.	O
it	O
can	O
reﬂect	O
various	O
things	O
about	O
the	O
speaker	B
or	O
the	O
ear	O
predictive	O
coding	O
(	O
lpc	O
)	O
of	O
a	O
reasonably	O
chosen	O
order	B
can	O
utterance	O
,	O
e.	O
g.	O
,	O
the	O
emotional	O
state	O
.	O
there	O
has	O
been	O
signiﬁcant	O
model	B
the	O
spectrum	B
of	O
a	O
single	B
speaker	I
quite	O
well	O
,	O
but	O
will	O
fail	O
effort	O
to	O
use	O
this	O
kind	O
of	O
higher	O
-	O
level	B
speech	O
information	B
for	O
var-	O
for	O
a	O
region	O
with	O
multiple	O
speakers	O
[	O
9	O
]	O
,	O
we	O
computed	O
the	O
resid-	O
ious	O
tasks	O
like	O
speaker	B
veriﬁcation	O
and	O
identiﬁcation	O
.	O
recently	O
,	O
ual	O
energy	O
of	O
a	O
12th	O
-	O
order	B
lpc	O
(	O
lpcre	O
)	O
over	O
a	O
25	O
ms	O
win-	O
prosodic	B
features	I
were	O
also	O
successfully	O
applied	O
for	O
speaker	B
di-	O
dow	O
.	O
residual	O
energy	O
,	O
which	O
corresponds	O
to	O
the	O
prediction	O
er-	O
arization	O
[	O
3	O
,	O
4	O
]	O
.	O
ror	O
,	O
should	O
be	O
higher	O
in	O
overlapping	B
speaker	B
situations	O
.	O
another	O
a	O
few	O
studies	O
were	O
published	O
which	O
researched	O
the	O
rela-	O
feature	O
is	O
the	O
spectral	O
ﬂatness	O
(	O
sf	O
)	O
extracted	O
over	O
a	O
window	O
tionship	O
between	O
prosodic	O
cues	O
and	O
the	O
interaction	O
of	O
conver-	O
of	O
30	O
ms	O
.	O
this	O
feature	O
was	O
applied	O
for	O
discrimination	O
between	O
sation	O
participants	B
,	O
e.	O
g.	O
,	O
one	O
speaker	B
jumping	O
into	O
the	O
talk	O
of	O
speech	O
and	O
non	O
-	O
speech	O
[	O
10	O
]	O
,	O
but	O
can	O
eventually	O
convey	O
also	O
in-	O
another	O
.	O
the	O
work	O
by	O
ward	O
and	O
tsukahara	O
[	O
5	O
]	O
suggests	O
that	O
formation	O
about	O
the	O
number	O
of	O
speakers	O
speaking	O
.	O
this	O
set	B
of	O
stretches	O
of	O
low	O
pitch	B
can	O
trigger	O
back	O
-	O
channel	O
feedback	O
from	O
spectral	O
parameters	O
is	O
extended	O
with	O
their	O
ﬁrst	O
order	B
derivatives	O
listener	O
(	O
yeah	O
,	O
uh	O
-	O
huh	O
,	O
right	O
)	O
.	O
shriberg	O
et	O
al	O
.	O
[	O
6	O
]	O
showed	O
that	O
and	O
all	O
features	O
were	O
mean	O
-	O
variance	O
normalized	O
according	O
to	O
speakers	O
raise	O
their	O
voices	O
when	O
starting	O
their	O
utterance	O
during	O
statistics	B
obtained	O
from	O
training	B
data	I
.	O
somebody	O
else	O
’s	O
talk	O
,	O
compared	O
to	O
starting	O
in	O
silence	B
.	O
some-	O
the	O
system	O
considers	O
three	O
acoustic	O
classes	O
representing	O
what	O
related	O
work	O
was	O
presented	O
in	O
[	O
7	O
]	O
,	O
where	O
a	O
speciﬁc	O
fea-	O
non	O
-	O
speech	O
,	O
single	O
-	O
speaker	B
speech	O
and	O
overlapping	B
speech	I
.	O
for	O
ture	O
based	O
on	O
pitch	B
prediction	O
was	O
used	O
for	O
speaker	B
count	O
label-	O
each	O
class	O
an	O
hmm	O
is	O
deﬁned	O
.	O
for	O
a	O
more	O
accurate	O
model-	O
this	O
work	O
has	O
been	O
funded	O
by	O
the	O
spanish	O
project	O
sarai	O
ing	O
of	O
transitions	O
between	O
classes	O
the	O
hmm	O
has	O
three	O
states	O
,	O
(	O
tec2010	O
-	O
21040-c02	O
-	O
01	O
)	O
.	O
which	O
also	O
works	O
as	O
a	O
minimum	O
duration	O
constraint	O
.	O
every	O
copyright	O
©	O
2011	O
isca	O
1041	O
28-	O
31	O
august	O
2011	O
,	O
florence	O
,	O
italymin	O
and	O
max	O
value	O
.	O
long	O
-	O
term	O
statistics	B
are	O
extracted	O
from	O
distant	O
microphone	O
 	O
500	O
ms	O
windows	O
with	O
10	O
ms	O
step	O
for	O
synchronization	O
reasons	O
with	O
spectral	O
features	O
.	O
prosodic	B
features	I
were	O
extracted	O
with	O
the	O
help	O
of	O
praat	O
1	O
.	O
the	O
feature	O
selection	O
process	B
can	O
be	O
divided	O
into	O
two	O
stages	O
.	O
in	O
the	O
ﬁrst	O
,	O
we	O
applied	O
a	O
mrmr	O
algorithm	O
[	O
11	O
]	O
on	O
spectral	O
prosodic	O
held	O
-	O
out	O
development	B
data	I
to	O
score	B
individually	O
the	O
candidate	O
features	O
features	O
features	O
against	O
the	O
target	O
class	O
(	O
overlapping	B
speech	I
vs.	O
single-	O
speaker	B
speech	O
)	O
and	O
sorted	O
them	O
according	O
to	O
their	O
minimum	O
redundancy	O
and	O
maximal	O
relevance	O
.	O
the	O
ordered	O
ﬁrst	O
25	O
out	O
of	O
total	O
42	O
candidate	O
features	O
are	O
given	O
in	O
table	O
1	O
.	O
table	O
1	O
:	O
candidate	O
prosodic	B
features	I
sorted	O
according	O
to	O
the	O
overlap	O
hmm	O
mrmr	O
criterion	B
,	O
f0—pitch	O
,	O
int	O
—	O
intensity	O
,	O
f1	O
-	O
4—formants	O
detection	B
 	O
decoder	O
system	O
1	O
.	O
f0	O
max	O
10	O
.	O
f3	O
max	O
19	O
.	O
f0	O
std	O
2	O
.	O
f4	O
max	O
11	O
.	O
int	O
diff	O
20	O
.	O
int	O
min	O
overlapped	B
speech	I
3	O
.	O
f4	O
12	O
.	O
f3	O
min	O
21	O
.	O
f4	O
std	O
hypothesis	B
4	O
.	O
f0	O
min	O
13	O
.	O
f0	O
22	O
.	O
f1	O
5	O
.	O
int	O
14	O
.	O
f2	O
23	O
.	O
f2	O
max	O
6	O
.	O
f2	O
min	O
15	O
.	O
f2	O
std	O
24	O
.	O
int	O
std	O
7	O
.	O
f4	O
min	O
16	O
.	O
f0	O
med	O
25	O
.	O
f3	O
med	O
speaker	B
 	O
8	O
.	O
f1	O
min	O
17	O
.	O
f4	O
med	O
diarization	B
9	O
.	O
f2	O
med	O
18	O
.	O
f1	O
max	O
figure	O
1	O
:	O
overlap	B
detection	I
system	O
block	O
diagram	O
the	O
second	O
feature	O
selection	O
stage	B
involves	O
conventional	O
hill	O
climbing	O
wrapper	O
approach	O
,	O
i.	O
e.	O
,	O
iteratively	O
adding	O
candi-	O
date	O
features	O
to	O
the	O
feature	O
set	B
,	O
creating	O
a	O
model	B
and	O
evaluating	O
state	O
is	O
modeled	O
with	O
a	O
gmm	O
using	O
diagonal	O
covariance	O
.	O
since	O
the	O
system	O
on	O
the	O
development	B
data	I
.	O
the	O
overlap	B
detection	I
per-	O
the	O
amount	B
of	O
training	B
data	I
is	O
not	O
balanced	O
among	O
classes	O
,	O
we	O
formance	O
for	O
the	O
baseline	B
spectral	O
system	O
and	O
ﬁve	O
prosodic	O
sub-	O
use	O
256	O
gaussian	O
components	B
for	O
single	O
-	O
speaker	B
speech	O
and	O
64	O
sets	O
are	O
given	O
in	O
figure	O
2	O
.	O
it	O
can	O
be	O
seen	O
that	O
the	O
systems	O
with	O
components	B
for	O
overlapping	B
speech	I
and	O
non	O
-	O
speech	O
.	O
gmms	O
prosodic	B
features	I
achieve	O
lower	O
error	O
especially	O
for	O
low	O
penal-	O
are	O
created	O
by	O
iterative	O
gaussian	O
-	O
splitting	O
technique	B
and	O
subse-	O
ization	O
values	B
when	O
compared	O
to	O
the	O
spectral	O
-	O
only	O
system	O
.	O
quent	O
re	O
-	O
estimation	B
.	O
a	O
diagram	O
of	O
the	O
overlap	B
detection	I
system	O
unfortunately	O
,	O
it	O
is	O
not	O
clear	O
from	O
the	O
graphic	O
what	O
number	O
with	O
link	O
to	O
speaker	B
diarization	I
is	O
given	O
in	O
figure	O
1	O
.	O
of	O
prosodic	B
features	I
is	O
the	O
optimal	O
value	O
.	O
in	O
order	B
to	O
solve	O
this	O
detection	B
hypothesis	B
is	O
obtained	O
by	O
viterbi	O
(	O
maximum-	O
problem	O
,	O
we	O
suggest	O
to	O
calculate	O
the	O
area	O
under	O
the	O
curves	O
in	O
likelihood	B
)	O
decoding	O
and	O
applying	O
a	O
word	B
network	B
.	O
the	O
tran-	O
figure	O
2	O
and	O
use	O
it	O
as	O
a	O
decision	O
factor	B
.	O
the	O
amount	B
of	O
area	O
re-	O
sition	O
probabilities	O
between	O
different	O
hmms	O
are	O
not	O
trained	O
.	O
ﬂects	O
the	O
overlap	B
detection	I
error	O
of	O
a	O
particular	O
system	O
.	O
for	O
a	O
they	O
are	O
set	B
manually	O
.	O
in	O
order	B
to	O
increase	O
the	O
precision	O
,	O
the	O
fair	O
comparison	O
,	O
every	O
curve	O
is	O
extended	O
with	O
the	O
same	O
ﬁctional	O
transition	O
from	O
single	O
-	O
speaker	B
speech	O
to	O
overlapping	B
speech	I
can	O
starting	O
point	O
(	O
recall	O
=	O
100	O
%	O
,	O
false	B
alarm	I
=	O
100	O
%	O
)	O
and	O
end-	O
be	O
penalized	O
with	O
an	O
overlap	O
insertion	O
penalty	O
(	O
oip	O
)	O
and	O
certain	O
ing	O
point	O
(	O
recall	O
=	O
0	O
%	O
,	O
false	B
alarm	I
=	O
0	O
%	O
)	O
.	O
the	O
values	B
of	O
this	O
transitions	O
are	O
completely	O
forbidden	O
.	O
“	O
overlap	B
detection	I
error	O
”	O
area	O
for	O
different	O
number	O
of	O
prosodic	O
overlap	B
detection	I
performance	O
is	O
measured	O
with	O
recall	O
—	O
features	O
are	O
given	O
in	O
figure	O
3	O
.	O
based	O
on	O
these	O
results	B
it	O
was	O
ratio	O
between	O
true	O
detected	O
and	O
reference	B
overlap	O
time	B
,	O
determined	O
to	O
select	O
the	O
ﬁrst	O
20	O
prosodic	B
features	I
from	O
table	O
1	O
.	O
precision	O
—	O
ratio	O
between	O
true	O
and	O
all	O
detected	O
overlap	O
time	B
,	O
and	O
the	O
fusion	O
strategy	O
is	O
very	O
similar	O
to	O
the	O
one	O
in	O
[	O
8	O
]	O
.	O
the	O
with	O
error	O
—	O
the	O
sum	O
of	O
missed	O
and	O
false	O
overlap	O
time	B
divided	O
emission	O
probabilities	O
are	O
weighted	O
by	O
0.9	O
and	O
0.1	O
for	O
spectral	O
by	O
reference	B
overlap	O
time	B
.	O
results	B
depend	O
very	O
much	O
on	O
the	O
and	O
prosodic	O
feature	O
stream	O
,	O
respectively	O
.	O
these	O
weights	O
were	O
value	O
of	O
the	O
oip	O
,	O
which	O
controls	O
the	O
amount	B
of	O
overlaps	B
the	O
sys-	O
deﬁned	O
in	O
a	O
similar	O
way	O
as	O
the	O
optimal	O
number	O
of	O
prosodic	O
fea-	O
tem	O
will	O
hypothesize	O
.	O
it	O
can	O
be	O
perceived	O
as	O
a	O
compensation	O
tures	O
on	O
the	O
development	B
data	I
.	O
for	O
an	O
undertrained	O
model	B
.	O
initially	O
,	O
four	O
values	B
of	O
oip	O
were	O
selected	O
based	O
on	O
results	B
on	O
development	B
data	I
,	O
accounting	O
for	O
4	O
.	O
speaker	B
diarization	I
system	I
hypotheses	B
with	O
the	O
highest	O
recall	O
(	O
oip	O
=	O
0	O
,	O
no	O
penalization	O
)	O
,	O
the	O
highest	O
f	O
-	O
ratio	O
(	O
oip	O
=	O
−10	O
)	O
,	O
the	O
low	O
detection	B
error	B
rate	I
our	O
speaker	B
diarization	I
system	I
,	O
detailed	O
in	O
[	O
12	O
]	O
,	O
follows	O
the	O
(	O
oip	O
=	O
−50	O
)	O
and	O
an	O
acceptably	O
high	O
precision	O
(	O
oip	O
=	O
−100	O
)	O
.	O
commonly	O
used	O
agglomerative	O
clustering	B
approach	O
.	O
in	O
the	O
be-	O
ginning	O
,	O
speech	O
is	O
broken	O
into	O
rather	O
short	O
uniform	O
segments	O
3	O
.	O
prosodic	B
features	I
and	O
feature	O
selection	O
and	O
the	O
successive	O
clustering	B
stage	B
groups	O
acoustically	O
similar	O
segments	O
and	O
assigns	O
them	O
to	O
speaker	B
clusters	O
.	O
the	O
number	O
of	O
the	O
prosodic	B
features	I
that	O
we	O
are	O
computing	O
can	O
be	O
assigned	O
to	O
initial	O
clusters	O
is	O
determined	O
automatically	O
from	O
audio	O
length	B
following	O
categories	O
:	O
pitch	B
,	O
intensity	O
and	O
(	O
four	O
)	O
formant	O
fre-	O
with	O
minimal	O
and	O
maximal	O
value	O
constraints	O
.	O
clusters	O
are	O
mod-	O
quencies	O
.	O
for	O
each	O
of	O
these	O
feature	O
categories	O
we	O
estimate	O
eled	O
with	O
gmms	O
and	O
cluster	O
pair	O
merging	O
in	O
each	O
iteration	O
is	O
besides	O
the	O
actual	O
value	O
for	O
every	O
given	O
time	B
point	O
also	O
long-	O
term	O
statistical	O
characteristics	B
such	O
as	O
mean	O
,	O
median	O
,	O
minimum	O
,	O
1praat	O
:	O
doing	O
phonetics	O
by	O
computer	B
[	O
computer	B
program	O
]	O
.	O
version	O
maximum	O
,	O
standard	O
deviation	O
and	O
the	O
difference	O
between	O
the	O
5.2.04	O
,	O
retrieved	O
from	O
http://www.praat.org/	O
1042false	O
alarm	O
rate	O
0,48	O
0	O
%	O
20	O
%	O
40	O
%	O
60	O
%	O
0,47	O
20	O
%	O
spct	O
ea	O
0,46	O
r	O
a	O
25	O
%	O
spct	O
+	O
prosod_5	O
or	O
 	O
0,45	O
spct	O
+	O
prosod_10	O
err	O
0,44	O
spct	O
+	O
prosod_15	O
d	O
 	O
30	O
%	O
o	O
0,43	O
spct	O
+	O
prosod_20	O
0,42	O
spct	O
+	O
prosod_25	O
35	O
%	O
0,41	O
all	O
0	O
10	O
20	O
30	O
c	O
e	O
#	O
prosodic	B
features	I
r	O
40	O
%	O
figure	O
3	O
:	O
the	O
amounts	O
of	O
area	O
under	O
the	O
roc	O
-	O
like	O
curves	O
of	O
figure	O
2	O
for	O
different	O
number	O
of	O
selected	O
prosodic	B
features	I
.	O
the	O
area	O
value	O
reﬂects	O
overall	O
overlap	B
detection	I
error	O
.	O
45	O
%	O
working	O
with	O
far-ﬁeld	O
microphone	O
array	O
channels	B
sampled	O
at	O
16	O
khz	O
.	O
we	O
used	O
recordings	O
from	O
the	O
idiap	O
site	O
and	O
divided	O
them	O
50	O
%	O
into	O
training	O
set	B
(	O
22	O
recordings	O
)	O
,	O
development	B
set	I
(	O
3	O
record-	O
ings	O
)	O
and	O
evaluation	B
set	I
(	O
11	O
recordings	O
)	O
.	O
the	O
average	B
amount	B
of	O
overlapping	B
speech	I
was	O
14.40	O
%	O
.	O
training	O
and	O
evaluation	B
55	O
%	O
of	O
the	O
overlap	B
detection	I
system	O
were	O
performed	O
with	O
forced-	O
alignment	O
annotations	O
obtained	O
by	O
the	O
sri	O
’s	O
decipher	O
recog-	O
figure	O
2	O
:	O
overlap	B
detection	I
performance	O
on	O
development	B
data	I
nizer	O
.	O
we	O
did	O
not	O
apply	O
any	O
forgiveness	O
collar	O
around	O
segment	B
for	O
spectral	O
features	O
(	O
spct	O
)	O
and	O
combinations	O
of	O
spectral	O
and	O
boundaries	B
in	O
scoring	O
to	O
make	O
sure	O
that	O
overlap	O
segments	O
are	O
various	O
number	O
of	O
prosodic	B
features	I
(	O
spct	O
+	O
prosod	O
5–25	O
)	O
.	O
per-	O
considered	O
,	O
because	O
the	O
median	O
overlap	O
duration	O
in	O
this	O
corpus	B
formance	O
is	O
measured	O
at	O
four	O
oip	O
values	B
(	O
0,-10,-50,-100	O
)	O
.	O
is	O
rather	O
short	O
(	O
0.46	O
s	O
)	O
.	O
driven	O
by	O
bayesian	O
information	B
criterion	B
(	O
bic	B
)	O
.	O
the	O
system	O
op-	O
5.2	O
.	O
overlap	B
detection	I
results	B
erates	O
with	O
20	O
mfccs	O
extracted	O
from	O
30	O
ms	O
frames	O
.	O
the	O
system	O
can	O
be	O
improved	O
by	O
multi	O
-	O
channel	O
approach	O
the	O
comparison	O
of	O
overlap	B
detection	I
performance	O
in	O
terms	B
of	O
based	O
on	O
conventional	O
techniques	B
.	O
we	O
applied	O
speech	B
signal	I
recall	O
,	O
precision	O
and	O
detection	B
error	O
for	O
the	O
pure	O
spectral	O
and	O
techniques	B
such	O
as	O
wiener	O
ﬁltering	O
and	O
beamforming	O
for	O
signal	B
combined	O
—	O
spectral	O
and	O
prosodic	O
—	O
system	O
on	O
evaluation	B
data	B
enhancement	O
,	O
and	O
we	O
also	O
combined	O
the	O
time	B
-	O
delay	O
-	O
of	O
-	O
arrival	O
is	O
given	O
in	O
figure	O
4	O
.	O
the	O
combined	O
features	O
outperform	O
the	O
(	O
tdoa	O
)	O
information	B
as	O
a	O
second	O
stream	O
in	O
the	O
diarization	B
[	O
13	O
]	O
.	O
spectral	O
in	O
terms	B
of	O
error	O
for	O
all	O
oips	O
with	O
the	O
lowest	O
value	O
of	O
the	O
performance	O
of	O
the	O
speaker	B
diarization	I
was	O
evaluated	O
75	O
%	O
at	O
oip	O
-50	O
.	O
on	O
the	O
other	O
hand	O
,	O
the	O
situation	O
is	O
not	O
so	O
un-	O
by	O
means	O
of	O
the	O
diarization	B
error	I
rate	I
(	O
der	O
)	O
.	O
deﬁned	O
by	O
nist	O
,	O
equivocal	O
with	O
precision	O
.	O
the	O
precision	O
does	O
not	O
rise	O
so	O
steeply	O
the	O
der	O
is	O
a	O
time	B
-	O
weighted	O
metric	B
composed	O
of	O
the	O
sum	O
of	O
with	O
increasing	O
oip	O
in	O
the	O
new	O
system	O
.	O
from	O
our	O
experience	O
,	O
missed	O
speaker	B
time	I
,	O
false	O
alarms	O
and	O
speaker	B
error	O
time	B
.	O
this	O
behavior	O
could	O
be	O
possibly	O
related	O
with	O
the	O
higher	O
amount	B
of	O
model	B
parameters	O
which	O
need	O
to	O
be	O
trained	O
in	O
the	O
combined	O
overlap	O
handling	O
in	O
diarization	B
comprises	O
the	O
labeling	O
system	O
.	O
and/or	O
exclusion	O
of	O
simultaneous	O
speech	O
.	O
the	O
ﬁrst	O
technique	B
seeks	O
to	O
select	O
the	O
two	O
most	O
likely	O
clusters	O
in	O
viterbi	O
decoding	O
instead	O
of	O
only	O
one	O
.	O
in	O
this	O
way	O
the	O
missed	O
speaker	B
time	I
should	O
5.3	O
.	O
speaker	B
diarization	I
results	B
be	O
decreased	O
.	O
overlap	O
exclusion	O
blocks	O
overlap	O
frames	O
from	O
based	O
on	O
previous	O
results	B
on	O
development	B
data	I
,	O
we	O
use	O
the	O
over-	O
being	O
included	O
into	O
cluster	O
initialization	O
and	O
gmm	O
training	O
,	O
but	O
lap	O
hypothesis	B
at	O
oip	O
-100	O
for	O
overlap	O
labeling	O
in	O
the	O
diariza-	O
does	O
not	O
prevent	O
decoding	O
them	O
.	O
the	O
aim	O
of	O
this	O
technique	B
is	O
to	O
tion	O
system	O
and	O
oip	O
0	O
hypothesis	B
for	O
overlap	O
exclusion	O
.	O
table	O
get	O
lower	O
speaker	B
detection	B
error	B
rates	I
with	O
more	O
precise	O
clus-	O
2	O
shows	O
the	O
der	O
improvements	B
of	O
baseline	B
diarization	B
system	O
ters	O
.	O
when	O
handling	O
overlap	O
detected	O
either	O
with	O
the	O
spectral	O
over-	O
in	O
order	B
to	O
evaluate	O
just	O
the	O
impact	O
of	O
overlapping	B
speech	I
on	O
lap	O
detection	B
system	O
,	O
or	O
with	O
the	O
combined	O
system	O
.	O
the	O
differ-	O
speaker	B
segmentation	I
,	O
detected	O
overlaps	B
are	O
masked	O
with	O
ref-	O
ence	O
is	O
not	O
dramatic	O
,	O
but	O
still	O
,	O
it	O
can	O
be	O
seen	O
a	O
slight	O
increase	O
erence	O
speech	O
/	O
non	O
-	O
speech	B
segments	I
before	O
given	O
to	O
diarization	B
of	O
improvement	O
when	O
overlap	O
segments	O
are	O
detected	O
also	O
with	O
system	O
.	O
the	O
diarization	B
system	O
is	O
using	O
reference	B
speech	O
seg-	O
prosodic	B
features	I
.	O
ments	O
as	O
well	O
.	O
the	O
results	B
of	O
a	O
similar	O
set	B
of	O
experiments	O
where	O
the	O
base-	O
line	O
diarization	B
was	O
improved	O
with	O
both	O
beamforming	O
and	O
5	O
.	O
experiments	O
tdoa	O
feature	O
stream	O
are	O
in	O
table	O
3	O
.	O
here	O
,	O
as	O
expected	O
,	O
the	O
ab-	O
solute	O
der	O
values	B
are	O
better	O
,	O
compared	O
with	O
table	O
2	O
.	O
the	O
rela-	O
5.1	O
.	O
database	O
and	O
experimental	O
setup	B
tive	O
der	O
improvements	B
by	O
overlap	O
labeling	O
are	O
higher	O
for	O
both	O
the	O
experiments	O
were	O
conducted	O
on	O
the	O
ami	O
meeting	O
corpus	B
,	O
feature	O
sets	O
,	O
because	O
the	O
clustering	B
is	O
improved	O
and	O
the	O
second	O
which	O
consists	O
of	O
100	O
hours	B
of	O
meeting	O
recordings	O
.	O
we	O
were	O
label	O
assignment	O
is	O
consequently	O
more	O
precise	O
.	O
interesting	O
is	O
1043table	O
3	O
:	O
speaker	B
diarization	I
improved	O
with	O
beamforming	O
and	O
100	O
%	O
tdoas	O
with	O
labeling	O
and	O
exclusion	O
of	O
overlapping	B
speech	I
.	O
comparison	O
of	O
using	O
overlaps	B
detected	O
with	O
spectral	O
(	O
spct	O
)	O
or	O
combined	O
spectral	O
-	O
prosodic	O
(	O
spct+prosod	O
20	O
)	O
system	O
.	O
der	O
and	O
rel	O
.	O
improvements	B
over	O
the	O
new	O
baseline	B
(	O
in	O
%	O
)	O
80	O
%	O
baseline	B
+	O
beam	O
.	O
+	O
tdoas	O
35.7	O
or	O
overlap	O
.	O
det	O
.	O
:	O
+	O
labeling	O
+	O
labl	O
.	O
+	O
excl	O
.	O
r	O
r	O
e	O
spct	O
33.8	O
/	O
+5.3	O
34.0	O
/	O
+4.9	O
n	O
,	O
 	O
spct	O
rcl	O
.	O
spct+prosod	O
20	O
33.4	O
/	O
+6.5	O
33.9	O
/	O
+5.0	O
o	O
cisi60	O
%	O
spct	O
prec	O
.	O
e	O
spct	O
error	O
r	O
7	O
.	O
references	B
p	O
ecall	O
,	O
 	O
ssppcctt	O
 	O
+	O
+	O
 	O
pprroossoodd__2200	O
 	O
rprcel.c	O
.	O
[	O
1	O
]	O
ew.hyshernibgeinrge	O
,	O
er“sssphoonutladnecoaures,”spineepcrho	O
:	O
c.heouwroppeeoapnlecroenafl.lyontaslkpeaenchd	O
r	O
spct	O
+	O
prosod_20	O
error	O
communication	B
and	O
technology	O
(	O
eurospeech	O
)	O
,	O
lisbon	O
,	O
portugal	O
,	O
2005	O
,	O
pp	O
.	O
1781–1784	O
.	O
40	O
%	O
[	O
2	O
]	O
n.	O
morgan	O
et	O
al	O
.	O
,	O
“	O
the	O
meeting	O
project	O
at	O
icsi	O
,	O
”	O
in	O
proc	O
.	O
1st	O
inter-	O
national	O
conference	O
on	O
human	O
language	O
technology	O
research	B
,	O
san	O
diego	O
,	O
usa	O
,	O
2001	O
,	O
pp	O
.	O
1–7	O
.	O
[	O
3	O
]	O
g.	O
friedland	O
and	O
o.	O
vinyals	O
and	O
y.	O
huang	O
and	O
c.	O
m´’uller	O
,	O
“	O
prosodic	O
and	O
other	O
long	O
-	O
term	O
features	O
for	O
speaker	B
diariza-	O
20	O
%	O
tion	O
,	O
”	O
ieee	O
transactions	O
on	O
audio	O
,	O
speech	O
,	O
and	O
language	O
pro-	O
cessing	O
,	O
vol	O
.	O
17	O
,	O
no	O
.	O
5	O
,	O
pp	O
.	O
985–993	O
,	O
jul	O
.	O
2009	O
.	O
0	O
-	O
50	O
-	O
100	O
[	O
4	O
]	O
j.	O
zˇ	O
ibert	O
and	O
f.	O
mihelicˇ	O
,	O
“	O
fusion	O
of	O
acoustic	O
and	O
prosodic	O
fea-	O
oip	O
tures	O
for	O
speaker	B
clustering	B
,	O
”	O
lecture	O
notes	O
in	O
computer	B
science	O
,	O
vol	O
.	O
5729/2009	O
,	O
pp	O
.	O
210–217	O
,	O
2009	O
.	O
figure	O
4	O
:	O
overlap	B
detection	I
performance	O
for	O
evaluation	B
data	B
using	O
spectral	O
features	O
only	O
(	O
spct	O
)	O
,	O
and	O
the	O
combination	O
of	O
[	O
5	O
]	O
n.	O
ward	O
and	O
w.	O
tsukahara	O
,	O
“	O
prosodic	B
features	I
which	O
cue	O
back-	O
channel	O
responses	O
in	O
english	O
and	O
japanese	O
,	O
”	O
journal	O
of	O
pragmat-	O
spectral	O
and	O
20	O
prosodic	B
features	I
(	O
spct	O
+	O
prosod	O
20	O
)	O
in	O
terms	B
ics	O
,	O
vol	O
.	O
32/2000	O
,	O
pp	O
.	O
1177–1207	O
,	O
2000	O
.	O
of	O
detection	B
error	O
(	O
solid	O
lines	O
)	O
,	O
precision	O
(	O
dotted	O
line	O
)	O
and	O
recall	O
(	O
dashed	O
line	O
)	O
.	O
[	O
6	O
]	O
e.	O
shriberg	O
,	O
a.	O
stolcke	O
,	O
and	O
d.	O
baron	O
,	O
“	O
can	O
prosody	O
aid	O
the	O
auto-	O
matic	O
processing	B
of	O
multi	O
-	O
party	O
meetings	O
?	O
evidence	O
from	O
predict-	O
ing	O
punctuation	O
,	O
disﬂuencies	O
,	O
and	O
overlapping	B
speech	I
,	O
”	O
in	O
proc	O
.	O
table	O
2	O
:	O
comparison	O
of	O
using	O
overlapping	B
speech	I
detected	O
isca	O
workshop	O
on	O
prosody	O
in	O
speech	B
recognition	I
and	O
under-	O
with	O
spectral	O
(	O
spct	O
)	O
or	O
combined	O
spectral	O
-	O
prosodic	O
system	O
standing	O
,	O
red	O
bank	O
,	O
usa	O
,	O
2001	O
,	O
pp	O
.	O
13–16	O
.	O
(	O
spct+prosod	O
20	O
)	O
for	O
labeling	O
and	O
exclusion	O
in	O
speaker	B
diariza-	O
[	O
7	O
]	O
m.	O
a.	O
lewis	O
and	O
r.	O
p.	O
ramachandran	O
,	O
“	O
cochannel	O
speaker	B
count	O
tion	O
.	O
der	O
and	O
rel	O
.	O
improvements	B
over	O
the	O
baseline	B
(	O
in	O
%	O
)	O
labelling	O
based	O
on	O
the	O
use	O
of	O
cepstral	O
and	O
pitch	B
prediction	O
derived	O
features	O
,	O
”	O
pattern	O
recognition	O
,	O
vol	O
.	O
34	O
,	O
no	O
.	O
2	O
,	O
pp	O
.	O
499–507	O
,	O
feb	O
.	O
baseline	B
38.3	O
2001	O
.	O
[	O
8	O
]	O
m.	O
zelena´k	O
,	O
c.	O
segura	O
,	O
and	O
j.	O
hernando	O
,	O
“	O
overlap	B
detection	I
for	O
overlap	O
.	O
det	O
.	O
:	O
+	O
labeling	O
+	O
labl	O
.	O
+	O
excl	O
.	O
speaker	B
diarization	I
by	O
fusing	O
spectral	O
and	O
spatial	O
features	O
,	O
”	O
in	O
proc	O
.	O
interspeech	O
’	O
10	O
,	O
makuhari	O
,	O
japan	O
,	O
2010	O
,	O
pp	O
.	O
2302–2305	O
.	O
spct	O
36.5	O
/	O
+4.7	O
35.6	O
/	O
+6.9	O
spct+prosod	O
20	O
36.2	O
/	O
+5.5	O
35.5	O
/	O
+7.2	O
[	O
9	O
]	O
n.	O
sundaram	O
,	O
r.	O
yantorno	O
,	O
b.	O
smolenski	O
,	O
and	O
a.	O
iyer	O
,	O
“	O
usable	O
speech	B
detection	I
using	O
linear	O
predictive	O
analysis	B
-	O
a	O
model	B
based	O
approach	O
,	O
”	O
in	O
proceedings	O
of	O
ispacs	O
,	O
awaji	O
island	O
,	O
japan	O
,	O
2003	O
,	O
pp	O
.	O
231–235	O
.	O
that	O
overlap	O
exclusion	O
did	O
not	O
lead	O
to	O
further	O
improvement	O
of	O
[	O
10	O
]	O
r.	O
yantorno	O
,	O
“	O
the	O
spectral	O
autocorrelation	O
peak	O
valley	O
ratio	O
the	O
ders	O
in	O
this	O
case	O
.	O
there	O
is	O
probably	O
some	O
sort	O
of	O
improve-	O
(	O
sapvr	O
)	O
–	O
a	O
usable	O
speech	O
measure	O
emplyed	O
as	O
a	O
co	O
-	O
channel	O
ment	O
redundancy	O
between	O
the	O
overlap	O
exclusion	O
technique	B
and	O
detection	B
system	O
,	O
”	O
in	O
proc	O
.	O
of	O
ieee	O
workshop	O
on	O
intelligent	O
sig-	O
beamforming	O
with	O
tdoas	O
in	O
speaker	B
diarization	I
.	O
nal	O
processing	B
,	O
2001	O
.	O
[	O
11	O
]	O
h.	O
peng	O
,	O
f.	O
long	O
,	O
and	O
c.	O
ding	O
,	O
“	O
feature	O
selection	O
based	O
on	O
mu-	O
6	O
.	O
conclusions	O
tual	O
information	B
:	O
criteria	O
of	O
max	O
-	O
dependency	O
,	O
max	O
-	O
relevance	O
,	O
and	O
min	O
-	O
redundancy	O
,	O
”	O
ieee	O
transactions	O
on	O
pattern	O
analysis	B
we	O
have	O
proposed	O
the	O
use	O
of	O
prosodic	B
features	I
for	O
the	O
detec-	O
and	O
machine	O
intelligence	O
,	O
vol	O
.	O
27	O
,	O
no	O
.	O
8	O
,	O
pp	O
.	O
1226–1238	O
,	O
aug	O
.	O
tion	O
of	O
simultaneous	O
speech	O
on	O
distant	O
channel	O
data	B
.	O
final	O
2005	O
.	O
subset	O
from	O
all	O
candidate	O
features	O
was	O
selected	O
according	O
to	O
[	O
12	O
]	O
j.	O
luque	O
,	O
x.	O
anguera	O
,	O
a.	O
temko	O
,	O
and	O
j.	O
hernando	O
,	O
“	O
speaker	B
di-	O
mrmr	O
criterion	B
and	O
successive	O
hill	O
-	O
climbing	O
wrapper	O
selection	O
arization	O
for	O
conference	O
room	O
:	O
the	O
upc	O
rt07s	O
evaluation	B
sys-	O
method	B
.	O
the	O
obtained	O
results	B
after	O
fusing	O
short	O
-	O
term	O
spectral	O
tem	O
,	O
”	O
multimodal	O
technologies	O
for	O
perception	O
of	O
humans	O
,	O
vol	O
.	O
4625/2008	O
,	O
pp	O
.	O
543–553	O
,	O
2008	O
.	O
and	O
long	O
-	O
term	O
prosodic	B
features	I
indicate	O
that	O
prosody	O
conveys	O
some	O
complementary	O
information	B
for	O
the	O
detection	B
of	O
speaker	B
[	O
13	O
]	O
x.	O
anguera	O
,	O
c.	O
wooters	O
,	O
and	O
j.	O
hernando	O
,	O
“	O
acoustic	O
beamform-	O
overlap	O
.	O
handling	O
detected	O
overlap	O
segments	O
in	O
speaker	B
diariza-	O
ing	O
for	O
speaker	B
diarization	I
of	O
meetings	O
,	O
”	O
ieee	O
transactions	O
on	O
audio	O
,	O
speech	O
,	O
and	O
language	B
processing	I
,	O
vol	O
.	O
15	O
,	O
no	O
.	O
7	O
,	O
pp	O
.	O
tion	O
so	O
that	O
a	O
second	O
speaker	B
label	O
is	O
assigned	O
did	O
improve	O
both	O
2011–2022	O
,	O
2007	O
.	O
diarization	B
baseline	B
and	O
diarization	B
extended	O
with	O
beamforming	O
and	O
tdoa	O
feature	O
stream	O
.	O
1044	O
vviieeww	O
 	O
ppuubblliiccaattiioonn	O

356	O
ieee	O
transactions	O
on	O
audio	O
,	O
speech	O
,	O
and	O
language	B
processing	I
,	O
vol	O
.	O
20	O
,	O
no	O
.	O
2	O
,	O
february	O
2012	O
speaker	B
diarization	I
:	O
a	O
review	O
of	O
recent	O
research	B
xavier	O
anguera	O
miro	O
,	O
member	O
,	O
ieee	O
,	O
simon	O
bozonnet	O
,	O
student	O
member	O
,	O
ieee	O
,	O
nicholas	O
evans	O
,	O
member	O
,	O
ieee	O
,	O
corinne	O
fredouille	O
,	O
gerald	O
friedland	O
,	O
member	O
,	O
ieee	O
,	O
and	O
oriol	O
vinyals	O
abstract	O
—	O
speaker	B
diarization	I
is	O
the	O
task	O
of	O
determining	O
“	O
who	O
speaker	B
diarization	I
has	O
utility	O
in	O
a	O
majority	O
of	O
applications	O
spoke	O
when	O
?	O
”	O
in	O
an	O
audio	O
or	O
video	O
recording	B
that	O
contains	O
an	O
related	O
to	O
audio	O
and/or	O
video	O
document	O
processing	B
,	O
such	O
as	O
unknown	O
amount	B
of	O
speech	O
and	O
also	O
an	O
unknown	O
number	O
of	O
information	B
retrieval	O
for	O
example	O
.	O
indeed	O
,	O
it	O
is	O
often	O
the	O
case	O
speakers	O
.	O
initially	O
,	O
it	O
was	O
proposed	O
as	O
a	O
research	B
topic	O
related	O
to	O
that	O
audio	O
and/or	O
video	O
recordings	O
contain	O
more	O
than	O
one	O
automatic	O
speech	B
recognition	I
,	O
where	O
speaker	B
diarization	I
serves	O
as	O
an	O
upstream	O
processing	B
step	O
.	O
over	O
recent	O
years	O
,	O
however	O
,	O
active	O
speaker	B
.	O
this	O
is	O
the	O
case	O
for	O
telephone	O
conversations	O
(	O
for	O
speaker	B
diarization	I
has	O
become	O
an	O
important	O
key	O
technology	O
for	O
example	O
stemming	O
from	O
call	O
centers	O
)	O
,	O
broadcast	O
news	O
,	O
debates	O
,	O
many	O
tasks	O
,	O
such	O
as	O
navigation	O
,	O
retrieval	O
,	O
or	O
higher	O
level	B
inference	B
shows	O
,	O
movies	O
,	O
meetings	O
,	O
domain	B
-	O
speciﬁc	O
videos	B
(	O
such	O
as	O
on	O
audio	O
data	B
.	O
accordingly	O
,	O
many	O
important	O
improvements	B
in	O
surgery	O
operations	O
for	O
instance	O
)	O
,	O
or	O
even	O
lecture	O
or	O
conference	O
accuracy	O
and	O
robustness	O
have	O
been	O
reported	O
in	O
journals	O
and	O
recordings	O
including	O
multiple	O
speakers	O
or	O
questions	O
/	O
answers	O
conferences	O
in	O
the	O
area	O
.	O
the	O
application	B
domains	O
,	O
from	O
broadcast	O
news	O
,	O
to	O
lectures	O
and	O
meetings	O
,	O
vary	O
greatly	O
and	O
pose	O
different	O
sessions	O
.	O
in	O
all	O
such	O
cases	O
,	O
it	O
can	O
be	O
advantageous	O
to	O
automat-	O
problems	O
,	O
such	O
as	O
having	O
access	O
to	O
multiple	O
microphones	O
and	O
ically	O
determine	O
the	O
number	O
of	O
speakers	O
involved	O
in	O
addition	O
multimodal	O
information	B
or	O
overlapping	B
speech	I
.	O
the	O
most	O
recent	O
to	O
the	O
periods	O
when	O
each	O
speaker	B
is	O
active	O
.	O
clear	O
examples	O
of	O
review	O
of	O
existing	O
technology	O
dates	O
back	O
to	O
2006	O
and	O
focuses	O
on	O
applications	O
for	O
speaker	B
diarization	I
algorithms	O
include	O
speech	O
the	O
broadcast	O
news	O
domain	B
.	O
in	O
this	O
paper	O
,	O
we	O
review	O
the	O
cur-	O
and	O
speaker	B
indexing	O
,	O
document	O
content	O
structuring	O
,	O
speaker	B
rent	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
,	O
focusing	O
on	O
research	B
developed	O
since	O
2006	O
that	O
relates	O
predominantly	O
to	O
speaker	B
diarization	I
for	O
conference	O
recognition	O
(	O
in	O
the	O
presence	B
of	O
multiple	O
or	O
competing	O
speakers	O
)	O
,	O
meetings	O
.	O
finally	O
,	O
we	O
present	O
an	O
analysis	B
of	O
speaker	B
diarization	I
to	O
help	O
in	O
speech	O
-	O
to	O
-	O
text	O
transcription	B
(	O
i.e.	O
,	O
so	O
-	O
called	O
speaker	B
at-	O
performance	O
as	O
reported	O
through	O
the	O
nist	O
rich	B
transcription	I
tributed	O
speech	O
-	O
to	O
-	O
text	O
)	O
,	O
speech	O
translation	O
and	O
,	O
more	O
generally	O
,	O
evaluations	O
on	O
meeting	O
data	B
and	O
identify	O
important	O
areas	O
for	O
rich	B
transcription	I
(	O
rt	O
)	O
,	O
a	O
community	O
within	O
which	O
the	O
current	O
future	O
research	B
.	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
technology	O
has	O
been	O
developed	O
.	O
the	O
most	O
sig-	O
index	O
terms	B
—	O
meetings	O
,	O
rich	B
transcription	I
,	O
speaker	B
diarization	I
.	O
niﬁcant	O
effort	O
in	O
the	O
rich	B
transcription	I
domain	B
comes	O
directly	O
from	O
the	O
internationally	O
competitive	O
rt	O
evaluations	O
,	O
sponsored	O
by	O
the	O
national	O
institute	O
of	O
standards	O
and	O
technology	O
(	O
nist	O
)	O
i.	O
introduction	O
in	O
the	O
unites	O
states	O
[	O
1	O
]	O
.	O
initiated	O
originally	O
within	O
the	O
telephony	O
s	O
peaker	O
diarization	B
has	O
emerged	O
as	O
an	O
increasingly	O
im-	O
domain	B
,	O
and	O
subsequently	O
in	O
that	O
of	O
broadcast	O
news	O
,	O
today	O
it	O
is	O
portant	O
and	O
dedicated	O
domain	B
of	O
speech	O
research	B
.	O
whereas	O
in	O
the	O
domain	B
of	O
conference	O
meetings	O
that	O
speaker	B
diarization	I
speaker	B
and	O
speech	B
recognition	I
involve	O
,	O
respectively	O
,	O
the	O
recog-	O
receives	O
the	O
most	O
attention	O
.	O
speaker	B
diarization	I
is	O
thus	O
an	O
nition	O
of	O
a	O
person	O
’s	O
identity	O
or	O
the	O
transcription	B
of	O
their	O
speech	O
,	O
extremely	O
important	O
area	O
of	O
speech	O
processing	B
research	B
.	O
speaker	B
diarization	I
relates	O
to	O
the	O
problem	O
of	O
determining	O
“	O
who	O
an	O
excellent	O
review	O
of	O
speaker	B
diarization	I
research	B
is	O
pre-	O
spoke	O
when	O
?	O
.	O
”	O
more	O
formally	O
this	O
requires	O
the	O
unsupervised	O
sented	O
in	O
[	O
2	O
]	O
,	O
although	O
it	O
predominantly	O
focuses	O
its	O
attention	O
to	O
identiﬁcation	O
of	O
each	O
speaker	B
within	O
an	O
audio	O
stream	O
and	O
the	O
speaker	B
diarization	I
for	O
broadcast	O
news	O
.	O
coupled	O
with	O
the	O
tran-	O
intervals	O
during	O
which	O
each	O
speaker	B
is	O
active	O
.	O
sition	O
to	O
conference	O
meetings	O
,	O
however	O
,	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
has	O
advanced	O
signiﬁcantly	O
since	O
then	O
.	O
this	O
paper	O
presents	O
an	O
up	O
-	O
to-	O
date	O
review	O
of	O
present	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
systems	O
and	O
reviews	O
the	O
manuscript	O
received	O
august	O
19	O
,	O
2010	O
;	O
revised	O
december	O
03	O
,	O
2010	O
;	O
accepted	O
progress	O
made	O
in	O
the	O
ﬁeld	O
of	O
speaker	B
diarization	I
since	O
2005	O
up	O
february	O
13	O
,	O
2011	O
.	O
date	O
of	O
current	O
version	O
january	O
13	O
,	O
2012	O
.	O
this	O
work	O
was	O
supported	O
in	O
part	O
by	O
the	O
joint	O
-	O
national	O
“	O
adaptable	O
ambient	O
living	O
assistant	O
”	O
until	O
now	O
,	O
including	O
the	O
most	O
recent	O
nist	O
rt	O
evaluation	B
that	O
(	O
alias	O
)	O
project	O
funded	O
through	O
the	O
european	O
ambient	O
assisted	O
living	O
(	O
aal	O
)	O
was	O
held	O
in	O
2009	O
.	O
ofﬁcial	O
evaluations	O
are	O
an	O
important	O
vehicle	O
program	O
under	O
agreement	O
aal-2009	O
-	O
2	O
-	O
049	O
and	O
in	O
part	O
by	O
the	O
“	O
annotation	O
for	O
pushing	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
forward	O
as	O
it	O
is	O
only	O
with	O
stan-	O
collaborative	O
pour	O
l’accessibilité	O
vidéo	O
”	O
(	O
acav	O
)	O
project	O
funded	O
by	O
the	O
french	O
ministry	O
of	O
industry	O
(	O
innovative	O
web	O
call	O
)	O
under	O
contract	O
09.2.93.0966	O
.	O
the	O
dard	O
experimental	O
protocols	O
and	O
databases	O
that	O
it	O
is	O
possible	O
to	O
work	O
of	O
x.	O
anguera	O
miro	O
was	O
supported	O
in	O
part	O
by	O
the	O
torres	O
quevedo	O
spanish	O
meaningfully	O
compare	O
different	O
approaches	O
.	O
while	O
we	O
also	O
ad-	O
program	O
.	O
the	O
associate	O
editor	O
coordinating	O
the	O
review	O
of	O
this	O
manuscript	O
and	O
dress	O
emerging	O
new	O
research	B
in	O
speaker	B
diarization	I
,	O
in	O
this	O
paper	O
approving	O
it	O
for	O
publication	O
was	O
prof	O
.	O
sadaoki	O
furui	O
.	O
x.	O
anguera	O
miro	O
is	O
with	O
the	O
multimedia	O
research	B
group	O
,	O
telefonica	O
re-	O
special	O
emphasis	O
is	O
placed	O
on	O
established	O
technologies	O
within	O
search	O
,	O
08021	O
barcelona	O
,	O
spain	O
(	O
e	O
-	O
mail	O
:	O
xanguera@tid.es	O
)	O
.	O
the	O
context	O
of	O
the	O
nist	O
rt	O
benchmark	O
evaluations	O
,	O
which	O
has	O
s.	O
bozonnet	O
and	O
n.	O
evans	O
are	O
with	O
the	O
multimedia	O
communications	O
become	O
a	O
reliable	O
indicator	O
for	O
the	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
in	O
department	O
,	O
eurecom	O
,	O
06904	O
sophia	O
antipolis	O
cedex	O
,	O
france	O
(	O
e	O
-	O
mail	O
:	O
bozonnet@eurecom.fr	O
)	O
.	O
speaker	B
diarization	I
.	O
this	O
paper	O
aims	O
at	O
giving	O
a	O
concise	O
refer-	O
c.	O
fredouille	O
is	O
with	O
the	O
university	O
of	O
avignon	O
,	O
ceri	O
/	O
lia	O
,	O
f-84911	O
avignon	O
ence	O
overview	O
of	O
established	O
approaches	O
,	O
both	O
for	O
the	O
general	O
cedex	O
9	O
,	O
france	O
(	O
e	O
-	O
mail	O
:	O
corinne.fredouille@univ-avignon.fr	O
)	O
.	O
reader	O
and	O
for	O
those	O
new	O
to	O
the	O
ﬁeld	O
.	O
despite	O
rapid	O
gains	O
in	O
g.	O
friedland	O
and	O
o.	O
vinyals	O
are	O
with	O
the	O
international	O
computer	B
science	O
institute	O
(	O
icsi	O
)	O
,	O
berkeley	O
,	O
ca	O
94704	O
usa	O
(	O
e	O
-	O
mail	O
:	O
fractor@icsi.berkeley.edu	O
;	O
popularity	O
over	O
recent	O
years	O
,	O
the	O
ﬁeld	O
is	O
relatively	O
embryonic	O
evans@eurecom.fr	O
)	O
.	O
compared	O
to	O
the	O
mature	O
ﬁelds	O
of	O
speech	O
and	O
speaker	B
recogni-	O
color	O
versions	O
of	O
one	O
or	O
more	O
of	O
the	O
ﬁgures	O
in	O
this	O
paper	O
are	O
available	O
online	O
tion	O
.	O
there	O
are	O
outstanding	O
opportunities	O
for	O
contributions	O
and	O
at	O
http://ieeexplore.ieee.org	O
.	O
digital	O
object	O
identiﬁer	O
10.1109	O
/	O
tasl.2011.2125954	O
we	O
hope	O
that	O
this	O
paper	O
serves	O
to	O
encourage	O
others	O
to	O
participate	O
.	O
1558	O
-	O
7916/$31.00	O
©	O
2012	O
ieee	O
authorized	O
licensed	O
use	O
limited	O
to	O
:	O
inria	O
.	O
downloaded	O
on	O
october	O
05,2020	O
at	O
07:30:52	O
utc	O
from	O
ieee	O
xplore	O
.	O
 	O
restrictions	O
apply	O
.	O
anguera	O
miro	O
et	O
al	O
.	O
:	O
speaker	B
diarization	I
:	O
a	O
review	O
of	O
recent	O
research	B
357	O
section	O
ii	O
presents	O
a	O
brief	O
history	O
of	O
speaker	B
diarization	I
linguistic	O
content	O
and	O
other	O
metadata	O
can	O
be	O
added	O
(	O
such	O
as	O
the	O
research	B
and	O
the	O
transition	O
to	O
the	O
conference	O
meeting	O
domain	B
.	O
dominant	O
speakers	O
,	O
the	O
level	B
of	O
interactions	O
,	O
or	O
emotions	O
)	O
.	O
we	O
describe	O
the	O
main	O
differences	O
between	O
broadcast	O
news	O
undertaking	O
benchmarking	O
evaluations	O
has	O
proven	O
to	O
be	O
and	O
conference	O
meetings	O
and	O
present	O
a	O
high	O
-	O
level	B
overview	O
of	O
an	O
extremely	O
productive	O
means	O
for	O
estimating	O
and	O
comparing	O
current	O
approaches	O
to	O
speaker	B
diarization	I
.	O
in	O
section	O
iii	O
,	O
we	O
algorithm	O
performance	O
and	O
for	O
verifying	O
genuine	O
technolog-	O
present	O
a	O
more	O
detailed	O
description	O
of	O
the	O
main	O
algorithms	O
that	O
ical	O
advances	O
.	O
speaker	B
diarization	I
is	O
no	O
exception	O
and	O
,	O
since	O
are	O
common	O
to	O
many	O
speaker	B
diarization	I
systems	I
,	O
including	O
2002	O
,	O
the	O
us	O
national	O
institute	O
for	O
standards	O
and	O
technology	O
those	O
recently	O
introduced	O
to	O
make	O
use	O
of	O
information	B
coming	O
(	O
nist	O
)	O
has	O
organized	O
ofﬁcial	O
speaker	B
diarization	I
evaluations1	O
from	O
multiple	O
microphones	O
,	O
namely	O
delay	O
-	O
and	O
-	O
sum	O
beam-	O
involving	O
broadcast	O
news	O
(	O
bn	O
)	O
and	O
,	O
more	O
recently	O
,	O
meeting	O
forming	O
.	O
section	O
iv	O
presents	O
some	O
of	O
the	O
most	O
recent	O
work	O
in	O
data	B
.	O
these	O
evaluations	O
have	O
crucially	O
contributed	O
to	O
bringing	O
the	O
ﬁeld	O
including	O
efforts	O
to	O
handle	O
multimodal	O
information	B
researchers	O
together	O
and	O
to	O
stimulating	O
new	O
ideas	O
to	O
advance	O
the	O
and	O
overlapping	B
speech	I
.	O
we	O
also	O
discuss	O
the	O
use	O
of	O
features	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
.	O
while	O
other	O
contrastive	O
sub	O
-	O
domains	O
such	O
as	O
based	O
on	O
inter	O
-	O
channel	O
delay	O
and	O
prosodics	O
and	O
also	O
attempts	O
lecture	O
meetings	O
and	O
coffee	O
breaks	O
have	O
also	O
been	O
considered	O
,	O
to	O
combine	O
speaker	B
diarization	I
systems	I
.	O
in	O
section	O
v	O
,	O
we	O
the	O
conference	O
meeting	O
scenario	O
has	O
been	O
the	O
primary	O
focus	O
present	O
an	O
overview	O
of	O
the	O
current	O
status	O
in	O
speaker	B
diarization	I
of	O
the	O
nist	O
rt	O
evaluations	O
since	O
2004	O
.	O
the	O
meeting	O
scenario	O
research	B
.	O
we	O
describe	O
the	O
nist	O
rt	O
evaluations	O
,	O
the	O
different	O
is	O
often	O
referred	O
to	O
as	O
“	O
speech	B
recognition	I
complete	O
,	O
”	O
i.e.	O
,	O
a	O
datasets	B
and	O
the	O
performance	O
achieved	O
by	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
sys-	O
scenario	O
in	O
which	O
all	O
of	O
the	O
problems	O
that	O
arise	O
in	O
any	O
speech	O
tems	O
.	O
we	O
also	O
identify	O
the	O
remaining	O
problems	O
and	O
highlight	O
recognition	O
can	O
be	O
encountered	O
in	O
this	O
domain	B
.	O
conference	O
potential	O
solutions	O
in	O
the	O
context	O
of	O
current	O
work	O
.	O
finally	O
,	O
our	O
meetings	O
thus	O
pose	O
a	O
number	O
of	O
new	O
challenges	B
to	O
speaker	B
conclusions	O
are	O
presented	O
in	O
section	O
vi	O
.	O
diarization	B
that	O
typically	O
were	O
less	O
relevant	O
in	O
earlier	O
research	B
.	O
ii	O
.	O
speaker	B
diarization	I
a.	O
broadcast	O
news	O
versus	O
conference	O
meetings	O
over	O
recent	O
years	O
,	O
the	O
scientiﬁc	O
community	O
has	O
developed	O
with	O
the	O
change	B
of	O
focus	O
of	O
the	O
nist	O
rt	O
evaluations	O
from	O
bn	O
research	B
on	O
speaker	B
diarization	I
in	O
a	O
number	O
of	O
different	O
do-	O
to	O
meetings	O
diarization	B
algorithms	O
had	O
to	O
be	O
adapted	O
according	O
mains	O
,	O
with	O
the	O
focus	O
usually	O
being	O
dictated	O
by	O
funded	O
research	B
to	O
the	O
differences	O
in	O
the	O
nature	O
of	O
the	O
data	B
.	O
first	O
,	O
bn	O
speech	O
projects	O
.	O
from	O
early	O
work	O
with	O
telephony	O
data	B
,	O
broadcast	O
data	B
is	O
usually	O
acquired	O
using	O
boom	O
or	O
lapel	O
microphones	O
with	O
news	O
(	O
bn	O
)	O
became	O
the	O
main	O
focus	O
of	O
research	B
towards	O
the	O
some	O
recordings	O
being	O
made	O
in	O
the	O
studio	O
and	O
others	O
in	O
the	O
late	O
1990s	O
and	O
early	O
2000s	O
and	O
the	O
use	O
of	O
speaker	B
diariza-	O
ﬁeld	O
.	O
conversely	O
,	O
meetings	O
are	O
usually	O
recorded	O
using	O
desktop	O
tion	O
was	O
aimed	O
at	O
automatically	O
annotating	O
tv	O
and	O
radio	O
or	O
far-ﬁeld	O
microphones	O
(	O
single	O
microphones	O
or	O
microphone	O
ar-	O
transmissions	O
that	O
are	O
broadcast	O
daily	O
all	O
over	O
the	O
world	O
.	O
an-	O
rays	O
)	O
which	O
are	O
more	O
convenient	O
for	O
users	O
than	O
head	O
-	O
mounted	O
or	O
notations	O
included	O
automatic	O
speech	O
transcription	B
and	O
meta	O
lapel	O
microphones.2	O
as	O
a	O
result	O
,	O
the	O
signal	B
-	O
to	O
-	O
noise	O
ratio	O
is	O
gen-	O
data	B
labeling	O
,	O
including	O
speaker	B
diarization	I
.	O
interest	O
in	O
the	O
erally	O
better	O
for	O
bn	O
data	B
than	O
it	O
is	O
for	O
meeting	O
recordings	O
.	O
addi-	O
meeting	O
domain	B
grew	O
extensively	O
from	O
2002	O
,	O
with	O
the	O
launch	O
tionally	O
,	O
differences	O
between	O
meeting	O
room	O
conﬁgurations	O
and	O
of	O
several	O
related	O
research	B
projects	O
including	O
the	O
european	O
microphone	O
placement	O
lead	O
to	O
variations	O
in	O
recording	B
quality	B
,	O
union	O
(	O
eu	O
)	O
multimodal	O
meeting	O
manager	O
(	O
m4	O
)	O
project	O
,	O
the	O
including	O
background	B
noise	I
,	O
reverberation	O
and	O
variable	O
speech	O
swiss	O
interactive	O
multimodal	O
information	B
management	O
(	O
im2	O
)	O
levels	O
(	O
depending	O
on	O
the	O
distance	B
between	O
speakers	O
and	O
micro-	O
project	O
,	O
the	O
eu	O
augmented	O
multi	O
-	O
party	O
interaction	O
(	O
ami	O
)	O
phones	O
)	O
.	O
project	O
,	O
subsequently	O
continued	O
through	O
the	O
eu	O
augmented	O
second	O
,	O
bn	O
speech	O
is	O
often	O
read	O
or	O
at	O
least	O
prepared	O
in	O
ad-	O
multi	O
-	O
party	O
interaction	O
with	O
distant	O
access	O
(	O
amida	O
)	O
project	O
vance	O
while	O
meeting	O
speech	O
tends	O
to	O
be	O
more	O
spontaneous	O
in	O
and	O
,	O
and	O
ﬁnally	O
,	O
the	O
eu	O
computers	O
in	O
the	O
human	O
interaction	O
nature	O
and	O
contains	O
more	O
overlapping	B
speech	I
.	O
although	O
bn	O
loop	O
(	O
chil	O
)	O
project	O
.	O
all	O
these	O
projects	O
addressed	O
the	O
research	B
recordings	O
can	O
contain	O
speech	O
that	O
is	O
overlapped	O
with	O
music	O
,	O
and	O
development	O
of	O
multimodal	O
technologies	O
dedicated	O
to	O
the	O
laughter	O
,	O
or	O
applause	O
(	O
far	O
less	O
common	O
for	O
conference	O
meeting	O
enhancement	O
of	O
human	O
-	O
to	O
-	O
human	O
communications	O
(	O
notably	O
in	O
data	B
)	O
,	O
in	O
general	O
,	O
the	O
detection	B
of	O
acoustic	O
events	O
and	O
speakers	O
distant	O
access	O
)	O
by	O
automatically	O
extracting	O
meeting	O
content	O
,	O
tends	O
to	O
be	O
more	O
challenging	O
for	O
conference	O
meeting	O
data	B
than	O
making	O
the	O
information	B
available	O
to	O
meeting	O
participants	B
,	O
or	O
for	O
for	O
bn	O
data	B
.	O
archiving	O
purposes	O
.	O
finally	O
,	O
the	O
number	O
of	O
speakers	O
is	O
usually	O
larger	O
in	O
bn	O
but	O
these	O
technologies	O
have	O
to	O
meet	O
challenging	O
demands	O
such	O
speaker	B
turns	O
occur	O
less	O
frequently	O
than	O
they	O
do	O
in	O
conference	O
as	O
content	O
indexing	O
,	O
linking	O
and/or	O
summarization	O
of	O
on	O
-	O
going	O
meeting	O
data	B
,	O
resulting	O
in	O
bn	O
having	O
a	O
longer	O
average	B
speaker	B
or	O
archived	O
meetings	O
,	O
the	O
inclusion	O
of	O
both	O
verbal	O
and	O
nonverbal	O
turn	O
length	B
.	O
an	O
extensive	O
analysis	B
of	O
bn	O
characteristics	B
is	O
re-	O
human	O
communication	B
(	O
people	O
movements	O
,	O
emotions	O
,	O
interac-	O
ported	O
in	O
[	O
3	O
]	O
and	O
a	O
comparison	O
of	O
bn	O
and	O
conference	O
meeting	O
tions	O
with	O
others	O
,	O
etc	O
.	O
)	O
.	O
this	O
is	O
achieved	O
by	O
exploiting	O
several	O
data	B
can	O
be	O
found	O
in	O
[	O
4	O
]	O
.	O
synchronized	O
data	B
streams	O
,	O
such	O
as	O
audio	O
,	O
video	O
and	O
textual	O
in-	O
formation	O
(	O
agenda	O
,	O
discussion	O
papers	O
,	O
slides	O
,	O
etc	O
.	O
)	O
,	O
that	O
are	O
able	O
1speaker	O
diarization	B
was	O
evaluated	O
prior	O
to	O
2002	O
through	O
nist	O
speaker	B
to	O
capture	O
different	O
kinds	O
of	O
information	B
that	O
are	O
useful	O
for	O
the	O
recognition	O
(	O
sr	O
)	O
evaluation	B
campaigns	O
(	O
focusing	O
on	O
telephone	B
speech	I
)	O
and	O
not	O
within	O
the	O
rt	O
evaluation	B
campaigns	O
.	O
structuring	O
and	O
analysis	B
of	O
meeting	O
content	O
.	O
speaker	B
diarization	I
2meeting	O
databases	O
recorded	O
for	O
research	B
purposes	O
usually	O
contain	O
plays	O
an	O
important	O
role	O
in	O
the	O
analysis	B
of	O
meeting	O
data	B
since	O
it	O
al-	O
head	O
-	O
mounted	O
and	O
lapel	O
microphone	O
recordings	O
for	O
ground	B
-	O
truth	O
creation	O
lows	O
for	O
such	O
content	O
to	O
be	O
structured	O
in	O
speaker	B
turns	O
,	O
to	O
which	O
purposes	O
only	O
.	O
authorized	O
licensed	O
use	O
limited	O
to	O
:	O
inria	O
.	O
downloaded	O
on	O
october	O
05,2020	O
at	O
07:30:52	O
utc	O
from	O
ieee	O
xplore	O
.	O
 	O
restrictions	O
apply	O
.	O
358	O
ieee	O
transactions	O
on	O
audio	O
,	O
speech	O
,	O
and	O
language	B
processing	I
,	O
vol	O
.	O
20	O
,	O
no	O
.	O
2	O
,	O
february	O
2012	O
assigned	O
to	O
the	O
two	O
individual	O
clusters	O
.	O
standard	O
distance	B
met-	O
rics	O
,	O
such	O
as	O
those	O
described	O
in	O
section	O
iii	O
-	O
c	O
,	O
are	O
used	O
to	O
iden-	O
tify	O
the	O
closest	O
clusters	O
.	O
a	O
reassignment	O
of	O
frames	O
to	O
clusters	O
is	O
usually	O
performed	O
after	O
each	O
cluster	O
merging	O
,	O
via	O
viterbi	O
re-	O
alignment	O
for	O
example	O
,	O
and	O
the	O
whole	O
process	B
is	O
repeated	O
itera-	O
tively	O
,	O
until	O
some	O
stopping	O
criterion	B
is	O
reached	O
,	O
upon	O
which	O
there	O
should	O
remain	O
only	O
one	O
cluster	O
for	O
each	O
detected	O
speaker	B
.	O
pos-	O
sible	O
stopping	O
criteria	O
include	O
thresholded	O
approaches	O
such	O
as	O
the	O
bayesian	O
information	B
criterion	B
(	O
bic	B
)	O
[	O
9	O
]	O
,	O
kullback	O
–	O
leibler	O
(	O
kl)-based	O
metrics	O
[	O
10	O
]	O
,	O
the	O
generalized	O
likelihood	B
ratio	I
(	O
glr	O
)	O
[	O
11	O
]	O
or	O
the	O
recently	O
proposed	O
metric	B
[	O
12	O
]	O
.	O
bottom	O
-	O
up	O
systems	O
submitted	O
to	O
the	O
nist	O
rt	O
evaluations	O
[	O
9	O
]	O
,	O
[	O
13	O
]	O
have	O
performed	O
consistently	O
well	O
.	O
2	O
)	O
top	O
-	O
down	O
approach	O
:	O
in	O
contrast	O
with	O
the	O
previous	O
ap-	O
fig	O
.	O
1	O
.	O
general	O
diarization	B
system	O
.	O
(	O
a	O
)	O
alternative	O
clustering	B
schemas	O
.	O
proach	O
,	O
the	O
top	O
-	O
down	O
approach	O
ﬁrst	O
models	B
the	O
entire	O
audio	O
(	O
b	O
)	O
general	O
speaker	B
diarization	I
architecture	B
.	O
stream	O
with	O
a	O
single	B
speaker	I
model	B
and	O
successively	O
adds	O
new	O
models	B
to	O
it	O
until	O
the	O
full	O
number	O
of	O
speakers	O
are	O
deemed	O
to	O
be	O
b.	O
main	O
approaches	O
accounted	O
for	O
.	O
a	O
single	O
gmm	O
model	B
is	O
trained	O
on	O
all	O
the	O
speech	O
most	O
of	O
present	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
speaker	B
diarization	I
systems	I
segments	O
available	O
,	O
all	O
of	O
which	O
are	O
marked	O
as	O
unlabeled	O
.	O
using	O
ﬁt	O
into	O
one	O
of	O
two	O
categories	O
:	O
the	O
bottom	O
-	O
up	O
and	O
the	O
top	O
-	O
down	O
some	O
selection	O
procedure	O
to	O
identify	O
suitable	O
training	B
data	I
from	O
approaches	O
,	O
as	O
illustrated	O
in	O
fig	O
.	O
1(a	O
)	O
.	O
the	O
top	O
-	O
down	O
approach	O
the	O
non	O
-	O
labeled	O
segments	O
,	O
new	O
speaker	B
models	B
are	O
iteratively	O
is	O
initialized	O
with	O
very	O
few	O
clusters	O
(	O
usually	O
one	O
)	O
whereas	O
the	O
added	O
to	O
the	O
model	B
one	O
-	O
by	O
-	O
one	O
,	O
with	O
interleaved	O
viterbi	O
realign-	O
bottom	O
-	O
up	O
approach	O
is	O
initialized	O
with	O
many	O
clusters	O
(	O
usually	O
ment	O
and	O
adaptation	O
.	O
segments	O
attributed	O
to	O
any	O
one	O
of	O
these	O
more	O
clusters	O
than	O
expected	O
speakers	O
)	O
.	O
in	O
both	O
cases	O
the	O
aim	O
new	O
models	B
are	O
marked	O
as	O
labeled	O
.	O
stopping	O
criteria	O
similar	O
to	O
is	O
to	O
iteratively	O
converge	O
towards	O
an	O
optimum	O
number	O
of	O
clus-	O
those	O
employed	O
in	O
bottom	O
-	O
up	O
systems	O
may	O
be	O
used	O
to	O
terminate	O
ters	O
.	O
if	O
the	O
ﬁnal	O
number	O
is	O
higher	O
than	O
the	O
optimum	O
then	O
the	O
the	O
process	B
or	O
it	O
can	O
continue	O
until	O
no	O
more	O
relevant	O
unlabeled	O
system	O
is	O
said	O
to	O
under	O
-	O
cluster	O
.	O
if	O
it	O
is	O
lower	O
it	O
is	O
said	O
to	O
over-	O
segments	O
with	O
which	O
to	O
train	O
new	O
speaker	B
models	B
remain	O
.	O
top-	O
cluster	O
.	O
both	O
bottom	O
-	O
up	O
and	O
top	O
-	O
down	O
approaches	O
are	O
generally	O
down	O
approaches	O
are	O
far	O
less	O
popular	O
than	O
their	O
bottom	O
-	O
up	O
coun-	O
based	O
on	O
hidden	O
markov	O
models	B
(	O
hmms	O
)	O
where	O
each	O
state	O
is	O
a	O
terparts	O
.	O
some	O
examples	O
include	O
[	O
14]–[16	O
]	O
.	O
while	O
they	O
are	O
gen-	O
gaussian	O
mixture	O
model	B
(	O
gmm	O
)	O
and	O
corresponds	O
to	O
a	O
speaker	B
.	O
erally	O
out	O
-	O
performed	O
by	O
the	O
best	O
bottom	O
-	O
up	O
systems	O
,	O
top	O
-	O
down	O
transitions	O
between	O
states	O
correspond	O
to	O
speaker	B
turns	O
.	O
in	O
this	O
approaches	O
have	O
performed	O
consistently	O
and	O
respectably	O
well	O
section	O
,	O
we	O
brieﬂy	O
outline	O
the	O
standard	O
bottom	O
-	O
up	O
and	O
top	O
-	O
down	O
against	O
the	O
broader	O
ﬁeld	O
of	O
other	O
bottom	O
-	O
up	O
entries	O
.	O
top	O
-	O
down	O
approaches	O
as	O
well	O
as	O
two	O
recently	O
proposed	O
alternatives	O
:	O
one	O
approaches	O
are	O
also	O
extremely	O
computationally	O
efﬁcient	O
and	O
can	O
based	O
on	O
information	B
theory	O
;	O
and	O
a	O
second	O
one	O
based	O
on	O
a	O
non	O
be	O
improved	O
through	O
cluster	O
puriﬁcation	O
[	O
17	O
]	O
.	O
parametric	O
bayesian	O
approach	O
.	O
although	O
these	O
new	O
approaches	O
3	O
)	O
other	O
approaches	O
:	O
a	O
recent	O
alternative	O
approach	O
,	O
though	O
have	O
not	O
been	O
reported	O
previously	O
in	O
the	O
context	O
of	O
ofﬁcial	O
nist	O
also	O
bottom	O
-	O
up	O
in	O
nature	O
,	O
is	O
inspired	O
from	O
rate	O
-	O
distortion	O
theory	O
rt	O
evaluations	O
they	O
have	O
shown	O
strong	O
potential	O
on	O
nist	O
rt	O
and	O
is	O
based	O
on	O
an	O
information	B
-	O
theoretic	O
framework	O
[	O
18	O
]	O
.	O
it	O
is	O
evaluation	B
datasets	B
and	O
are	O
thus	O
included	O
here	O
.	O
additionally	O
,	O
completely	O
non	O
parametric	O
and	O
its	O
results	B
have	O
been	O
shown	O
to	O
some	O
other	O
works	O
propose	O
sequential	O
single	O
-	O
pass	O
segmentation	B
be	O
comparable	O
to	O
those	O
of	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
parametric	O
systems	O
,	O
and	O
clustering	B
approaches	O
[	O
5]–[7	O
]	O
,	O
although	O
their	O
performance	O
with	O
signiﬁcant	O
savings	O
in	O
computation	O
.	O
clustering	B
is	O
based	O
on	O
tends	O
to	O
fall	O
short	O
of	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
.	O
mutual	O
information	B
,	O
which	O
measures	O
the	O
mutual	O
dependence	O
1	O
)	O
bottom	O
-	O
up	O
approach	O
:	O
the	O
bottom	O
-	O
up	O
approach	O
is	O
by	O
far	O
of	O
two	O
variables	O
[	O
19	O
]	O
.	O
only	O
a	O
single	O
global	O
gmm	O
is	O
tuned	O
for	O
the	O
most	O
common	O
in	O
the	O
literature	O
.	O
also	O
known	O
as	O
agglomer-	O
the	O
full	O
audio	O
stream	O
,	O
and	O
mutual	O
information	B
is	O
computed	O
in	O
ative	O
hierarchical	O
clustering	B
(	O
ahc	O
or	O
aghc	O
)	O
,	O
the	O
bottom	O
-	O
up	O
a	O
new	O
space	O
of	O
relevance	O
variables	O
deﬁned	O
by	O
the	O
gmm	O
com-	O
approach	O
trains	O
a	O
number	O
of	O
clusters	O
or	O
models	B
and	O
aims	O
at	O
ponents	O
.	O
the	O
approach	O
aims	O
at	O
minimizing	O
the	O
loss	O
of	O
mutual	O
successively	O
merging	O
and	O
reducing	O
the	O
number	O
of	O
clusters	O
until	O
information	B
between	O
successive	O
clusterings	O
while	O
preserving	O
as	O
only	O
one	O
remains	O
for	O
each	O
speaker	B
.	O
various	O
initializations	O
have	O
much	O
information	B
as	O
possible	O
from	O
the	O
original	O
dataset	O
.	O
two	O
been	O
studied	O
and	O
,	O
whereas	O
some	O
have	O
investigated	O
-means	O
clus-	O
suitable	O
methods	O
have	O
been	O
reported	O
:	O
the	O
agglomerative	O
infor-	O
tering	O
,	O
many	O
systems	O
use	O
a	O
uniform	O
initialization	O
,	O
where	O
the	O
mation	O
bottleneck	O
(	O
aib	O
)	O
[	O
18	O
]	O
and	O
the	O
sequential	O
information	B
bot-	O
audio	O
stream	O
is	O
divided	O
into	O
a	O
number	O
of	O
equal	O
length	B
abutted	O
tleneck	O
(	O
sib	O
)	O
[	O
19	O
]	O
.	O
even	O
if	O
this	O
new	O
system	O
does	O
not	O
lead	O
to	O
segments	O
.	O
this	O
simpler	O
approach	O
generally	O
leads	O
to	O
equivalent	O
better	O
performance	O
than	O
parametric	O
approaches	O
,	O
results	B
com-	O
performance	O
[	O
8	O
]	O
.	O
in	O
all	O
cases	O
the	O
audio	O
stream	O
is	O
initially	O
over-	O
parable	O
to	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
gmm	O
systems	O
are	O
reported	O
and	O
are	O
segmented	O
into	O
a	O
number	O
of	O
segments	O
which	O
exceeds	O
the	O
antic-	O
achieved	O
with	O
great	O
savings	O
in	O
computation	O
.	O
ipated	O
maximum	O
number	O
of	O
speakers	O
.	O
the	O
bottom	O
-	O
up	O
approach	O
alternatively	O
,	O
bayesian	O
machine	O
learning	O
became	O
popular	O
by	O
then	O
iteratively	O
selects	O
closely	O
matching	O
clusters	O
to	O
merge	O
,	O
hence	O
the	O
end	O
of	O
the	O
1990s	O
and	O
has	O
recently	O
been	O
used	O
for	O
speaker	B
reducing	O
the	O
number	O
of	O
clusters	O
by	O
one	O
upon	O
each	O
iteration	O
.	O
diarization	B
.	O
the	O
key	O
component	O
of	O
bayesian	O
inference	B
is	O
that	O
clusters	O
are	O
generally	O
modeled	O
with	O
a	O
gmm	O
and	O
,	O
upon	O
merging	O
,	O
it	O
does	O
not	O
aim	O
at	O
estimating	O
the	O
parameters	O
of	O
a	O
system	O
(	O
i.e.	O
,	O
a	O
single	O
new	O
gmm	O
is	O
trained	O
on	O
the	O
data	B
that	O
was	O
previously	O
to	O
perform	O
point	O
estimates	O
)	O
,	O
but	O
rather	O
the	O
parameters	O
of	O
their	O
authorized	O
licensed	O
use	O
limited	O
to	O
:	O
inria	O
.	O
downloaded	O
on	O
october	O
05,2020	O
at	O
07:30:52	O
utc	O
from	O
ieee	O
xplore	O
.	O
 	O
restrictions	O
apply	O
.	O
anguera	O
miro	O
et	O
al	O
.	O
:	O
speaker	B
diarization	I
:	O
a	O
review	O
of	O
recent	O
research	B
359	O
related	O
distribution	O
(	O
hyperparameters	O
)	O
.	O
this	O
allows	O
for	O
avoiding	O
clustering	B
[	O
15	O
]	O
,	O
[	O
16	O
]	O
.	O
next	O
,	O
in	O
fig	O
.	O
1(b)-iii	O
/	O
iv	O
,	O
a	O
distance	B
between	O
any	O
premature	O
hard	O
decision	O
in	O
the	O
diarization	B
problem	O
and	O
for	O
clusters	O
and	O
a	O
split	O
/	O
merging	O
mechanism	O
(	O
see	O
section	O
iii	O
-	O
d	O
)	O
is	O
automatically	O
regulating	O
the	O
system	O
with	O
the	O
observations	O
(	O
e.g.	O
,	O
used	O
to	O
iteratively	O
merge	O
clusters	O
[	O
13	O
]	O
,	O
[	O
31	O
]	O
or	O
to	O
introduce	O
new	O
the	O
complexity	O
of	O
the	O
model	B
is	O
data	B
dependent	O
)	O
.	O
however	O
,	O
the	O
ones	O
[	O
16	O
]	O
.	O
optionally	O
,	O
data	B
puriﬁcation	O
algorithms	O
can	O
be	O
used	O
computation	O
of	O
posterior	O
distributions	O
often	O
requires	O
intractable	O
to	O
make	O
clusters	O
more	O
discriminant	O
[	O
13	O
]	O
,	O
[	O
17	O
]	O
,	O
[	O
32	O
]	O
.	O
finally	O
,	O
as	O
integrals	O
and	O
,	O
as	O
a	O
result	O
,	O
the	O
statistics	B
community	O
has	O
developed	O
illustrated	O
in	O
fig	O
.	O
1(b)-v	O
,	O
stopping	O
criteria	O
are	O
used	O
to	O
determine	O
approximate	O
inference	B
methods	O
.	O
monte	O
carlo	O
markov	O
chains	O
when	O
the	O
optimum	O
number	O
of	O
clusters	O
has	O
been	O
reached	O
[	O
33	O
]	O
,	O
(	O
mcmcs	O
)	O
were	O
ﬁrst	O
used	O
[	O
20	O
]	O
to	O
provide	O
a	O
systematic	O
approach	O
[	O
34	O
]	O
.	O
to	O
the	O
computation	O
of	O
distributions	O
via	O
sampling	O
,	O
enabling	O
the	O
deployment	O
of	O
bayesian	O
methods	O
.	O
however	O
,	O
sampling	O
methods	O
a.	O
acoustic	O
beamforming	O
are	O
generally	O
slow	O
and	O
prohibitive	O
when	O
the	O
amount	B
of	O
data	B
is	O
the	O
application	B
of	O
speaker	B
diarization	I
to	O
the	O
meeting	O
domain	B
large	O
,	O
and	O
they	O
require	O
to	O
be	O
run	O
several	O
times	O
as	O
the	O
chains	O
may	O
triggered	O
the	O
need	O
for	O
dealing	O
with	O
multiple	O
microphones	O
which	O
get	O
stuck	O
and	O
not	O
converge	O
in	O
a	O
practical	O
number	O
of	O
iterations	O
.	O
are	O
often	O
used	O
to	O
record	O
the	O
same	O
meeting	O
from	O
different	O
lo-	O
another	O
alternative	O
approach	O
,	O
known	O
as	O
variational	O
bayes	O
,	O
cations	O
in	O
the	O
room	O
[	O
35]–[37	O
]	O
.	O
the	O
microphones	O
can	O
have	O
dif-	O
has	O
been	O
popular	O
since	O
1993	O
[	O
21	O
]	O
,	O
[	O
22	O
]	O
and	O
aims	O
at	O
providing	O
a	O
ferent	O
characteristics	B
:	O
wall	O
-	O
mounted	O
microphones	O
(	O
intended	O
for	O
deterministic	O
approximation	O
of	O
the	O
distributions	O
.	O
it	O
enables	O
an	O
speaker	B
localization	O
)	O
,	O
lapel	O
microphones	O
,	O
desktop	O
microphones	O
inference	B
problem	O
to	O
be	O
converted	O
to	O
an	O
optimization	O
problem	O
positioned	O
on	O
the	O
meeting	O
room	O
table	O
or	O
microphone	O
arrays	O
.	O
the	O
by	O
approximating	O
the	O
intractable	O
distribution	O
with	O
a	O
tractable	O
use	O
of	O
different	O
microphone	O
combinations	O
as	O
well	O
as	O
differences	O
approximation	O
obtained	O
by	O
minimizing	O
the	O
kullback	O
–	O
leibler	O
in	O
microphone	O
quality	B
called	O
for	O
new	O
approaches	O
to	O
speaker	B
di-	O
divergence	O
between	O
them	O
.	O
in	O
[	O
23	O
]	O
a	O
variational	O
bayes	O
-	O
em	O
arization	O
with	O
multiple	O
channels	B
.	O
algorithm	O
is	O
used	O
to	O
learn	O
a	O
gmm	O
speaker	B
model	B
and	O
optimize	O
the	O
multiple	O
distant	O
microphone	O
(	O
mdm	O
)	O
condition	B
was	O
in-	O
a	O
change	B
detection	I
process	B
and	O
the	O
merging	O
criterion	B
.	O
in	O
[	O
24	O
]	O
,	O
troduced	O
in	O
the	O
nist	O
rt’04	O
(	O
spring	O
)	O
evaluation	B
.	O
a	O
variety	O
of	O
variational	O
bayes	O
is	O
combined	O
successfully	O
with	O
eigenvoice	O
algorithms	O
have	O
been	O
proposed	O
to	O
extend	O
mono	O
-	O
channel	O
diariza-	O
modeling	O
,	O
described	O
in	O
[	O
25	O
]	O
,	O
for	O
the	O
speaker	B
diarization	I
of	O
tion	O
systems	O
to	O
handle	O
multiple	O
channels	B
.	O
one	O
option	O
,	O
proposed	O
telephone	O
conversations	O
.	O
however	O
,	O
these	O
systems	O
still	O
con-	O
in	O
[	O
38	O
]	O
,	O
is	O
to	O
perform	O
speaker	B
diarization	I
on	O
each	O
channel	O
inde-	O
sider	O
classical	O
viterbi	O
decoding	O
for	O
the	O
classiﬁcation	O
and	O
pendently	O
and	O
then	O
to	O
merge	O
the	O
individual	O
outputs	O
.	O
in	O
order	B
to	O
differ	O
from	O
the	O
nonparametric	O
bayesian	O
systems	O
introduced	O
in	O
do	O
so	O
,	O
a	O
two	O
axis	O
merging	O
algorithm	O
is	O
used	O
which	O
considers	O
the	O
section	O
iv	O
-	O
f	O
.	O
longest	O
detected	O
speaker	B
segments	I
in	O
each	O
channel	O
and	O
iterates	O
finally	O
,	O
the	O
recently	O
proposed	O
speaker	B
binary	O
keys	O
[	O
26	O
]	O
have	O
over	O
the	O
segmentation	B
output	B
.	O
in	O
the	O
same	O
year	O
,	O
a	O
late	O
-	O
stage	B
fu-	O
been	O
successfully	O
applied	O
to	O
speaker	B
diarization	I
in	O
meetings	O
sion	O
approach	O
was	O
also	O
proposed	O
[	O
39	O
]	O
.	O
in	O
it	O
,	O
speaker	B
segmen-	O
[	O
27	O
]	O
with	O
similar	O
performance	O
to	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
systems	O
but	O
tation	O
is	O
performed	O
separately	O
in	O
all	O
channels	B
and	O
diarization	B
also	O
with	O
considerable	O
computational	O
savings	O
(	O
running	O
in	O
is	O
applied	O
only	O
taking	O
into	O
account	O
the	O
channel	O
whose	O
speech	O
around	O
0.1	O
times	O
real	O
-	O
time	B
)	O
.	O
speaker	B
binary	O
keys	O
are	O
small	O
bi-	O
segments	O
have	O
the	O
best	O
signal	B
-	O
to	O
-	O
noise	O
ratio	O
(	O
snr	O
)	O
.	O
subsequent	O
nary	O
vectors	O
computed	O
from	O
the	O
acoustic	O
data	B
using	O
a	O
universal	O
approaches	O
investigated	O
preprocessing	O
to	O
combine	O
the	O
acoustic	O
background	O
model	B
(	O
ubm)-like	O
model	B
.	O
once	O
they	O
are	O
computed	O
signals	B
to	O
obtain	O
a	O
single	B
channel	I
which	O
could	O
then	O
be	O
processed	O
all	O
processing	B
tasks	O
take	O
place	O
in	O
the	O
binary	O
domain	B
.	O
other	O
by	O
a	O
regular	O
mono	O
-	O
channel	O
diarization	B
system	O
.	O
in	O
[	O
40	O
]	O
,	O
the	O
mul-	O
works	O
in	O
speaker	B
diarization	I
concerned	O
with	O
speed	O
include	O
[	O
28	O
]	O
,	O
tiple	O
channels	B
are	O
combined	O
with	O
a	O
simple	O
weighted	O
sum	O
ac-	O
[	O
29	O
]	O
which	O
achieve	O
faster	O
than	O
real	O
-	O
time	B
processing	B
through	O
the	O
cording	O
to	O
their	O
snr	O
.	O
though	O
straightforward	O
to	O
implement	O
,	O
it	O
use	O
of	O
several	O
processing	B
tricks	O
applied	O
to	O
a	O
standard	O
bottom	O
-	O
up	O
does	O
not	O
take	O
into	O
account	O
the	O
time	B
difference	O
of	O
arrival	O
between	O
approach	O
(	O
[	O
28	O
]	O
)	O
or	O
by	O
parallelizing	O
most	O
of	O
the	O
processing	B
each	O
microphone	O
channel	O
and	O
might	O
easily	O
lead	O
to	O
a	O
decrease	O
in	O
in	O
a	O
gpu	O
unit	O
(	O
[	O
29	O
]	O
)	O
.	O
the	O
need	O
for	O
efﬁcient	O
diarization	B
sys-	O
performance	O
.	O
tems	O
is	O
emphasized	O
when	O
processing	B
very	O
large	O
databases	O
or	O
since	O
the	O
nist	O
rt’05	O
evaluation	B
,	O
the	O
most	O
common	O
ap-	O
when	O
using	O
diarization	B
as	O
a	O
preprocessing	O
step	O
to	O
other	O
speech	O
proach	O
to	O
multi	O
-	O
channel	O
speaker	B
diarization	I
involves	O
acoustic	O
algorithms	O
.	O
beamforming	O
as	O
initially	O
proposed	O
in	O
[	O
41	O
]	O
and	O
described	O
in	O
de-	O
tail	O
in	O
[	O
42	O
]	O
.	O
many	O
rt	O
participants	B
use	O
the	O
free	O
and	O
open	O
-	O
source	B
iii	O
.	O
main	O
algorithms	O
acoustic	O
beamforming	O
toolkit	O
known	O
as	O
beamformit	O
[	O
43	O
]	O
fig	O
.	O
1(b	O
)	O
shows	O
a	O
block	O
diagram	O
of	O
the	O
generic	O
modules	O
which	O
which	O
consists	O
of	O
an	O
enhanced	O
delay	O
-	O
and	O
-	O
sum	O
algorithm	O
to	O
make	O
up	O
most	O
speaker	B
diarization	I
systems	I
.	O
the	O
data	B
prepro-	O
correct	O
misalignments	O
due	O
to	O
the	O
time	B
-	O
delay	O
-	O
of	O
-	O
arrival	O
(	O
tdoa	O
)	O
cessing	O
step	O
(	O
fig	O
.	O
1(b)-i	O
)	O
tends	O
to	O
be	O
somewhat	O
domain	B
spe-	O
of	O
speech	O
to	O
each	O
microphone	O
.	O
speech	O
data	B
can	O
be	O
optionally	O
ciﬁc	O
.	O
for	O
meeting	O
data	B
,	O
preprocessing	O
usually	O
involves	O
noise	O
re-	O
preprocessed	O
using	O
wiener	O
ﬁltering	O
[	O
44	O
]	O
to	O
attenuate	O
noise	O
duction	O
(	O
such	O
as	O
wiener	O
ﬁltering	O
for	O
example	O
)	O
,	O
multi	O
-	O
channel	O
using	O
,	O
for	O
example	O
,	O
[	O
45	O
]	O
.	O
a	O
reference	B
channel	O
is	O
selected	O
and	O
acoustic	O
beamforming	O
(	O
see	O
section	O
iii	O
-	O
a	O
)	O
,	O
the	O
parameterization	O
the	O
other	O
channels	B
are	O
appropriately	O
aligned	O
and	O
combined	O
with	O
of	O
speech	O
data	B
into	O
acoustic	B
features	I
(	O
such	O
as	O
mfcc	O
,	O
plp	O
,	O
etc	O
.	O
)	O
a	O
standard	O
delay	O
-	O
and	O
-	O
sum	O
algorithm	O
.	O
the	O
contribution	O
made	O
by	O
and	O
the	O
detection	B
of	O
speech	B
segments	I
with	O
a	O
speech	B
activity	I
each	O
signal	B
channel	O
to	O
the	O
output	B
is	O
then	O
dynamically	O
weighted	O
detection	B
algorithm	O
(	O
see	O
section	O
iii	O
-	O
b	O
)	O
.	O
cluster	O
initialization	O
according	O
to	O
its	O
snr	O
or	O
by	O
using	O
a	O
cross	O
-	O
correlation	O
-	O
based	O
(	O
fig	O
.	O
1(b)-ii	O
)	O
depends	O
on	O
the	O
approach	O
to	O
diarization	B
,	O
i.e.	O
,	O
the	O
metric	B
.	O
various	O
additional	O
algorithms	O
are	O
available	O
in	O
the	O
choice	O
of	O
an	O
initial	O
set	B
of	O
clusters	O
in	O
bottom	O
-	O
up	O
clustering	B
[	O
8	O
]	O
,	O
beamformit	O
toolkit	O
to	O
select	O
the	O
optimum	O
reference	B
channel	O
[	O
13	O
]	O
,	O
[	O
30	O
]	O
(	O
see	O
section	O
iii	O
-	O
c	O
)	O
or	O
a	O
single	O
segment	B
in	O
top	O
-	O
down	O
and	O
to	O
stabilize	O
the	O
tdoa	O
values	B
between	O
channels	B
before	O
the	O
authorized	O
licensed	O
use	O
limited	O
to	O
:	O
inria	O
.	O
downloaded	O
on	O
october	O
05,2020	O
at	O
07:30:52	O
utc	O
from	O
ieee	O
xplore	O
.	O
 	O
restrictions	O
apply	O
.	O
360	O
ieee	O
transactions	O
on	O
audio	O
,	O
speech	O
,	O
and	O
language	B
processing	I
,	O
vol	O
.	O
20	O
,	O
no	O
.	O
2	O
,	O
february	O
2012	O
signals	B
are	O
summed	O
.	O
finally	O
,	O
the	O
tdoa	O
estimates	O
themselves	O
speech	O
and	O
nonspeech	O
models	B
may	O
optionally	O
be	O
adapted	O
to	O
are	O
made	O
available	O
as	O
outputs	O
and	O
have	O
been	O
used	O
successfully	O
speciﬁc	O
meeting	O
conditions	O
[	O
15	O
]	O
.	O
discriminant	O
classiﬁers	O
such	O
to	O
improve	O
diarization	B
,	O
as	O
explained	O
in	O
section	O
iv	O
-	O
a	O
.	O
note	O
as	O
linear	O
discriminant	B
analysis	I
(	O
lda	O
)	O
coupled	O
with	O
mel	O
fre-	O
that	O
,	O
although	O
there	O
are	O
other	O
algorithms	O
that	O
can	O
provide	O
quency	O
cepstrum	O
coefﬁcients	O
(	O
mfccs	O
)	O
[	O
53	O
]	O
or	O
support	O
vector	O
better	O
beamforming	O
results	B
for	O
some	O
cases	O
,	O
delay	O
-	O
and	O
-	O
sum	O
machines	O
(	O
svms	O
)	O
[	O
54	O
]	O
have	O
also	O
been	O
proposed	O
in	O
the	O
litera-	O
beamforming	O
is	O
the	O
most	O
reliable	O
one	O
when	O
no	O
information	B
on	O
ture	O
.	O
the	O
main	O
drawback	O
of	O
model	B
-	O
based	O
approaches	O
is	O
their	O
re-	O
the	O
location	O
or	O
nature	O
of	O
each	O
microphone	O
is	O
known	O
a	O
priori	O
.	O
liance	O
on	O
external	O
data	B
for	O
the	O
training	O
of	O
speech	O
and	O
nonspeech	O
among	O
alternative	O
beamforming	O
algorithms	O
we	O
ﬁnd	O
maximum	O
models	B
which	O
makes	O
them	O
less	O
robust	O
to	O
changes	O
in	O
acoustic	O
likelihood	B
(	O
ml	O
)	O
[	O
46	O
]	O
or	O
generalized	O
sidelobe	O
canceller	O
(	O
gsc	O
)	O
conditions	O
.	O
hybrid	O
approaches	O
have	O
been	O
proposed	O
as	O
a	O
poten-	O
[	O
47	O
]	O
which	O
adaptively	O
ﬁnd	O
the	O
optimum	O
parameters	O
,	O
and	O
min-	O
tial	O
solution	O
.	O
in	O
most	O
cases	O
,	O
an	O
energy	O
-	O
based	O
detection	B
is	O
ﬁrst	O
ap-	O
imum	O
variance	O
distortionless	O
response	O
(	O
mvdr	O
)	O
[	O
48	O
]	O
when	O
plied	O
in	O
order	B
to	O
label	O
a	O
limited	O
amount	B
of	O
speech	O
and	O
nonspeech	O
prior	O
information	B
on	O
ambient	O
noise	O
is	O
available	O
.	O
all	O
of	O
these	O
data	B
for	O
which	O
there	O
is	O
high	O
conﬁdence	O
in	O
the	O
classiﬁcation	O
.	O
in	O
a	O
have	O
higher	O
computational	O
requirements	O
and	O
,	O
in	O
the	O
case	O
of	O
the	O
second	O
step	O
,	O
the	O
labeled	O
data	B
are	O
used	O
to	O
train	O
meeting	O
-	O
speciﬁc	O
adaptive	O
algorithms	O
,	O
there	O
is	O
the	O
danger	O
of	O
converging	O
to	O
inac-	O
speech	O
and	O
nonspeech	O
models	B
,	O
which	O
are	O
subsequently	O
used	O
in	O
a	O
curate	O
parameters	O
,	O
especially	O
when	O
processing	B
microphones	O
of	O
model	B
-	O
based	O
detector	O
to	O
obtain	O
the	O
ﬁnal	O
speech	O
/	O
nonspeech	O
seg-	O
different	O
types	O
.	O
mentation	O
[	O
9	O
]	O
,	O
[	O
55]–[57	O
]	O
.	O
finally	O
,	O
[	O
58	O
]	O
combines	O
a	O
model	B
-	O
based	O
with	O
a	O
4-hz	O
modulation	O
energy	O
-	O
based	O
detector	O
.	O
interestingly	O
,	O
in-	O
b.	O
speech	B
activity	I
detection	I
stead	O
of	O
being	O
applied	O
as	O
a	O
preprocessing	O
stage	B
,	O
in	O
this	O
system	O
speech	B
activity	I
detection	I
(	O
sad	O
)	O
involves	O
the	O
labeling	O
of	O
sad	O
is	O
incorporated	O
into	O
the	O
speaker	B
diarization	I
process	B
.	O
speech	O
and	O
nonspeech	O
segments	O
.	O
sad	O
can	O
have	O
a	O
signiﬁcant	O
c.	O
segmentation	B
impact	O
on	O
speaker	B
diarization	I
performance	O
for	O
two	O
reasons	O
.	O
the	O
ﬁrst	O
stems	O
directly	O
from	O
the	O
standard	O
speaker	B
diarization	I
in	O
the	O
literature	O
,	O
the	O
term	O
“	O
speaker	B
segmentation	I
”	O
is	O
some-	O
performance	O
metric	B
,	O
namely	O
the	O
diarization	B
error	I
rate	I
(	O
der	O
)	O
,	O
times	O
used	O
to	O
refer	O
to	O
both	O
segmentation	B
and	O
clustering	B
.	O
while	O
which	O
takes	O
into	O
account	O
both	O
the	O
false	B
alarm	I
and	O
missed	O
some	O
systems	O
treat	O
each	O
task	O
separately	O
many	O
of	O
present	O
speaker	B
error	B
rates	I
(	O
see	O
section	O
vi	O
-	O
a	O
for	O
more	O
details	O
on	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
systems	O
tackle	O
them	O
simultaneously	O
,	O
as	O
de-	O
evaluation	B
metrics	I
)	O
;	O
poor	O
sad	O
performance	O
will	O
therefore	O
scribed	O
in	O
section	O
iii	O
-	O
e	O
.	O
in	O
these	O
cases	O
the	O
notion	O
of	O
strictly	O
lead	O
to	O
an	O
increased	O
der	O
.	O
the	O
second	O
follows	O
from	O
the	O
fact	O
independent	O
segmentation	B
and	O
clustering	B
modules	O
is	O
less	O
rel-	O
that	O
nonspeech	O
segments	O
can	O
disturb	O
the	O
speaker	B
diarization	I
evant	O
.	O
however	O
,	O
both	O
modules	O
are	O
fundamental	O
to	O
the	O
task	O
of	O
process	B
,	O
and	O
more	O
speciﬁcally	O
the	O
acoustic	O
models	B
involved	O
in	O
speaker	B
diarization	I
and	O
some	O
systems	O
,	O
such	O
as	O
that	O
reported	O
in	O
the	O
process	B
[	O
49	O
]	O
.	O
indeed	O
,	O
the	O
inclusion	O
of	O
non	O
-	O
speech	B
segments	I
[	O
6	O
]	O
,	O
apply	O
distinctly	O
independent	O
segmentation	B
and	O
clustering	B
in	O
speaker	B
modelling	O
leads	O
to	O
less	O
discriminant	O
models	B
and	O
thus	O
stages	O
.	O
thus	O
,	O
the	O
segmentation	B
and	O
clustering	B
models	B
are	O
increased	O
difﬁculties	O
in	O
segmentation	B
.	O
consequently	O
,	O
a	O
good	O
described	O
separately	O
here	O
.	O
compromise	O
between	O
missed	O
and	O
false	B
alarm	I
speech	O
error	B
rates	I
speaker	B
segmentation	I
is	O
core	O
to	O
the	O
diarization	B
process	B
and	O
has	O
to	O
be	O
found	O
to	O
enhance	O
the	O
quality	B
of	O
the	O
following	O
speaker	B
aims	O
at	O
splitting	O
the	O
audio	O
stream	O
into	O
speaker	B
homogeneous	O
diarization	B
process	B
.	O
segments	O
or	O
,	O
alternatively	O
,	O
to	O
detect	O
changes	O
in	O
speakers	O
,	O
also	O
sad	O
is	O
a	O
fundamental	O
task	O
in	O
almost	O
all	O
ﬁelds	O
of	O
speech	O
known	O
as	O
speaker	B
turns	O
.	O
the	O
classical	O
approach	O
to	O
segmentation	B
processing	B
(	O
coding	O
,	O
enhancement	O
,	O
and	O
recognition	O
)	O
and	O
many	O
performs	O
a	O
hypothesis	B
testing	O
using	O
the	O
acoustic	O
segments	O
in	O
different	O
approaches	O
and	O
studies	O
have	O
been	O
reported	O
in	O
the	O
two	O
sliding	O
and	O
possibly	O
overlapping	B
,	O
consecutive	O
windows	O
.	O
for	O
literature	O
[	O
50	O
]	O
.	O
initial	O
approaches	O
for	O
diarization	B
tried	O
to	O
solve	O
each	O
considered	O
change	B
point	O
there	O
are	O
two	O
possible	O
hypotheses	B
:	O
speech	B
activity	I
detection	I
on	O
the	O
ﬂy	O
,	O
i.e.	O
,	O
by	O
having	O
a	O
non-	O
ﬁrst	O
that	O
both	O
segments	O
come	O
from	O
the	O
same	B
speaker	I
(	O
)	O
,	O
and	O
speech	O
cluster	O
be	O
a	O
by	O
-	O
product	O
of	O
the	O
diarization	B
.	O
however	O
,	O
thus	O
that	O
they	O
can	O
be	O
well	O
represented	O
by	O
a	O
single	O
model	B
;	O
and	O
it	O
became	O
evident	O
that	O
better	O
results	B
are	O
obtained	O
using	O
a	O
second	O
that	O
there	O
are	O
two	O
different	O
speakers	O
(	O
)	O
,	O
and	O
thus	O
that	O
dedicated	O
speech	O
/	O
nonspeech	O
detector	O
as	O
preprocessing	O
step	O
.	O
two	O
different	O
models	B
are	O
more	O
appropriate	O
.	O
in	O
practice	O
,	O
models	B
in	O
the	O
context	O
of	O
meetings	O
nonspeech	O
segments	O
may	O
include	O
are	O
estimated	O
from	O
each	O
of	O
the	O
speech	O
windows	O
and	O
some	O
cri-	O
silence	B
,	O
but	O
also	O
ambient	O
noise	O
such	O
as	O
paper	O
shufﬂing	O
,	O
door	O
teria	O
are	O
used	O
to	O
determine	O
whether	O
they	O
are	O
best	O
accounted	O
for	O
knocks	O
or	O
non	O
-	O
lexical	O
noise	O
such	O
as	O
breathing	O
,	O
coughing	O
,	O
and	O
by	O
two	O
separate	O
models	B
(	O
and	O
hence	O
two	O
separate	O
speakers	O
)	O
,	O
or	O
by	O
laughing	O
,	O
among	O
other	O
background	O
noises	O
.	O
therefore	O
,	O
highly	O
a	O
single	O
model	B
(	O
and	O
hence	O
the	O
same	B
speaker	I
)	O
by	O
using	O
an	O
empir-	O
variable	O
energy	O
levels	O
can	O
be	O
observed	O
in	O
the	O
nonspeech	O
parts	O
ically	O
determined	O
or	O
dynamically	O
adapted	O
threshold	B
[	O
10	O
]	O
,	O
[	O
59	O
]	O
.	O
of	O
the	O
signal	B
.	O
moreover	O
,	O
differences	O
in	O
microphones	O
or	O
room	O
this	O
is	O
performed	O
across	O
the	O
whole	O
audio	O
stream	O
and	O
a	O
sequence	B
conﬁgurations	O
may	O
result	O
in	O
variable	O
snrs	O
from	O
one	O
meeting	O
of	O
speaker	B
turns	O
is	O
extracted	O
.	O
to	O
another	O
.	O
thus	O
,	O
sad	O
is	O
far	O
from	O
being	O
trivial	O
in	O
this	O
context	O
many	O
different	O
distance	B
metrics	O
have	O
appeared	O
in	O
the	O
liter-	O
and	O
typical	O
techniques	B
based	O
on	O
feature	O
extraction	B
(	O
energy	O
,	O
ature	O
.	O
next	O
,	O
we	O
review	O
the	O
dominant	O
approaches	O
which	O
have	O
spectrum	B
divergence	O
between	O
speech	O
and	O
background	B
noise	I
,	O
been	O
used	O
for	O
the	O
nist	O
rt	O
speaker	B
diarization	I
evaluations	O
and	O
pitch	B
estimation	B
)	O
combined	O
with	O
a	O
threshold	B
-	O
based	O
decision	O
during	O
the	O
last	O
four	O
years	O
.	O
the	O
most	O
common	O
approach	O
is	O
that	O
have	O
proven	O
to	O
be	O
relatively	O
ineffective	O
.	O
of	O
the	O
bayesian	O
information	B
criterion	B
(	O
bic	B
)	O
and	O
its	O
associated	O
model	B
-	O
based	O
approaches	O
tend	O
to	O
have	O
better	O
performances	O
bic	B
metric	B
[	O
33	O
]	O
which	O
has	O
proved	O
to	O
be	O
extremely	O
popular	O
,	O
and	O
rely	O
on	O
a	O
two	O
-	O
class	O
detector	O
,	O
with	O
models	B
pre	O
-	O
trained	O
with	O
e.g	O
.	O
,[60]–[62	O
]	O
.	O
the	O
approach	O
requires	O
the	O
setting	O
of	O
an	O
explicit	O
external	O
speech	O
and	O
nonspeech	O
data	B
[	O
6	O
]	O
,	O
[	O
41	O
]	O
,	O
[	O
49	O
]	O
,	O
[	O
51	O
]	O
,	O
[	O
52	O
]	O
.	O
penalty	O
term	O
which	O
controls	O
the	O
tradeoff	O
between	O
missed	O
turns	O
authorized	O
licensed	O
use	O
limited	O
to	O
:	O
inria	O
.	O
downloaded	O
on	O
october	O
05,2020	O
at	O
07:30:52	O
utc	O
from	O
ieee	O
xplore	O
.	O
 	O
restrictions	O
apply	O
.	O
anguera	O
miro	O
et	O
al	O
.	O
:	O
speaker	B
diarization	I
:	O
a	O
review	O
of	O
recent	O
research	B
361	O
and	O
those	O
falsely	O
detected	O
.	O
it	O
is	O
generally	O
difﬁcult	O
to	O
estimate	O
since	O
this	O
is	O
rarely	O
the	O
case	O
,	O
alternative	O
approaches	O
combine	O
the	O
penalty	O
term	O
such	O
that	O
it	O
gives	O
stable	O
performance	O
across	O
clustering	B
with	O
iterative	O
resegmentation	B
,	O
hence	O
facilitating	O
different	O
meetings	O
and	O
thus	O
new	O
,	O
more	O
robust	O
approaches	O
have	O
the	O
introduction	O
of	O
missing	O
speaker	B
turns	O
.	O
most	O
of	O
present	O
been	O
devised	O
.	O
they	O
either	O
adapt	O
the	O
penalty	O
term	O
automatically	O
,	O
diarization	B
systems	I
thus	O
perform	O
segmentation	B
and	O
clustering	B
i.e.	O
,	O
the	O
modiﬁed	O
bic	B
criterion	B
[	O
33	O
]	O
,	O
[	O
63	O
]	O
,	O
[	O
64	O
]	O
,	O
or	O
avoid	O
the	O
use	O
simultaneously	O
or	O
clustering	B
on	O
a	O
frame	B
-	O
to	O
-	O
cluster	O
basis	O
,	O
as	O
of	O
a	O
penalty	O
term	O
altogether	O
by	O
controlling	O
model	B
complexity	O
described	O
in	O
section	O
iii	O
-	O
e	O
.	O
the	O
general	O
approach	O
involves	O
[	O
65	O
]	O
.	O
bic	B
-	O
based	O
approaches	O
are	O
computationally	O
demanding	O
viterbi	O
realignment	O
where	O
the	O
audio	O
stream	O
is	O
resegmented	O
and	O
some	O
systems	O
have	O
been	O
developed	O
in	O
order	B
to	O
use	O
the	O
bic	B
based	O
on	O
the	O
current	O
clustering	B
hypothesis	B
before	O
the	O
models	B
only	O
in	O
a	O
second	O
pass	O
,	O
while	O
a	O
statistical	O
-	O
based	O
distance	B
is	O
used	O
are	O
retrained	O
on	O
the	O
new	O
segmentation	B
.	O
several	O
iterations	O
are	O
in	O
a	O
ﬁrst	O
pass	O
[	O
66	O
]	O
.	O
another	O
bic	B
-	O
variant	O
metric	B
,	O
referred	O
to	O
as	O
usually	O
performed	O
.	O
in	O
order	B
to	O
make	O
the	O
viterbi	O
decoding	O
more	O
cross	O
-	O
bic	B
and	O
introduced	O
in	O
[	O
67	O
]	O
and	O
[	O
68	O
]	O
,	O
involves	O
the	O
com-	O
stable	O
,	O
it	O
is	O
common	O
to	O
use	O
a	O
viterbi	O
buffer	O
to	O
smooth	O
the	O
state	O
,	O
putation	O
of	O
cross	O
-	O
likelihood	B
:	O
the	O
likelihood	B
of	O
a	O
ﬁrst	O
segment	B
cluster	O
or	O
speaker	B
sequence	B
to	O
remove	O
erroneously	O
detected	O
,	O
according	O
to	O
a	O
model	B
tuned	O
from	O
the	O
second	O
segment	B
and	O
vice	O
brief	O
speaker	B
turns	O
,	O
as	O
in	O
[	O
16	O
]	O
.	O
most	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
systems	O
versa	O
.	O
in	O
[	O
69	O
]	O
,	O
different	O
techniques	B
for	O
likelihood	B
normalization	O
employ	O
some	O
variations	O
on	O
this	O
particular	O
issue	O
.	O
are	O
presented	O
and	O
are	O
referred	O
to	O
as	O
bilateral	O
scoring	O
.	O
an	O
alternative	O
approach	O
to	O
clustering	B
involves	O
majority	O
voting	O
a	O
popular	O
and	O
alternative	O
approach	O
to	O
bic	B
-	O
based	O
measures	O
is	O
[	O
82	O
]	O
,	O
[	O
83	O
]	O
whereby	O
short	O
windows	O
of	O
frames	O
are	O
entirely	O
as-	O
the	O
generalized	O
likelihood	B
ratio	I
(	O
glr	O
)	O
,	O
e.g	O
.	O
,[70	O
]	O
,	O
[	O
71	O
]	O
.	O
in	O
con-	O
signed	O
to	O
the	O
closest	O
cluster	O
,	O
i.e.	O
,	O
that	O
which	O
attracts	O
the	O
most	O
trast	O
to	O
the	O
bic	B
,	O
the	O
glr	O
is	O
a	O
likelihood	B
-	O
based	O
metric	B
and	O
corre-	O
frames	O
during	O
decoding	O
.	O
this	O
technique	B
leads	O
to	O
savings	O
in	O
com-	O
sponds	O
to	O
the	O
ratio	O
between	O
the	O
two	O
aforementioned	O
hypotheses	B
,	O
putation	O
but	O
is	O
more	O
suited	O
to	O
online	O
or	O
live	O
speaker	B
diarization	I
as	O
described	O
in	O
[	O
39	O
]	O
,	O
[	O
72	O
]	O
,	O
and	O
[	O
73	O
]	O
.	O
to	O
adapt	O
the	O
criterion	B
in	O
systems	O
.	O
order	B
to	O
take	O
into	O
account	O
the	O
amount	B
of	O
training	B
data	I
available	O
e.	O
one	O
-	O
step	O
segmentation	B
and	O
clustering	B
in	O
the	O
two	O
segments	O
,	O
a	O
penalized	O
glr	O
was	O
proposed	O
in	O
[	O
74	O
]	O
.	O
the	O
last	O
of	O
the	O
dominant	O
approaches	O
is	O
the	O
kullback	O
–	O
leibler	O
most	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
speaker	B
diarization	I
engines	O
unify	O
the	O
(	O
kl	O
)	O
divergence	O
which	O
estimates	O
the	O
distance	B
between	O
two	O
segmentation	B
and	O
clustering	B
tasks	O
into	O
one	O
step	O
.	O
in	O
these	O
sys-	O
random	O
distributions	O
[	O
75	O
]	O
.	O
however	O
,	O
the	O
kl	O
divergence	O
is	O
tems	O
,	O
segmentation	B
and	O
clustering	B
are	O
performed	O
hand	O
-	O
in	O
-	O
hand	O
asymmetric	O
,	O
and	O
thus	O
the	O
kl2	O
metric	B
,	O
a	O
symmetric	O
alternative	O
,	O
in	O
one	O
loop	O
.	O
such	O
a	O
method	B
was	O
initially	O
proposed	O
by	O
icsi	O
for	O
has	O
proved	O
to	O
be	O
more	O
popular	O
in	O
speaker	B
diarization	I
when	O
used	O
a	O
bottom	O
-	O
up	O
system	O
[	O
31	O
]	O
and	O
has	O
subsequently	O
been	O
adopted	O
to	O
characterize	O
the	O
similarity	B
of	O
two	O
audio	O
segments	O
[	O
75]–[77	O
]	O
.	O
by	O
many	O
others	O
[	O
9	O
]	O
,	O
[	O
41	O
]	O
,	O
[	O
52	O
]	O
,	O
[	O
84]–[86	O
]	O
.	O
for	O
top	O
-	O
down	O
algo-	O
finally	O
,	O
in	O
this	O
section	O
we	O
include	O
a	O
newly	O
introduced	O
distance	B
rithms	O
it	O
was	O
initially	O
proposed	O
by	O
lia	O
[	O
14	O
]	O
as	O
used	O
in	O
their	O
latest	O
metric	B
that	O
has	O
shown	O
promise	O
in	O
a	O
speaker	B
diarization	I
task	O
.	O
the	O
system	O
[	O
16	O
]	O
.	O
information	B
change	B
rate	O
(	O
icr	O
)	O
,	O
or	O
entropy	O
can	O
be	O
used	O
to	O
char-	O
in	O
all	O
cases	O
the	O
different	O
acoustic	O
classes	O
are	O
represented	O
using	O
acterize	O
the	O
similarity	B
of	O
two	O
neighboring	O
speech	B
segments	I
.	O
the	O
hmm	O
/	O
gmm	O
models	B
.	O
em	O
training	O
or	O
map	O
adaptation	O
is	O
used	O
to	O
icr	O
determines	O
the	O
change	B
in	O
information	B
that	O
would	O
be	O
ob-	O
obtain	O
the	O
closest	O
possible	O
models	B
given	O
the	O
current	O
frame	B
-	O
to-	O
tained	O
by	O
merging	O
any	O
two	O
speech	B
segments	I
under	O
considera-	O
model	B
assignments	O
,	O
and	O
a	O
viterbi	O
algorithm	O
is	O
used	O
to	O
reassign	O
tion	O
and	O
can	O
thus	O
be	O
used	O
for	O
speaker	B
segmentation	I
.	O
unlike	O
the	O
all	O
the	O
data	B
into	O
the	O
closest	O
newly	O
-	O
created	O
models	B
.	O
such	O
pro-	O
measures	O
outlined	O
above	O
,	O
the	O
icr	O
similarity	B
is	O
not	O
based	O
on	O
a	O
cessing	O
is	O
sometimes	O
performed	O
several	O
times	O
for	O
the	O
frame	B
as-	O
model	B
of	O
each	O
segment	B
but	O
,	O
instead	O
,	O
on	O
the	O
distance	B
between	O
signments	O
to	O
stabilize	O
.	O
this	O
step	O
is	O
useful	O
when	O
a	O
class	O
is	O
cre-	O
segments	O
in	O
a	O
space	O
of	O
relevance	O
variables	O
,	O
with	O
maximum	O
mu-	O
ated	O
/	O
eliminated	O
so	O
that	O
the	O
resulting	O
class	O
distribution	O
is	O
allowed	O
tual	O
information	B
or	O
minimum	O
entropy	O
.	O
one	O
suitable	O
space	O
comes	O
to	O
adapt	O
to	O
the	O
data	B
.	O
from	O
gmm	O
component	O
parameters	O
[	O
18	O
]	O
.	O
the	O
icr	O
approach	O
is	O
the	O
one	O
-	O
step	O
segmentation	B
and	O
clustering	B
approach	O
,	O
although	O
computationally	O
efﬁcient	O
and	O
,	O
in	O
[	O
78	O
]	O
,	O
icr	O
is	O
shown	O
to	O
be	O
more	O
much	O
slower	O
,	O
constitutes	O
a	O
clear	O
advantage	O
versus	O
sequential	O
robust	O
to	O
data	B
source	B
variation	O
than	O
a	O
bic	B
-	O
based	O
distance	B
.	O
single	O
-	O
pass	O
segmentation	B
and	O
clustering	B
approaches	O
[	O
5]–[7	O
]	O
.	O
on	O
the	O
one	O
hand	O
,	O
early	O
errors	B
(	O
mostly	O
missed	O
speaker	B
turns	O
from	O
the	O
d.	O
clustering	B
segmentation	B
step	O
)	O
can	O
be	O
later	O
corrected	O
by	O
the	O
re	O
-	O
segmentation	B
whereas	O
the	O
segmentation	B
step	O
operates	O
on	O
adjacent	O
windows	O
steps	B
.	O
on	O
the	O
other	O
hand	O
,	O
most	O
speaker	B
segmentation	I
algorithms	O
in	O
order	B
to	O
determine	O
whether	O
or	O
not	O
they	O
correspond	O
to	O
the	O
same	O
use	O
only	O
local	O
information	B
to	O
decide	O
on	O
a	O
speaker	B
change	I
while	O
speaker	B
,	O
clustering	B
aims	O
at	O
identifying	O
and	O
grouping	O
together	O
when	O
using	O
speaker	B
models	B
and	O
viterbi	O
realignment	O
all	O
data	B
is	O
same	O
-	O
speaker	B
segments	I
which	O
can	O
be	O
localized	O
anywhere	O
in	O
the	O
taken	O
into	O
consideration	O
.	O
audio	O
stream	O
.	O
ideally	O
,	O
there	O
will	O
be	O
one	O
cluster	O
for	O
each	O
speaker	B
.	O
when	O
performing	O
frame	B
assignment	O
using	O
viterbi	O
algorithm	O
the	O
problem	O
of	O
measuring	O
segment	B
similarity	B
remains	O
the	O
same	O
a	O
minimum	O
assignment	O
duration	O
is	O
usually	O
enforced	O
to	O
avoid	O
and	O
all	O
the	O
distance	B
metrics	O
described	O
in	O
section	O
iii	O
-	O
c	O
may	O
also	O
an	O
unrealistic	O
assignment	O
of	O
very	O
small	O
consecutive	O
segments	O
be	O
used	O
for	O
clustering	B
,	O
i.e.	O
,	O
the	O
kl	O
distance	B
as	O
in	O
[	O
10	O
]	O
,	O
a	O
modiﬁed	O
to	O
different	O
speaker	B
models	B
.	O
such	O
minimum	O
duration	O
is	O
usually	O
kl2	O
metric	B
as	O
in	O
[	O
61	O
]	O
,	O
a	O
bic	B
measure	O
as	O
in	O
[	O
79	O
]	O
or	O
the	O
cross	O
made	O
according	O
to	O
the	O
estimated	O
minimum	O
length	B
of	O
any	O
given	O
likelihood	B
ratio	I
(	O
clr	O
)	O
as	O
in	O
[	O
80	O
]	O
and	O
[	O
81	O
]	O
.	O
speaker	B
turn	O
.	O
however	O
,	O
with	O
such	O
an	O
approach	O
to	O
diarization	B
,	O
there	O
is	O
no	O
provision	O
for	O
splitting	O
segments	O
which	O
contain	O
more	O
than	O
a	O
iv	O
.	O
current	O
research	B
directions	O
single	B
speaker	I
,	O
and	O
thus	O
diarization	B
algorithms	O
can	O
only	O
work	O
in	O
this	O
section	O
,	O
we	O
review	O
those	O
areas	O
of	O
work	O
which	O
are	O
still	O
well	O
if	O
the	O
initial	O
segmentation	B
is	O
of	O
sufﬁciently	O
high	O
quality	B
.	O
not	O
mature	O
but	O
which	O
have	O
the	O
potential	O
to	O
improve	O
diarization	B
authorized	O
licensed	O
use	O
limited	O
to	O
:	O
inria	O
.	O
downloaded	O
on	O
october	O
05,2020	O
at	O
07:30:52	O
utc	O
from	O
ieee	O
xplore	O
.	O
 	O
restrictions	O
apply	O
.	O
362	O
ieee	O
transactions	O
on	O
audio	O
,	O
speech	O
,	O
and	O
language	B
processing	I
,	O
vol	O
.	O
20	O
,	O
no	O
.	O
2	O
,	O
february	O
2012	O
performance	O
.	O
we	O
ﬁrst	O
discuss	O
the	O
trend	O
in	O
recent	O
nist	O
rt	O
eval-	O
diarization	B
performance	O
and	O
the	O
success	O
of	O
these	O
systems	O
in	O
uations	O
to	O
use	O
spatial	O
information	B
obtained	O
from	O
multiple	O
micro-	O
nist	O
rt	O
evaluations	O
would	O
seem	O
to	O
support	O
their	O
use	O
.	O
phones	O
,	O
which	O
are	O
used	O
by	O
many	O
in	O
combination	O
with	O
mfccs	O
b.	O
use	O
of	O
prosodic	B
features	I
in	O
diarization	B
to	O
improve	O
performance	O
.	O
then	O
,	O
we	O
discuss	O
the	O
use	O
of	O
prosodic	O
information	B
which	O
has	O
led	O
to	O
promising	O
speaker	B
diarization	I
re-	O
the	O
use	O
of	O
prosodic	B
features	I
for	O
both	O
speaker	B
detection	B
sults	O
.	O
also	O
addressed	O
in	O
this	O
section	O
is	O
the	O
“	O
achilles	O
heel	O
”	O
of	O
and	O
diarization	B
is	O
emerging	O
as	O
a	O
reaction	O
to	O
the	O
theoretical	O
speaker	B
diarization	I
for	O
meetings	O
,	O
which	O
involves	O
overlapping	B
inconsistency	O
derived	O
from	O
using	O
mfcc	O
features	O
both	O
for	O
speech	O
;	O
many	O
researchers	O
have	O
started	O
to	O
tackle	O
the	O
detection	B
speaker	B
recognition	O
(	O
which	O
requires	O
invariance	O
against	O
words	B
)	O
of	O
overlapping	B
speech	I
and	O
its	O
correct	O
labeling	O
for	O
improved	O
di-	O
and	O
speech	B
recognition	I
(	O
which	O
requires	O
invariance	O
against	O
arization	O
outputs	O
.	O
we	O
then	O
consider	O
a	O
recent	O
trend	O
towards	O
mul-	O
speakers	O
)	O
[	O
93	O
]	O
.	O
in	O
[	O
84	O
]	O
,	O
the	O
authors	O
present	O
a	O
systematic	O
investi-	O
timodal	O
speaker	B
diarization	I
including	O
studies	O
of	O
multimodal	O
,	O
gation	O
of	O
the	O
speaker	B
discriminability	O
of	O
70	O
long	O
-	O
term	O
features	O
,	O
audiovisual	O
techniques	B
which	O
have	O
been	O
successfully	O
used	O
for	O
most	O
of	O
them	O
prosodic	B
features	I
.	O
they	O
provide	O
evidence	O
that	O
speaker	B
diarization	I
,	O
at	O
least	O
for	O
laboratory	O
conditions	O
.	O
finally	O
,	O
despite	O
the	O
dominance	O
of	O
short	O
-	O
term	O
cepstral	O
features	O
in	O
speaker	B
we	O
consider	O
general	O
combination	O
strategies	O
that	O
can	O
be	O
used	O
to	O
recognition	O
,	O
a	O
number	O
of	O
long	O
-	O
term	O
features	O
can	O
provide	O
sig-	O
combine	O
the	O
output	B
of	O
different	O
diarization	B
systems	I
.	O
the	O
fol-	O
niﬁcant	O
information	B
for	O
speaker	B
discrimination	O
.	O
as	O
already	O
lowing	O
summarizes	O
recent	O
work	O
in	O
all	O
of	O
these	O
areas	O
.	O
suggested	O
in	O
[	O
94	O
]	O
,	O
the	O
consideration	O
of	O
patterns	O
derived	O
from	O
larger	O
segments	O
of	O
speech	O
can	O
reveal	O
individual	O
characteristics	B
a.	O
time	B
-	O
delay	O
features	O
of	O
the	O
speakers	O
’	O
voices	O
as	O
well	O
as	O
their	O
speaking	O
behavior	O
,	O
estimates	O
of	O
inter	O
-	O
channel	O
delay	O
may	O
be	O
used	O
not	O
only	O
for	O
information	B
which	O
can	O
not	O
be	O
captured	O
using	O
a	O
short	O
-	O
term	O
,	O
delay	O
-	O
and	O
-	O
sum	O
beamforming	O
of	O
multiple	O
microphone	O
channels	B
,	O
frame	B
-	O
based	O
cepstral	O
analysis	B
.	O
the	O
authors	O
use	O
fisher	O
lda	O
as	O
as	O
described	O
in	O
section	O
iii	O
-	O
a	O
,	O
but	O
also	O
for	O
speaker	B
localization	O
.	O
a	O
ranking	O
methodology	O
and	O
sort	O
the	O
70	O
prosodic	O
and	O
long	O
-	O
term	O
if	O
we	O
assume	O
that	O
speakers	O
do	O
not	O
move	O
,	O
or	O
that	O
appropriate	O
features	O
by	O
speaker	B
discriminability	O
.	O
the	O
combination	O
of	O
the	O
tracking	O
algorithms	O
are	O
used	O
,	O
then	O
estimates	O
of	O
speaker	B
location	O
top	O
-	O
ten	O
ranked	O
prosodic	O
and	O
long	O
-	O
term	O
features	O
combined	O
with	O
may	O
thus	O
be	O
used	O
as	O
alternative	O
features	O
,	O
which	O
have	O
nowadays	O
regular	O
mfccs	O
leads	O
to	O
a	O
30	O
%	O
relative	O
improvement	O
in	O
terms	B
become	O
extremely	O
popular	O
.	O
much	O
of	O
the	O
early	O
work	O
,	O
e.g	O
.	O
,[87	O
]	O
,	O
of	O
der	O
compared	O
to	O
the	O
top	O
-	O
performing	O
system	O
of	O
the	O
nist	O
requires	O
explicit	O
knowledge	B
of	O
microphone	O
placement	O
.	O
how-	O
rt	O
evaluation	B
in	O
2007	O
.	O
an	O
extension	O
of	O
the	O
work	O
is	O
provided	O
ever	O
,	O
as	O
is	O
the	O
case	O
with	O
nist	O
evaluations	O
,	O
such	O
a	O
priori	O
in-	O
in	O
[	O
95	O
]	O
.	O
the	O
paper	O
presents	O
a	O
novel	O
,	O
adaptive	O
initialization	O
formation	O
is	O
not	O
always	O
available	O
.	O
the	O
ﬁrst	O
work	O
[	O
88	O
]	O
that	O
does	O
scheme	O
that	O
can	O
be	O
applied	O
to	O
standard	O
bottom	O
-	O
up	O
diarization	B
not	O
rely	O
on	O
microphone	O
locations	O
led	O
to	O
promising	O
results	B
,	O
even	O
algorithms	O
.	O
the	O
initialization	O
method	B
is	O
a	O
combination	O
of	O
the	O
if	O
error	B
rates	I
were	O
considerably	O
higher	O
than	O
that	O
achieved	O
with	O
recently	O
proposed	O
“	O
adaptive	O
seconds	B
per	O
gaussian	O
”	O
(	O
aspg	O
)	O
acoustic	B
features	I
.	O
early	O
efforts	O
to	O
combine	O
acoustic	B
features	I
and	O
method	B
[	O
96	O
]	O
and	O
a	O
new	O
pre	O
-	O
clustering	B
method	B
in	O
addition	O
to	O
estimates	O
of	O
inter	O
-	O
channel	O
delay	O
clearly	O
demonstrated	O
their	O
po-	O
a	O
new	O
strategy	O
which	O
automatically	O
estimates	O
an	O
appropriate	O
tential	O
,	O
e.g	O
.	O
,[89	O
]	O
,	O
though	O
this	O
work	O
again	O
relied	O
upon	O
known	O
mi-	O
number	O
of	O
initial	O
clusters	O
based	O
on	O
prosodic	B
features	I
.	O
it	O
outper-	O
crophone	O
locations	O
.	O
forms	O
previous	O
cluster	O
initialization	O
algorithms	O
by	O
up	O
to	O
67	O
%	O
more	O
recent	O
work	O
,	O
and	O
speciﬁcally	O
in	O
the	O
context	O
of	O
nist	O
(	O
relative	O
)	O
.	O
evaluations	O
,	O
reports	O
the	O
successful	O
combination	O
of	O
acoustic	O
c.	O
overlap	B
detection	I
and	O
inter	O
-	O
channel	O
delay	O
features	O
[	O
86	O
]	O
,	O
[	O
90	O
]	O
,	O
[	O
91	O
]	O
when	O
they	O
are	O
combined	O
at	O
the	O
weighted	O
log	B
-	O
likelihood	B
level	B
,	O
though	O
a	O
fundamental	O
limitation	O
of	O
most	O
current	O
speaker	B
diarization	I
optimum	O
weights	O
were	O
found	O
to	O
vary	O
across	O
meetings	O
.	O
better	O
systems	O
is	O
that	O
only	O
one	O
speaker	B
is	O
assigned	O
to	O
each	O
segment	B
.	O
results	B
are	O
reported	O
in	O
[	O
42	O
]	O
where	O
automatic	O
weighting	O
based	O
the	O
presence	B
of	O
overlapped	B
speech	I
,	O
though	O
,	O
is	O
common	O
in	O
mul-	O
on	O
an	O
entropy	O
-	O
based	O
metric	B
is	O
used	O
for	O
cluster	O
comparison	O
in	O
a	O
tiparty	O
meetings	O
and	O
,	O
consequently	O
,	O
presents	O
a	O
signiﬁcant	O
chal-	O
bottom	O
-	O
up	O
speaker	B
diarization	I
system	I
.	O
a	O
complete	O
front	O
-	O
end	O
for	O
lenge	O
to	O
automatic	O
systems	O
.	O
speciﬁcally	O
,	O
in	O
regions	O
where	O
more	O
speaker	B
diarization	I
with	O
multiple	O
microphones	O
was	O
proposed	O
in	O
than	O
one	O
speaker	B
is	O
active	O
,	O
missed	O
speech	O
errors	B
will	O
be	O
incurred	O
[	O
42	O
]	O
.	O
here	O
a	O
two	O
-	O
step	O
tdoa	O
viterbi	O
post	O
-	O
processing	B
algorithm	O
and	O
,	O
given	O
the	O
high	O
performance	O
of	O
some	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
sys-	O
together	O
with	O
a	O
dynamic	O
output	B
signal	B
weighting	O
algorithm	O
tems	O
,	O
this	O
can	O
be	O
a	O
substantial	O
fraction	O
of	O
the	O
overall	O
diariza-	O
were	O
shown	O
to	O
greatly	O
improve	O
speaker	B
diarization	I
accuracy	O
tion	O
error	O
.	O
a	O
less	O
direct	O
,	O
but	O
also	O
signiﬁcant	O
,	O
effect	O
of	O
over-	O
and	O
the	O
robustness	O
of	O
inter	O
-	O
channel	O
delay	O
estimates	O
to	O
noise	O
lapped	O
speech	O
in	O
diarization	B
pertains	O
to	O
speaker	B
clustering	B
and	O
and	O
reverberation	O
,	O
which	O
commonly	O
afﬂict	O
source	B
localization	O
modeling	O
.	O
segments	O
which	O
contain	O
speech	O
from	O
more	O
than	O
a	O
algorithms	O
.	O
more	O
recently	O
,	O
an	O
approach	O
to	O
the	O
unsupervised	O
dis-	O
single	B
speaker	I
should	O
not	O
be	O
assigned	O
to	O
any	O
individual	O
speaker	B
criminant	O
analysis	B
of	O
inter	O
-	O
channel	O
delay	O
features	O
was	O
proposed	O
cluster	O
nor	O
included	O
in	O
any	O
individual	O
speaker	B
model	B
.	O
doing	O
in	O
[	O
92	O
]	O
and	O
results	B
of	O
approximately	O
20	O
%	O
der	O
were	O
reported	O
so	O
adversely	O
affects	O
the	O
purity	O
of	O
speaker	B
models	B
,	O
which	O
ulti-	O
using	O
delay	O
features	O
alone	O
.	O
mately	O
reduces	O
diarization	B
performance	O
.	O
approaches	O
to	O
overlap	O
in	O
the	O
most	O
recent	O
nist	O
rt	O
evaluation	B
,	O
in	O
2009	O
,	O
all	O
but	O
one	O
detection	B
were	O
thoroughly	O
assessed	O
in	O
[	O
97	O
]	O
and	O
[	O
98	O
]	O
and	O
,	O
even	O
entry	O
used	O
estimates	O
of	O
inter	O
-	O
channel	O
delay	O
both	O
for	O
beam-	O
while	O
applied	O
to	O
asr	B
as	O
opposed	O
to	O
speaker	B
diarization	I
,	O
only	O
forming	O
and	O
as	O
features	O
.	O
since	O
comparative	O
experiments	O
are	O
a	O
small	O
number	O
of	O
systems	O
actually	O
detects	O
overlapping	B
speech	I
rarely	O
reported	O
it	O
is	O
not	O
possible	O
to	O
assess	O
the	O
contribution	O
well	O
enough	O
to	O
improve	O
error	B
rates	I
[	O
99]–[101	O
]	O
.	O
of	O
delay	O
features	O
to	O
diarization	B
performance	O
.	O
however	O
,	O
those	O
initially	O
,	O
the	O
authors	O
in	O
[	O
102	O
]	O
demonstrated	O
a	O
theoretical	O
who	O
do	O
use	O
delay	O
features	O
report	O
signiﬁcant	O
improvements	B
in	O
improvement	O
in	O
diarization	B
performance	O
by	O
adding	O
a	O
second	O
authorized	O
licensed	O
use	O
limited	O
to	O
:	O
inria	O
.	O
downloaded	O
on	O
october	O
05,2020	O
at	O
07:30:52	O
utc	O
from	O
ieee	O
xplore	O
.	O
 	O
restrictions	O
apply	O
.	O
anguera	O
miro	O
et	O
al	O
.	O
:	O
speaker	B
diarization	I
:	O
a	O
review	O
of	O
recent	O
research	B
363	O
speaker	B
during	O
overlap	O
regions	O
using	O
a	O
simple	O
strategy	O
of	O
detection	B
of	O
the	O
mouth	O
is	O
not	O
always	O
feasible	O
.	O
therefore	O
,	O
other	O
assigning	O
speaker	B
labels	I
according	O
to	O
the	O
labels	O
of	O
the	O
neigh-	O
forms	O
of	O
body	O
behavior	O
,	O
e.g.	O
,	O
head	O
gestures	O
,	O
which	O
are	O
also	O
boring	O
segments	O
,	O
as	O
well	O
as	O
by	O
excluding	O
overlap	O
regions	O
from	O
visible	O
manifestations	O
of	O
speech	O
[	O
116	O
]	O
are	O
used	O
.	O
while	O
there	O
the	O
input	B
to	O
the	O
diarization	B
system	O
.	O
however	O
,	O
this	O
initial	O
study	O
has	O
been	O
relatively	O
little	O
work	O
on	O
using	O
global	O
body	O
movements	O
assumed	O
ground	B
-	O
truth	O
overlap	B
detection	I
.	O
in	O
[	O
100	O
]	O
,	O
a	O
real	O
overlap	O
for	O
inferring	O
speaking	O
status	O
,	O
some	O
studies	O
have	O
been	O
carried	O
detection	B
system	O
was	O
developed	O
,	O
as	O
well	O
as	O
a	O
better	O
heuristic	O
out	O
[	O
82	O
]	O
,	O
[	O
117]–[119	O
]	O
that	O
show	O
promising	O
initial	O
results	B
.	O
that	O
computed	O
posterior	O
probabilities	O
from	O
diarization	B
to	O
post	O
however	O
,	O
until	O
the	O
work	O
presented	O
in	O
[	O
120	O
]	O
,	O
approaches	O
have	O
process	B
the	O
output	B
and	O
include	O
a	O
second	O
speaker	B
on	O
overlap	O
never	O
considered	O
audiovisual	O
diarization	B
as	O
a	O
single	O
,	O
unsuper-	O
regions	O
.	O
the	O
main	O
bottleneck	O
of	O
the	O
achieved	O
performance	O
gain	O
vised	O
joint	O
optimization	O
problem	O
.	O
the	O
work	O
in	O
[	O
120	O
]	O
,	O
though	O
,	O
is	O
mainly	O
due	O
to	O
errors	B
in	O
overlap	B
detection	I
,	O
and	O
more	O
work	O
on	O
relies	O
on	O
multiple	O
cameras	O
.	O
the	O
ﬁrst	O
paper	O
that	O
discusses	O
joint	O
enhancing	O
its	O
precision	O
and	O
recall	O
is	O
reported	O
in	O
[	O
99	O
]	O
and	O
[	O
101	O
]	O
.	O
audiovisual	O
diarization	B
using	O
only	O
a	O
single	O
,	O
low	O
-	O
resolution	O
the	O
main	O
approach	O
consists	O
of	O
a	O
three	O
-	O
state	O
hmm	O
-	O
gmm	O
overview	O
camera	O
and	O
also	O
tests	O
on	O
meeting	O
scenarios	O
where	O
system	O
(	O
nonspeech	O
,	O
nonoverlapped	O
speech	O
,	O
and	O
overlapped	O
the	O
participants	B
are	O
able	O
to	O
move	O
around	O
freely	O
in	O
the	O
room	O
is	O
speech	O
)	O
,	O
and	O
the	O
best	O
feature	O
combination	O
is	O
mfcc	O
and	O
modu-	O
[	O
121	O
]	O
.	O
the	O
algorithm	O
relies	O
on	O
very	O
few	O
assumptions	O
and	O
is	O
able	O
lation	O
spectrogram	O
features	O
[	O
103	O
]	O
,	O
although	O
comparable	O
results	B
to	O
cope	O
with	O
an	O
arbitrary	O
amount	B
of	O
cameras	O
and	O
subframes	O
.	O
were	O
achieved	O
with	O
other	O
features	O
such	O
as	O
root	O
mean	O
squared	O
most	O
importantly	O
,	O
as	O
a	O
result	O
of	O
training	O
a	O
combined	O
audiovisual	O
energy	O
,	O
spectral	O
ﬂatness	O
,	O
or	O
harmonic	O
energy	O
ratio	O
.	O
the	O
reported	O
model	B
,	O
the	O
authors	O
found	O
that	O
speaker	B
diarization	I
algorithms	O
performance	O
of	O
the	O
overlap	B
detection	I
is	O
82	O
%	O
precision	O
and	O
can	O
result	O
in	O
speaker	B
localization	O
as	O
side	O
information	B
.	O
this	O
way	O
21	O
%	O
recall	O
,	O
and	O
yielded	O
a	O
relative	O
improvement	O
of	O
11	O
%	O
der	O
.	O
joint	O
audiovisual	O
speaker	B
diarization	I
can	O
answer	O
the	O
question	O
however	O
,	O
assuming	O
reference	B
overlap	B
detection	I
,	O
the	O
relative	O
“	O
who	O
spoken	O
when	O
and	O
from	O
where	O
.	O
”	O
this	O
solution	O
to	O
the	O
local-	O
der	O
improvement	O
goes	O
up	O
to	O
37	O
%	O
.	O
this	O
way	O
,	O
this	O
area	O
has	O
ization	O
problem	O
has	O
properties	O
that	O
may	O
not	O
be	O
observed	O
either	O
potential	O
for	O
future	O
research	B
efforts	O
.	O
by	O
audio	O
-	O
only	O
diarization	B
nor	O
by	O
video	O
-	O
only	O
localization	O
,	O
such	O
as	O
increased	O
robustness	O
against	O
various	O
issues	O
present	O
in	O
the	O
d.	O
audiovisual	O
diarization	B
channel	O
.	O
in	O
addition	O
,	O
in	O
contrast	O
to	O
audio	O
-	O
only	O
speaker	B
diariza-	O
reference	B
[	O
104	O
]	O
presents	O
an	O
empirical	O
study	O
to	O
review	O
deﬁ-	O
tion	O
,	O
this	O
solution	O
provides	O
a	O
means	O
for	O
identifying	O
speakers	O
nitions	O
of	O
audiovisual	O
synchrony	O
and	O
examine	O
their	O
empirical	O
beyond	O
clustering	B
numbers	O
by	O
associating	O
video	O
regions	O
with	O
behavior	O
.	O
the	O
results	B
provide	O
justiﬁcations	O
for	O
the	O
application	B
the	O
clusters	O
.	O
of	O
audiovisual	O
synchrony	O
techniques	B
to	O
the	O
problem	O
of	O
active	O
e.	O
system	O
combination	O
speaker	B
localization	O
in	O
broadcast	O
video	O
.	O
the	O
authors	O
of	O
[	O
105	O
]	O
present	O
a	O
multi	O
-	O
modal	O
speaker	B
localization	O
method	B
using	O
a	O
spe-	O
system	O
or	O
component	O
combination	O
is	O
often	O
reported	O
in	O
the	O
cialized	O
satellite	O
microphone	O
and	O
an	O
omni	O
-	O
directional	O
camera	O
.	O
literature	O
as	O
an	O
effective	O
means	O
for	O
improving	O
performance	O
though	O
the	O
results	B
seem	O
comparable	O
to	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
,	O
the	O
in	O
many	O
speech	O
processing	B
applications	O
.	O
however	O
,	O
very	O
few	O
solution	O
requires	O
specialized	O
hardware	O
.	O
the	O
work	O
presented	O
studies	O
related	O
to	O
speaker	B
diarization	I
have	O
been	O
reported	O
in	O
in	O
[	O
106	O
]	O
integrates	O
audiovisual	O
features	O
for	O
online	O
audiovisual	O
recent	O
years	O
.	O
this	O
could	O
be	O
due	O
to	O
the	O
inherent	O
difﬁculty	O
of	O
speaker	B
diarization	I
using	O
a	O
dynamic	O
bayesian	O
network	B
(	O
dbn	O
)	O
merging	O
multiple	O
output	B
segmentations	O
.	O
combination	O
strategies	O
but	O
tests	O
were	O
limited	O
to	O
discussions	O
with	O
two	O
to	O
three	O
people	O
have	O
to	O
accommodate	O
differences	O
in	O
temporal	O
synchronization	O
,	O
on	O
two	O
short	O
test	B
scenarios	O
.	O
another	O
use	O
of	O
dbn	O
,	O
also	O
called	O
outputs	O
with	O
different	O
number	O
of	O
speakers	O
,	O
and	O
the	O
matching	O
factorial	O
hmms	O
[	O
107	O
]	O
,	O
is	O
proposed	O
in	O
[	O
108	O
]	O
as	O
an	O
audiovisual	O
of	O
speaker	B
labels	I
.	O
moreover	O
,	O
systems	O
involved	O
in	O
the	O
combina-	O
framework	O
.	O
the	O
factorial	O
hmm	O
arises	O
by	O
forming	O
a	O
dynamic	O
tion	O
have	O
to	O
exhibit	O
segmentation	B
outputs	O
that	O
are	O
sufﬁciently	O
bayesian	O
belief	O
network	B
composed	O
of	O
several	O
layers	O
.	O
each	O
of	O
orthogonal	O
in	O
order	B
to	O
ensure	O
signiﬁcant	O
gains	O
in	O
performance	O
the	O
layers	O
has	O
independent	O
dynamics	O
but	O
the	O
ﬁnal	O
observation	O
when	O
combined	O
.	O
some	O
of	O
the	O
combination	O
strategies	O
proposed	O
vector	O
depends	O
upon	O
the	O
state	O
in	O
each	O
of	O
the	O
layers	O
.	O
in	O
[	O
109	O
]	O
,	O
consist	O
of	O
applying	O
different	O
algorithms	O
/	O
components	B
sequen-	O
the	O
authors	O
demonstrate	O
that	O
the	O
different	O
shapes	O
the	O
mouth	O
can	O
tially	O
,	O
based	O
on	O
the	O
segmentation	B
outputs	O
of	O
the	O
previous	O
steps	B
take	O
when	O
speaking	O
facilitate	O
word	B
recognition	O
under	O
tightly	O
in	O
order	B
to	O
reﬁne	O
boundaries	B
(	O
referred	O
to	O
as	O
“	O
hybridization	O
”	O
or	O
constrained	O
test	B
conditions	O
(	O
e.g.	O
,	O
frontal	O
position	O
of	O
the	O
subject	O
“	O
piped	O
”	O
systems	O
in	O
[	O
122	O
]	O
)	O
.	O
in	O
[	O
123	O
]	O
for	O
instance	O
,	O
the	O
authors	O
with	O
respect	O
to	O
the	O
camera	O
while	O
reading	O
digits	O
)	O
.	O
combine	O
two	O
different	O
algorithms	O
based	O
on	O
the	O
information	B
common	O
approaches	O
to	O
audiovisual	O
speaker	B
identiﬁ-	O
bottleneck	O
framework	O
.	O
in	O
[	O
124	O
]	O
,	O
the	O
best	O
components	B
of	O
two	O
cation	O
involve	O
identifying	O
lip	O
motion	O
from	O
frontal	O
faces	O
,	O
different	O
speaker	B
diarization	I
systems	I
implemented	O
by	O
two	O
dif-	O
e.g	O
.	O
,[110]–[114	O
]	O
.	O
therefore	O
,	O
the	O
underlying	O
assumption	O
is	O
that	O
ferent	O
french	O
laboratories	O
(	O
lium	O
and	O
irit	O
)	O
are	O
merged	O
and/or	O
motion	O
from	O
a	O
person	O
comes	O
predominantly	O
from	O
the	O
motion	O
used	O
sequentially	O
,	O
which	O
leads	O
to	O
a	O
performance	O
gain	O
compared	O
of	O
the	O
lower	O
half	O
of	O
their	O
face	O
.	O
in	O
addition	O
,	O
gestural	O
or	O
other	O
to	O
results	B
from	O
individual	O
systems	O
.	O
an	O
original	O
approach	O
is	O
pro-	O
nonverbal	O
behaviors	O
associated	O
with	O
natural	O
body	O
motion	O
posed	O
in	O
[	O
125	O
]	O
,	O
based	O
on	O
a	O
“	O
real	O
”	O
system	O
combination	O
.	O
here	O
,	O
a	O
during	O
conversations	O
are	O
artiﬁcially	O
suppressed	O
,	O
e.g.	O
,	O
for	O
the	O
couple	O
of	O
systems	O
uniquely	O
differentiated	O
by	O
their	O
input	B
features	O
cuave	O
database	O
[	O
115	O
]	O
.	O
most	O
of	O
the	O
techniques	B
involve	O
the	O
(	O
parameterizations	O
based	O
on	O
gaussianized	O
against	O
non	O
-	O
gaus-	O
identiﬁcation	O
of	O
one	O
or	O
two	O
people	O
in	O
a	O
single	O
video	O
camera	O
sianized	O
mfccs	O
)	O
are	O
combined	O
for	O
the	O
speaker	B
diarization	I
of	O
only	O
where	O
short	O
term	O
synchrony	O
of	O
lip	O
motion	O
and	O
speech	O
are	O
phone	O
calls	O
conversations	O
.	O
the	O
combination	O
approach	O
relies	O
on	O
the	O
basis	O
for	O
audiovisual	O
localization	O
.	O
in	O
a	O
real	O
scenario	O
the	O
both	O
systems	O
identifying	O
some	O
common	O
clusters	O
which	O
are	O
then	O
subject	O
behavior	O
is	O
not	O
controlled	O
and	O
,	O
consequently	O
,	O
the	O
correct	O
considered	O
as	O
the	O
most	O
relevant	O
.	O
all	O
the	O
segments	O
not	O
belonging	O
authorized	O
licensed	O
use	O
limited	O
to	O
:	O
inria	O
.	O
downloaded	O
on	O
october	O
05,2020	O
at	O
07:30:52	O
utc	O
from	O
ieee	O
xplore	O
.	O
 	O
restrictions	O
apply	O
.	O
364	O
ieee	O
transactions	O
on	O
audio	O
,	O
speech	O
,	O
and	O
language	B
processing	I
,	O
vol	O
.	O
20	O
,	O
no	O
.	O
2	O
,	O
february	O
2012	O
to	O
these	O
common	O
clusters	O
are	O
labeled	O
as	O
misclassiﬁed	O
and	O
are	O
a	O
common	O
characteristic	O
of	O
these	O
evaluations	O
is	O
that	O
the	O
only	O
involved	O
in	O
a	O
new	O
re	O
-	O
classiﬁcation	O
step	O
based	O
on	O
a	O
gmm	O
mod-	O
a	O
priori	O
knowledge	B
available	O
to	O
the	O
participants	B
relates	O
to	O
the	O
eling	O
of	O
the	O
common	O
clusters	O
and	O
a	O
maximum	O
likelihood	B
-	O
based	O
recording	B
scenario	O
/	O
source	B
(	O
e.g.	O
,	O
conference	O
meetings	O
,	O
lectures	O
,	O
decision	O
.	O
or	O
coffee	O
breaks	O
for	O
the	O
meetings	O
domain	B
)	O
,	O
the	O
language	O
(	O
eng-	O
lish	O
)	O
,	O
and	O
the	O
formats	O
of	O
the	O
input	B
and	O
output	B
ﬁles	O
.	O
evaluation	B
f.	O
alternative	O
models	B
participants	B
may	O
use	O
external	O
or	O
background	O
data	B
for	O
building	O
world	O
models	B
and/or	O
for	O
normalization	O
purposes	O
but	O
no	O
a	O
priori	O
among	O
the	O
clustering	B
structures	O
recently	O
developed	O
some	O
information	B
relating	O
to	O
speakers	O
in	O
the	O
recordings	O
is	O
available	O
.	O
differ	O
from	O
the	O
standard	O
hmm	O
insofar	O
as	O
they	O
are	O
fully	O
nonpara-	O
the	O
number	O
of	O
speakers	O
is	O
also	O
not	O
known	O
.	O
metric	B
(	O
that	O
is	O
,	O
the	O
number	O
of	O
parameters	O
of	O
the	O
system	O
depends	O
in	O
recent	O
years	O
,	O
the	O
nist	O
rt	O
evaluations	O
have	O
focussed	O
on	O
the	O
observations	O
)	O
.	O
the	O
dirichlet	O
process	B
(	O
dp	O
)	O
[	O
126	O
]	O
allows	O
on	O
the	O
conference	O
meeting	O
domain	B
,	O
where	O
the	O
spontaneous	O
for	O
converting	O
the	O
systems	O
into	O
bayesian	O
and	O
nonparametric	O
speaking	O
style	O
presents	O
a	O
considerable	O
challenge	B
for	O
speaker	B
systems	O
.	O
the	O
dp	O
mixture	O
model	B
produces	O
inﬁnite	O
gaussian	O
diarization	B
.	O
each	O
meeting	O
used	O
in	O
the	O
evaluations	O
was	O
recorded	O
mixtures	O
and	O
deﬁnes	O
the	O
number	O
of	O
components	B
by	O
a	O
measure	O
using	O
multiple	O
microphones	O
(	O
of	O
different	O
types	O
and	O
quality	B
)	O
over	O
distributions	O
.	O
the	O
authors	O
of	O
[	O
127	O
]	O
illustrate	O
the	O
use	O
of	O
the	O
which	O
are	O
positioned	O
on	O
the	O
participants	B
or	O
in	O
different	O
locations	O
dirichlet	O
process	B
mixtures	O
,	O
showing	O
an	O
improvement	O
compared	O
around	O
the	O
meeting	O
room	O
.	O
by	O
grouping	O
these	O
microphones	O
into	O
to	O
other	O
classical	O
methods	O
.	O
reference	B
[	O
128	O
]	O
proposes	O
another	O
different	O
classes	O
,	O
nist	O
created	O
several	O
contrastive	O
evaluation	B
nonparametric	O
bayesian	O
approach	O
,	O
in	O
which	O
a	O
stochastic	O
hier-	O
conditions	O
.	O
these	O
include	O
:	O
individual	O
headphone	O
microphones	O
archical	O
dirichlet	O
process	B
(	O
hdp	O
)	O
deﬁnes	O
a	O
prior	O
distribution	O
(	O
ihm	O
)	O
,	O
single	O
distant	O
microphones	O
(	O
sdm	O
)	O
,	O
multiple	O
distant	O
on	O
transition	O
matrices	O
over	O
countably	O
inﬁnite	O
state	O
spaces	O
,	O
that	O
microphones	O
(	O
mdm	O
)	O
,	O
multiple	O
mark	O
iii	O
arrays	O
(	O
mm3a	O
)	O
,	O
and	O
is	O
,	O
no	O
ﬁxed	O
number	O
of	O
speakers	O
is	O
assumed	O
,	O
nor	O
found	O
through	O
all	O
distant	O
microphones	O
(	O
adm	O
)	O
.	O
mm3a	O
microphones	O
are	O
those	O
either	O
split	O
or	O
merging	O
approaches	O
using	O
classical	O
model	B
selec-	O
exclusively	O
found	O
within	O
the	O
arrays	O
built	O
and	O
provided	O
by	O
nist	O
.	O
tion	O
approaches	O
(	O
such	O
as	O
the	O
bic	B
criterion	B
)	O
.	O
instead	O
,	O
this	O
prior	O
these	O
are	O
usually	O
not	O
included	O
within	O
the	O
mdm	O
condition	B
,	O
measure	O
is	O
placed	O
over	O
distributions	O
(	O
called	O
a	O
random	O
measure	O
)	O
,	O
they	O
are	O
included	O
within	O
the	O
adm	O
condition	B
.	O
in	O
this	O
section	O
which	O
is	O
integrated	O
out	O
using	O
likelihood	B
-	O
prior	O
conjugacy	O
.	O
the	O
we	O
show	O
results	B
for	O
the	O
mdm	O
and	O
sdm	O
conditions	O
since	O
we	O
resulting	O
hdp	O
-	O
hmm	O
leads	O
to	O
a	O
data	B
-	O
driven	O
learning	O
algorithm	O
consider	O
them	O
to	O
be	O
the	O
most	O
representative	O
of	O
standard	O
meeting	O
which	O
infers	O
posterior	O
distributions	O
over	O
the	O
number	O
of	O
states	O
.	O
room	O
recording	B
equipment	O
.	O
these	O
conditions	O
have	O
also	O
proven	O
this	O
posterior	O
uncertainty	O
can	O
be	O
integrated	O
out	O
when	O
making	O
to	O
be	O
the	O
most	O
popular	O
among	O
evaluation	B
participants	B
.	O
predictions	O
effectively	O
averaging	O
over	O
models	B
of	O
varying	O
com-	O
participating	O
teams	O
are	O
required	O
to	O
submit	O
a	O
hypothesis	B
of	O
plexity	O
.	O
the	O
hdp	O
-	O
hmm	O
has	O
shown	O
promise	O
in	O
diarization	B
speaker	B
activity	O
including	O
start	O
-	O
stop	O
times	O
of	O
speech	B
segments	I
[	O
129	O
]	O
,	O
yielding	O
similar	O
performance	O
to	O
the	O
standard	O
agglom-	O
with	O
speaker	B
labels	I
,	O
which	O
are	O
used	O
solely	O
to	O
identify	O
the	O
mul-	O
erative	O
hmm	O
with	O
gmm	O
emissions	O
,	O
while	O
requiring	O
very	O
tiple	O
interventions	O
of	O
a	O
given	O
speaker	B
,	O
but	O
do	O
not	O
need	O
to	O
reﬂect	O
little	O
hyperparameter	O
tuning	O
and	O
providing	O
a	O
statistically	O
sound	O
the	O
speaker	B
’s	O
real	O
identity	O
.	O
these	O
system	O
outputs	O
are	O
compared	O
model	B
.	O
globally	O
,	O
these	O
non	O
parametric	O
bayesian	O
approaches	O
did	O
to	O
the	O
ground	B
-	O
truth	O
reference	B
in	O
order	B
to	O
obtain	O
the	O
overall	O
der	O
.	O
not	O
bring	O
a	O
major	O
improvement	O
compared	O
to	O
classical	O
systems	O
the	O
der	O
metric	B
is	O
the	O
sum	O
of	O
three	O
sources	O
of	O
error	O
:	O
missed	O
as	O
presented	O
in	O
section	O
iii	O
.	O
however	O
,	O
they	O
may	O
be	O
promising	O
speech	O
(	O
percentage	B
of	O
speech	O
in	O
the	O
ground	B
-	O
truth	O
but	O
not	O
in	O
the	O
insofar	O
as	O
they	O
do	O
not	O
necessarily	O
need	O
to	O
be	O
optimized	O
for	O
hypothesis	B
)	O
,	O
false	B
alarm	I
speech	O
(	O
percentage	B
of	O
speech	O
in	O
the	O
certain	O
data	B
compared	O
to	O
methods	O
cited	O
in	O
section	O
ii	O
.	O
further-	O
hypothesis	B
but	O
not	O
in	O
the	O
ground	B
-	O
truth	O
)	O
and	O
speaker	B
error	O
(	O
per-	O
more	O
,	O
they	O
provide	O
a	O
probabilistic	O
interpretation	O
on	O
posterior	O
centage	O
of	O
speech	O
assigned	O
to	O
the	O
wrong	O
speaker	B
)	O
.	O
the	O
speaker	B
distributions	O
(	O
e.g.	O
,	O
number	O
of	O
speakers	O
)	O
.	O
error	O
can	O
be	O
further	O
classiﬁed	O
into	O
incorrectly	O
assigned	O
speakers	O
and	O
speaker	B
overlap	O
error	O
.	O
in	O
the	O
ﬁrst	O
case	O
,	O
the	O
hypothesized	O
speaker	B
does	O
not	O
correspond	O
to	O
the	O
real	O
(	O
ground	B
-	O
truth	O
)	O
speaker	B
.	O
v.	O
performance	O
evaluation	B
speaker	B
overlap	O
error	O
refers	O
to	O
the	O
case	O
when	O
the	O
wrong	O
number	O
in	O
this	O
section	O
,	O
we	O
report	O
an	O
analysis	B
of	O
speaker	B
diarization	I
of	O
speakers	O
is	O
hypothesized	O
when	O
multiple	O
speakers	O
speak	O
at	O
performance	O
as	O
reported	O
during	O
the	O
four	O
most	O
recent	O
nist	O
rt	O
the	O
same	O
time	B
.	O
the	O
inclusion	O
of	O
overlapping	B
speech	I
error	O
in	O
the	O
evaluations	O
.	O
the	O
analysis	B
focuses	O
solely	O
on	O
conference	O
meetings	O
evaluation	B
was	O
restricted	O
to	O
a	O
contrastive	O
metric	B
in	O
the	O
initial	O
rt	O
which	O
are	O
the	O
core	O
evaluation	B
condition	B
.	O
we	O
also	O
present	O
an	O
anal-	O
evaluations	O
but	O
has	O
been	O
the	O
primary	O
metric	B
since	O
2006	O
.	O
overlap	O
ysis	O
of	O
the	O
ground	B
-	O
truth	O
references	B
in	O
order	B
to	O
underline	O
the	O
char-	O
errors	B
can	O
be	O
classiﬁed	O
as	O
missed	O
overlap	O
(	O
when	O
fewer	O
speakers	O
acteristics	O
of	O
the	O
data	B
with	O
respect	O
to	O
meeting	O
sources	O
and	O
the	O
than	O
the	O
real	O
number	O
are	O
hypothesized	O
)	O
and	O
false	B
alarm	I
overlap	O
different	O
evaluation	B
campaigns	O
.	O
finally	O
we	O
show	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
(	O
when	O
too	O
many	O
speakers	O
are	O
hypothesized	O
)	O
.	O
in	O
the	O
nist	O
eval-	O
system	O
results	B
,	O
collated	O
from	O
four	O
nist	O
rt’07	O
and	O
rt’09	O
eval-	O
uations	O
up	O
to	O
four	O
overlapping	B
speakers	O
are	O
considered	O
in	O
the	O
uation	O
participants	B
,	O
which	O
aim	O
at	O
giving	O
a	O
baseline	B
for	O
future	O
scoring	O
.	O
research	B
.	O
note	O
that	O
as	O
the	O
der	O
is	O
time	B
-	O
weighted	O
,	O
it	O
ascribes	O
little	O
im-	O
portance	O
to	O
the	O
diarization	B
quality	B
of	O
speakers	O
whose	O
overall	O
a.	O
benchmarking	O
evaluations	O
speaking	O
time	B
is	O
small	O
.	O
additionally	O
,	O
a	O
nonscoring	O
collar	O
of	O
250	O
ms	O
is	O
generally	O
applied	O
either	O
side	O
of	O
the	O
ground	B
-	O
truth	O
segment	B
since	O
2004	O
,	O
nist	O
has	O
organized	O
a	O
series	O
of	O
benchmark	O
eval-	O
boundaries	B
to	O
account	O
for	O
inevitable	O
inconsistencies	O
in	O
precise	O
uations	O
within	O
the	O
rich	B
transcription	I
(	O
rt	O
)	O
campaigns.3	O
one	O
of	O
start	O
and	O
end	O
point	O
labeling	O
.	O
when	O
comparing	O
the	O
system	O
out-	O
the	O
tasks	O
involves	O
speaker	B
diarization	I
of	O
different	O
sets	O
of	O
data	B
.	O
puts	O
with	O
the	O
ground	B
-	O
truth	O
,	O
and	O
given	O
that	O
the	O
labels	O
identifying	O
3see	O
http://nist.gov/speech/tests/rt	O
.	O
the	O
speakers	O
are	O
just	O
relative	O
identiﬁers	O
,	O
the	O
scoring	O
algorithm	O
authorized	O
licensed	O
use	O
limited	O
to	O
:	O
inria	O
.	O
downloaded	O
on	O
october	O
05,2020	O
at	O
07:30:52	O
utc	O
from	O
ieee	O
xplore	O
.	O
 	O
restrictions	O
apply	O
.	O
anguera	O
miro	O
et	O
al	O
.	O
:	O
speaker	B
diarization	I
:	O
a	O
review	O
of	O
recent	O
research	B
365	O
table	O
i	O
ground	B
-	O
truth	O
analysis	B
for	O
the	O
datasets	B
of	O
the	O
last	O
four	O
speaker	B
diarization	I
evaluation	B
campaigns	O
(	O
rt’05	O
to	O
rt’09	O
)	O
and	O
meeting	O
source	B
.	O
comparisons	O
are	O
based	O
on	O
the	O
average	B
speaker	B
and	O
turn	O
durations	O
(	O
left	O
-	O
half	O
side	O
)	O
and	O
the	O
percentage	B
of	O
silence	B
and	O
overlapping	B
speech	I
(	O
right	O
-	O
half	O
side	O
)	O
for	O
rt’05	O
the	O
average	B
speaker	B
segment	B
duration	O
is	O
2.5	O
s.	O
this	O
value	O
decreases	O
continuously	O
for	O
subsequent	O
datasets	B
(	O
2.3	O
s	O
for	O
rt’06	O
,	O
2.0	O
s	O
for	O
rt’07	O
,	O
and	O
1.8	O
s	O
for	O
rt’09	O
)	O
.	O
this	O
tendency	O
leads	O
to	O
increasingly	O
more	O
frequent	O
speaker	B
turns	O
and	O
increases	O
the	O
chances	O
of	O
miss	B
-	O
classifying	O
a	O
speech	B
segment	I
.	O
the	O
average	B
turn	O
segment	B
duration	O
is	O
2.1	O
s	O
for	O
rt’05	O
.	O
this	O
value	O
falls	O
to	O
1.4	O
s	O
for	O
rt’06	O
and	O
remains	O
stable	O
for	O
rt’07	O
and	O
rt’09	O
(	O
1.5	O
s	O
and	O
1.4	O
fig	O
.	O
2	O
.	O
examples	O
of	O
turn	O
and	O
speaker	B
durations	O
in	O
the	O
presence	B
of	O
overlapped	O
s	O
respectively	O
)	O
.	O
the	O
consistent	O
decrease	O
in	O
speaker	B
/	O
turn	O
duration	O
speech	O
and	O
silences	O
.	O
ratio	O
highlights	O
a	O
general	O
trend	O
of	O
increasing	O
spontaneity	O
and	O
helps	O
to	O
explain	O
the	O
differences	O
in	O
results	B
from	O
one	O
dataset	O
to	O
an-	O
ﬁrst	O
computes	O
an	O
optimum	O
mapping	O
between	O
both	O
sets	O
of	O
la-	O
other	O
.	O
there	O
are	O
no	O
distinct	O
differences	O
across	O
different	O
meeting	O
bels	O
in	O
order	B
to	O
obtain	O
the	O
der	O
.	O
this	O
is	O
normally	O
performed	O
ac-	O
sites	O
.	O
cording	O
to	O
a	O
standard	O
dynamic	O
programming	O
algorithm	O
deﬁned	O
there	O
are	O
also	O
noticeable	O
differences	O
in	O
silence	B
and	O
overlap	O
by	O
nist	O
.	O
statistics	B
.	O
the	O
percentage	B
of	O
silence	B
is	O
lower	O
for	O
the	O
rt’05	O
and	O
rt’09	O
datasets	B
than	O
it	O
is	O
for	O
the	O
rt’06	O
and	O
rt’09	O
datasets	B
b.	O
ground	B
-	O
truth	O
analysis	B
(	O
10.3	O
%	O
and	O
17.5	O
%	O
cf	O
.	O
31.5	O
%	O
and	O
24.9	O
%	O
)	O
.	O
however	O
,	O
the	O
rt’05	O
ground	B
-	O
truth	O
references	B
for	O
evaluating	O
speaker	B
diarization	I
and	O
rt’09	O
datasets	B
have	O
a	O
higher	O
overlap	O
rate	O
than	O
the	O
rt’06	O
were	O
initially	O
obtained	O
via	O
manual	O
labeling	O
of	O
the	O
acoustic	O
data	B
;	O
and	O
rt’07	O
datasets	B
(	O
16.0	O
%	O
and	O
13.6	O
%	O
cf	O
.	O
7.7	O
%	O
and	O
7.6	O
%	O
)	O
.	O
however	O
,	O
high	O
variations	O
between	O
different	O
labelers	O
proved	O
to	O
this	O
is	O
primarily	O
due	O
to	O
three	O
meetings	O
(	O
from	O
cmu	O
,	O
icsi	O
,	O
be	O
problematic	O
.	O
therefore	O
,	O
more	O
recently	O
,	O
an	O
automatically	O
gen-	O
and	O
nist	O
sites	O
)	O
which	O
have	O
overlap	O
rates	B
over	O
25	O
%	O
(	O
note	O
that	O
erated	O
forced	O
alignment	O
has	O
been	O
used	O
in	O
order	B
to	O
extract	O
more	O
values	B
in	O
table	O
i	O
are	O
averaged	O
across	O
sites	O
,	O
and	O
do	O
not	O
reﬂect	O
reliable	O
speaker	B
start	O
and	O
end	O
points	O
using	O
an	O
automatic	O
speech	O
individual	O
meeting	O
scores	O
)	O
.	O
in	O
the	O
case	O
of	O
the	O
rt’09	O
dataset	O
,	O
recognition	O
(	O
asr	B
)	O
system	O
,	O
human	O
-	O
created	O
transcriptions	B
,	O
and	O
the	O
slightly	O
high	O
average	B
overlap	O
of	O
13	O
%	O
is	O
due	O
to	O
a	O
single	O
the	O
audio	O
from	O
individual	O
head	O
microphones	O
(	O
ihm	O
)	O
.	O
meeting	O
(	O
recorded	O
by	O
nist	O
)	O
in	O
which	O
the	O
overlap	O
reaches	O
31	O
%	O
.	O
as	O
meeting	O
data	B
come	O
from	O
a	O
variety	O
of	O
sources	O
some	O
differ-	O
listening	O
to	O
this	O
meeting	O
we	O
concluded	O
that	O
the	O
reason	O
of	O
such	O
ences	O
between	O
them	O
are	O
expected	O
.	O
furthermore	O
,	O
large	O
changes	O
in	O
overlap	O
is	O
that	O
it	O
is	O
not	O
a	O
professional	O
meeting	O
but	O
a	O
social	O
the	O
ﬁnal	O
der	O
scores	O
from	O
different	O
evaluations	O
would	O
suggest	O
rendezvous	O
.	O
conversely	O
,	O
rt’05	O
and	O
rt’09	O
have	O
in	O
average	B
a	O
that	O
there	O
are	O
differences	O
between	O
the	O
sets	O
of	O
meetings	O
used	O
each	O
lower	O
percentage	B
of	O
silence	B
(	O
10	O
%	O
and	O
17	O
%	O
)	O
compared	O
to	O
rt’06	O
year	O
.	O
to	O
gauge	O
the	O
differences	O
we	O
have	O
analyzed	O
over	O
20	O
dif-	O
and	O
rt’07	O
(	O
31	O
%	O
and	O
25	O
%	O
)	O
.	O
a	O
lower	O
silence	B
rate	O
and	O
higher	O
ferent	O
parameters	O
computed	O
on	O
the	O
ground	B
-	O
truth	O
data	B
.	O
in	O
table	O
i	O
,	O
overlap	O
might	O
indicate	O
that	O
these	O
meetings	O
are	O
more	O
dynamic	O
,	O
we	O
report	O
four	O
of	O
these	O
parameters	O
,	O
which	O
we	O
found	O
most	O
inter-	O
with	O
less	O
idle	O
time	B
and	O
more	O
discussion	O
,	O
although	O
this	O
does	O
esting	O
,	O
and	O
group	O
results	B
by	O
meeting	O
source	B
and	O
by	O
evaluation	B
not	O
mean	O
that	O
they	O
are	O
more	O
spontaneous	O
,	O
as	O
their	O
speech	O
and	O
year	O
.	O
speaker	B
segment	B
lengths	O
are	O
still	O
high	O
compared	O
to	O
the	O
rt’09	O
in	O
the	O
left	O
side	O
of	O
the	O
table	O
we	O
report	O
average	B
speaker	B
and	O
turn	O
dataset	O
.	O
durations	O
.	O
as	O
exempliﬁed	O
in	O
fig	O
.	O
2	O
,	O
the	O
average	B
speaker	B
duration	O
overall	O
,	O
we	O
see	O
that	O
,	O
although	O
all	O
recordings	O
belong	O
to	O
the	O
refers	O
to	O
the	O
average	B
time	B
during	O
which	O
a	O
speaker	B
is	O
active	O
(	O
i.e.	O
,	O
a	O
same	O
task	O
,	O
there	O
are	O
large	O
differences	O
between	O
the	O
datasets	B
used	O
single	O
line	O
in	O
the	O
rttm	O
reference	B
ﬁles	O
)	O
.	O
conversely	O
,	O
the	O
average	B
for	O
each	O
evaluation	B
campaign	O
,	O
as	O
well	O
as	O
between	O
recordings	O
turn	O
duration	O
refers	O
to	O
the	O
average	B
time	B
during	O
which	O
there	O
is	O
from	O
the	O
same	O
source	B
(	O
recording	B
site	O
)	O
,	O
but	O
from	O
different	O
no	O
change	B
in	O
speaker	B
activity	O
and	O
is	O
thus	O
always	O
smaller	O
than	O
datasets	B
.	O
this	O
emphasizes	O
the	O
need	O
for	O
robust	O
systems	O
which	O
the	O
average	B
speaker	B
duration	O
.	O
the	O
difference	O
between	O
the	O
two	O
perform	O
well	O
regardless	O
of	O
particular	O
dataset	O
characteristics	B
.	O
it	O
is	O
statistics	B
reﬂects	O
the	O
degree	O
of	O
overlap	O
and	O
spontaneity	O
.	O
without	O
important	O
to	O
note	O
,	O
however	O
,	O
that	O
the	O
nist	O
rt	O
datasets	B
discussed	O
any	O
overlap	O
and	O
a	O
pause	O
between	O
each	O
speaker	B
exchange	O
the	O
here	O
typically	O
contain	O
around	O
eight	O
meetings	O
per	O
dataset	O
,	O
each	O
average	B
speaker	B
and	O
turn	O
durations	O
would	O
be	O
identical	O
.	O
increases	O
of	O
them	O
contributing	O
to	O
a	O
single	O
der	O
score	B
.	O
random	O
variations	O
in	O
overlap	O
and	O
spontaneity	O
will	O
result	O
in	O
a	O
larger	O
speaker	B
/	O
turn	O
on	O
any	O
meeting	O
from	O
these	O
small	O
datasets	B
have	O
a	O
signiﬁcant	O
ratio	O
.	O
in	O
the	O
right	O
side	O
of	O
table	O
i	O
we	O
report	O
the	O
percentage	B
of	O
impact	O
on	O
average	B
results	B
.	O
it	O
is	O
then	O
difﬁcult	O
to	O
reliably	O
interpret	O
silence	B
and	O
of	O
overlapping	B
speech	I
.	O
results	B
and	O
hence	O
also	O
difﬁcult	O
to	O
draw	O
meaningful	O
conclusions	O
.	O
authorized	O
licensed	O
use	O
limited	O
to	O
:	O
inria	O
.	O
downloaded	O
on	O
october	O
05,2020	O
at	O
07:30:52	O
utc	O
from	O
ieee	O
xplore	O
.	O
 	O
restrictions	O
apply	O
.	O
366	O
ieee	O
transactions	O
on	O
audio	O
,	O
speech	O
,	O
and	O
language	B
processing	I
,	O
vol	O
.	O
20	O
,	O
no	O
.	O
2	O
,	O
february	O
2012	O
fig	O
.	O
3	O
.	O
ders	O
for	O
the	O
rt’07	O
and	O
rt’09	O
(	O
a	O
)	O
in	O
multiple	O
distant	O
microphone	O
(	O
mdm	O
)	O
condition	B
,	O
and	O
(	O
b	O
)	O
single	O
distant	O
microphone	O
(	O
sdm	O
)	O
condition	B
(	O
note	O
that	O
spkr_error	O
in	O
meeting	O
nist_20080201–1405	O
has	O
been	O
trimmed	O
to	O
ﬁt	O
the	O
screen	O
,	O
with	O
a	O
speaker	B
error	O
of	O
31.79	O
%	O
and	O
a	O
total	O
der	O
of	O
49.65	O
%	O
)	O
.	O
comparisons	O
with	O
the	O
work	O
of	O
the	O
speech	O
and	O
speaker	B
dataset	O
and	O
between	O
7.4	O
%	O
and	O
49.7	O
%	O
for	O
the	O
rt’09	O
dataset	O
.	O
recognition	O
communities	O
highlight	O
the	O
rapid	O
acceleration	O
in	O
thus	O
,	O
there	O
is	O
a	O
large	O
variation	O
in	O
performance	O
across	O
different	O
research	B
effort	O
and	O
progress	O
stemming	O
from	O
the	O
availability	O
meetings	O
and	O
in	O
all	O
cases	O
we	O
observe	O
signiﬁcant	O
overlap	O
er-	O
of	O
huge	O
datasets	B
.	O
advances	O
in	O
sophisticated	O
modeling	O
and	O
rors	O
and	O
their	O
often	O
-	O
dominant	O
impact	O
upon	O
the	O
ﬁnal	O
der	O
.	O
of	O
normalization	O
strategies	O
have	O
revolutionized	O
research	B
in	O
these	O
particular	O
note	O
is	O
the	O
poor	O
performance	O
obtained	O
on	O
the	O
single	O
related	O
ﬁelds	O
over	O
recent	O
years	O
.	O
it	O
becomes	O
apparent	O
that	O
the	O
nist_20080201–1405	O
,	O
which	O
correlates	O
with	O
the	O
particularly	O
fundamental	O
lack	O
of	O
larger	O
speaker	B
diarization	I
datasets	B
,	O
which	O
high	O
percentage	B
of	O
overlapping	B
speech	I
for	O
this	O
meeting	O
as	O
illus-	O
makes	O
it	O
difﬁcult	O
to	O
assess	O
novel	O
algorithms	O
,	O
is	O
a	O
critical	O
barrier	O
trated	O
in	O
table	O
i.	O
hence	O
,	O
the	O
detection	B
and	O
appropriate	O
treatment	O
to	O
further	O
research	B
in	O
our	O
ﬁeld	O
.	O
signiﬁcantly	O
larger	O
datasets	B
are	O
of	O
overlapping	B
speech	I
remains	O
an	O
unsolved	O
problem	O
.	O
in	O
fact	O
,	O
the	O
needed	O
in	O
order	B
to	O
obtain	O
more	O
robust	O
and	O
meaningful	O
perfor-	O
overlap	O
error	O
shown	O
in	O
fig	O
.	O
3	O
is	O
entirely	O
due	O
to	O
missed	O
overlap	O
mance	O
estimates	O
and	O
comparisons	O
.	O
as	O
a	O
result	O
of	O
processing	B
regions	O
,	O
as	O
none	O
of	O
the	O
speaker	B
diarization	I
systems	I
considered	O
more	O
data	B
,	O
faster	O
algorithms	O
will	O
also	O
need	O
to	O
be	O
investigated	O
in	O
this	O
analysis	B
included	O
an	O
overlap	O
detector	O
.	O
also	O
of	O
note	O
is	O
for	O
research	B
in	O
speaker	B
diarization	I
to	O
be	O
feasible	O
with	O
standard	O
the	O
general	O
stability	O
of	O
speech	B
activity	I
detection	I
(	O
sad	O
)	O
algo-	O
computing	O
resources	O
.	O
rithms	O
which	O
achieve	O
impressive	O
levels	O
of	O
performance	O
in	O
both	O
mdm	O
and	O
sdm	O
conditions	O
(	O
i.e.	O
,	O
they	O
are	O
robust	O
to	O
the	O
quality	B
c.	O
evaluation	B
results	B
of	O
the	O
signal	B
)	O
.	O
values	B
of	O
around	O
1	O
%	O
to	O
2	O
%	O
missed	O
speech	O
error	O
to	O
assess	O
the	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
and	O
provide	O
a	O
baseline	B
rates	B
and	O
2	O
%	O
to	O
3	O
%	O
false	B
alarm	I
error	B
rates	I
are	O
currently	O
typ-	O
for	O
future	O
research	B
we	O
present	O
results	B
for	O
the	O
rt’07	O
(	O
fig	O
.	O
3	O
left	O
ical	O
.	O
the	O
main	O
difference	O
between	O
mdm	O
and	O
sdm	O
performance	O
half	O
)	O
and	O
rt’09	O
(	O
fig	O
.	O
3	O
right	O
half	O
)	O
nist	O
evaluations	O
for	O
the	O
rests	O
mainly	O
in	O
the	O
speaker	B
error	O
.	O
here	O
diarization	B
systems	I
are	O
mdm	O
[	O
fig	O
.	O
3(a	O
)	O
]	O
and	O
sdm	O
[	O
fig	O
.	O
3(b	O
)	O
]	O
conditions	O
.	O
both	O
ﬁg-	O
affected	O
by	O
the	O
reduced	O
signal	B
quality	B
which	O
characterizes	O
the	O
ures	O
have	O
been	O
compiled	O
from	O
a	O
comparison	O
of	O
results	B
from	O
sdm	O
condition	B
.	O
four	O
of	O
the	O
participating	O
sites	O
(	O
lia	O
/	O
eurecom,4	O
i2r	O
/	O
ntu	O
,	O
icsi	O
overall	O
,	O
the	O
large	O
variations	O
in	O
der	O
observed	O
among	O
the	O
dif-	O
and	O
upc	O
)	O
and	O
by	O
selecting	O
the	O
result	O
with	O
lowest	O
der	O
for	O
each	O
ferent	O
meetings	O
and	O
meeting	O
sets	O
originate	O
from	O
the	O
large	O
vari-	O
meeting	O
recording	B
.	O
given	O
the	O
volatility	O
of	O
the	O
results	B
described	O
ance	O
of	O
many	O
important	O
factors	O
for	O
speaker	B
diarization	I
,	O
which	O
and	O
studied	O
in	O
[	O
3	O
]	O
,	O
by	O
selecting	O
the	O
best	O
result	O
in	O
each	O
case	O
we	O
hy-	O
makes	O
the	O
conference	O
meeting	O
domain	B
not	O
as	O
easily	O
tractable	O
pothesize	O
that	O
these	O
results	B
are	O
a	O
more	O
meaningful	O
estimation	B
of	O
as	O
more	O
formalized	O
settings	O
such	O
as	O
broadcast	O
news	O
,	O
lectures	O
,	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
in	O
speaker	B
diarization	I
for	O
con-	O
or	O
court	O
house	O
trials	O
.	O
previous	O
work	O
has	O
highlighted	O
the	O
difﬁ-	O
ference	O
meeting	O
data	B
than	O
selecting	O
all	O
results	B
from	O
any	O
single	O
culty	O
in	O
assessing	O
the	O
performance	O
of	O
speaker	B
diarization	I
algo-	O
system	O
output	B
.	O
to	O
illustrate	O
the	O
variation	O
in	O
performance	O
for	O
dif-	O
rithms	O
with	O
the	O
view	O
of	O
improving	O
performance	O
[	O
130	O
]	O
.	O
as	O
re-	O
ferent	O
meetings	O
we	O
provide	O
results	B
for	O
individual	O
meetings	O
.	O
in	O
ported	O
in	O
section	O
iii	O
,	O
current	O
approaches	O
to	O
speaker	B
diarization	I
both	O
ﬁgures	O
,	O
errors	B
are	O
decomposed	O
into	O
the	O
speaker	B
error	O
(	O
spkr	O
involve	O
a	O
sequence	B
of	O
separate	O
stages	O
where	O
each	O
stage	B
takes	O
error	O
)	O
,	O
overlap	O
error	O
(	O
ovl	O
error	O
)	O
,	O
false	B
alarm	I
speech	O
error	O
(	O
fa	O
its	O
input	B
from	O
the	O
preceding	O
stage(s	O
)	O
.	O
when	O
combined	O
in	O
such	O
a	O
speech	O
)	O
,	O
and	O
missed	O
speech	O
error	O
(	O
miss	B
speech	O
)	O
.	O
fashion	O
,	O
it	O
is	O
exceedingly	O
difﬁcult	O
to	O
assess	O
the	O
performance	O
of	O
for	O
the	O
mdm	O
condition	B
[	O
fig	O
.	O
3(a	O
)	O
]	O
the	O
average	B
der	O
for	O
the	O
each	O
system	O
component	O
since	O
every	O
single	O
one	O
is	O
affected	O
by	O
the	O
rt’07	O
and	O
rt’09	O
datasets	B
is	O
7.5	O
%	O
and	O
10.1	O
%	O
,	O
respectively	O
.	O
performance	O
of	O
all	O
previous	O
processing	B
stages	O
.	O
furthermore	O
,	O
it	O
performance	O
varies	O
between	O
3.5	O
%	O
and	O
15.7	O
%	O
for	O
the	O
rt’07	O
is	O
not	O
guaranteed	O
that	O
improvements	B
to	O
one	O
stage	B
,	O
for	O
example	O
dataset	O
whereas	O
for	O
the	O
rt’09	O
dataset	O
performance	O
varies	O
be-	O
that	O
of	O
segmentation	B
,	O
will	O
lead	O
unequivocally	O
to	O
improvements	B
tween	O
5.3	O
%	O
and	O
22.2	O
%	O
.	O
for	O
the	O
sdm	O
condition	B
the	O
average	B
in	O
later	O
stages	O
,	O
for	O
example	O
that	O
of	O
clustering	B
.	O
this	O
makes	O
the	O
op-	O
der	O
is	O
11.6	O
%	O
and	O
17.7	O
%	O
for	O
the	O
rt’07	O
and	O
rt’09	O
datasets	B
,	O
re-	O
timization	O
of	O
different	O
system	O
components	B
rather	O
troublesome	O
.	O
spectively	O
.	O
performance	O
is	O
always	O
poorer	O
than	O
that	O
for	O
the	O
mdm	O
once	O
again	O
,	O
by	O
drawing	O
comparisons	O
to	O
the	O
speech	O
and	O
speaker	B
condition	B
and	O
varies	O
between	O
3.7	O
%	O
and	O
19.9	O
%	O
for	O
the	O
rt’07	O
recognition	O
ﬁelds	O
,	O
it	O
is	O
reasonable	O
to	O
foresee	O
more	O
uniﬁed	O
ap-	O
proaches	O
,	O
as	O
is	O
already	O
in	O
progress	O
with	O
the	O
now	O
commonplace	O
4eurecom	O
was	O
associated	O
with	O
the	O
lia	O
for	O
the	O
rt’09	O
campaign	O
only	O
.	O
authorized	O
licensed	O
use	O
limited	O
to	O
:	O
inria	O
.	O
downloaded	O
on	O
october	O
05,2020	O
at	O
07:30:52	O
utc	O
from	O
ieee	O
xplore	O
.	O
 	O
restrictions	O
apply	O
.	O
anguera	O
miro	O
et	O
al	O
.	O
:	O
speaker	B
diarization	I
:	O
a	O
review	O
of	O
recent	O
research	B
367	O
combined	O
approaches	O
to	O
segmentation	B
and	O
clustering	B
.	O
in	O
par-	O
references	B
ticular	O
,	O
we	O
believe	O
that	O
important	O
decreases	O
in	O
der	O
will	O
have	O
to	O
come	O
in	O
the	O
near	O
future	O
from	O
systems	O
incorporating	O
effec-	O
[	O
1	O
]	O
“	O
the	O
nist	O
rich	B
transcription	I
2009	O
(	O
rt’09	O
)	O
evaluation	B
,	O
”	O
nist	O
,	O
2009	O
[	O
online	O
]	O
.	O
available	O
:	O
http://www.itl.nist.gov/iad/mig/tests/rt/2009/	O
tive	O
algorithms	O
that	O
can	O
detect	O
and	O
correctly	O
assign	O
overlapping	B
docs	O
/	O
rt09-meeting	O
-	O
eval	O
-	O
plan	O
-	O
v2.pdf	O
speech	O
.	O
[	O
2	O
]	O
s.	O
tranter	O
and	O
d.	O
reynolds	O
,	O
“	O
an	O
overview	O
of	O
automatic	O
speaker	B
di-	O
arization	O
systems	O
,	O
”	O
ieee	O
trans	O
.	O
audio	O
,	O
speech	O
,	O
lang	O
.	O
process	B
.	O
,	O
vol	O
.	O
14	O
,	O
no	O
.	O
5	O
,	O
pp	O
.	O
1557–1565	O
,	O
sep	O
.	O
2006	O
.	O
[	O
3	O
]	O
n.	O
mirghafori	O
and	O
c.	O
wooters	O
,	O
“	O
nuts	O
and	O
ﬂakes	O
:	O
a	O
study	O
of	O
data	B
char-	O
vi	O
.	O
conclusion	O
and	O
directions	O
for	O
future	O
research	B
acteristics	O
in	O
speaker	B
diarization	I
,	O
”	O
in	O
proc	O
.	O
icassp	O
,	O
2006	O
.	O
[	O
4	O
]	O
x.	O
anguera	O
,	O
“	O
robust	B
speaker	I
diarization	B
for	O
meetings	O
,	O
”	O
ph.d	O
.	O
disser-	O
research	B
on	O
speaker	B
diarization	I
has	O
been	O
developed	O
in	O
many	O
tation	O
,	O
univ	O
.	O
politecnica	O
de	O
catalunya	O
,	O
barcelona	O
,	O
spain	O
,	O
2006	O
.	O
domains	O
,	O
from	O
phone	O
calls	O
conversations	O
within	O
the	O
speaker	B
[	O
5	O
]	O
m.	O
kotti	O
,	O
e.	O
benetos	O
,	O
and	O
c.	O
kotropoulos	O
,	O
“	O
computationally	O
efﬁcient	O
and	O
robust	O
bic	B
-	O
based	B
speaker	I
segmentation	B
,	O
”	O
ieee	O
trans	O
.	O
audio	O
,	O
recognition	O
evaluations	O
,	O
to	O
broadcast	O
news	O
and	O
meeting	O
record-	O
speech	O
,	O
lang	O
.	O
process	B
.	O
,	O
vol	O
.	O
16	O
,	O
no	O
.	O
5	O
,	O
pp	O
.	O
920–933	O
,	O
jul	O
.	O
2008	O
.	O
ings	O
in	O
the	O
nist	O
rich	B
transcription	I
evaluations	O
.	O
furthermore	O
,	O
[	O
6	O
]	O
x.	O
zhu	O
,	O
c.	O
barras	O
,	O
l.	O
lamel	O
,	O
and	O
j.-l	O
.	O
gauvain	O
,	O
“	O
multi	O
-	O
stage	B
speaker	B
it	O
has	O
been	O
used	O
in	O
many	O
applications	O
such	O
as	O
a	O
front	O
-	O
end	O
for	O
diarization	B
for	O
conference	O
and	O
lecture	O
meetings	O
,	O
”	O
in	O
proc	O
.	O
multimodal	O
technol	O
.	O
perception	O
of	O
humans	O
:	O
int	O
.	O
eval	O
.	O
workshops	O
clear	O
2007	O
and	O
speaker	B
and	O
speech	B
recognition	I
,	O
as	O
a	O
meta	O
-	O
data	B
extraction	B
tool	O
rt	O
2007	O
,	O
baltimore	O
,	O
md	O
,	O
may	O
8–11	O
,	O
2007	O
,	O
revised	O
selected	O
papers	O
,	O
to	O
aid	O
navigation	O
in	O
broadcast	O
tv	O
,	O
lecture	O
recordings	O
,	O
meetings	O
,	O
berlin	O
,	O
heidelberg	O
:	O
springer	O
-	O
verlag	O
,	O
2008	O
,	O
pp	O
.	O
533–542	O
.	O
and	O
video	O
conferences	O
and	O
even	O
for	O
applications	O
such	O
as	O
media	O
[	O
7	O
]	O
s.	O
jothilakshmi	O
,	O
v.	O
ramalingam	O
,	O
and	O
s.	O
palanivel	O
,	O
“	O
speaker	B
diariza-	O
tion	O
using	O
autoassociative	O
neural	B
networks	I
,	O
”	O
eng	O
.	O
applicat	O
.	O
artif	O
.	O
in-	O
similarity	B
estimation	B
for	O
copyright	O
detection	B
.	O
also	O
,	O
speaker	B
di-	O
tell	O
.	O
,	O
vol	O
.	O
22	O
,	O
no	O
.	O
4	O
-	O
5	O
,	O
pp	O
.	O
667–675	O
,	O
2009	O
.	O
arization	O
research	B
has	O
led	O
to	O
various	O
by	O
-	O
products	O
.	O
for	O
example	O
,	O
[	O
8	O
]	O
x.	O
anguera	O
,	O
c.	O
wooters	O
,	O
and	O
j.	O
hernando	O
,	O
“	O
robust	B
speaker	I
diarization	B
for	O
meetings	O
:	O
icsi	O
rt06s	O
evaluation	B
system	O
,	O
”	O
in	O
proc	O
.	O
icslp	O
,	O
pitts-	O
with	O
the	O
availability	O
of	O
recordings	O
using	O
multiple	O
microphones	O
,	O
burgh	O
,	O
pa	O
,	O
sep	O
.	O
2006	O
.	O
a	O
set	B
of	O
algorithms	O
has	O
been	O
proposed	O
in	O
recent	O
years	O
both	O
for	O
[	O
9	O
]	O
c.	O
wooters	O
and	O
m.	O
huijbregts	O
,	O
“	O
the	O
icsi	O
rt07s	O
speaker	B
diarization	I
signal	B
enhancement	O
and	O
to	O
take	O
advantage	O
of	O
the	O
extra	O
infor-	O
system	O
,	O
”	O
in	O
multimodal	O
technologies	O
for	O
perception	O
of	O
humans	O
:	O
inter-	O
national	O
evaluation	B
workshops	O
clear	O
2007	O
and	O
rt	O
2007	O
,	O
baltimore	O
,	O
mation	O
that	O
these	O
offer	O
.	O
in	O
addition	O
,	O
the	O
availability	O
of	O
other	O
md	O
,	O
usa	O
,	O
may	O
8–11	O
,	O
2007	O
,	O
revised	O
selected	O
papers	O
,	O
berlin	O
,	O
heidel-	O
modalities	O
,	O
such	O
as	O
video	O
,	O
have	O
started	O
to	O
inspire	O
multimodal	O
berg	O
:	O
springer	O
-	O
verlag	O
,	O
2008	O
,	O
pp	O
.	O
509–519	O
.	O
[	O
10	O
]	O
j.	O
rougui	O
,	O
m.	O
rziza	O
,	O
d.	O
aboutajdine	O
,	O
m.	O
gelgon	O
,	O
and	O
j.	O
martinez	O
,	O
“	O
fast	O
diarization	B
systems	I
,	O
thus	O
merging	O
the	O
visual	O
and	O
the	O
acoustic	O
incremental	O
clustering	B
of	O
gaussian	O
mixture	O
speaker	B
models	B
for	O
scaling	O
domains	O
.	O
up	O
retrieval	O
in	O
on	O
-	O
line	O
broadcast	O
,	O
”	O
in	O
proc	O
.	O
icassp	O
,	O
may	O
2006	O
,	O
vol	O
.	O
5	O
,	O
this	O
paper	O
provides	O
an	O
overview	O
of	O
the	O
current	O
state	O
-	O
of-	O
pp	O
.	O
521–524	O
.	O
[	O
11	O
]	O
w.	O
tsai	O
,	O
s.	O
cheng	O
,	O
and	O
h.	O
wang	O
,	O
in	O
proc	O
.	O
icslp	O
,	O
2004	O
.	O
the	O
-	O
art	O
in	O
speaker	B
diarization	I
systems	I
and	O
underlines	O
several	O
[	O
12	O
]	O
t.	O
h.	O
nguyen	O
,	O
e.	O
s.	O
chng	O
,	O
and	O
h.	O
li	O
,	O
“	O
t	O
-	O
test	B
distance	B
and	O
clustering	B
challenges	B
that	O
need	O
to	O
be	O
addressed	O
in	O
future	O
years	O
.	O
for	O
ex-	O
criterion	B
for	O
speaker	B
diarization	I
,	O
”	O
in	O
proc	O
.	O
interspeech	O
,	O
brisbane	O
,	O
aus-	O
tralia	O
,	O
2008	O
.	O
ample	O
,	O
speaker	B
diarization	I
is	O
not	O
yet	O
sufﬁciently	O
mature	O
so	O
[	O
13	O
]	O
t.	O
nguyen	O
et	O
al	O
.	O
,	O
“	O
the	O
iir	O
-	O
ntu	O
speaker	B
diarization	I
systems	I
for	O
rt	O
that	O
methods	O
can	O
be	O
easily	O
ported	O
across	O
different	O
domains	O
,	O
as	O
2009	O
,	O
”	O
in	O
proc	O
.	O
rt’09	O
,	O
nist	O
rich	B
transcription	I
workshop	O
,	O
melbourne	O
,	O
shown	O
in	O
section	O
v	O
,	O
where	O
small	O
differences	O
in	O
meeting	O
data	B
fl	O
,	O
2009	O
.	O
[	O
14	O
]	O
s.	O
meignier	O
,	O
j.-f	O
.	O
bonastre	O
,	O
and	O
s.	O
igounet	O
,	O
“	O
e	O
-	O
hmm	O
approach	O
for	O
(	O
recorded	O
at	O
identical	O
sites	O
)	O
lead	O
to	O
large	O
variations	O
in	O
perfor-	O
learning	O
and	O
adapting	O
sound	O
models	B
for	O
speaker	B
indexing	O
,	O
”	O
in	O
proc	O
.	O
mance	O
.	O
in	O
the	O
meantime	O
,	O
larger	O
datasets	B
need	O
to	O
be	O
compiled	O
in	O
odyssey	O
speaker	B
and	O
lang	O
.	O
recognition	O
workshop	O
,	O
chania	O
,	O
creete	O
,	O
order	B
for	O
results	B
to	O
become	O
more	O
meaningful	O
and	O
for	O
systems	O
to	O
jun	O
.	O
2001	O
,	O
pp	O
.	O
175–180	O
.	O
[	O
15	O
]	O
c.	O
fredouille	O
and	O
n.	O
evans	O
,	O
“	O
the	O
lia	O
rt’07	O
speaker	B
diarization	I
be	O
more	O
robust	O
to	O
unseen	O
variations	O
.	O
of	O
course	O
,	O
with	O
increasing	O
system	O
,	O
”	O
in	O
proc	O
.	O
multimodal	O
technol	O
.	O
for	O
perception	O
of	O
humans	O
:	O
dataset	O
sizes	O
,	O
systems	O
will	O
have	O
to	O
become	O
more	O
efﬁcient	O
in	O
int	O
.	O
eval	O
.	O
workshops	O
clear	O
2007	O
and	O
rt	O
2007	O
,	O
baltimore	O
,	O
md	O
,	O
usa	O
,	O
may	O
8–11	O
,	O
2007	O
,	O
revised	O
selected	O
papers	O
,	O
berlin	O
,	O
heidelberg	O
:	O
order	B
to	O
process	B
such	O
data	B
in	O
reasonable	O
time	B
.	O
still	O
,	O
the	O
biggest	O
springer	O
-	O
verlag	O
,	O
2008	O
,	O
pp	O
.	O
520–532	O
.	O
single	O
challenge	B
is	O
probably	O
the	O
handling	O
of	O
overlapping	B
[	O
16	O
]	O
c.	O
fredouille	O
,	O
s.	O
bozonnet	O
,	O
and	O
n.	O
w.	O
d.	O
evans	O
,	O
“	O
the	O
lia	O
-	O
eurecom	O
speech	O
,	O
which	O
needs	O
to	O
be	O
attributed	O
to	O
multiple	O
speakers	O
.	O
as	O
rt’09	O
speaker	B
diarization	I
system	I
,	O
”	O
in	O
proc	O
.	O
rt’09	O
,	O
nist	O
rich	O
tran-	O
scription	O
workshop	O
,	O
melbourne	O
,	O
fl	O
,	O
2009	O
.	O
a	O
relatively	O
embryonic	O
community	O
,	O
at	O
least	O
compared	O
to	O
the	O
[	O
17	O
]	O
s.	O
bozonnet	O
,	O
n.	O
w.	O
d.	O
evans	O
,	O
and	O
c.	O
fredouille	O
,	O
“	O
the	O
lia	O
-	O
eurecom	O
more	O
established	O
ﬁelds	O
of	O
speech	O
and	O
speaker	B
recognition	O
,	O
there	O
rt’09	O
speaker	B
diarization	I
system	I
:	O
enhancements	O
in	O
speaker	B
modelling	O
and	O
cluster	O
puriﬁcation	O
,	O
”	O
in	O
proc	O
.	O
icassp	O
,	O
dallas	O
,	O
tx	O
,	O
mar	O
.	O
14–19	O
,	O
are	O
thus	O
outstanding	O
opportunities	O
for	O
signiﬁcant	O
advances	O
2010	O
,	O
pp	O
.	O
4958–4961	O
.	O
and	O
important	O
changes	O
to	O
the	O
somewhat	O
ad	O
hoc	O
and	O
heuristic	O
[	O
18	O
]	O
d.	O
vijayasenan	O
,	O
f.	O
valente	O
,	O
and	O
h.	O
bourlard	O
,	O
“	O
agglomerative	O
infor-	O
approaches	O
that	O
currently	O
dominate	O
the	O
ﬁeld	O
.	O
mation	O
bottleneck	O
for	O
speaker	B
diarization	I
of	O
meetings	O
data	B
,	O
”	O
in	O
proc	O
.	O
asru	O
,	O
dec	O
.	O
2007	O
,	O
pp	O
.	O
250–255	O
.	O
overall	O
,	O
the	O
future	O
of	O
the	O
ﬁeld	O
seems	O
even	O
broader	O
and	O
[	O
19	O
]	O
d.	O
vijayasenan	O
,	O
f.	O
valente	O
,	O
and	O
h.	O
bourlard	O
,	O
“	O
an	O
information	B
theoretic	O
brighter	O
than	O
the	O
present	O
,	O
as	O
more	O
and	O
more	O
people	O
acknowl-	O
approach	O
to	O
speaker	B
diarization	I
of	O
meeting	O
data	B
,	O
”	O
ieee	O
trans	O
.	O
audio	O
,	O
speech	O
,	O
lang	O
.	O
process	B
.	O
,	O
vol	O
.	O
17	O
,	O
no	O
.	O
7	O
,	O
pp	O
.	O
1382–1393	O
,	O
sep	O
.	O
2009	O
.	O
edge	O
the	O
usefulness	O
of	O
audio	O
methods	O
for	O
many	O
tasks	O
that	O
have	O
[	O
20	O
]	O
s.	O
mceachern	O
,	O
“	O
estimating	O
normal	O
means	O
with	O
a	O
conjugate	O
style	O
traditionally	O
been	O
thought	O
to	O
be	O
exclusively	O
solvable	O
in	O
the	O
dirichlet	O
process	B
prior	O
,	O
”	O
in	O
proc	O
.	O
commun	O
.	O
statist	O
.	O
:	O
simul	O
.	O
comput	O
.	O
,	O
visual	O
domain	B
.	O
speaker	B
diarization	I
is	O
one	O
of	O
the	O
fundamental	O
1994	O
,	O
vol	O
.	O
23	O
,	O
pp	O
.	O
727–741	O
.	O
[	O
21	O
]	O
g.	O
e.	O
hinton	O
and	O
d.	O
van	O
camp	O
,	O
“	O
keeping	O
the	O
neural	B
networks	I
simple	O
by	O
problems	O
underlying	O
virtually	O
any	O
task	O
that	O
involves	O
acoustics	B
minimizing	O
the	O
description	O
length	B
of	O
the	O
weights	O
,	O
”	O
in	O
proc	O
.	O
6th	O
annu	O
.	O
and	O
the	O
presence	B
of	O
more	O
than	O
one	O
person	O
.	O
conf	O
.	O
comput	O
.	O
learn	O
.	O
theory	O
,	O
new	O
york	O
,	O
1993	O
,	O
colt	O
’	O
93	O
,	O
pp	O
.	O
5–13	O
.	O
[	O
22	O
]	O
m.	O
j.	O
wainwright	O
and	O
m.	O
i.	O
jordan	O
,	O
“	O
variational	O
inference	B
in	O
graphical	O
models	B
:	O
the	O
view	O
from	O
the	O
marginal	O
polytope	O
,	O
”	O
in	O
proc	O
.	O
41st	O
annu	O
.	O
allerton	O
conf	O
.	O
commun	O
.	O
,	O
control	O
,	O
comput	O
.	O
,	O
urbana	O
-	O
champaign	O
,	O
il	O
,	O
acknowledgment	O
2003	O
.	O
[	O
23	O
]	O
f.	O
valente	O
,	O
“	O
variational	O
bayesian	O
methods	O
for	O
audio	O
indexing	O
,	O
”	O
ph.d	O
.	O
the	O
authors	O
would	O
like	O
to	O
thank	O
those	O
rt	O
participating	O
sites	O
dissertation	O
,	O
eurecom	O
inst	O
.	O
,	O
sophia	O
-	O
antipolis	O
,	O
france	O
,	O
2005	O
.	O
that	O
lent	O
them	O
their	O
results	B
for	O
this	O
study	O
,	O
in	O
particular	O
j.	O
luque	O
[	O
24	O
]	O
d.	O
reynolds	O
,	O
p.	O
kenny	O
,	O
and	O
f.	O
castaldo	O
,	O
“	O
a	O
study	O
of	O
new	O
approaches	O
to	O
speaker	B
diarization	I
,	O
”	O
in	O
proc	O
.	O
interspeech	O
,	O
2009	O
.	O
from	O
upc	O
,	O
spain	O
,	O
and	O
t.h	O
.	O
nguyen	O
and	O
h.	O
li	O
from	O
i2r	O
and	O
[	O
25	O
]	O
p.	O
kenny	O
,	O
“	O
bayesian	O
analysis	B
of	O
speaker	B
diarization	I
with	O
eigenvoice	O
ntu	O
,	O
singapore	O
.	O
priors	O
,	O
”	O
technical	O
report	O
.	O
montreal	O
,	O
qc	O
,	O
canada	O
:	O
crim	O
,	O
2008	O
.	O
authorized	O
licensed	O
use	O
limited	O
to	O
:	O
inria	O
.	O
downloaded	O
on	O
october	O
05,2020	O
at	O
07:30:52	O
utc	O
from	O
ieee	O
xplore	O
.	O
 	O
restrictions	O
apply	O
.	O
368	O
ieee	O
transactions	O
on	O
audio	O
,	O
speech	O
,	O
and	O
language	B
processing	I
,	O
vol	O
.	O
20	O
,	O
no	O
.	O
2	O
,	O
february	O
2012	O
[	O
26	O
]	O
x.	O
anguera	O
and	O
j.-f	O
.	O
bonastre	O
,	O
“	O
a	O
novel	O
speaker	B
binary	O
key	O
derived	O
[	O
50	O
]	O
j.	O
ramirez	O
,	O
j.	O
m.	O
girriz	O
,	O
and	O
j.	O
c.	O
segura	O
,	O
m.	O
grimm	O
and	O
k.	O
kroschel	O
,	O
from	O
anchor	O
models	B
,	O
”	O
in	O
proc	O
.	O
interspeech	O
,	O
2010	O
.	O
eds	O
.	O
,	O
“	O
voice	O
activity	B
detection	I
.	O
fundamentals	O
and	O
speech	B
recognition	I
[	O
27	O
]	O
x.	O
anguera	O
and	O
j.-f	O
.	O
bonastre	O
,	O
“	O
fast	O
speaker	B
diarization	I
based	O
on	O
bi-	O
system	O
robustness	O
,	O
”	O
in	O
proc	O
.	O
robust	O
speech	O
recognit	O
.	O
understand	O
.	O
,	O
vi-	O
nary	O
keys	O
,	O
”	O
in	O
proc	O
.	O
icassp	O
,	O
2011	O
.	O
enna	O
,	O
austria	O
,	O
jun	O
.	O
2007	O
,	O
p.	O
460	O
.	O
[	O
28	O
]	O
y.	O
huang	O
,	O
o.	O
vinyals	O
,	O
g.	O
friedland	O
,	O
c.	O
muller	O
,	O
n.	O
mirghafori	O
,	O
and	O
[	O
51	O
]	O
c.	O
fredouille	O
and	O
g.	O
senay	O
,	O
“	O
technical	O
improvements	B
of	O
the	O
e	O
-	O
hmm	O
c.	O
wooters	O
,	O
“	O
a	O
fast	O
-	O
match	O
approach	O
for	O
robust	O
,	O
faster	O
than	O
real	O
-	O
time	B
based	B
speaker	I
diarization	B
system	O
for	O
meeting	O
records	O
,	O
”	O
in	O
proc	O
.	O
mlmi	O
speaker	B
diarization	I
,	O
”	O
in	O
proc	O
.	O
ieee	O
workshop	O
autom	O
.	O
speech	O
recogni-	O
third	O
int	O
.	O
workshop	O
,	O
bethesda	O
,	O
md	O
,	O
usa	O
,	O
revised	O
selected	O
paper	O
,	O
tion	O
understanding	O
,	O
kyoto	O
,	O
japan	O
,	O
dec	O
.	O
2007	O
,	O
pp	O
.	O
693–698	O
.	O
berlin	O
,	O
heidelberg	O
:	O
springer	O
-	O
verlag	O
,	O
2006	O
,	O
pp	O
.	O
359–370	O
.	O
[	O
29	O
]	O
g.	O
friedland	O
,	O
j.	O
ching	O
,	O
and	O
a.	O
janin	O
,	O
“	O
parallelizing	O
speaker	B
-	O
attributed	O
[	O
52	O
]	O
d.	O
a.	O
v.	O
leeuwen	O
and	O
m.	O
konecˇný	O
,	O
“	O
progress	O
in	O
the	O
amida	O
speaker	B
speech	B
recognition	I
for	O
meeting	O
browsing	O
,	O
”	O
in	O
proc	O
.	O
ieee	O
int	O
.	O
symp	O
.	O
diarization	B
system	O
for	O
meeting	O
data	B
,	O
”	O
in	O
proc	O
.	O
multimodal	O
technol	O
.	O
for	O
multimedia	O
,	O
taichung	O
,	O
taiwan	O
,	O
dec	O
.	O
2010	O
,	O
pp	O
.	O
121–128	O
.	O
percept	O
.	O
of	O
humans	O
:	O
int	O
.	O
eval	O
.	O
workshops	O
clear	O
2007	O
and	O
rt	O
2007	O
,	O
[	O
30	O
]	O
x.	O
anguera	O
,	O
c.	O
wooters	O
,	O
and	O
j.	O
hernando	O
,	O
“	O
friends	O
and	O
enemies	O
:	O
a	O
baltimore	O
,	O
md	O
,	O
may	O
8–11	O
,	O
2007	O
,	O
revised	O
selected	O
papers	O
,	O
berlin	O
,	O
hei-	O
novel	O
initialization	O
for	O
speaker	B
diarization	I
,	O
”	O
in	O
proc	O
.	O
icslp	O
,	O
pittsburgh	O
,	O
delberg	O
:	O
springer	O
-	O
verlag	O
,	O
2008	O
,	O
pp	O
.	O
475–483	O
.	O
pa	O
,	O
sep	O
.	O
2006	O
.	O
[	O
53	O
]	O
a.	O
rentzeperis	O
,	O
a.	O
stergious	O
,	O
c.	O
boukis	O
,	O
a.	O
pnevmatikakis	O
,	O
and	O
l.	O
[	O
31	O
]	O
j.	O
ajmera	O
,	O
“	O
a	O
robust	B
speaker	I
clustering	B
algorithm	O
,	O
”	O
in	O
proc	O
.	O
asru	O
,	O
polymenakos	O
,	O
“	O
the	O
2006	O
athens	O
information	B
technology	O
speech	O
ac-	O
2003	O
,	O
pp	O
.	O
411–416	O
.	O
tivity	O
detection	B
and	O
speaker	B
diarization	I
systems	I
,	O
”	O
in	O
proc	O
.	O
mach	O
.	O
learn	O
.	O
[	O
32	O
]	O
x.	O
anguera	O
,	O
c.	O
wooters	O
,	O
and	O
j.	O
hernando	O
,	O
“	O
purity	O
algorithms	O
for	O
multimodal	O
interaction	O
:	O
3rd	O
int	O
.	O
workshop	O
,	O
mlmi	O
2006	O
,	O
bethesda	O
,	O
speaker	B
diarization	I
of	O
meetings	O
data	B
,	O
”	O
in	O
proc	O
.	O
icassp	O
,	O
toulouse	O
,	O
md	O
,	O
revised	O
selected	O
paper	O
,	O
berlin	O
,	O
heidelberg	O
:	O
springer	O
-	O
verlag	O
,	O
france	O
,	O
may	O
2006	O
,	O
pp	O
.	O
1025–1028	O
.	O
2006	O
,	O
pp	O
.	O
385–395	O
.	O
[	O
33	O
]	O
s.	O
s.	O
chen	O
and	O
p.	O
s.	O
gopalakrishnan	O
,	O
“	O
speaker	B
,	O
environment	O
and	O
[	O
54	O
]	O
a.	O
temko	O
,	O
d.	O
macho	O
,	O
and	O
c.	O
nadeu	O
,	O
“	O
enhanced	O
svm	O
training	O
for	O
ro-	O
channel	O
change	B
detection	I
and	O
clustering	B
via	O
the	O
bayesian	O
information	B
bust	O
speech	B
activity	I
detection	I
,	O
”	O
in	O
proc	O
.	O
icassp	O
,	O
honolulu	O
,	O
hi	O
,	O
2007	O
,	O
criterion	B
,	O
”	O
in	O
proc	O
.	O
darpa	O
broadcast	O
news	O
transcription	B
and	O
under-	O
pp	O
.	O
1025–1028	O
.	O
standing	O
workshop	O
,	O
lansdowne	O
,	O
va	O
,	O
feb	O
.	O
1998	O
,	O
pp	O
.	O
127–132	O
.	O
[	O
55	O
]	O
x.	O
anguera	O
,	O
c.	O
wooters	O
,	O
m.	O
anguilo	O
,	O
and	O
c.	O
nadeu	O
,	O
“	O
hybrid	O
speech/	O
[	O
34	O
]	O
h.	O
gish	O
and	O
m.	O
schmidt	O
,	O
“	O
text	O
independent	O
speaker	B
identiﬁcation	O
,	O
”	O
non	O
-	O
speech	O
detector	O
applied	O
to	O
speaker	B
diarization	I
of	O
meetings	O
,	O
”	O
in	O
ieee	O
signal	B
process	B
.	O
mag	O
.	O
,	O
vol	O
.	O
11	O
,	O
no	O
.	O
4	O
,	O
pp	O
.	O
18–32	O
,	O
oct	O
.	O
1994	O
.	O
proc	O
.	O
speaker	B
odyssey	O
workshop	O
,	O
puerto	O
rico	O
,	O
jun	O
.	O
2006	O
.	O
[	O
35	O
]	O
a.	O
janin	O
,	O
j.	O
ang	O
,	O
s.	O
bhagat	O
,	O
r.	O
dhillon	O
,	O
j.	O
edwards	O
,	O
j.	O
macias	O
-	O
guarasa	O
,	O
[	O
56	O
]	O
h.	O
sun	O
,	O
t.	O
l.	O
nwe	O
,	O
b.	O
ma	O
,	O
and	O
h.	O
li	O
,	O
“	O
speaker	B
diarization	I
for	O
meeting	O
n.	O
morgan	O
,	O
b.	O
peskin	O
,	O
e.	O
shriberg	O
,	O
a.	O
stolcke	O
,	O
c.	O
wooters	O
,	O
and	O
b.	O
room	O
audio	O
,	O
”	O
in	O
proc	O
.	O
interspeech’09	O
,	O
sep	O
.	O
2009	O
.	O
wrede	O
,	O
“	O
the	O
icsi	O
meeting	O
project	O
:	O
resources	O
and	O
research	B
,	O
”	O
in	O
proc	O
.	O
[	O
57	O
]	O
t.	O
l.	O
nwe	O
,	O
h.	O
sun	O
,	O
h.	O
li	O
,	O
and	O
s.	O
rahardja	O
,	O
“	O
speaker	B
diarization	I
icassp	O
meeting	O
recognition	O
workshop	O
,	O
2004	O
.	O
in	O
meeting	O
audio	O
,	O
”	O
in	O
proc	O
.	O
icassp	O
,	O
taipei	O
,	O
taiwan	O
,	O
2009	O
,	O
pp	O
.	O
[	O
36	O
]	O
i.	O
mccowan	O
,	O
j.	O
carletta	O
,	O
w.	O
kraaij	O
,	O
s.	O
ashby	O
,	O
s.	O
bourban	O
,	O
m.	O
4073–4076	O
.	O
flynn	O
,	O
m.	O
guillemot	O
,	O
t.	O
hain	O
,	O
j.	O
kadlec	O
,	O
v.	O
karaiskos	O
,	O
m.	O
kronen-	O
[	O
58	O
]	O
e.	O
el	O
-	O
khoury	O
,	O
c.	O
senac	O
,	O
and	O
j.	O
pinquier	O
,	O
“	O
improved	O
speaker	B
diariza-	O
thal	O
,	O
g.	O
lathoud	O
,	O
m.	O
lincoln	O
,	O
a.	O
lisowska	O
,	O
w.	O
post	O
,	O
d.	O
reidsma	O
,	O
tion	O
system	O
for	O
meetings	O
,	O
”	O
in	O
proc	O
.	O
icassp	O
,	O
taipei	O
,	O
taiwan	O
,	O
2009	O
,	O
pp	O
.	O
and	O
p.	O
wellner	O
,	O
“	O
the	O
ami	O
meeting	O
corpus	B
,	O
”	O
in	O
proc	O
.	O
meas	O
.	O
be-	O
4097–4100	O
.	O
havior	O
,	O
2005	O
.	O
[	O
59	O
]	O
l.	O
lu	O
,	O
h.-j	O
.	O
zhang	O
,	O
and	O
h.	O
jiang	O
,	O
“	O
content	O
analysis	B
for	O
audio	O
classiﬁ-	O
[	O
37	O
]	O
d.	O
mostefa	O
,	O
n.	O
moreau	O
,	O
k.	O
choukri	O
,	O
g.	O
potamianos	O
,	O
s.	O
m.	O
chu	O
,	O
a.	O
cation	O
and	O
segmentation	B
,	O
”	O
ieee	O
trans	O
.	O
speech	O
audio	O
process	B
.	O
,	O
vol	O
.	O
10	O
,	O
tyagi	O
,	O
j.	O
r.	O
casas	O
,	O
j.	O
turmo	O
,	O
l.	O
cristoforetti	O
,	O
f.	O
tobia	O
,	O
a.	O
pnev-	O
no	O
.	O
7	O
,	O
pp	O
.	O
504–516	O
,	O
oct	O
.	O
2002	O
.	O
matikakis	O
,	O
v.	O
mylonakis	O
,	O
f.	O
talantzis	O
,	O
s.	O
burger	O
,	O
r.	O
stiefelhagen	O
,	O
k.	O
[	O
60	O
]	O
r.	O
li	O
,	O
q.	O
jin	O
,	O
and	O
t.	O
schultz	O
,	O
“	O
improving	O
speaker	B
segmentation	I
via	O
bernardin	O
,	O
and	O
c.	O
rochet	O
,	O
“	O
the	O
chil	O
audiovisual	O
corpus	B
for	O
lecture	O
speaker	B
identiﬁcation	O
and	O
text	O
segmentation	B
,	O
”	O
in	O
proc	O
.	O
interspeech	O
,	O
and	O
meeting	O
analysis	B
inside	O
smart	O
rooms	O
,	O
”	O
lang	O
.	O
resources	O
eval	O
.	O
,	O
vol	O
.	O
sep	O
.	O
2009	O
,	O
pp	O
.	O
3073–3076	O
.	O
41	O
,	O
dec	O
.	O
2007	O
.	O
[	O
61	O
]	O
m.	O
ben	O
,	O
m.	O
betser	O
,	O
f.	O
bimbot	O
,	O
and	O
g.	O
gravier	O
,	O
“	O
speaker	B
diarization	I
[	O
38	O
]	O
c.	O
fredouille	O
,	O
d.	O
moraru	O
,	O
s.	O
meignier	O
,	O
l.	O
besacier	O
,	O
and	O
j.-f	O
.	O
bonastre	O
,	O
using	O
bottom	O
-	O
up	O
clustering	B
based	O
on	O
a	O
parameter	O
-	O
derived	O
distance	B
be-	O
“	O
the	O
nist	O
2004	O
spring	O
rich	B
transcription	I
evaluation	B
:	O
two	O
-	O
axis	O
tween	O
adapted	O
gmms	O
,	O
”	O
in	O
proc	O
.	O
icslp	O
,	O
jeju	O
island	O
,	O
korea	O
,	O
2004	O
.	O
merging	O
strategy	O
in	O
the	O
context	O
of	O
multiple	O
distant	O
microphone	O
based	O
[	O
62	O
]	O
d.	O
van	O
leeuwen	O
and	O
m.	O
huijbregts	O
,	O
“	O
the	O
ami	O
speaker	B
diarization	I
meeting	O
speaker	B
segmentation	I
,	O
”	O
in	O
proc	O
.	O
nist	O
2004	O
spring	O
rich	O
system	O
for	O
nist	O
rt06s	O
meeting	O
data	B
,	O
”	O
in	O
machine	O
learning	O
for	O
transcript	O
.	O
eval	O
.	O
workshop	O
,	O
montreal	O
,	O
qc	O
,	O
canada	O
,	O
2004	O
.	O
multimodal	O
interaction	O
.	O
berlin	O
,	O
germany	O
:	O
springer	O
-	O
verlag	O
,	O
2007	O
,	O
[	O
39	O
]	O
q.	O
jin	O
,	O
k.	O
laskowski	O
,	O
t.	O
schultz	O
,	O
and	O
a.	O
waibel	O
,	O
“	O
speaker	B
segmen-	O
vol	O
.	O
4299	O
,	O
lecture	O
notes	O
in	O
computer	B
science	O
,	O
pp	O
.	O
371–384	O
.	O
tation	O
and	O
clustering	B
in	O
meetings	O
,	O
”	O
in	O
proc	O
.	O
icslp	O
,	O
jeju	O
,	O
korea	O
,	O
sep	O
.	O
[	O
63	O
]	O
a.	O
vandecatseye	O
,	O
j.-p	O
.	O
martens	O
,	O
j.	O
neto	O
,	O
h.	O
meinedo	O
,	O
c.	O
garcia	O
-	O
mateo	O
,	O
2004	O
.	O
j.	O
dieguez	O
,	O
f.	O
mihelic	O
,	O
j.	O
zibert	O
,	O
j.	O
nouza	O
,	O
p.	O
david	O
,	O
m.	O
pleva	O
,	O
a.	O
[	O
40	O
]	O
d.	O
istrate	O
,	O
c.	O
fredouille	O
,	O
s.	O
meignier	O
,	O
l.	O
besacier	O
,	O
and	O
j.-f	O
.	O
bonastre	O
,	O
cizmar	O
,	O
h.	O
papageorgiou	O
,	O
and	O
c.	O
alexandris	O
,	O
“	O
the	O
cost278	O
pan	O
-	O
eu-	O
“	O
nist	O
rt05s	O
evaluation	B
:	O
pre	O
-	O
processing	B
techniques	B
and	O
speaker	B
di-	O
ropean	O
broadcast	O
news	O
database	O
,	O
”	O
in	O
proc	O
.	O
lrec	O
,	O
lisbon	O
,	O
portugal	O
,	O
5	O
,	O
arization	O
on	O
multiple	O
microphone	O
meetings	O
,	O
”	O
in	O
proc	O
.	O
nist	O
2005	O
spring	O
2004	O
,	O
vol	O
.	O
4	O
,	O
pp	O
.	O
873–876	O
.	O
rich	O
transcript	O
.	O
eval	O
.	O
workshop	O
,	O
edinburgh	O
,	O
u.k	O
.	O
,	O
jul	O
.	O
2005	O
.	O
[	O
64	O
]	O
k.	O
mori	O
and	O
s.	O
nakagawa	O
,	O
“	O
speaker	B
change	I
detection	B
and	O
speaker	B
clus-	O
[	O
41	O
]	O
x.	O
anguera	O
,	O
c.	O
wooters	O
,	O
b.	O
peskin	O
,	O
and	O
m.	O
aguilo	O
,	O
“	O
robust	B
speaker	I
tering	O
using	O
vq	O
distortion	O
for	O
broadcast	O
news	O
speech	B
recognition	I
,	O
”	O
in	O
segmentation	B
for	O
meetings	O
:	O
the	O
icsi	O
-	O
sri	O
spring	O
2005	O
diarization	B
proc	O
.	O
icassp	O
,	O
2001	O
,	O
pp	O
.	O
413–416	O
.	O
system	O
,	O
”	O
in	O
proc	O
.	O
nist	O
mlmi	O
meeting	O
recognition	O
workshop	O
,	O
edin-	O
[	O
65	O
]	O
j.	O
ajmera	O
and	O
i.	O
mccowan	O
,	O
“	O
robust	B
speaker	I
change	B
detection	I
,	O
”	O
ieee	O
burgh	O
,	O
u.k	O
.	O
,	O
2005	O
.	O
signal	B
process	B
.	O
lett	O
.	O
,	O
vol	O
.	O
11	O
,	O
pp	O
.	O
649–651	O
,	O
2004	O
.	O
[	O
42	O
]	O
x.	O
anguera	O
,	O
c.	O
wooters	O
,	O
and	O
j.	O
hernando	O
,	O
“	O
acoustic	O
beamforming	O
for	O
[	O
66	O
]	O
l.	O
lu	O
and	O
h.-j	O
.	O
zhang	O
,	O
“	O
real	O
-	O
time	B
unsupervised	O
speaker	B
change	I
speaker	B
diarization	I
of	O
meetings	O
,	O
”	O
ieee	O
trans	O
.	O
audio	O
,	O
speech	O
,	O
lang	O
.	O
detection	B
,	O
”	O
in	O
16th	O
int	O
.	O
conf	O
.	O
pattern	O
recognit	O
.	O
,	O
2002	O
,	O
vol	O
.	O
2	O
,	O
pp	O
.	O
process	B
.	O
,	O
vol	O
.	O
15	O
,	O
no	O
.	O
7	O
,	O
pp	O
.	O
2011–2023	O
,	O
sep	O
.	O
2007	O
.	O
358–361	O
.	O
[	O
43	O
]	O
x.	O
anguera	O
,	O
beamformit	O
(	O
the	O
fast	O
and	O
robust	O
acoustic	O
beamformer	O
)	O
[	O
67	O
]	O
x.	O
anguera	O
and	O
j.	O
hernando	O
,	O
“	O
evolutive	O
speaker	B
segmentation	I
using	O
a	O
[	O
online	O
]	O
.	O
available	O
:	O
http://www.xavieranguera.com/beamformit/	O
repository	O
system	O
,	O
”	O
in	O
proc	O
.	O
interspeech	O
,	O
2004	O
.	O
[	O
44	O
]	O
n.	O
wiener	O
,	O
extrapolation	O
,	O
interpolation	O
,	O
and	O
smoothing	O
of	O
stationary	O
[	O
68	O
]	O
x.	O
anguera	O
,	O
c.	O
wooters	O
,	O
and	O
j.	O
hernando	O
,	O
“	O
speaker	B
diarization	I
for	O
time	B
series	O
.	O
new	O
york	O
:	O
wiley	O
,	O
1949	O
.	O
multi	O
-	O
party	O
meetings	O
using	O
acoustic	O
fusion	O
,	O
”	O
in	O
proc	O
.	O
asru	O
,	O
nov	O
.	O
2005	O
,	O
[	O
45	O
]	O
a.	O
adami	O
,	O
l.	O
burget	O
,	O
s.	O
dupont	O
,	O
h.	O
garudadri	O
,	O
f.	O
grezl	O
,	O
h.	O
her-	O
pp	O
.	O
426–431	O
.	O
mansky	O
,	O
p.	O
jain	O
,	O
s.	O
kajarekar	O
,	O
n.	O
morgan	O
,	O
and	O
s.	O
sivadas	O
,	O
“	O
qual-	O
[	O
69	O
]	O
a.	O
malegaonkar	O
,	O
a.	O
ariyaeeinia	O
,	O
p.	O
sivakumaran	O
,	O
and	O
j.	O
fortuna	O
,	O
comm	O
-	O
icsi	O
-	O
ogi	O
features	O
for	O
asr	B
,	O
”	O
in	O
proc	O
.	O
icslp	O
,	O
2002	O
,	O
vol	O
.	O
1	O
,	O
pp	O
.	O
“	O
unsupervised	O
speaker	B
change	I
detection	B
using	O
probabilistic	O
pattern	O
4–7	O
.	O
matching	O
,	O
”	O
ieee	O
signal	B
process	B
.	O
lett	O
.	O
,	O
vol	O
.	O
13	O
,	O
no	O
.	O
8	O
,	O
pp	O
.	O
509–512	O
,	O
[	O
46	O
]	O
m.	O
l.	O
seltzer	O
,	O
b.	O
raj	O
,	O
and	O
r.	O
m.	O
stern	O
,	O
“	O
likelihood	B
maximizing	O
beam-	O
aug	O
.	O
2006	O
.	O
forming	O
for	O
robust	O
hands	O
-	O
free	O
speech	B
recognition	I
,	O
”	O
ieee	O
trans	O
.	O
speech	O
[	O
70	O
]	O
m.-h	O
.	O
siu	O
,	O
g.	O
yu	O
,	O
and	O
h.	O
gish	O
,	O
“	O
segregation	O
of	O
speakers	O
for	O
speech	O
audio	O
process	B
.	O
,	O
vol	O
.	O
12	O
,	O
no	O
.	O
5	O
,	O
pp	O
.	O
489–498	O
,	O
sep	O
.	O
2004	O
.	O
recognition	O
and	O
speaker	B
identiﬁcation	O
,	O
”	O
in	O
proc	O
.	O
icassp’91	O
,	O
1991	O
,	O
pp	O
.	O
[	O
47	O
]	O
l.	O
j.	O
grifﬁths	O
and	O
c.	O
w.	O
jim	O
,	O
“	O
an	O
alternative	O
approach	O
to	O
linearly	O
con-	O
873–876	O
.	O
strained	O
adaptive	O
beamforming	O
,	O
”	O
ieee	O
trans	O
.	O
antennas	O
propagat	O
.	O
,	O
vol	O
.	O
[	O
71	O
]	O
p.	O
delacourt	O
and	O
c.	O
wellekens	O
,	O
“	O
distbic	O
:	O
a	O
speaker	B
-	O
based	O
segmen-	O
ap-30	O
,	O
no	O
.	O
1	O
,	O
pp	O
.	O
27–34	O
,	O
jan	O
.	O
1982	O
.	O
tation	O
for	O
audio	O
data	B
indexing	O
,	O
”	O
speech	O
commun	O
.	O
,	O
pp	O
.	O
111–126	O
,	O
2000	O
.	O
[	O
48	O
]	O
m.	O
woelfel	O
and	O
j.	O
mcdonough	O
,	O
distant	O
speech	B
recognition	I
.	O
new	O
[	O
72	O
]	O
s.	O
s.	O
han	O
and	O
k.	O
j.	O
narayanan	O
,	O
“	O
agglomerative	O
hierarchical	O
speaker	B
york	O
:	O
wiley	O
,	O
2009	O
.	O
clustering	B
using	O
incremental	O
gaussian	O
mixture	O
cluster	O
modeling	O
,	O
”	O
in	O
[	O
49	O
]	O
c.	O
wooters	O
,	O
j.	O
fung	O
,	O
b.	O
peskin	O
,	O
and	O
x.	O
anguera	O
,	O
“	O
towards	O
robust	O
proc	O
.	O
interspeech’08	O
,	O
brisbane	O
,	O
australia	O
,	O
2008	O
,	O
pp	O
.	O
20–23	O
.	O
speaker	B
segmentation	I
:	O
the	O
icsi	O
-	O
sri	O
fall	O
2004	O
diarization	B
system	O
,	O
”	O
[	O
73	O
]	O
r.	O
gangadharaiah	O
,	O
b.	O
narayanaswamy	O
,	O
and	O
n.	O
balakrishnan	O
,	O
“	O
a	O
novel	O
in	O
proc	O
.	O
fall	O
2004	O
rich	O
transcript	O
.	O
workshop	O
(	O
rt04	O
)	O
,	O
palisades	O
,	O
ny	O
,	O
method	B
for	O
two	O
speaker	B
segmentation	I
,	O
”	O
in	O
proc	O
.	O
icslp	O
,	O
jeju	O
,	O
korea	O
,	O
nov	O
.	O
2004	O
.	O
sep	O
.	O
2004	O
.	O
authorized	O
licensed	O
use	O
limited	O
to	O
:	O
inria	O
.	O
downloaded	O
on	O
october	O
05,2020	O
at	O
07:30:52	O
utc	O
from	O
ieee	O
xplore	O
.	O
 	O
restrictions	O
apply	O
.	O
anguera	O
miro	O
et	O
al	O
.	O
:	O
speaker	B
diarization	I
:	O
a	O
review	O
of	O
recent	O
research	B
369	O
[	O
74	O
]	O
d.	O
liu	O
and	O
f.	O
kubala	O
,	O
“	O
fast	O
speaker	B
change	I
detection	B
for	O
broadcast	O
[	O
101	O
]	O
k.	O
boakye	O
,	O
“	O
audio	O
segmentation	B
for	O
meetings	O
speech	O
processing	B
,	O
”	O
news	O
transcription	B
and	O
indexing	O
,	O
”	O
in	O
proc	O
.	O
eurospeech’99	O
,	O
sep	O
.	O
1999	O
,	O
ph.d	O
.	O
dissertation	O
,	O
univ	O
.	O
of	O
california	O
,	O
berkeley	O
,	O
2008	O
.	O
pp	O
.	O
1031–1034	O
.	O
[	O
102	O
]	O
s.	O
otterson	O
and	O
m.	O
ostendorf	O
,	O
“	O
efﬁcient	O
use	O
of	O
overlap	O
information	B
in	O
[	O
75	O
]	O
m.	O
a.	O
siegler	O
,	O
u.	O
jain	O
,	O
b.	O
raj	O
,	O
and	O
r.	O
m.	O
stern	O
,	O
“	O
automatic	O
segmen-	O
speaker	B
diarization	I
,	O
”	O
in	O
proc	O
.	O
asru	O
,	O
kyoto	O
,	O
japan	O
,	O
2007	O
,	O
pp	O
.	O
686–6	O
.	O
tation	O
,	O
classiﬁcation	O
and	O
clustering	B
of	O
broadcast	O
news	O
audio	O
,	O
”	O
in	O
proc	O
.	O
[	O
103	O
]	O
b.	O
e.	O
d.	O
kingsbury	O
,	O
n.	O
morgan	O
,	O
and	O
s.	O
greenberg	O
,	O
“	O
robust	O
speech	O
darpa	O
speech	O
recognit	O
.	O
workshop	O
,	O
1997	O
,	O
pp	O
.	O
97–99	O
.	O
recognition	O
using	O
the	O
modulation	O
spectrogram	O
,	O
”	O
speech	O
commun	O
.	O
,	O
vol	O
.	O
[	O
76	O
]	O
p.	O
zochová	O
and	O
v.	O
radová	O
,	O
“	O
modiﬁed	O
distbic	O
algorithm	O
for	O
speaker	B
25	O
,	O
no	O
.	O
1	O
-	O
3	O
,	O
pp	O
.	O
117–132	O
,	O
1998	O
.	O
change	B
detection	I
,	O
”	O
in	O
proc	O
.	O
9th	O
eur	O
.	O
conf	O
.	O
speech	O
commun	O
.	O
technol	O
.	O
,	O
[	O
104	O
]	O
h.	O
j.	O
nock	O
,	O
g.	O
iyengar	O
,	O
and	O
c.	O
neti	O
,	O
“	O
speaker	B
localization	O
using	O
audio-	O
bonn	O
,	O
germany	O
,	O
2005	O
,	O
pp	O
.	O
3073–3076	O
.	O
visual	O
synchrony	O
:	O
an	O
empirical	O
study	O
,	O
”	O
lecture	O
notes	O
in	O
comput	O
.	O
sci	O
.	O
,	O
[	O
77	O
]	O
x.	O
zhu	O
,	O
c.	O
barras	O
,	O
l.	O
lamel	O
,	O
and	O
j.-l	O
.	O
gauvain	O
,	O
“	O
speaker	B
diarization	I
:	O
vol	O
.	O
2728	O
,	O
pp	O
.	O
565–570	O
,	O
2003	O
.	O
from	O
broadcast	O
news	O
to	O
lectures	O
,	O
”	O
in	O
proc	O
.	O
mlmi	O
,	O
2006	O
,	O
pp	O
.	O
396–406	O
.	O
[	O
105	O
]	O
c.	O
zhang	O
,	O
p.	O
yin	O
,	O
y.	O
rui	O
,	O
r.	O
cutler	O
,	O
and	O
p.	O
viola	O
,	O
“	O
boosting	O
-	O
based	O
[	O
78	O
]	O
k.	O
han	O
and	O
s.	O
narayanan	O
,	O
“	O
novel	O
inter	O
-	O
cluster	O
distance	B
measure	O
com-	O
multimodal	O
speaker	B
detection	B
for	O
distributed	O
meetings	O
,	O
”	O
in	O
proc	O
.	O
ieee	O
bining	O
glr	O
and	O
icr	O
for	O
improved	O
agglomerative	O
hierarchical	O
speaker	B
int	O
.	O
workshop	O
multimedia	O
signal	B
process	B
.	O
(	O
mmsp	O
)	O
,	O
2006	O
,	O
pp	O
.	O
86–91	O
.	O
clustering	B
,	O
”	O
in	O
proc	O
.	O
icassp	O
,	O
apr	O
.	O
2008	O
,	O
pp	O
.	O
4373–4376	O
.	O
[	O
106	O
]	O
a.	O
noulas	O
and	O
b.	O
j.	O
a.	O
krose	O
,	O
“	O
on	O
-	O
line	O
multi	O
-	O
modal	O
speaker	B
diariza-	O
[	O
79	O
]	O
d.	O
moraru	O
,	O
m.	O
ben	O
,	O
and	O
g.	O
gravier	O
,	O
“	O
experiments	O
on	O
speaker	B
tracking	O
tion	O
,	O
”	O
in	O
proc	O
.	O
9th	O
int	O
.	O
conf	O
.	O
multimodal	O
interfaces	O
icmi	O
’	O
07	O
,	O
new	O
and	O
segmentation	B
in	O
radio	O
broadcast	O
news	O
,	O
”	O
in	O
proc	O
.	O
icslp	O
,	O
2005	O
.	O
york	O
,	O
2007	O
,	O
pp	O
.	O
350–357	O
.	O
[	O
80	O
]	O
c.	O
barras	O
,	O
x.	O
zhu	O
,	O
s.	O
meignier	O
,	O
and	O
j.-l	O
.	O
gauvain	O
,	O
“	O
improving	O
speaker	B
[	O
107	O
]	O
z.	O
ghahramani	O
and	O
m.	O
i.	O
jordan	O
,	O
“	O
factorial	O
hidden	O
markov	O
models	B
,	O
”	O
diarization	B
,	O
”	O
in	O
proc	O
.	O
darpa	O
rt04	O
,	O
2004	O
.	O
mach	O
.	O
learn	O
.	O
,	O
vol	O
.	O
29	O
,	O
pp	O
.	O
245–273	O
,	O
nov	O
.	O
1997	O
.	O
[	O
81	O
]	O
h.	O
aronowitz	O
,	O
“	O
trainable	O
speaker	B
diarization	I
,	O
”	O
in	O
proc	O
.	O
interspeech	O
,	O
[	O
108	O
]	O
a.	O
k.	O
noulas	O
,	O
g.	O
englebienne	O
,	O
and	O
b.	O
j.	O
a.	O
krose	O
,	O
“	O
mutimodal	O
speaker	B
aug	O
.	O
2007	O
,	O
pp	O
.	O
1861–1864	O
.	O
diarization	B
,	O
”	O
ieee	O
trans	O
.	O
pattern	O
anal	O
.	O
mach	O
.	O
intell	O
.	O
,	O
2011	O
,	O
preprint	O
,	O
to	O
[	O
82	O
]	O
h.	O
hung	O
and	O
g.	O
friedland	O
,	O
“	O
towards	O
audio	O
-	O
visual	O
on	O
-	O
line	O
diarization	B
of	O
be	O
published	O
.	O
participants	B
in	O
group	O
meetings	O
,	O
”	O
in	O
proc	O
.	O
workshop	O
multi	O
-	O
camera	O
and	O
[	O
109	O
]	O
s.	O
tamura	O
,	O
k.	O
iwano	O
,	O
and	O
s.	O
furui	O
,	O
“	O
multi	O
-	O
modal	O
speech	O
recogni-	O
multi	O
-	O
modal	O
sensor	O
fusion	O
algorithms	O
applicat	O
.	O
–	O
m2sfa2	O
,	O
marseille	O
,	O
tion	O
using	O
optical-ﬂow	O
analysis	B
for	O
lip	O
images	O
,	O
”	O
real	O
world	O
speech	O
france	O
,	O
2008	O
.	O
process	B
.	O
,	O
vol	O
.	O
36	O
,	O
no	O
.	O
2–3	O
,	O
pp	O
.	O
117–124	O
,	O
2004	O
.	O
[	O
83	O
]	O
g.	O
friedland	O
and	O
o.	O
vinyals	O
,	O
“	O
live	O
speaker	B
identiﬁcation	O
in	O
conversa-	O
[	O
110	O
]	O
t.	O
chen	O
and	O
r.	O
rao	O
,	O
“	O
cross	O
-	O
modal	O
prediction	O
in	O
audio	O
-	O
visual	O
commu-	O
tions	O
,	O
”	O
in	O
proc	O
.	O
mm’08	O
:	O
proc	O
.	O
16th	O
acm	O
int	O
.	O
conf	O
.	O
multimedia	O
,	O
new	O
nication	O
,	O
”	O
in	O
proc	O
.	O
icassp	O
,	O
1996	O
,	O
vol	O
.	O
4	O
,	O
pp	O
.	O
2056–2059	O
.	O
york	O
,	O
2008	O
,	O
pp	O
.	O
1017–1018	O
.	O
[	O
111	O
]	O
j.	O
w.	O
fisher	O
,	O
t.	O
darrell	O
,	O
w.	O
t.	O
freeman	O
,	O
and	O
p.	O
a.	O
viola	O
,	O
“	O
learning	O
joint	O
[	O
84	O
]	O
g.	O
friedland	O
,	O
o.	O
vinyals	O
,	O
y.	O
huang	O
,	O
and	O
c.	O
muller	O
,	O
“	O
prosodic	O
and	O
other	O
statistical	O
models	B
for	O
audio	O
-	O
visual	O
fusion	O
and	O
segregation	O
,	O
”	O
in	O
proc	O
.	O
long	O
-	O
term	O
features	O
for	O
speaker	B
diarization	I
,	O
”	O
ieee	O
trans	O
.	O
audio	O
,	O
speech	O
,	O
nips	O
,	O
2000	O
,	O
pp	O
.	O
772–778	O
.	O
lang	O
.	O
process	B
.	O
,	O
vol	O
.	O
17	O
,	O
no	O
.	O
5	O
,	O
pp	O
.	O
985–993	O
,	O
jul	O
.	O
2009	O
.	O
[	O
112	O
]	O
j.	O
w.	O
fisher	O
and	O
t.	O
darrell	O
,	O
“	O
speaker	B
association	O
with	O
signal	B
-	O
level	B
au-	O
[	O
85	O
]	O
j.	O
luque	O
,	O
x.	O
anguera	O
,	O
a.	O
temko	O
,	O
and	O
j.	O
hernando	O
,	O
“	O
speaker	B
diariza-	O
diovisual	O
fusion	O
,	O
”	O
ieee	O
trans	O
.	O
multimedia	O
,	O
vol	O
.	O
6	O
,	O
no	O
.	O
3	O
,	O
pp	O
.	O
406–413	O
,	O
tion	O
for	O
conference	O
room	O
:	O
the	O
upc	O
rt07s	O
evaluation	B
system	O
,	O
”	O
in	O
jun	O
.	O
2004	O
.	O
proc	O
.	O
multimodal	O
technol	O
.	O
perception	O
of	O
humans	O
:	O
int	O
.	O
eval	O
.	O
work-	O
[	O
113	O
]	O
r.	O
rao	O
and	O
t.	O
chen	O
,	O
“	O
exploiting	O
audio	O
-	O
visual	O
correlation	O
in	O
coding	O
of	O
shops	O
clear	O
2007	O
and	O
rt	O
2007	O
,	O
baltimore	O
,	O
md	O
,	O
may	O
8–11	O
,	O
2007	O
,	O
talking	O
head	O
sequences	O
,	O
”	O
in	O
proc	O
.	O
int	O
.	O
picture	O
coding	O
symp	O
.	O
,	O
mar	O
.	O
1996	O
.	O
revised	O
selected	O
papers	O
,	O
berlin	O
,	O
heidelberg	O
:	O
springer	O
-	O
verlag	O
,	O
2008	O
,	O
[	O
114	O
]	O
m.	O
siracusa	O
and	O
j.	O
fisher	O
,	O
“	O
dynamic	O
dependency	O
tests	O
for	O
audio	O
-	O
visual	O
pp	O
.	O
543–553	O
.	O
speaker	B
association	O
,	O
”	O
in	O
proc	O
.	O
icassp	O
,	O
apr	O
.	O
2007	O
,	O
pp	O
.	O
457–460	O
.	O
[	O
86	O
]	O
j.	O
pardo	O
,	O
x.	O
anguera	O
,	O
and	O
c.	O
wooters	O
,	O
“	O
speaker	B
diarization	I
for	O
mul-	O
[	O
115	O
]	O
e.	O
k.	O
patterson	O
,	O
s.	O
gurbuz	O
,	O
z.	O
tufekci	O
,	O
and	O
j.	O
n.	O
gowdy	O
,	O
“	O
cuave	O
:	O
a	O
tiple	O
distant	O
microphone	O
meetings	O
:	O
mixing	O
acoustic	B
features	I
and	O
inter-	O
new	O
audio	O
-	O
visual	O
database	O
for	O
multimodal	O
human	O
–	O
computer	B
interface	O
channel	O
time	B
differences	O
,	O
”	O
in	O
proc	O
.	O
interspeech	O
,	O
2006	O
.	O
research	B
,	O
”	O
in	O
proc	O
.	O
icassp	O
,	O
2002	O
,	O
pp	O
.	O
2017–2020	O
.	O
[	O
87	O
]	O
g.	O
lathoud	O
and	O
i.	O
m.	O
cowan	O
,	O
“	O
location	O
based	B
speaker	I
segmentation	B
,	O
”	O
[	O
116	O
]	O
d.	O
mcneill	O
,	O
language	O
and	O
gesture	O
.	O
new	O
york	O
:	O
cambridge	O
univ	O
.	O
in	O
proc	O
.	O
icassp	O
,	O
2003	O
,	O
vol	O
.	O
1	O
,	O
pp	O
.	O
176–179	O
.	O
press	O
,	O
2000	O
.	O
[	O
88	O
]	O
d.	O
ellis	O
and	O
j.	O
c.	O
liu	O
,	O
“	O
speaker	B
turn	O
detection	B
based	O
on	O
between	O
-	O
chan-	O
[	O
117	O
]	O
h.	O
vajaria	O
,	O
t.	O
islam	O
,	O
s.	O
sarkar	O
,	O
r.	O
sankar	O
,	O
and	O
r.	O
kasturi	O
,	O
“	O
audio	O
nels	O
differences	O
,	O
”	O
in	O
proc	O
.	O
icassp	O
,	O
2004	O
.	O
segmentation	B
and	O
speaker	B
localization	O
in	O
meeting	O
videos	B
,	O
”	O
in	O
proc	O
.	O
[	O
89	O
]	O
j.	O
ajmera	O
,	O
g.	O
lathoud	O
,	O
and	O
l.	O
mccowan	O
,	O
“	O
clustering	B
and	O
segmenting	O
18th	O
int	O
.	O
conf	O
.	O
pattern	O
recognit	O
.	O
(	O
icpr’06	O
)	O
,	O
2006	O
,	O
vol	O
.	O
2	O
,	O
pp	O
.	O
speakers	O
and	O
their	O
locations	O
in	O
meetings	O
,	O
”	O
in	O
proc	O
.	O
icassp	O
,	O
2004	O
,	O
vol	O
.	O
1150–1153	O
.	O
1	O
,	O
pp	O
.	O
605–608	O
.	O
[	O
118	O
]	O
h.	O
hung	O
,	O
y.	O
huang	O
,	O
c.	O
yeo	O
,	O
and	O
d.	O
gatica	O
-	O
perez	O
,	O
“	O
associating	O
audio-	O
[	O
90	O
]	O
j.	O
m.	O
pardo	O
,	O
x.	O
anguera	O
,	O
and	O
c.	O
wooters	O
,	O
“	O
speaker	B
diarization	I
for	O
visual	O
activity	O
cues	O
in	O
a	O
dominance	O
estimation	B
framework	O
,	O
”	O
in	O
proc	O
.	O
multiple	O
distant	O
microphone	O
meetings	O
:	O
mixing	O
acoustic	B
features	I
and	O
ieee	O
comput	O
.	O
soc	O
.	O
conf	O
.	O
comput	O
.	O
vis	O
.	O
pattern	O
recognition	O
(	O
cvpr	O
)	O
inter	O
-	O
channel	O
time	B
differences	O
,	O
”	O
in	O
proc	O
.	O
interspeech	O
,	O
2006	O
.	O
workshop	O
human	O
communicative	O
behavior	O
,	O
anchorage	O
,	O
ak	O
,	O
2008	O
,	O
[	O
91	O
]	O
j.	O
pardo	O
,	O
x.	O
anguera	O
,	O
and	O
c.	O
wooters	O
,	O
“	O
speaker	B
diarization	I
for	O
mul-	O
pp	O
.	O
1–6	O
.	O
tiple	O
-	O
distant	O
-	O
microphone	O
meetings	O
using	O
several	O
sources	O
of	O
informa-	O
[	O
119	O
]	O
n.	O
campbell	O
and	O
n.	O
suzuki	O
,	O
“	O
working	O
with	O
very	O
sparse	O
data	B
to	O
detect	O
tion	O
,	O
”	O
ieee	O
trans	O
.	O
comput	O
.	O
,	O
vol	O
.	O
56	O
,	O
no	O
.	O
9	O
,	O
pp	O
.	O
1212–1224	O
,	O
sep	O
.	O
2007	O
.	O
speaker	B
and	O
listener	O
participation	O
in	O
a	O
meetings	O
corpus	B
,	O
”	O
in	O
proc	O
.	O
work-	O
[	O
92	O
]	O
n.	O
w.	O
d.	O
evans	O
,	O
c.	O
fredouille	O
,	O
and	O
j.-f	O
.	O
bonastre	O
,	O
“	O
speaker	B
diariza-	O
shop	O
programme	O
,	O
may	O
2006	O
,	O
vol	O
.	O
10	O
.	O
tion	O
using	O
unsupervised	O
discriminant	B
analysis	I
of	O
inter	O
-	O
channel	O
delay	O
[	O
120	O
]	O
g.	O
friedland	O
,	O
h.	O
hung	O
,	O
and	O
c.	O
yeo	O
,	O
“	O
multimodal	O
speaker	B
diarization	I
features	O
,	O
”	O
in	O
proc	O
.	O
icassp	O
,	O
apr	O
.	O
2009	O
,	O
pp	O
.	O
4061–4064	O
.	O
of	O
real	O
-	O
world	O
meetings	O
using	O
compressed	O
-	O
domain	B
video	O
features	O
,	O
”	O
in	O
[	O
93	O
]	O
m.	O
wölfel	O
,	O
q.	O
yang	O
,	O
q.	O
jin	O
,	O
and	O
t.	O
schultz	O
,	O
“	O
speaker	B
identiﬁcation	O
proc	O
.	O
icassp	O
,	O
apr	O
.	O
2009	O
,	O
pp	O
.	O
4069–4072	O
.	O
using	O
warped	O
mvdr	O
cepstral	O
features	O
,	O
”	O
in	O
proc	O
.	O
interspeech	O
,	O
2009	O
.	O
[	O
121	O
]	O
g.	O
friedland	O
,	O
c.	O
yeo	O
,	O
and	O
h.	O
hung	O
,	O
“	O
visual	O
speaker	B
localization	O
aided	O
[	O
94	O
]	O
e.	O
shriberg	O
,	O
“	O
higher	O
-	O
level	B
features	O
in	O
speaker	B
recognition	O
,	O
”	O
in	O
speaker	B
by	O
acoustic	O
models	B
,	O
”	O
in	O
proc	O
.	O
17th	O
acm	O
int	O
.	O
conf	O
.	O
multimedia	O
mm’09	O
:	O
classiﬁcation	O
i	O
,	O
c.	O
müller	O
,	O
ed	O
.	O
berlin	O
,	O
heidelberg	O
,	O
germany	O
:	O
,	O
new	O
york	O
,	O
2009	O
,	O
pp	O
.	O
195–202	O
.	O
springer	O
,	O
2007	O
,	O
vol	O
.	O
4343	O
,	O
lecture	O
notes	O
in	O
artiﬁcial	O
intelligence	O
.	O
[	O
122	O
]	O
s.	O
meignier	O
,	O
d.	O
moraru	O
,	O
c.	O
fredouille	O
,	O
j.-f	O
.	O
bonastre	O
,	O
and	O
l.	O
besacier	O
,	O
[	O
95	O
]	O
d.	O
imseng	O
and	O
g.	O
friedland	O
,	O
“	O
tuning	O
-	O
robust	O
initialization	O
methods	O
for	O
“	O
step	O
-	O
by	O
-	O
step	O
and	O
integrated	O
approaches	O
in	O
broadcast	O
news	O
speaker	B
di-	O
speaker	B
diarization	I
,	O
”	O
ieee	O
trans	O
.	O
audio	O
,	O
speech	O
,	O
lang	O
.	O
process	B
.	O
,	O
vol	O
.	O
arization	O
,	O
”	O
in	O
proc	O
.	O
csl	O
,	O
sel	O
.	O
papers	O
from	O
speaker	B
lang	O
.	O
recognit	O
.	O
18	O
,	O
no	O
.	O
8	O
,	O
pp	O
.	O
2028–2037	O
,	O
nov	O
.	O
2010	O
.	O
workshop	O
(	O
odyssey’04	O
)	O
,	O
2006	O
,	O
pp	O
.	O
303–330	O
.	O
[	O
96	O
]	O
d.	O
imseng	O
and	O
g.	O
friedland	O
,	O
“	O
robust	B
speaker	I
diarization	B
for	O
short	O
[	O
123	O
]	O
d.	O
vijayasenan	O
,	O
f.	O
valente	O
,	O
and	O
h.	O
bourlard	O
,	O
“	O
combination	O
of	O
ag-	O
speech	O
recordings	O
,	O
”	O
in	O
proc	O
.	O
ieee	O
workshop	O
autom	O
.	O
speech	O
recognit	O
.	O
glomerative	O
and	O
sequential	O
clustering	B
for	O
speaker	B
diarization	I
,	O
”	O
in	O
proc	O
.	O
understand	O
.	O
,	O
dec	O
.	O
2009	O
,	O
pp	O
.	O
432–437	O
.	O
icassp	O
,	O
las	O
vegas	O
,	O
nv	O
,	O
2008	O
,	O
pp	O
.	O
4361–4364	O
.	O
[	O
97	O
]	O
e.	O
shriberg	O
,	O
a.	O
stolcke	O
,	O
and	O
d.	O
baron	O
,	O
“	O
observations	O
on	O
overlap	O
:	O
[	O
124	O
]	O
e.	O
el	O
-	O
khoury	O
,	O
c.	O
senac	O
,	O
and	O
s.	O
meignier	O
,	O
“	O
speaker	B
diarization	I
:	O
com-	O
findings	O
and	O
implications	O
for	O
automatic	O
processing	B
of	O
multi	O
-	O
party	O
bination	O
of	O
the	O
lium	O
and	O
irit	O
systems	O
,	O
”	O
in	O
internal	O
report	O
,	O
2008	O
.	O
conversations	O
,	O
”	O
in	O
proc	O
.	O
eurospeech’01	O
,	O
aalborg	O
,	O
denmark	O
,	O
2001	O
,	O
pp	O
.	O
[	O
125	O
]	O
v.	O
gupta	O
,	O
p.	O
kenny	O
,	O
p.	O
ouellet	O
,	O
g.	O
boulianne	O
,	O
and	O
p.	O
dumouchel	O
,	O
1359–1362	O
.	O
“	O
combining	O
gaussianized	O
/	O
non	O
-	O
gaussianized	O
features	O
to	O
improve	O
[	O
98	O
]	O
o.	O
çetin	O
and	O
e.	O
shriberg	O
,	O
“	O
speaker	B
overlaps	B
and	O
asr	B
errors	B
in	O
meet-	O
speaker	B
diarization	I
of	O
telephone	O
conversations	O
,	O
”	O
in	O
ieee	O
signal	B
ings	O
:	O
effects	O
before	O
,	O
during	O
,	O
and	O
after	O
the	O
overlap	O
,	O
”	O
in	O
proc	O
.	O
icassp	O
,	O
process	B
.	O
lett	O
.	O
,	O
dec	O
.	O
2007	O
,	O
vol	O
.	O
14	O
,	O
no	O
.	O
12	O
,	O
pp	O
.	O
1040–1043	O
.	O
toulouse	O
,	O
france	O
,	O
2006	O
,	O
pp	O
.	O
357–360	O
.	O
[	O
126	O
]	O
t.	O
s.	O
ferguson	O
,	O
“	O
a	O
bayesian	O
analysis	B
of	O
some	O
nonparametric	O
prob-	O
[	O
99	O
]	O
k.	O
boakye	O
,	O
b.	O
trueba	O
-	O
hornero	O
,	O
o.	O
vinyals	O
,	O
and	O
g.	O
friedland	O
,	O
“	O
over-	O
lems	O
,	O
”	O
ann	O
.	O
statist	O
.	O
,	O
vol	O
.	O
1	O
,	O
no	O
.	O
2	O
,	O
pp	O
.	O
209–230	O
,	O
1973	O
.	O
lapped	O
speech	B
detection	I
for	O
improved	O
speaker	B
diarization	I
in	O
multiparty	O
[	O
127	O
]	O
f.	O
valente	O
,	O
“	O
inﬁnite	O
models	B
for	O
speaker	B
clustering	B
,	O
”	O
in	O
proc	O
.	O
int	O
.	O
conf	O
.	O
meetings	O
,	O
”	O
in	O
proc	O
.	O
icassp	O
,	O
2008	O
,	O
pp	O
.	O
4353–4356	O
.	O
spoken	O
lang	O
.	O
process	B
.	O
,	O
2006	O
,	O
idiap	O
-	O
rr	O
06–19	O
.	O
[	O
100	O
]	O
b.	O
trueba	O
-	O
hornero	O
,	O
“	O
handling	O
overlapped	B
speech	I
in	O
speaker	B
diariza-	O
[	O
128	O
]	O
y.	O
w.	O
teh	O
,	O
m.	O
i.	O
jordan	O
,	O
m.	O
j.	O
beal	O
,	O
and	O
d.	O
m.	O
blei	O
,	O
“	O
hierarchical	O
tion	O
,	O
”	O
m.s	O
.	O
thesis	O
,	O
univ	O
.	O
politecnica	O
de	O
catalunya	O
,	O
barcelona	O
,	O
spain	O
,	O
dirichlet	O
processes	O
,	O
”	O
j.	O
amer	O
.	O
statist	O
.	O
assoc	O
.	O
,	O
vol	O
.	O
101	O
,	O
no	O
.	O
476	O
,	O
pp	O
.	O
2008	O
.	O
1566–1581	O
,	O
2006	O
.	O
authorized	O
licensed	O
use	O
limited	O
to	O
:	O
inria	O
.	O
downloaded	O
on	O
october	O
05,2020	O
at	O
07:30:52	O
utc	O
from	O
ieee	O
xplore	O
.	O
 	O
restrictions	O
apply	O
.	O
370	O
ieee	O
transactions	O
on	O
audio	O
,	O
speech	O
,	O
and	O
language	B
processing	I
,	O
vol	O
.	O
20	O
,	O
no	O
.	O
2	O
,	O
february	O
2012	O
[	O
129	O
]	O
e.	O
b.	O
fox	O
,	O
e.	O
b.	O
sudderth	O
,	O
m.	O
i.	O
jordan	O
,	O
and	O
a.	O
s.	O
willsky	O
,	O
“	O
an	O
biometrics	O
,	O
speech	O
enhancement	O
,	O
and	O
acoustic	O
echo	O
cancellation	O
.	O
his	O
team	O
led	O
hdp	O
-	O
hmm	O
for	O
systems	O
with	O
state	O
persistence	O
,	O
”	O
in	O
proc	O
.	O
icml	O
,	O
jul	O
.	O
lia	O
-	O
eurecom	O
’s	O
joint	O
entry	O
to	O
the	O
nist	O
rich	B
transcription	I
evaluations	O
in	O
2008	O
.	O
2009	O
.	O
he	O
has	O
authored	O
or	O
coauthored	O
in	O
excess	O
of	O
50	O
peer	O
-	O
reviewed	O
research	B
[	O
130	O
]	O
m.	O
huijbregts	O
and	O
c.	O
wooters	O
,	O
“	O
the	O
blame	O
game	O
:	O
performance	O
analysis	B
articles	O
and	O
participates	O
in	O
several	O
national	O
and	O
european	O
projects	O
,	O
all	O
involving	O
of	O
speaker	B
diarization	I
system	I
components	B
,	O
”	O
in	O
proc	O
.	O
interspeech	O
,	O
aug	O
.	O
speech	O
processing	B
.	O
2007	O
,	O
pp	O
.	O
1857–60	O
.	O
dr	O
.	O
evans	O
is	O
a	O
member	O
of	O
the	O
ieee	O
signal	B
processing	I
society	O
,	O
isca	O
,	O
and	O
eurasip	O
and	O
he	O
serves	O
as	O
an	O
associate	O
editor	O
of	O
the	O
eurasip	O
journal	O
on	O
xavier	O
anguera	O
miro	O
(	O
m’06	O
)	O
received	O
the	O
telecom-	O
audio	O
,	O
speech	O
,	O
and	O
music	O
processing	B
.	O
munications	O
engineering	O
and	O
european	O
masters	O
in	O
language	O
and	O
speech	O
(	O
m.s	O
.	O
)	O
degrees	O
from	O
the	O
uni-	O
versitat	O
politècnica	O
de	O
catalunya	O
(	O
upc	O
)	O
,	O
barcelona	O
,	O
spain	O
,	O
in	O
2001	O
and	O
the	O
ph.d	O
.	O
degree	O
from	O
upc	O
,	O
with	O
a	O
corinne	O
fredouille	O
received	O
the	O
ph.d	O
.	O
degree	O
from	O
thesis	O
on	O
“	O
robust	B
speaker	I
diarization	B
for	O
meetings	O
.	O
”	O
the	O
laboratoire	O
informatique	O
d’avignon	O
(	O
lia	O
)	O
,	O
uni-	O
from	O
2001	O
to	O
2003	O
,	O
he	O
was	O
with	O
panasonic	O
speech	O
versity	O
of	O
avignon	O
,	O
avignon	O
,	O
france	O
,	O
in	O
2000	O
technology	O
lab	O
,	O
santa	O
barbara	O
,	O
ca	O
.	O
from	O
2004	O
to	O
she	O
was	O
appointed	O
as	O
an	O
assistant	O
professor	O
at	O
2006	O
,	O
he	O
was	O
a	O
visiting	O
researcher	O
at	O
the	O
interna-	O
lia	O
in	O
2003	O
.	O
her	O
research	B
interests	O
include	O
acoustic	O
tional	O
computer	B
science	O
institute	O
(	O
icsi	O
)	O
,	O
berkeley	O
,	O
analysis	B
,	O
voice	O
quality	B
assessment	O
,	O
statistical	O
ca	O
,	O
where	O
he	O
pursued	O
research	B
on	O
speaker	B
diariza-	O
modeling	O
,	O
automatic	O
speaker	B
recognition	O
,	O
speaker	B
tion	O
for	O
meetings	O
,	O
contributing	O
to	O
icsi	O
’s	O
participation	O
in	O
the	O
nist	O
rt	O
evalua-	O
diarization	B
and	O
,	O
more	O
recently	O
,	O
speech	O
and	O
voice	O
tions	O
in	O
2004	O
(	O
broadcast	O
news	O
)	O
and	O
2005–2007	O
(	O
meetings	O
)	O
,	O
obtaining	O
state	O
-	O
of-	O
disorder	O
assessment	O
and	O
acoustic	O
-	O
based	O
characteri-	O
the	O
-	O
art	O
results	B
.	O
he	O
brieﬂy	O
joined	O
limsi	O
,	O
paris	O
,	O
france	O
,	O
in	O
2006	O
.	O
he	O
has	O
been	O
zation	O
.	O
she	O
has	O
participated	O
in	O
several	O
national	O
and	O
with	O
telefonica	O
research	B
,	O
barcelona	O
,	O
spain	O
,	O
since	O
2007	O
,	O
pursuing	O
research	B
in	O
international	O
speaker	B
diarization	I
system	I
evaluation	B
multimedia	O
.	O
his	O
current	O
research	B
interests	O
include	O
speaker	B
characterization	O
(	O
in-	O
campaigns	O
and	O
has	O
published	O
over	O
15	O
research	B
papers	O
in	O
this	O
ﬁeld	O
.	O
cluding	O
diarization	B
,	O
recognition	O
,	O
etc	O
.	O
)	O
,	O
language	O
identiﬁcation	O
(	O
including	O
a	O
par-	O
prof	O
.	O
fredouille	O
is	O
a	O
member	O
of	O
the	O
international	O
speech	B
communication	I
as-	O
ticipation	O
in	O
nist	O
lre’07	O
evaluation	B
)	O
and	O
several	O
topics	O
in	O
multimodal	O
multi-	O
sociation	O
(	O
isca	O
)	O
and	O
secretary	O
of	O
the	O
french	O
speaking	O
communication	B
associ-	O
media	O
analysis	B
(	O
e.g.	O
,	O
video	O
copy	O
detection	B
,	O
involving	O
the	O
participation	O
in	O
nist	O
ation	O
(	O
afcp	O
)	O
,	O
special	O
interest	O
group	O
(	O
sig	O
)	O
of	O
isca	O
.	O
trecvid	O
2009	O
and	O
2010	O
evaluations	O
)	O
.	O
he	O
has	O
authored	O
or	O
coauthored	O
over	O
50	O
peer	O
-	O
reviewed	O
research	B
articles	O
.	O
he	O
is	O
the	O
main	O
developer	O
of	O
the	O
beamformit	O
toolkit	O
,	O
extensively	O
used	O
by	O
the	O
rt	O
community	O
for	O
processing	B
multiple	O
micro-	O
phone	O
recordings	O
.	O
gerald	O
friedland	O
(	O
m’08	O
)	O
received	O
the	O
diplom	O
and	O
dr	O
.	O
anguera	O
miro	O
is	O
a	O
member	O
of	O
isca	O
,	O
acm	O
,	O
and	O
ieee	O
signal	B
processing	I
doctorate	O
(	O
summa	O
cum	O
laude	O
)	O
degrees	O
in	O
computer	B
society	O
and	O
has	O
been	O
involved	O
in	O
the	O
organization	O
of	O
several	O
acm	O
and	O
ieee	O
science	O
from	O
freie	O
universität	O
berlin	O
,	O
berlin	O
,	O
ger-	O
conferences	O
.	O
he	O
has	O
been	O
a	O
reviewer	O
for	O
many	O
conferences	O
,	O
as	O
well	O
as	O
for	O
several	O
many	O
,	O
in	O
2002	O
and	O
2006	O
,	O
respectively	O
.	O
journals	O
in	O
the	O
multimedia	O
domain	B
.	O
he	O
is	O
a	O
senior	O
research	B
scientist	O
at	O
the	O
interna-	O
tional	O
computer	B
science	O
institute	O
(	O
icsi	O
)	O
,	O
berkeley	O
,	O
ca	O
,	O
an	O
independent	O
nonproﬁt	O
research	B
lab	O
associated	O
with	O
the	O
university	O
of	O
california	O
(	O
uc	O
)	O
at	O
berkeley	O
simon	O
bozonnet	O
(	O
s’08	O
)	O
received	O
the	O
diploma	O
in	O
where	O
he	O
,	O
among	O
other	O
functions	O
,	O
is	O
currently	O
leading	O
electrical	O
engineering	O
from	O
insa	O
de	O
lyon	O
,	O
france	O
,	O
the	O
speaker	B
diarization	I
research	B
.	O
apart	O
from	O
speech	O
,	O
in	O
2008	O
with	O
specialization	O
in	O
signal	B
processing	I
his	O
interests	O
also	O
include	O
image	O
and	O
video	O
processing	B
and	O
the	O
master	O
of	O
research	B
in	O
images	O
and	O
systems	O
and	O
multimodal	O
machine	O
learning	O
.	O
he	O
is	O
a	O
principal	O
investigator	O
on	O
an	O
iarpa	O
from	O
insa	O
.	O
he	O
undertook	O
his	O
m.s	O
.	O
thesis	O
at	O
the	O
project	O
on	O
video	O
concept	O
detection	B
and	O
a	O
co	O
-	O
principal	O
investigator	O
on	O
an	O
nga	O
nuclear	O
energy	O
center	O
(	O
cea	O
)	O
,	O
bruyères	O
-	O
le	O
-	O
châtel	O
,	O
nuri	O
grant	O
on	O
multimodal	O
location	O
estimation	B
.	O
until	O
2009	O
he	O
had	O
been	O
a	O
site	O
france	O
,	O
where	O
he	O
worked	O
on	O
signal	B
fusion	O
and	O
coordinator	O
for	O
the	O
eu	O
-	O
funded	O
amida	O
and	O
the	O
swiss	O
-	O
funded	O
im2	O
projects	O
intelligent	O
systems	O
for	O
source	B
localization	O
.	O
he	O
is	O
which	O
sponsored	O
the	O
research	B
on	O
multimodal	O
meeting	O
analysis	B
algorithms	O
.	O
currently	O
pursuing	O
the	O
ph.d	O
.	O
degree	O
from	O
telecom	O
dr	O
.	O
friedland	O
is	O
a	O
member	O
of	O
the	O
ieee	O
computer	B
society	O
and	O
the	O
ieee	O
com-	O
paristech	O
,	O
paris	O
,	O
france	O
,	O
and	O
joined	O
the	O
multimedia	O
munication	O
society	O
,	O
and	O
he	O
is	O
involved	O
in	O
the	O
organization	O
of	O
various	O
acm	O
and	O
communications	O
department	O
as	O
a	O
ph.d	O
.	O
candidate	O
ieee	O
conferences	O
,	O
including	O
the	O
ieee	O
international	O
conference	O
on	O
semantic	O
with	O
lia	O
-	O
eurecom	O
,	O
sophia	O
-	O
antipolis	O
,	O
france	O
.	O
computing	O
(	O
icsc	O
)	O
,	O
where	O
he	O
served	O
as	O
cochair	O
and	O
the	O
ieee	O
international	O
sym-	O
as	O
part	O
of	O
his	O
studies	O
,	O
he	O
spent	O
one	O
year	O
at	O
kth	O
(	O
royal	O
institute	O
of	O
posium	O
on	O
multimedia	O
(	O
ism2009	O
)	O
,	O
where	O
he	O
served	O
as	O
program	O
cochair	O
.	O
he	O
is	O
technology	O
)	O
,	O
stockholm	O
,	O
sweden	O
.	O
his	O
research	B
interests	O
include	O
multimedia	O
also	O
cofounder	O
and	O
program	O
director	O
of	O
the	O
ieee	O
international	O
summer	O
school	O
indexing	O
,	O
and	O
speciﬁcally	O
speaker	B
diarization	I
.	O
he	O
participated	O
in	O
lia	O
-	O
eu-	O
for	O
semantic	O
computing	O
at	O
uc	O
berkeley	O
.	O
he	O
is	O
the	O
recipient	O
of	O
several	O
research	B
recom	O
recent	O
submission	O
to	O
the	O
nist	O
rt’09	O
evaluation	B
and	O
contributes	O
his	O
and	O
industry	O
recognitions	O
,	O
among	O
them	O
the	O
multimedia	O
entrepreneur	O
award	O
by	O
expertise	O
in	O
speaker	B
diarization	I
to	O
the	O
national	O
“	O
acav	O
”	O
project	O
which	O
aims	O
to	O
the	O
german	O
government	O
and	O
the	O
european	O
academic	O
software	O
award	O
.	O
most	O
re-	O
improve	O
web	O
accessibility	O
for	O
the	O
visually	O
and	O
hearing	O
impaired	O
.	O
cently	O
,	O
he	O
won	O
the	O
ﬁrst	O
prize	O
in	O
the	O
acm	O
multimedia	O
grand	O
challenge	B
2009	O
.	O
nicholas	O
evans	O
(	O
m’06	O
)	O
received	O
the	O
m.eng	O
.	O
oriol	O
vinyals	O
received	O
a	O
double	O
degree	O
in	O
math-	O
and	O
ph.d	O
.	O
degrees	O
from	O
the	O
university	O
of	O
wales	O
ematics	O
and	O
telecommunication	O
engineering	O
from	O
swansea	O
(	O
uws	O
)	O
,	O
swansea	O
,	O
u.k	O
.	O
,	O
in	O
1999	O
and	O
2003	O
,	O
the	O
polytechnic	O
university	O
of	O
catalonia	O
,	O
barcelona	O
,	O
respectively	O
.	O
spain	O
,	O
and	O
the	O
m.s	O
.	O
degree	O
in	O
computer	B
science	O
from	O
from	O
2002	O
and	O
2006	O
,	O
he	O
was	O
a	O
lecturer	O
at	O
uws	O
the	O
university	O
of	O
california	O
,	O
san	O
diego	O
,	O
in	O
2009	O
.	O
and	O
was	O
an	O
honorary	O
lecturer	O
until	O
2009	O
.	O
he	O
brieﬂy	O
he	O
is	O
currently	O
pursuing	O
the	O
ph.d	O
.	O
degree	O
at	O
the	O
joined	O
the	O
laboratoire	O
informatique	O
d’avignon	O
university	O
of	O
california	O
,	O
berkeley	O
.	O
(	O
lia	O
)	O
,	O
at	O
the	O
université	O
d’avignon	O
et	O
des	O
pays	O
de	O
his	O
interests	O
include	O
artiﬁcial	O
intelligence	O
,	O
with	O
vaucluse	O
(	O
uapv	O
)	O
,	O
avignon	O
,	O
france	O
,	O
in	O
2006	O
before	O
particular	O
emphasis	O
on	O
machine	O
learning	O
,	O
speech	O
,	O
and	O
moving	O
to	O
eurecom	O
,	O
sophia	O
antipolis	O
,	O
france	O
,	O
vision	O
.	O
he	O
was	O
a	O
visiting	O
scholar	O
at	O
the	O
computer	B
in	O
2007	O
where	O
he	O
is	O
now	O
an	O
assistant	O
professor	O
.	O
at	O
science	O
department	O
,	O
carnegie	O
mellon	O
university	O
,	O
eurecom	O
,	O
he	O
heads	O
research	B
in	O
speech	O
and	O
audio	O
processing	B
and	O
is	O
currently	O
pittsburgh	O
,	O
pa	O
,	O
in	O
2006	O
,	O
where	O
he	O
worked	O
in	O
computer	B
vision	O
and	O
robotics	O
.	O
active	O
in	O
the	O
ﬁelds	O
of	O
speaker	B
diarization	I
,	O
speaker	B
recognition	O
,	O
multimodal	O
dr	O
.	O
vinyals	O
received	O
a	O
microsoft	O
research	B
ph.d	O
.	O
fellowship	O
in	O
2011	O
.	O
authorized	O
licensed	O
use	O
limited	O
to	O
:	O
inria	O
.	O
downloaded	O
on	O
october	O
05,2020	O
at	O
07:30:52	O
utc	O
from	O
ieee	O
xplore	O
.	O
 	O
restrictions	O

a	O
review	O
of	O
speaker	B
diarization	I
:	O
recent	O
advances	O
with	O
deep	B
learning	I
tae	O
jin	O
parka,∗	O
,	O
naoyuki	O
kandab,∗	O
,	O
dimitrios	O
dimitriadisb,∗	O
,	O
kyu	O
j.	O
hanc,∗	O
,	O
shinji	O
watanabed,∗	O
,	O
shrikanth	O
narayanana	O
auniversity	O
of	O
southern	O
california	O
,	O
los	O
angeles	O
,	O
usa	O
bmicrosoft	O
,	O
redmond	O
,	O
usa	O
casapp	O
,	O
mountain	O
view	O
,	O
usa	O
djohns	O
hopkins	O
university	O
,	O
baltimore	O
,	O
usa	O
abstract	O
speaker	B
diarization	I
is	O
a	O
task	O
to	O
label	O
audio	O
or	O
video	O
recordings	O
with	O
classes	O
corresponding	O
to	O
speaker	B
identity	O
,	O
or	O
in	O
short	O
,	O
a	O
task	O
1	O
to	O
identify	O
“	O
who	O
spoke	O
when	O
”	O
.	O
in	O
the	O
early	O
years	O
,	O
speaker	B
diarization	I
algorithms	O
were	O
developed	O
for	O
speech	B
recognition	I
on	O
multi-	O
2	O
speaker	B
audio	O
recordings	O
to	O
enable	O
speaker	B
adaptive	O
processing	B
,	O
but	O
also	O
gained	O
its	O
own	O
value	O
as	O
a	O
stand	O
-	O
alone	O
application	B
over	O
0	O
time	B
to	O
provide	O
speaker	B
-	O
speciﬁc	O
meta	O
information	B
for	O
downstream	O
tasks	O
such	O
as	O
audio	O
retrieval	O
.	O
more	O
recently	O
,	O
with	O
the	O
rise	O
of	O
2	O
deep	B
learning	I
technology	O
that	O
has	O
been	O
a	O
driving	O
force	O
to	O
revolutionary	O
changes	O
in	O
research	B
and	O
practices	O
across	O
speech	O
application	B
  	O
n	O
domains	O
in	O
the	O
past	O
decade	O
,	O
more	O
rapid	O
advancements	O
have	O
been	O
made	O
for	O
speaker	B
diarization	I
.	O
in	O
this	O
paper	O
,	O
we	O
review	O
not	O
a	O
only	O
the	O
historical	O
development	O
of	O
speaker	B
diarization	I
technology	O
but	O
also	O
the	O
recent	O
advancements	O
in	O
neural	O
speaker	B
diarization	I
j	O
  	O
approaches	O
.	O
we	O
also	O
discuss	O
how	O
speaker	B
diarization	I
systems	I
have	O
been	O
integrated	O
with	O
speech	B
recognition	I
applications	O
and	O
how	O
4	O
the	O
recent	O
surge	O
of	O
deep	B
learning	I
is	O
leading	O
the	O
way	O
of	O
jointly	O
modeling	O
these	O
two	O
components	B
to	O
be	O
complementary	O
to	O
each	O
other	O
.	O
2	O
by	O
considering	O
such	O
exciting	O
technical	O
trends	O
,	O
we	O
believe	O
that	O
it	O
is	O
a	O
valuable	O
contribution	O
to	O
the	O
community	O
to	O
provide	O
a	O
survey	O
  	O
]	O
 	O
work	O
by	O
consolidating	O
the	O
recent	O
developments	O
with	O
neural	O
methods	O
and	O
thus	O
facilitating	O
further	O
progress	O
towards	O
a	O
more	O
eﬃcient	O
s	O
speaker	B
diarization	I
.	O
a	O
keywords	O
:	O
speaker	B
diarization	I
,	O
automatic	O
speech	B
recognition	I
,	O
deep	B
learning	I
.	O
s	O
s	O
e	O
e	O
1	O
.	O
introduction	O
processing	B
techniques	B
,	O
for	O
example	O
,	O
speech	O
enhancement	O
,	O
dere-	O
[	O
  	O
verberation	O
,	O
speech	B
separation	I
or	O
target	O
speaker	B
extraction	B
,	O
are	O
  	O
1	O
“	O
diarize	O
”	O
is	O
a	O
word	B
that	O
means	O
making	O
a	O
note	O
or	O
keeping	O
an	O
utilized	O
.	O
voice	O
or	O
speech	B
activity	I
detection	I
is	O
then	O
applied	O
to	O
v	O
event	O
in	O
a	O
diary	O
.	O
speaker	B
diarization	I
,	O
like	O
keeping	O
a	O
record	O
separate	O
speech	O
from	O
non	O
-	O
speech	O
events	O
.	O
raw	O
speech	O
signals	B
4	O
of	O
events	O
in	O
such	O
a	O
diary	O
,	O
addresses	O
the	O
“	O
who	O
spoke	O
when	O
”	O
in	O
the	O
selected	O
speech	O
portions	O
are	O
transformed	O
to	O
acoustic	O
fea-	O
2	O
6	O
question	O
[	O
1	O
,	O
2	O
,	O
3	O
]	O
by	O
logging	O
speaker	B
-	O
speciﬁc	O
salient	O
events	O
tures	O
or	O
embedding	O
vectors	O
.	O
in	O
the	O
clustering	B
stage	B
,	O
the	O
speech	O
9	O
on	O
multi	O
-	O
participant	O
(	O
or	O
multi	O
-	O
speaker	B
)	O
audio	O
data	B
.	O
through-	O
portion	O
represented	O
by	O
the	O
embedding	O
vectors	O
are	O
grouped	O
and	O
0	O
out	O
the	O
diarization	B
process	B
,	O
the	O
audio	O
data	B
would	O
be	O
divided	O
labeled	O
by	O
speaker	B
classes	O
and	O
in	O
the	O
post	O
-	O
processing	B
stage	B
,	O
the	O
1	O
.	O
and	O
clustered	O
into	O
groups	O
of	O
speech	B
segments	I
with	O
the	O
same	O
clustering	B
results	B
are	O
further	O
reﬁned	O
.	O
each	O
of	O
these	O
sub	O
-	O
modules	O
0	O
speaker	B
identity	O
/	O
label	O
.	O
as	O
a	O
result	O
,	O
salient	O
events	O
,	O
such	O
as	O
non-	O
is	O
optimized	O
individually	O
in	O
general	O
.	O
1	O
speech	O
/	O
speech	O
transition	O
,	O
speaker	B
turn	O
changes	O
,	O
speaker	B
classi-	O
2	O
ﬁcation	O
or	O
speaker	B
role	O
identiﬁcation	O
,	O
are	O
labeled	O
in	O
an	O
auto-	O
:	O
1.1	O
.	O
historical	O
development	O
of	O
speaker	B
diarization	I
v	O
matic	O
fashion	O
.	O
in	O
general	O
,	O
this	O
process	B
does	O
not	O
require	O
any	O
i	O
prior	O
knowledge	B
of	O
the	O
speakers	O
,	O
such	O
as	O
their	O
real	O
identity	O
or	O
during	O
the	O
early	O
years	O
of	O
diarization	B
technology	O
(	O
in	O
the	O
x	O
number	O
of	O
participating	O
speakers	O
in	O
the	O
audio	O
data	B
.	O
thanks	O
to	O
1990s	O
)	O
,	O
the	O
research	B
focus	O
was	O
on	O
unsupervised	O
speech	O
seg-	O
r	O
a	O
its	O
innate	O
feature	O
of	O
separating	O
audio	O
streams	O
by	O
these	O
speaker-	O
mentation	O
and	O
clustering	B
of	O
acoustic	O
events	O
including	O
not	O
only	O
speciﬁc	O
events	O
,	O
speaker	B
diarization	I
can	O
be	O
eﬀectively	O
employed	O
speaker	B
-	O
speciﬁc	O
ones	O
but	O
also	O
those	O
related	O
to	O
environmental	O
for	O
indexing	O
or	O
analyzing	O
various	O
types	O
of	O
audio	O
data	B
,	O
e.g.	O
,	O
au-	O
or	O
background	O
changes	O
[	O
4	O
,	O
5	O
,	O
6	O
,	O
7	O
,	O
8	O
,	O
9	O
,	O
10	O
,	O
11	O
,	O
12	O
,	O
13	O
,	O
14	O
]	O
.	O
dio	O
/	O
video	O
broadcasts	O
from	O
media	O
stations	O
,	O
conversations	O
in	O
con-	O
in	O
this	O
period	O
some	O
of	O
the	O
fundamental	O
approaches	O
to	O
speaker	B
ferences	O
,	O
personal	O
videos	B
from	O
online	O
social	O
media	O
or	O
hand	O
-	O
held	O
change	B
detection	I
and	O
clustering	B
,	O
such	O
as	O
leveraging	O
generalized	O
devices	O
,	O
court	O
proceedings	O
,	O
business	O
meetings	O
,	O
earnings	O
reports	O
likelihood	B
ratio	I
(	O
glr	O
)	O
and	O
bayesian	O
information	B
criterion	B
in	O
a	O
ﬁnancial	O
sector	O
,	O
just	O
to	O
name	O
a	O
few	O
.	O
(	O
bic	B
)	O
,	O
were	O
developed	O
and	O
quickly	O
became	O
the	O
golden	O
stan-	O
traditionally	O
speaker	B
diarization	I
systems	I
consist	O
of	O
multiple	O
,	O
dard	O
.	O
most	O
of	O
the	O
works	O
beneﬁted	O
automatic	O
speech	O
recogni-	O
independent	O
sub	O
-	O
modules	O
as	O
shown	O
in	O
fig	O
.	O
1	O
.	O
in	O
order	B
to	O
mit-	O
tion	O
(	O
asr	B
)	O
on	O
broadcast	O
news	O
recordings	O
,	O
by	O
enabling	O
speaker	B
igate	O
any	O
artifacts	O
in	O
acoustic	O
environments	O
,	O
various	O
front	O
-	O
end	O
adaptive	O
training	O
of	O
acoustic	O
models	B
[	O
10	O
,	O
15	O
,	O
16	O
,	O
17	O
,	O
18	O
]	O
.	O
all	O
these	O
eﬀorts	O
collectively	O
laid	O
out	O
a	O
path	O
to	O
consolidate	O
ac-	O
tivities	O
across	O
research	B
groups	O
around	O
the	O
world	O
,	O
leading	O
to	O
∗authors	O
contributed	O
equally	O
several	O
research	B
consortia	O
and	O
challenges	B
in	O
the	O
early	O
2000s	O
,	O
preprint	O
submitted	O
to	O
computer	B
,	O
speech	O
and	O
language	O
january	O
26	O
,	O
2021audio	O
 	O
input	B
diarization	B
 	O
output	B
(	O
rttm	O
)	O
front	O
-	O
end	O
 	O
speech	B
activity	I
speaker	B
 	O
post	O
segmentation	B
clustering	B
processing	B
detection	B
embedding	O
processing	B
section	O
2.1	O
section	O
2.2	O
section	O
2.3	O
section	O
2.4	O
section	O
2.5	O
section	O
2.6	O
fig	O
.	O
1	O
:	O
traditional	O
speaker	B
diarization	I
systems	I
.	O
among	O
which	O
there	O
were	O
the	O
augmented	O
multi	O
-	O
party	O
interac-	O
corresponding	O
technologies	O
to	O
mitigate	O
problems	O
from	O
the	O
per-	O
tion	O
(	O
ami	O
)	O
consortium	O
[	O
19	O
]	O
supported	O
by	O
the	O
european	O
com-	O
spective	O
of	O
meeting	O
environments	O
,	O
where	O
there	O
are	O
usually	O
more	O
mission	O
and	O
the	O
rich	B
transcription	I
evaluation	B
[	O
20	O
]	O
hosted	O
by	O
participants	B
than	O
broadcast	O
news	O
or	O
cts	O
data	B
and	O
multi	O
-	O
modal	O
the	O
national	O
institute	O
of	O
standards	O
and	O
technology	O
(	O
nist	O
)	O
.	O
data	B
is	O
frequently	O
available	O
.	O
since	O
these	O
two	O
papers	O
,	O
especially	O
these	O
organizations	O
,	O
spanning	O
over	O
from	O
a	O
few	O
years	O
to	O
a	O
thanks	O
to	O
leap	O
-	O
frog	O
advancements	O
in	O
deep	B
learning	I
approaches	O
decade	O
,	O
had	O
fostered	O
further	O
advancements	O
on	O
speaker	B
diariza-	O
addressing	O
technical	O
challenges	B
across	O
multiple	O
machine	O
learn-	O
tion	O
technologies	O
across	O
diﬀerent	O
data	B
domains	O
from	O
broadcast	O
ing	O
domains	O
,	O
speaker	B
diarization	I
systems	I
have	O
gone	O
through	O
a	O
news	O
[	O
21	O
,	O
22	O
,	O
23	O
,	O
24	O
,	O
25	O
,	O
26	O
,	O
27	O
,	O
28	O
,	O
29	O
]	O
and	O
conversational	O
lot	O
of	O
notable	O
changes	O
.	O
we	O
believe	O
that	O
this	O
survey	O
work	O
is	O
a	O
telephone	B
speech	I
(	O
cts	O
)	O
[	O
24	O
,	O
30	O
,	O
31	O
,	O
32	O
,	O
33	O
,	O
34	O
]	O
to	O
meeting	O
valuable	O
contribution	O
to	O
the	O
community	O
to	O
consolidate	O
the	O
re-	O
conversations	O
[	O
35	O
,	O
36	O
,	O
37	O
,	O
38	O
,	O
39	O
,	O
40	O
,	O
41	O
,	O
42	O
,	O
43	O
,	O
44	O
,	O
45	O
]	O
.	O
the	O
cent	O
developments	O
with	O
neural	O
methods	O
and	O
thus	O
facilitate	O
fur-	O
new	O
approaches	O
resulting	O
from	O
these	O
advancements	O
include	O
,	O
ther	O
progress	O
towards	O
a	O
more	O
eﬃcient	O
diarization	B
.	O
but	O
not	O
limited	O
to	O
,	O
beamforming	O
[	O
42	O
]	O
,	O
information	B
bottleneck	O
clustering	B
(	O
ibc	O
)	O
[	O
44	O
]	O
,	O
variational	O
bayesian	O
(	O
vb	O
)	O
approaches	O
1.3	O
.	O
overview	O
and	O
taxonomy	O
of	O
speaker	B
diarization	I
[	O
33	O
,	O
45	O
]	O
,	O
joint	O
factor	B
analysis	I
(	O
jfa	O
)	O
[	O
46	O
,	O
34	O
]	O
.	O
attempting	O
to	O
categorize	O
the	O
existing	O
,	O
most	O
-	O
diverse	O
speaker	B
since	O
the	O
advent	O
of	O
deep	B
learning	I
in	O
the	O
2010s	O
,	O
there	O
has	O
diarization	B
technologies	O
,	O
both	O
on	O
the	O
space	O
of	O
modularized	O
been	O
a	O
considerable	O
amount	B
of	O
research	B
to	O
take	O
the	O
advantage	O
speaker	B
diarization	I
systems	I
before	O
the	O
deep	B
learning	I
era	O
and	O
of	O
powerful	O
modeling	O
capabilities	O
of	O
the	O
neural	B
networks	I
for	O
those	O
based	O
on	O
neural	B
networks	I
of	O
the	O
recent	O
years	O
,	O
a	O
proper	O
speaker	B
diarization	I
.	O
one	O
representative	O
example	O
is	O
extracting	O
grouping	O
would	O
be	O
helpful	O
.	O
the	O
main	O
categorization	O
we	O
adopt	O
the	O
speaker	B
embeddings	I
using	O
neural	B
networks	I
,	O
such	O
as	O
the	O
d-	O
in	O
this	O
paper	O
is	O
based	O
on	O
two	O
criteria	O
,	O
resulting	O
in	O
the	O
total	O
four	O
vectors	O
[	O
47	O
,	O
48	O
,	O
49	O
]	O
or	O
the	O
x	O
-	O
vectors	O
[	O
50	O
]	O
,	O
which	O
most	O
often	O
are	O
categories	O
,	O
as	O
shown	O
in	O
table	O
1	O
.	O
the	O
ﬁrst	O
criterion	B
is	O
whether	O
embedding	O
vector	O
representations	O
based	O
on	O
the	O
bottleneck	O
layer	B
the	O
model	B
is	O
trained	O
based	O
on	O
speaker	B
diarization	I
-	O
oriented	O
ob-	O
output	B
of	O
a	O
“	O
deep	O
neural	B
network	I
”	O
(	O
dnn	O
)	O
trained	O
for	O
speaker	B
jective	O
function	O
or	O
not	O
.	O
any	O
trainable	O
approaches	O
to	O
optimize	O
recognition	O
.	O
the	O
shift	O
from	O
i	O
-	O
vector	O
[	O
51	O
,	O
52	O
,	O
53	O
,	O
54	O
]	O
to	O
these	O
models	B
in	O
a	O
multi	O
-	O
speaker	B
situation	O
and	O
learn	O
relations	O
between	O
neural	O
embeddings	O
contributed	O
to	O
enhanced	O
performance	O
,	O
eas-	O
speakers	O
are	O
categorized	O
into	O
the	O
“	O
diarization	B
objective	O
”	O
class	O
.	O
ier	O
training	O
with	O
more	O
data	B
[	O
55	O
]	O
,	O
and	O
robustness	O
against	O
speaker	B
the	O
second	O
criterion	B
is	O
whether	O
multiple	O
modules	O
are	O
jointly	O
variability	O
and	O
acoustic	O
conditions	O
.	O
more	O
recently	O
,	O
end	O
-	O
to	O
-	O
end	O
optimized	O
towards	O
some	O
objective	O
function	O
.	O
if	O
a	O
single	O
sub-	O
neural	O
diarization	B
(	O
eend	O
)	O
where	O
individual	O
sub	O
-	O
modules	O
in	O
module	O
is	O
replaced	O
into	O
a	O
trainable	O
one	O
,	O
such	O
method	B
is	O
catego-	O
the	O
traditional	O
speaker	B
diarization	I
systems	I
(	O
c.f	O
.	O
,	O
fig	O
.	O
1	O
)	O
can	O
rized	O
into	O
the	O
“	O
single	O
-	O
module	O
optimization	O
”	O
class	O
.	O
on	O
the	O
other	O
be	O
replaced	O
by	O
one	O
neural	B
network	I
gets	O
more	O
attention	O
with	O
hand	O
,	O
for	O
example	O
,	O
joint	O
modeling	O
of	O
segmentation	B
and	O
cluster-	O
promising	O
results	B
[	O
56	O
,	O
57	O
]	O
.	O
this	O
research	B
direction	O
,	O
although	O
not	O
ing	O
[	O
55	O
]	O
,	O
joint	O
modeling	O
of	O
speech	B
separation	I
and	O
speaker	B
di-	O
fully	O
matured	O
yet	O
,	O
could	O
open	O
up	O
unprecedented	O
opportunities	O
arization	O
[	O
76	O
]	O
or	O
fully	O
end	O
-	O
to	O
-	O
end	O
neural	O
diarization	B
[	O
56	O
,	O
57	O
]	O
is	O
to	O
address	O
challenges	B
in	O
the	O
ﬁeld	O
of	O
speaker	B
diarization	I
,	O
such	O
categorized	O
into	O
the	O
“	O
joint	O
optimization	O
”	O
class	O
.	O
as	O
,	O
the	O
joint	O
optimization	O
with	O
other	O
speech	O
applications	O
,	O
with	O
note	O
that	O
our	O
intention	O
of	O
this	O
categorization	O
is	O
to	O
help	O
read-	O
overlapping	B
speech	I
,	O
if	O
large	O
-	O
scale	O
data	B
is	O
available	O
for	O
training	O
ers	O
to	O
quickly	O
overview	O
the	O
broad	O
development	O
in	O
the	O
ﬁeld	O
,	O
and	O
such	O
powerful	O
network	B
-	O
based	O
models	B
.	O
it	O
is	O
not	O
our	O
intention	O
to	O
divide	O
the	O
categories	O
into	O
superior-	O
inferior	O
.	O
also	O
,	O
while	O
we	O
are	O
aware	O
of	O
many	O
techniques	B
that	O
fall	O
1.2	O
.	O
motivation	O
into	O
the	O
category	O
“	O
non	O
-	O
diarization	B
objective	O
”	O
and	O
“	O
joint	O
opti-	O
mization	O
”	O
(	O
e.g.	O
,	O
joint	O
front	O
-	O
end	O
and	O
asr	B
[	O
67	O
,	O
68	O
,	O
69	O
,	O
70	O
,	O
71	O
,	O
72	O
]	O
,	O
till	O
now	O
,	O
there	O
are	O
two	O
well	O
-	O
rounded	O
overview	O
papers	O
in	O
joint	O
speaker	B
identiﬁcation	O
and	O
speech	B
separation	I
[	O
73	O
,	O
74	O
]	O
,	O
etc	O
.	O
)	O
,	O
the	O
area	O
of	O
speaker	B
diarization	I
surveying	O
the	O
development	O
of	O
we	O
exclude	O
them	O
in	O
the	O
paper	O
to	O
focus	O
on	O
the	O
review	O
of	O
speaker	B
speaker	B
diarization	I
technology	O
with	O
diﬀerent	O
focuses	O
.	O
in	O
[	O
2	O
]	O
,	O
diarization	B
techniques	B
.	O
various	O
speaker	B
diarization	I
systems	I
and	O
their	O
subtasks	O
in	O
the	O
context	O
of	O
broadcast	O
news	O
and	O
cts	O
data	B
are	O
reviewed	O
up	O
to	O
1.4	O
.	O
paper	O
organization	O
the	O
point	O
of	O
mid	O
2000s	O
.	O
as	O
such	O
,	O
the	O
historical	O
progress	O
of	O
the	O
rest	O
of	O
the	O
paper	O
is	O
organized	O
as	O
follows	O
.	O
speaker	B
diarization	I
technology	O
development	O
in	O
the	O
1990s	O
and	O
early	O
2000s	O
are	O
hence	O
covered	O
.	O
in	O
contrast	O
,	O
the	O
focus	O
of	O
[	O
3	O
]	O
•	O
in	O
section	O
2	O
,	O
we	O
overview	O
techniques	B
belonging	O
to	O
the	O
was	O
put	O
more	O
on	O
speaker	B
diarization	I
for	O
meeting	O
speech	O
and	O
“	O
non	O
-	O
diarization	B
objective	O
”	O
and	O
“	O
single	O
-	O
module	O
opti-	O
its	O
respective	O
challenges	B
.	O
this	O
paper	O
thus	O
weighs	O
more	O
in	O
the	O
mization	O
”	O
class	O
in	O
the	O
proposed	O
taxonomy	O
,	O
mostly	O
those	O
2table	O
1	O
:	O
table	O
of	O
taxonomy	O
non	O
-	O
diarization	B
diarization	B
objective	O
objective	O
section	O
2	O
section	O
3.1	O
single	O
-	O
module	O
front	O
-	O
end	O
[	O
58	O
,	O
59	O
,	O
60	O
]	O
,	O
speaker	B
idec	O
[	O
64	O
]	O
,	O
aﬃnity	O
matrix	O
optimization	O
embedding	O
[	O
61	O
,	O
62	O
,	O
50	O
]	O
,	O
speech	O
reﬁnement	O
[	O
65	O
]	O
,	O
ts	O
-	O
vad	O
[	O
66	O
]	O
,	O
etc	O
.	O
activity	B
detection	I
[	O
63	O
]	O
,	O
etc	O
.	O
out	O
of	O
scope	O
section	O
3.2	O
joint	O
front	O
-	O
end	O
&	O
asr	B
uis	O
-	O
rnn	O
[	O
55	O
]	O
,	O
rpn	O
[	O
75	O
]	O
,	O
online	O
joint	O
[	O
67	O
,	O
68	O
,	O
69	O
,	O
70	O
,	O
71	O
,	O
72	O
]	O
,	O
joint	O
rsan	O
[	O
76	O
]	O
,	O
eend	O
[	O
56	O
,	O
57	O
]	O
,	O
etc	O
.	O
optimization	O
speaker	B
identiﬁcation	O
&	O
speech	O
section	O
4	O
separation	O
[	O
73	O
,	O
74	O
]	O
,	O
etc	O
.	O
joint	O
asr	B
&	O
speaker	B
diarization	I
.	O
[	O
77	O
,	O
78	O
,	O
79	O
,	O
80	O
]	O
,	O
etc	O
.	O
used	O
in	O
the	O
traditional	O
,	O
modular	O
speaker	B
diarization	I
sys-	O
each	O
module	O
,	O
this	O
section	O
also	O
summarizes	O
the	O
latest	O
schemes	O
tems	O
.	O
while	O
there	O
are	O
some	O
overlaps	B
with	O
the	O
counterpart	O
within	O
the	O
module	O
.	O
sections	O
of	O
the	O
aforementioned	O
two	O
survey	O
papers	O
[	O
2	O
,	O
3	O
]	O
in	O
terms	B
of	O
reviewing	O
notable	O
developments	O
in	O
the	O
past	O
,	O
this	O
2.1	O
.	O
front	O
-	O
end	O
processing	B
section	O
would	O
add	O
more	O
latest	O
schemes	O
as	O
well	O
in	O
the	O
corre-	O
this	O
section	O
describes	O
mostly	O
front	O
-	O
end	O
techniques	B
,	O
used	O
for	O
sponding	O
components	B
of	O
the	O
speaker	B
diarization	I
systems	I
.	O
speech	O
enhancement	O
,	O
dereverberation	O
,	O
speech	B
separation	I
,	O
and	O
•	O
in	O
section	O
3	O
,	O
we	O
discuss	O
advancements	O
mostly	O
leveraging	O
speech	O
extraction	B
as	O
part	O
of	O
the	O
speaker	B
diarization	I
pipeline	O
.	O
let	O
dnns	O
trained	O
with	O
the	O
diarization	B
objective	O
where	O
single	O
si	O
,	O
f	O
,	O
t	O
∈	O
c	O
be	O
the	O
stft	O
representation	O
of	O
source	B
speaker	B
i	O
on	O
sub	O
-	O
modules	O
are	O
independently	O
optimized	O
(	O
subsection	O
3.1	O
)	O
frequency	B
bin	O
f	O
at	O
frame	B
t.	O
the	O
observed	O
noisy	O
signal	B
xt	O
,	O
f	O
can	O
be	O
or	O
jointly	O
optimized	O
(	O
subsection	O
3.2	O
)	O
toward	O
fully	O
end	O
-	O
to-	O
represented	O
by	O
a	O
mixture	O
of	O
the	O
source	B
signals	B
,	O
a	O
room	O
impulse	O
end	O
speaker	B
diarization	I
.	O
response	O
hi	O
,	O
f	O
,	O
t	O
∈	O
c	O
,	O
and	O
additive	O
noise	O
nt	O
,	O
f	O
∈	O
c	O
,	O
•	O
in	O
section	O
4	O
,	O
we	O
present	O
a	O
perspective	O
of	O
how	O
speaker	B
di-	O
(	O
cid:88)k	O
(	O
cid:88	O
)	O
arization	O
has	O
been	O
investigated	O
in	O
the	O
context	O
of	O
asr	B
,	O
re-	O
xt	O
,	O
f	O
=	O
hi	O
,	O
f	O
,	O
τsi	O
,	O
f	O
,	O
t−τ	O
+	O
nt	O
,	O
f	O
,	O
(	O
1	O
)	O
viewing	O
historical	O
interactions	O
between	O
these	O
two	O
domains	O
i=1	O
τ	O
to	O
peek	O
the	O
past	O
,	O
present	O
and	O
future	O
of	O
speaker	B
diarization	I
where	O
k	O
denotes	O
the	O
number	O
of	O
speakers	O
present	O
in	O
the	O
audio	O
applications	O
.	O
signal	B
.	O
•	O
section	O
5	O
provides	O
information	B
of	O
speaker	B
diarization	I
chal-	O
the	O
front	O
-	O
end	O
techniques	B
described	O
in	O
this	O
section	O
is	O
to	O
esti-	O
mate	O
the	O
original	O
source	B
signal	B
xˆ	O
given	O
the	O
observation	O
x	O
=	O
lenges	O
and	O
corpora	B
to	O
facilitate	O
research	B
activities	O
and	O
an-	O
i	O
,	O
t	O
(	O
{	O
x	O
}	O
)	O
for	O
the	O
downstream	O
diarization	B
task	O
,	O
chor	O
techonology	O
advances	O
.	O
we	O
also	O
discuss	O
evaluation	B
t	O
,	O
f	O
f	O
t	O
metrics	O
such	O
as	O
diarization	B
error	I
rate	I
(	O
der	O
)	O
,	O
jaccard	O
er-	O
xˆ	O
=	O
frontend(x	O
)	O
,	O
i	O
=	O
1	O
,	O
.	O
.	O
.	O
,	O
k	O
,	O
(	O
2	O
)	O
ror	O
rate	O
(	O
jer	O
)	O
and	O
word	B
-	O
level	B
der	O
(	O
wder	O
)	O
in	O
the	O
sec-	O
i	O
,	O
t	O
tion	O
.	O
where	O
xˆ	O
∈	O
cd	O
is	O
the	O
i	O
-	O
th	O
speaker	B
’s	O
estimated	O
stft	O
spectrum	B
i	O
,	O
t	O
•	O
we	O
share	O
a	O
few	O
examples	O
of	O
how	O
speaker	B
diarization	I
sys-	O
with	O
d	O
frequency	B
bins	O
at	O
frame	B
t.	O
although	O
there	O
are	O
numerous	O
speech	O
enhancement	O
,	O
dereber-	O
tems	O
are	O
employed	O
in	O
both	O
research	B
and	O
industry	O
practices	O
beration	O
,	O
and	O
separation	O
algorithms	O
,	O
e.g.	O
,	O
[	O
81	O
,	O
82	O
,	O
83	O
]	O
,	O
herein	O
in	O
section	O
6	O
and	O
conclude	O
this	O
work	O
in	O
section	O
7	O
with	O
pro-	O
most	O
of	O
the	O
recent	O
techniques	B
used	O
in	O
the	O
dihard	B
challenge	I
viding	O
summary	O
and	O
future	O
challenges	B
in	O
speaker	B
diariza-	O
series	O
[	O
84	O
,	O
85	O
,	O
86	O
]	O
,	O
libricss	O
meeting	O
recognition	O
task	O
[	O
87	O
,	O
88	O
]	O
,	O
tion	O
.	O
and	O
chime-6	O
challenge	B
track	O
2	O
[	O
89	O
,	O
90	O
,	O
91	O
]	O
are	O
covered	O
.	O
2.1.1	O
.	O
speech	O
enhancement	O
(	O
denoising	O
)	O
2	O
.	O
modular	O
speaker	B
diarization	I
systems	I
speech	O
enhancement	O
techniques	B
focus	O
mainly	O
on	O
suppress-	O
this	O
section	O
provides	O
an	O
overview	O
of	O
algorithms	O
for	O
speaker	B
ing	O
the	O
noise	O
component	O
of	O
the	O
noisy	O
speech	O
.	O
single	O
-	O
channel	O
diarization	B
belonging	O
to	O
the	O
“	O
single	O
-	O
module	O
optimization	O
,	O
speech	O
enhancement	O
has	O
shown	O
a	O
signiﬁcant	O
improvement	O
in	O
non	O
-	O
diarization	B
objective	O
”	O
class	O
mostly	O
modular	O
speaker	B
,	O
as	O
denoising	O
performance	O
[	O
92	O
,	O
93	O
,	O
94	O
]	O
thanks	O
to	O
deep	B
learning	I
,	O
shown	O
in	O
figure	O
1	O
.	O
each	O
subsection	O
in	O
this	O
section	O
corresponds	O
when	O
compared	O
with	O
classical	O
signal	B
processing	I
based	O
speech	O
to	O
the	O
explanation	O
of	O
each	O
module	O
in	O
the	O
traditional	O
speaker	B
di-	O
enhancement	O
[	O
95	O
]	O
.	O
for	O
example	O
,	O
lstm	O
-	O
based	O
speech	O
enhance-	O
arization	O
system	O
.	O
in	O
addition	O
to	O
the	O
introductory	O
explanation	O
of	O
ment	O
[	O
96	O
,	O
94	O
]	O
is	O
used	O
as	O
a	O
front	O
-	O
end	O
technique	B
in	O
the	O
dihard	O
3ii	O
baseline	B
[	O
85	O
]	O
,	O
i.e.	O
,	O
2.1.3	O
.	O
speech	B
separation	I
and	O
target	O
speaker	B
extraction	B
speech	B
separation	I
is	O
a	O
promising	O
family	O
of	O
techniques	B
when	O
xˆt	O
=	O
lstm(x	O
)	O
,	O
(	O
3	O
)	O
the	O
overlapping	B
speech	I
regions	O
are	O
signiﬁcant	O
.	O
similarly	O
to	O
other	O
research	B
areas	O
,	O
dl	O
-	O
based	O
speech	B
separation	I
has	O
become	O
where	O
we	O
only	O
consider	O
the	O
single	O
source	B
example	O
(	O
i.e.	O
,	O
k	O
=	O
1	O
)	O
popular	O
,	O
e.g	O
,	O
“	O
deep	O
clustering	B
”	O
[	O
58	O
]	O
,	O
“	O
permutation	O
invariant	O
and	O
omit	O
the	O
source	B
index	O
i.	O
this	O
is	O
a	O
regression	B
-	O
based	O
approach	O
training	O
”	O
(	O
pit	O
)	O
[	O
59	O
]	O
,	O
and	O
conv	O
-	O
tasnet	O
[	O
60	O
]	O
.	O
the	O
eﬀective-	O
by	O
minimizing	O
the	O
objective	O
function	O
,	O
ness	O
of	O
multi	O
-	O
channel	O
speech	B
separation	I
based	O
on	O
beamforming	O
has	O
been	O
widely	O
conﬁrmed	O
[	O
102	O
,	O
103	O
]	O
,	O
as	O
well	O
.	O
for	O
example	O
,	O
lmse	O
=	O
||st	O
−	O
xˆt||2	O
.	O
(	O
4	O
)	O
in	O
the	O
chime-6	O
challenge	B
[	O
89	O
]	O
,	O
“	O
guided	O
source	B
separation	O
”	O
(	O
gss	O
)	O
[	O
103	O
]	O
based	O
multi	O
-	O
channel	O
speech	O
extraction	B
techniques	B
the	O
log	B
power	O
spectrum	B
or	O
ideal	O
ratio	O
mask	O
is	O
often	O
used	O
as	O
the	O
have	O
been	O
used	O
to	O
achieve	O
the	O
top	O
result	O
.	O
on	O
the	O
other	O
hand	O
,	O
target	O
domain	B
of	O
the	O
output	B
st	O
.	O
also	O
,	O
the	O
speech	O
enhancement	O
single	O
-	O
channel	O
speech	B
separation	I
techniques	B
do	O
not	O
often	O
show	O
used	O
in	O
[	O
95	O
]	O
applies	O
this	O
objective	O
function	O
in	O
each	O
layer	B
based	O
any	O
signiﬁcant	O
eﬀectiveness	O
in	O
realistic	O
multi	O
-	O
speaker	B
scenar-	O
on	O
a	O
progressive	O
manner	O
.	O
ios	O
like	O
the	O
libricss	O
[	O
87	O
]	O
or	O
the	O
chime-6	O
tasks	O
[	O
89	O
]	O
,	O
where	O
the	O
eﬀectiveness	O
of	O
the	O
speech	O
enhancement	O
techniques	B
can	O
speech	O
signals	B
are	O
continuous	O
and	O
contain	O
both	O
overlapping	B
and	O
be	O
boosted	O
multi	O
-	O
channel	O
processing	B
,	O
including	O
minimum	O
vari-	O
overlap	O
-	O
free	O
speech	O
regions	O
.	O
the	O
single	O
-	O
channel	O
speech	O
sepa-	O
ance	O
distortionless	O
response	O
(	O
mvdr	O
)	O
beamforming	O
[	O
81	O
]	O
.	O
[	O
88	O
]	O
ration	O
systems	O
often	O
produce	O
a	O
redundant	O
non	O
-	O
speech	O
or	O
even	O
shows	O
the	O
signiﬁcant	O
improvement	O
of	O
the	O
der	O
from	O
18.3	O
%	O
a	O
duplicated	O
speech	B
signal	I
for	O
the	O
non	O
-	O
overlap	O
regions	O
,	O
and	O
as	O
to	O
13.9	O
%	O
in	O
the	O
libricss	O
meeting	O
task	O
based	O
on	O
mask	O
-	O
based	O
such	O
the	O
“	O
leakage	O
”	O
of	O
audio	O
causes	O
many	O
false	O
alarms	O
of	O
speech	O
mvdr	O
beamforming	O
[	O
97	O
,	O
98	O
]	O
.	O
activity	O
.	O
a	O
leakage	O
ﬁltering	O
method	B
was	O
proposed	O
in	O
[	O
104	O
]	O
tack-	O
ling	O
the	O
problem	O
,	O
where	O
a	O
signiﬁcant	O
improvement	O
of	O
speaker	B
diarization	I
performance	O
was	O
shown	O
after	O
including	O
this	O
pro-	O
2.1.2	O
.	O
dereverberation	O
cessing	O
step	O
in	O
the	O
top	O
-	O
ranked	O
system	O
on	O
the	O
voxceleb	O
speaker	B
compared	O
with	O
other	O
front	O
-	O
end	O
techniques	B
,	O
the	O
major	O
dere-	O
recognition	O
challenge	B
2020	O
[	O
105	O
]	O
.	O
verberation	O
techniques	B
used	O
in	O
various	O
tasks	O
is	O
based	O
on	O
statis-	O
tical	O
signal	B
processing	I
methods	O
.	O
one	O
of	O
the	O
most	O
widely	O
used	O
2.2	O
.	O
speech	B
activity	I
detection	I
(	O
sad	O
)	O
techniques	B
is	O
weighted	O
prediction	O
error	O
(	O
wpe	O
)	O
based	O
derever-	O
beration	O
[	O
99	O
,	O
100	O
,	O
101	O
]	O
.	O
sad	O
distinguishes	O
speech	B
segments	I
from	O
non	O
-	O
speech	O
seg-	O
the	O
basic	O
idea	O
of	O
wpe	O
,	O
for	O
the	O
case	O
of	O
single	O
source	B
,	O
i.e.	O
ments	O
such	O
as	O
background	B
noise	I
.	O
a	O
sad	O
system	O
is	O
mostly	O
k	O
=	O
1	O
,	O
without	O
noise	O
,	O
is	O
to	O
decompose	O
the	O
original	O
signal	B
model	B
comprised	O
of	O
two	O
parts	O
.	O
the	O
ﬁrst	O
one	O
is	O
a	O
feature	O
extraction	B
eq	O
.	O
(	O
1	O
)	O
into	O
the	O
early	O
reﬂection	O
xearly	O
and	O
late	O
reverberation	O
xlate	O
frontend	O
,	O
where	O
acoustic	B
features	I
such	O
as	O
mel	O
-	O
frequency	B
cep-	O
t	O
,	O
f	O
t	O
,	O
f	O
as	O
follows	O
:	O
stral	O
coeﬃcients	O
(	O
mfccs	O
)	O
are	O
extracted	O
.	O
the	O
other	O
part	O
is	O
a	O
(	O
cid:88	O
)	O
classiﬁer	O
,	O
where	O
a	O
model	B
predicts	O
whether	O
the	O
input	B
frame	B
is	O
xt	O
,	O
f	O
=	O
h	O
f	O
,	O
τs	O
f	O
,	O
t−τ	O
=	O
xte	O
,	O
afrly	O
+	O
xtla	O
,	O
fte	O
.	O
(	O
5	O
)	O
speech	O
or	O
not	O
.	O
these	O
models	B
may	O
include	O
gaussian	O
mixture	O
τ	O
models	B
(	O
gmms	O
)	O
[	O
106	O
]	O
,	O
hidden	O
markov	O
models	B
(	O
hmms	O
)	O
[	O
107	O
]	O
or	O
dnns	O
[	O
63	O
]	O
.	O
wpe	O
tries	O
to	O
estimate	O
ﬁlter	O
coeﬃcients	O
hˆwf	O
,	O
pt	O
e	O
∈	O
c	O
,	O
which	O
main-	O
the	O
performance	O
of	O
sad	O
largely	O
aﬀects	O
the	O
overall	O
perfor-	O
tain	O
the	O
early	O
reﬂection	O
while	O
suppress	O
the	O
late	O
reverberation	O
mance	O
of	O
the	O
speaker	B
diarization	I
system	I
because	O
it	O
can	O
cre-	O
based	O
on	O
the	O
maximum	O
likelihood	B
estimation	B
.	O
ate	O
a	O
signiﬁcant	O
amount	B
of	O
false	O
positive	O
salient	O
events	O
or	O
miss	B
speech	B
segments	I
[	O
108	O
]	O
.	O
a	O
common	O
practice	O
in	O
speaker	B
diariza-	O
(	O
cid:88)l	O
xˆearly	O
=	O
x	O
−	O
hˆwpex	O
,	O
(	O
6	O
)	O
tion	O
tasks	O
is	O
to	O
report	O
der	O
with	O
“	O
oracle	O
sad	O
”	O
setup	B
which	O
in-	O
t	O
,	O
,	O
f	O
t	O
,	O
f	O
f	O
,	O
τ	O
f	O
,	O
t−τ	O
τ=∆	O
dicates	O
that	O
the	O
system	O
output	B
is	O
using	O
speech	B
activity	I
detection	I
output	B
that	O
is	O
identical	O
to	O
the	O
ground	B
truth	I
.	O
on	O
the	O
other	O
hand	O
,	O
where	O
∆	O
is	O
the	O
number	O
of	O
frames	O
to	O
split	O
the	O
early	O
reﬂection	O
and	O
the	O
system	O
output	B
with	O
an	O
actual	O
speech	B
activity	I
detector	O
is	O
re-	O
late	O
reverberation	O
,	O
and	O
l	O
is	O
the	O
ﬁlter	O
size	B
.	O
ferred	O
to	O
as	O
“	O
system	O
sad	O
”	O
output	B
.	O
wpe	O
is	O
widely	O
used	O
as	O
one	O
of	O
the	O
golden	O
standard	O
front-	O
end	O
processing	B
methods	O
,	O
e.g.	O
,	O
it	O
is	O
part	O
of	O
the	O
dihard	O
and	O
2.3	O
.	O
segmentation	B
chime	O
both	O
the	O
baseline	B
and	O
the	O
top	O
-	O
performing	O
systems	O
[	O
84	O
,	O
85	O
,	O
86	O
,	O
89	O
,	O
90	O
]	O
.	O
although	O
the	O
performance	O
improvement	O
speech	O
segmentation	B
breaks	O
the	O
input	B
audio	O
stream	O
into	O
mul-	O
of	O
wpe	O
-	O
based	O
dereverberation	O
is	O
not	O
signiﬁcant	O
,	O
it	O
provides	O
tiple	O
segments	O
so	O
that	O
the	O
each	O
segment	B
can	O
be	O
assigned	O
to	O
a	O
solid	O
performance	O
improvement	O
across	O
almost	O
all	O
tasks	O
.	O
also	O
,	O
speaker	B
label	O
.	O
before	O
re	O
-	O
segmentation	B
phase	O
,	O
the	O
unit	O
of	O
the	O
out-	O
wpe	O
is	O
based	O
on	O
the	O
linear	O
ﬁltering	O
and	O
since	O
it	O
does	O
not	O
intro-	O
put	O
of	O
speaker	B
diarization	I
system	I
is	O
determined	O
by	O
segmenta-	O
duce	O
signal	B
distortions	O
,	O
it	O
can	O
be	O
safely	O
combined	O
with	O
down-	O
tion	O
process	B
.	O
there	O
are	O
two	O
ways	O
of	O
performing	O
speech	O
segmen-	O
stream	O
front	O
-	O
end	O
and	O
back	O
-	O
end	O
processing	B
steps	B
.	O
similar	O
to	O
the	O
tation	O
for	O
speaker	B
diarization	I
tasks	O
:	O
either	O
with	O
speaker	B
change	I
speech	O
enhancement	O
techniques	B
,	O
wpe	O
-	O
based	O
dereberberation	O
point	B
detection	I
or	O
uniform	O
segmentation	B
.	O
the	O
segmentation	B
by	O
shows	O
additional	O
peformance	O
improvements	B
when	O
applied	O
on	O
detecting	O
the	O
speaker	B
change	I
point	O
was	O
the	O
golder	O
standard	O
of	O
multi	O
-	O
channel	O
signals	B
.	O
the	O
earlier	O
speaker	B
diarization	I
systems	I
,	O
where	O
speaker	B
change	I
4points	O
are	O
detected	O
by	O
comparing	O
two	O
hypotheses	B
:	O
hypothe-	O
however	O
,	O
the	O
process	B
of	O
uniformly	O
segmenting	O
the	O
input	B
sig-	O
sis	O
h	O
assumes	O
both	O
left	O
and	O
right	O
samples	O
are	O
from	O
the	O
same	O
nals	O
for	O
diarization	B
poses	O
some	O
potential	O
problems	O
.	O
first	O
,	O
uni-	O
0	O
speaker	B
and	O
hypothesis	B
h	O
assumes	O
the	O
two	O
samples	O
are	O
from	O
form	O
segmentation	B
introduces	O
a	O
trade	O
-	O
oﬀ	O
error	O
related	O
to	O
the	O
1	O
the	O
diﬀerent	O
speakers	O
.	O
many	O
algorithms	O
for	O
the	O
hypothesis	B
test-	O
segment	B
length	B
:	O
segments	O
need	O
to	O
be	O
suﬃciently	O
short	O
to	O
safely	O
ing	O
,	O
such	O
as	O
kullback	O
leibler	O
2	O
(	O
kl2	O
)	O
[	O
10	O
]	O
,	O
“	O
generalized	O
like-	O
assume	O
that	O
they	O
do	O
not	O
contain	O
multiple	O
speakers	O
but	O
at	O
the	O
lihood	O
ratio	O
”	O
(	O
glr	O
)	O
[	O
109	O
]	O
and	O
bic	B
[	O
110	O
,	O
111	O
]	O
were	O
proposed	O
same	O
time	B
it	O
is	O
necessary	O
to	O
capture	O
enough	O
acoustic	O
informa-	O
with	O
the	O
bic	B
method	B
been	O
the	O
most	O
widely	O
used	O
method	B
.	O
the	O
tion	O
to	O
extract	O
a	O
meaningful	O
speaker	B
representation	O
x	O
.	O
j	O
bic	B
approach	O
can	O
be	O
applied	O
to	O
segmentation	B
process	B
as	O
fol-	O
lows	O
:	O
assuming	O
that	O
x	O
=	O
{	O
x1	O
,	O
·	O
·	O
·	O
,	O
xn	O
}	O
is	O
the	O
sequence	B
of	O
speech	O
2.4	O
.	O
speaker	B
representations	O
and	O
speaker	B
embeddings	I
features	O
extracted	O
from	O
the	O
given	O
audio	O
stream	O
and	O
x	O
is	O
drawn	O
in	O
this	O
section	O
,	O
we	O
explain	O
a	O
few	O
popular	O
methods	O
for	O
mea-	O
from	O
from	O
an	O
independent	O
multivariate	O
gaussian	O
process	B
:	O
suring	O
the	O
similarity	B
of	O
speech	B
segments	I
.	O
these	O
methods	O
are	O
x	O
∼	O
n	O
(	O
µ	O
,	O
σ	O
)	O
,	O
(	O
7	O
)	O
paired	O
with	O
clustering	B
algorithms	O
,	O
which	O
will	O
be	O
explained	O
in	O
i	O
i	O
i	O
the	O
next	O
section	O
.	O
we	O
ﬁrst	O
introduce	O
gmm	O
based	O
hypothesis	B
where	O
µi	O
,	O
σi	O
is	O
mean	O
and	O
covariance	O
matrix	O
of	O
the	O
i	O
-	O
th	O
feature	O
testing	O
approaches	O
which	O
are	O
usually	O
employed	O
with	O
segmenta-	O
window	O
,	O
two	O
hypothesis	B
h0	O
and	O
h1	O
can	O
be	O
denoted	O
as	O
follows	O
:	O
tion	O
approaches	O
based	O
on	O
a	O
speaker	B
change	I
point	B
detection	I
.	O
we	O
then	O
introduce	O
well	O
-	O
known	O
speaker	B
representations	O
for	O
speaker	B
h	O
:	O
x	O
·	O
·	O
·	O
x	O
∼	O
n(µ	O
,	O
σ	O
)	O
(	O
8)	O
0	O
1	O
n	O
diarization	B
systems	I
that	O
are	O
usually	O
employed	O
with	O
the	O
uniform	O
h1	O
:	O
x1	O
·	O
·	O
·	O
xi	O
∼	O
n	O
(	O
µ1	O
,	O
σ1	O
)	O
(	O
9	O
)	O
segmentation	B
method	B
in	O
section	O
2.4.2	O
and	O
section	O
2.4.3	O
.	O
xi+1	O
·	O
·	O
·	O
xn	O
∼	O
n	O
(	O
µ2	O
,	O
σ2	O
)	O
(	O
10	O
)	O
2.4.1	O
.	O
gmm	O
speaker	B
model	B
for	O
similarity	B
measure	O
thus	O
,	O
hypothesis	B
h	O
models	B
two	O
sample	O
windows	O
with	O
one	O
0	O
the	O
early	O
days	O
of	O
speaker	B
diarization	I
systems	I
were	O
based	O
on	O
gaussian	O
while	O
hypothesis	B
h	O
models	B
two	O
sample	O
windows	O
1	O
a	O
gmm	O
built	O
on	O
acoustic	B
features	I
such	O
as	O
the	O
mfccs	O
.	O
along	O
with	O
two	O
gaussians	O
.	O
using	O
the	O
eq	O
.	O
(	O
8)	O
,	O
the	O
maximum	O
likeli-	O
with	O
gmm	O
based	O
method	B
,	O
ahc	O
was	O
also	O
employed	O
for	O
clus-	O
hood	O
ratio	O
statistics	B
can	O
be	O
expressed	O
as	O
tering	O
,	O
resulting	O
in	O
the	O
speaker	B
homogeneous	O
clusters	O
.	O
while	O
r(i	O
)	O
=	O
n	O
log	B
|σ|	O
−	O
n	O
log	B
|σ	O
|	O
−	O
n	O
log	B
|σ	O
|	O
,	O
(	O
11	O
)	O
there	O
are	O
many	O
hypothesis	B
testing	O
methods	O
for	O
speech	B
segment	I
1	O
1	O
2	O
2	O
clustering	B
process	B
such	O
as	O
greedy	O
bic	B
[	O
110	O
]	O
,	O
glr	O
[	O
114	O
]	O
and	O
where	O
the	O
sample	O
covariance	O
σ	O
is	O
from	O
{	O
x	O
,	O
·	O
·	O
·	O
,	O
x	O
}	O
,	O
σ	O
is	O
from	O
kl	O
[	O
115	O
]	O
methods	O
,	O
greedy	O
bic	B
method	B
was	O
the	O
most	O
popular	O
1	O
n	O
1	O
{	O
x1	O
,	O
·	O
·	O
·	O
,	O
xi	O
}	O
and	O
σ2	O
is	O
from	O
{	O
xi+1	O
,	O
·	O
·	O
·	O
,	O
xn	O
}	O
.	O
finally	O
,	O
a	O
bic	B
value	O
approach	O
.	O
while	O
greedy	O
bic	B
method	B
also	O
employs	O
bic	B
value	O
as	O
between	O
two	O
models	B
is	O
expressed	O
:	O
in	O
speaker	B
change	I
point	B
detection	I
,	O
in	O
greedy	O
bic	B
method	B
,	O
bic	B
value	O
is	O
used	O
for	O
measuring	O
the	O
similarity	B
between	O
two	O
nodes	O
bic(i	O
)	O
=	O
r(i	O
)	O
−	O
λp	O
,	O
(	O
12	O
)	O
during	O
the	O
ahc	O
process	B
.	O
for	O
the	O
given	O
nodes	O
to	O
be	O
clustered	O
,	O
s	O
=	O
{	O
s	O
,	O
·	O
·	O
·	O
,	O
s	O
}	O
,	O
greedy	O
bic	B
method	B
model	B
each	O
node	O
s	O
as	O
a	O
where	O
p	O
is	O
the	O
penalty	O
term	O
[	O
110	O
]	O
deﬁned	O
as	O
multiva1riate	O
gakussian	O
distribution	O
n	O
(	O
µ	O
,	O
σ	O
)	O
where	O
µ	O
and	O
σi	O
are	O
i	O
i	O
i	O
i	O
(	O
cid:32	O
)	O
(	O
cid:33	O
)	O
mean	O
and	O
co	O
variance	O
matrix	O
of	O
the	O
merged	O
samples	O
in	O
the	O
node	O
1	O
1	O
p	O
=	O
d	O
+	O
d(d	O
+	O
1	O
)	O
log	B
n	O
,	O
(	O
13	O
)	O
s	O
.	O
bic	B
value	O
for	O
merging	O
the	O
node	O
s	O
and	O
s	O
is	O
calculated	O
as	O
2	O
2	O
i	O
1	O
2	O
and	O
d	O
is	O
dimension	O
of	O
the	O
feature	O
.	O
the	O
penalty	O
weight	B
λ	O
is	O
gen-	O
bic	B
=	O
n	O
log	B
|σ|	O
−	O
n1	O
log	B
|σ1|	O
−	O
n2	O
log	B
|σ2|	O
−	O
λp	O
,	O
(	O
15	O
)	O
erally	O
set	B
to	O
λ	O
=	O
1	O
.	O
the	O
change	B
point	O
is	O
set	B
when	O
the	O
following	O
equation	O
becomes	O
true	O
,	O
where	O
λ	O
and	O
p	O
value	O
are	O
identical	O
to	O
eq	O
.	O
(	O
12	O
)	O
and	O
n	O
is	O
sample	O
size	B
of	O
the	O
merged	O
node	O
(	O
n	O
=	O
n	O
+	O
n	O
)	O
.	O
during	O
the	O
clustering	B
(	O
cid:26	O
)	O
(	O
cid:27	O
)	O
1	O
2	O
process	B
,	O
we	O
merge	O
the	O
modes	O
if	O
eq	O
.	O
(	O
15	O
)	O
is	O
negative	O
.	O
gmm	O
max	O
bic(i	O
)	O
>	O
0	O
.	O
(	O
14	O
)	O
i	O
based	O
hypothesis	B
testing	O
method	B
with	O
bottom	O
-	O
up	O
hierarchical	O
clustering	B
method	B
was	O
popularly	O
used	O
until	O
i	O
-	O
vector	O
and	O
dnn-	O
as	O
described	O
above	O
,	O
the	O
speaker	B
change	I
points	O
can	O
be	O
detected	O
based	B
speaker	I
representations	O
dominate	O
the	O
speaker	B
diarization	I
by	O
using	O
hypothesis	B
testing	O
based	O
on	O
bic	B
values	B
or	O
other	O
meth-	O
research	B
scene	O
.	O
ods	O
such	O
as	O
kl2	O
[	O
10	O
]	O
,	O
glr	O
[	O
109	O
]	O
.	O
however	O
,	O
if	O
speech	O
seg-	O
mentation	O
is	O
done	O
by	O
speaker	B
change	I
point	B
detection	I
method	B
,	O
the	O
length	B
of	O
each	O
segment	B
is	O
not	O
consistent	O
.	O
therefore	O
,	O
after	O
2.4.2	O
.	O
joint	O
factor	B
analysis	I
and	O
i	O
-	O
vector	O
the	O
advent	O
of	O
i	O
-	O
vector	O
[	O
51	O
]	O
and	O
dnn	O
-	O
based	O
embeddings	O
[	O
61	O
]	O
before	O
the	O
advent	O
of	O
speaker	B
representations	O
such	O
as	O
i-	O
the	O
segmentation	B
based	O
on	O
speaker	B
change	I
point	B
detection	I
was	O
vector	O
[	O
51	O
]	O
or	O
x	O
-	O
vector	O
[	O
50	O
]	O
,	O
“	O
universal	O
background	O
model	B
”	O
mostly	O
replaced	O
by	O
uniform	O
segmentation	B
[	O
112	O
,	O
113	O
,	O
49	O
]	O
,	O
since	O
(	O
ubm	O
)	O
[	O
116	O
]	O
framework	O
showed	O
success	O
for	O
speaker	B
recogni-	O
varying	O
length	B
of	O
the	O
segment	B
created	O
an	O
additional	O
variability	O
tion	O
tasks	O
by	O
employing	O
a	O
large	O
mixture	O
of	O
gaussians	O
,	O
while	O
into	O
the	O
speaker	B
representation	O
and	O
deteriorated	O
the	O
ﬁdelity	O
of	O
covering	O
a	O
fairly	O
large	O
amount	B
of	O
speech	O
data	B
.	O
the	O
idea	O
of	O
the	O
speaker	B
representations	O
.	O
in	O
uniform	O
segmentation	B
schemes	O
,	O
modeling	O
and	O
testing	O
the	O
similarity	B
of	O
voice	O
characteristics	B
with	O
the	O
given	O
audio	O
stream	O
input	B
is	O
segmented	O
with	O
a	O
ﬁxed	O
win-	O
gmm	O
-	O
ubm	O
[	O
116	O
]	O
is	O
largely	O
improved	O
by	O
jfa	O
[	O
117	O
,	O
118	O
]	O
.	O
dow	O
length	B
and	O
overlap	O
length	B
.	O
thus	O
,	O
the	O
length	B
of	O
the	O
unit	O
of	O
gmm	O
-	O
ubm	O
based	O
hypothesis	B
testing	O
had	O
a	O
problem	O
of	O
max-	O
speaker	B
diarization	I
result	O
is	O
remains	O
ﬁxed	O
.	O
imum	O
a	O
posterior	O
(	O
map	O
)	O
adaptation	O
that	O
is	O
not	O
only	O
aﬀected	O
5by	O
speaker	B
-	O
speciﬁc	O
characteristics	B
but	O
also	O
other	O
nuisance	O
fac-	O
tors	O
such	O
as	O
channel	O
and	O
background	B
noise	I
.	O
therefore	O
,	O
the	O
con-	O
cept	O
of	O
supervector	O
generated	O
by	O
gmm	O
-	O
ubm	O
method	B
was	O
not	O
ideal	O
.	O
jfa	O
tackles	O
this	O
problem	O
and	O
decompose	O
a	O
supervector	O
into	O
speaker	B
independent	O
,	O
speaker	B
dependent	O
,	O
channel	O
depen-	O
dent	O
and	O
residual	O
components	B
.	O
thus	O
,	O
the	O
ideal	O
speaker	B
super-	O
vector	O
s	O
can	O
be	O
decomposed	O
as	O
in	O
the	O
eq	O
.	O
(	O
16	O
)	O
.	O
a	O
term	O
m	O
de-	O
notes	O
speaker	B
independent	O
component	O
,	O
u	O
denotes	O
channel	O
de-	O
pendent	O
component	O
matrix	O
,	O
and	O
d	O
denotes	O
speaker	B
-	O
dependent	O
residual	O
component	O
matrix	O
.	O
along	O
with	O
these	O
component	O
ma-	O
trices	O
,	O
vector	O
y	O
is	O
for	O
the	O
speaker	B
factors	O
,	O
vector	O
x	O
is	O
for	O
the	O
channel	O
factors	O
and	O
vector	O
z	O
is	O
for	O
the	O
speaker	B
-	O
speciﬁc	O
residual	O
factors	O
.	O
all	O
of	O
these	O
vectors	O
have	O
a	O
prior	O
distribution	O
of	O
n(0	O
,	O
1	O
)	O
.	O
m(s	O
)	O
=	O
m	O
+	O
vy	O
+	O
ux	O
+	O
dz	O
.	O
(	O
16	O
)	O
the	O
idea	O
of	O
jfa	O
approach	O
is	O
further	O
simpliﬁed	O
by	O
employing	O
fig	O
.	O
2	O
:	O
diagram	O
of	O
d	O
-	O
vector	O
model	B
.	O
the	O
so	O
called	O
“	O
total	O
variability	O
”	O
matrix	O
t	O
modeling	O
both	O
the	O
channel	O
and	O
the	O
speaker	B
variability	O
,	O
and	O
the	O
vector	O
w	O
which	O
is	O
referred	O
to	O
as	O
the	O
“	O
i	O
-	O
vector	O
”	O
[	O
51	O
]	O
.	O
the	O
supervector	O
m	O
is	O
modeled	O
as	O
:	O
m	O
=	O
m	O
+	O
tw	O
,	O
(	O
17	O
)	O
in	O
eq	O
.	O
(	O
17	O
)	O
,	O
m	O
is	O
the	O
session	O
and	O
channel	O
-	O
independent	O
com-	O
ponent	O
of	O
the	O
mean	O
supervector	O
.	O
similarly	O
to	O
jfa	O
,	O
w	O
is	O
as-	O
sumed	O
to	O
follow	O
standard	O
normal	O
distribution	O
and	O
calculated	O
by	O
map	O
estimation	B
,	O
in	O
[	O
119	O
]	O
.	O
the	O
notion	O
of	O
speaker	B
representa-	O
tion	O
is	O
popularized	O
by	O
i	O
-	O
vectors	O
,	O
where	O
the	O
speaker	B
represen-	O
tation	O
vector	O
can	O
contain	O
a	O
numerical	O
feature	O
that	O
characterize	O
the	O
vocal	O
tract	O
of	O
each	O
speaker	B
.	O
the	O
i	O
-	O
vector	O
speaker	B
represen-	O
tations	O
have	O
employed	O
in	O
not	O
only	O
speaker	B
recognition	O
studies	O
but	O
also	O
in	O
numerous	O
speaker	B
diarization	I
studies	O
[	O
112	O
,	O
120	O
,	O
121	O
]	O
and	O
showed	O
superior	O
performance	O
over	O
gmm	O
-	O
based	O
hypothesis	B
testing	O
methods	O
.	O
2.4.3	O
.	O
neural	B
network	I
based	B
speaker	I
representations	O
fig	O
.	O
3	O
:	O
diagram	O
of	O
x	O
-	O
vector	O
embedding	O
extractor	B
.	O
speaker	B
representations	O
for	O
speaker	B
diarization	I
has	O
also	O
been	O
heavily	O
aﬀected	O
by	O
the	O
rise	O
of	O
neural	B
networks	I
and	O
deep	O
learn-	O
ing	O
approaches	O
.	O
the	O
idea	O
of	O
representation	O
learning	O
was	O
ﬁrst	O
with	O
the	O
cross	O
entropy	O
loss	O
.	O
the	O
d	O
-	O
vector	O
embeddings	O
are	O
ob-	O
introduced	O
for	O
face	O
recognition	O
tasks	O
[	O
122	O
,	O
123	O
]	O
.	O
the	O
fun-	O
tained	O
in	O
the	O
last	O
fully	O
connected	O
layer	B
as	O
in	O
fig	O
.	O
2	O
.	O
the	O
d	O
-	O
vector	O
damental	O
idea	O
of	O
neural	B
network	I
-	O
based	O
representations	O
is	O
that	O
scheme	O
appears	O
in	O
numerous	O
speaker	B
diarization	I
papers	O
,	O
e.g.	O
,	O
in	O
we	O
can	O
use	O
deep	O
neural	B
network	I
architecture	B
to	O
map	O
the	O
in-	O
[	O
49	O
,	O
55	O
]	O
.	O
put	O
signal	B
source	B
(	O
an	O
image	O
or	O
an	O
audio	O
clip	O
)	O
to	O
a	O
dense	O
vec-	O
dnn	O
-	O
based	B
speaker	I
representations	O
are	O
even	O
more	O
improved	O
tor	O
by	O
sampling	O
the	O
activations	O
of	O
a	O
layer	B
in	O
the	O
neural	B
network	I
by	O
x	O
-	O
vector	O
[	O
62	O
,	O
50	O
]	O
.	O
the	O
x	O
-	O
vector	O
showed	O
a	O
superior	O
per-	O
model	B
.	O
the	O
neural	B
network	I
based	O
representation	O
does	O
not	O
re-	O
formance	O
by	O
winning	O
the	O
nist	O
speaker	B
recognition	O
challenge	B
quire	O
eigenvalue	O
decomposition	O
or	O
factor	B
analysis	I
model	B
that	O
[	O
124	O
]	O
and	O
the	O
ﬁrst	O
dihard	B
challenge	I
[	O
84	O
]	O
.	O
fig	O
.	O
3	O
shows	O
the	O
involves	O
hand	O
-	O
crafted	O
design	O
of	O
the	O
intrinsic	O
factor	B
.	O
also	O
,	O
there	O
structure	O
of	O
x	O
-	O
vector	O
framework	O
.	O
the	O
time	B
-	O
delay	O
architecture	B
is	O
no	O
assumption	O
or	O
requirement	O
of	O
gaussianity	O
for	O
the	O
input	B
and	O
statistical	O
pooling	O
layer	B
diﬀerentiate	O
x	O
-	O
vector	O
architecture	B
data	B
.	O
thus	O
,	O
the	O
representation	O
learning	O
process	B
has	O
become	O
from	O
d	O
-	O
vector	O
while	O
statistical	O
pooling	O
layer	B
mitigates	O
the	O
eﬀect	O
more	O
straight	O
-	O
forward	O
and	O
the	O
inference	B
speed	O
has	O
been	O
also	O
im-	O
of	O
the	O
input	B
length	B
.	O
this	O
is	O
especially	O
advantageous	O
when	O
it	O
proved	O
compared	O
to	O
the	O
traditional	O
factor	B
analysis	I
based	O
meth-	O
comes	O
to	O
speaker	B
diarization	I
since	O
the	O
speaker	B
diarization	I
sys-	O
ods	O
.	O
tems	O
are	O
bound	O
to	O
process	B
segments	O
that	O
are	O
shorter	O
than	O
the	O
among	O
many	O
of	O
the	O
neural	B
network	I
based	B
speaker	I
repre-	O
regular	O
window	O
length	B
.	O
sentations	O
,	O
d	O
-	O
vector	O
[	O
61	O
]	O
remains	O
one	O
of	O
the	O
most	O
prominent	O
for	O
speaker	B
diarization	I
tasks	O
,	O
“	O
probabilistic	O
linear	O
distcrim-	O
speaker	B
representation	O
extraction	B
frameworks	O
.	O
the	O
d	O
-	O
vector	O
inant	O
analysis	B
”	O
(	O
plda	B
)	O
has	O
been	O
frequently	O
used	O
along	O
with	O
employs	O
stacked	O
ﬁlterbank	O
features	O
that	O
include	O
context	O
frames	O
x	O
-	O
vector	O
or	O
i	O
-	O
vector	O
to	O
measure	O
the	O
aﬃnity	O
between	O
two	O
speech	O
as	O
an	O
input	B
feature	O
and	O
trains	O
a	O
multiple	O
fully	O
connected	O
layers	O
segments	O
.	O
plda	B
employs	O
the	O
following	O
modeling	O
for	O
the	O
given	O
6speaker	O
representation	O
φ	O
of	O
the	O
i	O
-	O
th	O
speaker	B
and	O
j	O
-	O
th	O
session	O
as	O
i	O
j	O
below	O
:	O
φ	O
=	O
µ	O
+	O
fh	O
+	O
gw	O
+	O
(	O
cid:15	O
)	O
.	O
(	O
18	O
)	O
i	O
j	O
i	O
i	O
j	O
i	O
j	O
here	O
,	O
m	O
is	O
mean	O
vector	O
,	O
f	O
is	O
speaker	B
variability	O
matrix	O
,	O
g	O
is	O
channel	O
variability	O
matrix	O
and	O
(	O
cid:15	O
)	O
is	O
residual	O
component	O
.	O
the	O
terms	B
h	O
and	O
w	O
are	O
latent	O
variable	O
for	O
f	O
and	O
g	O
respectively	O
.	O
i	O
i	O
j	O
during	O
the	O
training	O
process	B
of	O
plda	B
,	O
m	O
,	O
σ	O
,	O
f	O
and	O
g	O
are	O
esti-	O
mated	O
using	O
expectation	O
maximization	O
(	O
em	O
)	O
algorithm	O
where	O
σ	O
is	O
a	O
covariance	O
matrix	O
.	O
based	O
on	O
the	O
estimated	O
variability	O
fig	O
.	O
4	O
:	O
agglomerative	O
hierarchical	O
clustering	B
.	O
matrices	O
and	O
the	O
latent	O
variables	O
h	O
and	O
w	O
,	O
two	O
hypotheses	B
are	O
i	O
i	O
j	O
tested	O
:	O
hypothesis	B
h	O
for	O
the	O
case	O
that	O
two	O
samples	O
are	O
from	O
the	O
0	O
same	B
speaker	I
and	O
hypothesis	B
h	O
for	O
the	O
case	O
that	O
two	O
samples	O
1	O
are	O
from	O
diﬀerent	O
speakers	O
.	O
the	O
hypothesis	B
h	O
can	O
be	O
written	O
0	O
as	O
follows	O
:	O
	O
	O
(	O
cid:34	O
)	O
φφ12	O
(	O
cid:35	O
)	O
=	O
(	O
cid:34	O
)	O
µµ	O
(	O
cid:35	O
)	O
+	O
(	O
cid:34	O
)	O
ff	O
g0	O
0	O
g	O
(	O
cid:35	O
)	O
	O
hww112	O
	O
+	O
(	O
cid:34	O
)	O
(	O
cid:15)(cid:15)12	O
(	O
cid:35	O
)	O
.	O
(	O
19	O
)	O
2	O
on	O
the	O
other	O
hand	O
,	O
the	O
hypothesis	B
h	O
can	O
be	O
modeled	O
as	O
the	O
1	O
following	O
equation	O
.	O
	O
	O
h	O
(	O
cid:34	O
)	O
φφ12	O
(	O
cid:35	O
)	O
=	O
(	O
cid:34	O
)	O
µµ	O
(	O
cid:35	O
)	O
+	O
(	O
cid:34	O
)	O
f0	O
g0	O
f0	O
g0	O
(	O
cid:35	O
)	O
	O
wh121	O
	O
+	O
(	O
cid:34	O
)	O
(	O
cid:15)(cid:15)12	O
(	O
cid:35	O
)	O
.	O
(	O
20	O
)	O
fig	O
.	O
5	O
:	O
general	O
steps	B
of	O
spectral	O
clustering	B
.	O
w	O
2	O
3	O
.	O
shift	O
the	O
search	O
window	O
to	O
the	O
new	O
mean	O
.	O
the	O
plda	B
model	B
projects	O
the	O
given	O
speaker	B
representation	O
onto	O
the	O
subspace	O
f	O
to	O
co	O
-	O
vary	O
the	O
most	O
while	O
de	O
-	O
emphasizing	O
4	O
.	O
repeat	O
the	O
process	B
until	O
convergence	O
.	O
the	O
subspace	O
g	O
pertaining	O
to	O
channel	O
variability	O
.	O
using	O
the	O
above	O
hypotheses	B
,	O
we	O
can	O
calculate	O
a	O
log	B
likelihood	B
ratio	I
.	O
mean	O
-	O
shift	O
clustering	B
algorithm	O
was	O
applied	O
to	O
speaker	B
diariza-	O
tion	O
task	O
with	O
kl	O
distance	B
[	O
126	O
]	O
,	O
i	O
-	O
vector	O
and	O
cosine	O
distance	B
s	O
(	O
φ1	O
,	O
φ2	O
)	O
=	O
log	B
p	O
(	O
φ1	O
,	O
φ2	O
|	O
h0	O
)	O
−	O
log	B
p	O
(	O
φ1	O
,	O
φ2	O
|	O
h1	O
)	O
.	O
(	O
21	O
)	O
in	O
[	O
112	O
,	O
127	O
]	O
and	O
i	O
-	O
vector	O
and	O
plda	B
[	O
128	O
]	O
.	O
the	O
advantage	O
of	O
mean	O
-	O
shift	O
clustering	B
algorithm	O
is	O
that	O
the	O
clustering	B
algo-	O
ideally	O
,	O
stopping	O
criterion	B
should	O
be	O
0	O
,	O
but	O
in	O
practice	O
it	O
varies	O
rithm	O
does	O
not	O
require	O
the	O
number	O
of	O
clusters	O
in	O
advance	O
unlike	O
from	O
around	O
zero	O
values	B
and	O
the	O
stopping	O
criterion	B
needs	O
to	O
be	O
k	O
-	O
means	O
clustering	B
methods	O
.	O
this	O
becomes	O
a	O
signiﬁcant	O
advan-	O
tuned	O
on	O
development	B
set	I
.	O
the	O
stopping	O
criterion	B
largely	O
aﬀects	O
tage	O
in	O
speaker	B
diarization	I
tasks	O
where	O
the	O
number	O
of	O
speakers	O
the	O
estimated	O
number	O
of	O
speakers	O
because	O
the	O
clustering	B
pro-	O
is	O
unknown	O
as	O
in	O
most	O
of	O
the	O
applications	O
.	O
cess	O
stops	O
when	O
the	O
distance	B
between	O
closest	O
samples	O
reaches	O
threshold	B
and	O
the	O
number	O
of	O
clusters	O
is	O
determined	O
by	O
the	O
num-	O
2.5.2	O
.	O
agglomerative	O
hierarchical	O
clustering	B
(	O
ahc	O
)	O
ber	O
of	O
remaining	O
clusters	O
at	O
the	O
step	O
where	O
clustering	B
is	O
stopped	O
.	O
ahc	O
is	O
a	O
clustering	B
method	B
that	O
has	O
been	O
constantly	O
em-	O
ployed	O
in	O
many	O
speaker	B
diarization	I
systems	I
with	O
a	O
number	O
of	O
2.5	O
.	O
clustering	B
diﬀerent	O
distance	B
metric	B
such	O
as	O
bic	B
[	O
110	O
,	O
129	O
]	O
,	O
kl	O
[	O
115	O
]	O
and	O
after	O
generating	O
the	O
speaker	B
representations	O
for	O
each	O
seg-	O
plda	B
[	O
84	O
,	O
90	O
,	O
130	O
]	O
.	O
ahc	O
is	O
an	O
iterative	O
process	B
of	O
merging	O
ment	O
,	O
clustering	B
algorithm	O
is	O
applied	O
to	O
make	O
clusters	O
of	O
seg-	O
the	O
existing	O
clusters	O
until	O
the	O
clustering	B
process	B
meets	O
a	O
crite-	O
ments	O
.	O
we	O
introduce	O
the	O
most	O
commonly	O
used	O
clustering	B
meth-	O
rion	O
.	O
ahc	O
process	B
starts	O
by	O
calculating	O
the	O
similarity	B
between	O
ods	O
for	O
speaker	B
diarization	I
task	O
.	O
n	O
singleton	O
clusters	O
.	O
at	O
each	O
step	O
,	O
a	O
pair	O
of	O
clusters	O
that	O
has	O
the	O
highest	O
similarity	B
is	O
merged	O
.	O
the	O
iterative	O
merging	O
process	B
of	O
2.5.1	O
.	O
mean	O
-	O
shift	O
ahc	O
produces	O
a	O
dendrogram	O
which	O
is	O
depicted	O
in	O
fig	O
.	O
4	O
.	O
mean	O
-	O
shift	O
[	O
125	O
]	O
is	O
a	O
clustering	B
algorithm	O
that	O
assigns	O
the	O
one	O
of	O
the	O
most	O
important	O
aspect	O
of	O
ahc	O
is	O
the	O
stopping	O
given	O
data	B
points	O
to	O
the	O
clusters	O
iteratively	O
by	O
ﬁnding	O
the	O
modes	O
criterion	B
.	O
for	O
speaker	B
diarization	I
task	O
,	O
ahc	O
process	B
can	O
be	O
in	O
a	O
non	O
-	O
parametric	O
distribution	O
.	O
mean	O
-	O
shift	O
algorithm	O
follows	O
stopped	O
using	O
either	O
a	O
similarity	B
threshold	B
or	O
a	O
target	O
number	O
the	O
following	O
steps	B
:	O
of	O
clusters	O
.	O
ideally	O
,	O
if	O
plda	B
is	O
employed	O
as	O
distance	B
metric	B
,	O
the	O
ahc	O
process	B
should	O
be	O
stopped	O
at	O
s	O
(	O
φ	O
,	O
φ	O
)	O
=	O
0	O
in	O
eq	O
.	O
1	O
.	O
start	O
with	O
the	O
data	B
points	O
assigned	O
to	O
a	O
cluster	O
of	O
their	O
own	O
.	O
1	O
2	O
(	O
18	O
)	O
.	O
however	O
,	O
it	O
is	O
widely	O
employed	O
that	O
the	O
stopping	O
metric	B
2	O
.	O
compute	O
a	O
mean	O
for	O
the	O
each	O
group	O
.	O
is	O
adjusted	O
to	O
get	O
an	O
accurate	O
number	O
of	O
clusters	O
based	O
on	O
a	O
7development	O
set	B
.	O
on	O
the	O
other	O
hand	O
,	O
if	O
the	O
number	O
of	O
speakers	O
while	O
choosing	O
σ	O
by	O
using	O
predeﬁned	O
scalar	O
value	O
β	O
and	O
vari-	O
is	O
known	O
or	O
estimated	O
by	O
other	O
methods	O
,	O
ahc	O
process	B
can	O
be	O
ance	O
values	B
from	O
the	O
data	B
points	O
while	O
the	O
speaker	B
diarization	I
stopped	O
when	O
the	O
clusters	O
created	O
by	O
ahc	O
process	B
reaches	O
the	O
system	O
in	O
[	O
134	O
]	O
did	O
not	O
use	O
β	O
value	O
for	O
njw	O
algorithm	O
.	O
on	O
the	O
pre	O
-	O
determined	O
number	O
of	O
speaker	B
k.	O
other	O
hand	O
,	O
in	O
the	O
speaker	B
diarization	I
system	I
in	O
[	O
52	O
]	O
,	O
σ2	O
=	O
0.5	O
for	O
njw	O
algorithm	O
.	O
2.5.3	O
.	O
spectral	O
clustering	B
aside	O
from	O
njw	O
spectral	O
clustering	B
algorithm	O
,	O
many	O
other	O
spectral	O
clustering	B
is	O
another	O
popular	O
clustering	B
approach	O
types	O
of	O
spectral	O
clustering	B
were	O
successfully	O
applied	O
to	O
speaker	B
for	O
speaker	B
diarization	I
.	O
while	O
there	O
are	O
many	O
variations	O
,	O
spec-	O
diarization	B
task	O
.	O
the	O
speaker	B
diarization	I
system	I
in	O
[	O
49	O
]	O
em-	O
tral	O
clustering	B
involves	O
the	O
following	O
steps	B
.	O
ployed	O
gaussian	O
blur	O
for	O
aﬃnity	O
values	B
,	O
diﬀusion	O
process	B
y	O
=	O
xxt	O
and	O
row	O
-	O
wise	O
max	O
normalization	O
(	O
y	O
=	O
x	O
/	O
max	O
x	O
)	O
.	O
i	O
j	O
i	O
j	O
k	O
ik	O
i.	O
aﬃnity	O
matrix	O
calculation	O
:	O
there	O
are	O
many	O
ways	O
to	O
gen-	O
in	O
the	O
spectral	O
clustering	B
approach	O
appeared	O
in	O
[	O
135	O
]	O
,	O
similar-	O
erate	O
an	O
aﬃnity	O
matrix	O
a	O
depending	O
on	O
the	O
way	O
the	O
aﬃnity	O
ity	O
values	B
that	O
are	O
calculated	O
from	O
a	O
neural	B
network	I
model	B
were	O
value	O
is	O
processed	O
.	O
the	O
raw	O
aﬃnity	O
value	O
d	O
is	O
processed	O
used	O
without	O
any	O
kernel	O
,	O
and	O
the	O
unnormalized	O
graph	O
laplacian	O
(	O
cid:16	O
)	O
(	O
cid:17	O
)	O
by	O
kernel	O
such	O
as	O
exp	O
−d2	O
/	O
σ2	O
where	O
σ	O
is	O
a	O
scaling	O
pa-	O
is	O
employed	O
to	O
perform	O
spectral	O
clustering	B
.	O
more	O
recently	O
,	O
auto-	O
rameter	O
.	O
on	O
the	O
other	O
hand	O
,	O
the	O
raw	O
aﬃnity	O
value	O
d	O
could	O
tuning	O
spectral	O
clustering	B
method	B
was	O
proposed	O
for	O
speaker	B
di-	O
also	O
be	O
masked	O
by	O
zeroing	O
the	O
values	B
below	O
a	O
threshold	B
to	O
arization	O
task	O
[	O
136	O
]	O
where	O
the	O
proposed	O
clustering	B
method	B
does	O
only	O
keep	O
the	O
prominent	O
values	B
.	O
not	O
require	O
parameter	O
tuning	O
on	O
a	O
separate	O
development	B
set	I
.	O
the	O
work	O
in	O
[	O
136	O
]	O
employs	O
binarized	O
aﬃnity	O
matrix	O
with	O
the	O
ii	O
.	O
laplacian	O
matrix	O
calculation	O
[	O
131	O
]	O
:	O
the	O
graph	O
laplacian	O
row	O
-	O
wise	O
count	O
p	O
and	O
the	O
binarization	O
parameter	O
p	O
is	O
selected	O
can	O
be	O
calculated	O
in	O
the	O
following	O
two	O
types	O
;	O
normalized	O
by	O
choosing	O
the	O
minimum	O
value	O
of	O
r(p	O
)	O
=	O
p	O
/	O
g	O
where	O
g	O
rep-	O
p	O
p	O
and	O
unnormalized	O
.	O
the	O
degree	O
matrix	O
d	O
contains	O
diagonal	O
resents	O
the	O
maximum	O
eigengap	O
from	O
the	O
unnormalized	O
graph	O
elements	O
d	O
=	O
(	O
cid:80)n	O
a	O
where	O
a	O
is	O
the	O
element	O
of	O
the	O
i	O
-	O
th	O
laplacian	O
matrix	O
.	O
thus	O
,	O
r(p	O
)	O
represents	O
how	O
clear	O
the	O
clusters	O
i	O
j=1	O
i	O
j	O
i	O
j	O
row	O
and	O
j	O
-	O
th	O
column	O
in	O
an	O
aﬃnity	O
matrix	O
a.	O
are	O
for	O
the	O
given	O
value	O
p	O
and	O
p	O
could	O
be	O
automatically	O
selected	O
to	O
perform	O
spectral	O
clustering	B
without	O
tuning	O
the	O
p	O
-	O
value	O
.	O
(	O
a	O
)	O
normalized	O
graph	O
laplacian	O
:	O
2.6	O
.	O
post	O
-	O
processing	B
l	O
=	O
d−1/2ad−1/2	O
.	O
(	O
22	O
)	O
2.6.1	O
.	O
resegmentation	B
resegmentation	B
is	O
a	O
process	B
to	O
reﬁne	O
the	O
speaker	B
boundary	O
(	O
b	O
)	O
unnormalized	O
graph	O
laplacian	O
:	O
that	O
is	O
roughly	O
estimated	O
by	O
the	O
clustering	B
procedure	O
.	O
in	O
[	O
137	O
]	O
,	O
l	O
=	O
d	O
−	O
a.	O
(	O
23	O
)	O
viterbi	O
resegmentation	B
method	B
based	O
on	O
the	O
baum	O
-	O
welch	O
al-	O
gorithm	O
was	O
introduced	O
.	O
in	O
this	O
method	B
,	O
estimation	B
of	O
gaus-	O
iii	O
.	O
eigen	O
decomposition	O
:	O
the	O
graph	O
laplacian	O
matrix	O
l	O
is	O
sian	O
mixture	O
model	B
corresponding	O
to	O
each	O
speaker	B
and	O
viterbi-	O
decomposed	O
into	O
the	O
eigenvector	O
matrix	O
x	O
and	O
the	O
diago-	O
algorithm	O
-	O
based	O
resgmentation	O
by	O
using	O
the	O
estimated	O
speaker	B
nal	O
matrix	O
that	O
contains	O
eigenvalues	O
.	O
thus	O
,	O
l	O
=	O
xλx(cid:62	O
)	O
.	O
gmm	O
are	O
alternately	O
applied	O
.	O
later	O
,	O
a	O
method	B
to	O
represent	O
the	O
diarization	B
process	B
based	O
on	O
iv	O
.	O
re	O
-	O
normalization	O
(	O
optional	O
)	O
:	O
the	O
rows	O
of	O
x	O
is	O
normalized	O
variational	O
bayeian	O
hidden	O
markov	O
model	B
(	O
vb	O
-	O
hmm	O
)	O
was	O
so	O
that	O
y	O
=	O
x	O
/	O
(	O
cid:16)(cid:80	O
)	O
x2	O
(	O
cid:17)1/2	O
where	O
x	O
and	O
y	O
are	O
the	O
ele-	O
proposed	O
,	O
and	O
was	O
shown	O
to	O
be	O
superior	O
as	O
a	O
resegmentation	B
i	O
j	O
i	O
j	O
j	O
i	O
j	O
i	O
j	O
i	O
j	O
ments	O
of	O
the	O
i	O
-	O
th	O
row	O
and	O
j	O
-	O
th	O
column	O
in	O
matrix	O
x	O
and	O
y	O
,	O
method	B
compared	O
to	O
viterbi	O
resegmentation	B
[	O
138	O
,	O
139	O
,	O
140	O
]	O
.	O
respectively	O
.	O
in	O
the	O
vb	O
-	O
hmm	O
framework	O
,	O
the	O
speech	O
feature	O
x	O
=	O
(	O
xt|t	O
=	O
1	O
,	O
...	O
,	O
t	O
)	O
is	O
assumed	O
to	O
be	O
generated	O
from	O
hmm	O
where	O
each	O
v.	O
speaker	B
counting	O
:	O
speaker	B
number	O
is	O
estimated	O
by	O
ﬁnd-	O
hmm	O
state	O
corresponds	O
to	O
one	O
of	O
k	O
possible	O
speakers	O
.	O
given	O
ing	O
the	O
maximum	O
eigengap	O
.	O
we	O
have	O
m	O
hmm	O
states	O
,	O
m	O
-	O
dimensional	O
variable	O
z	O
=	O
(	O
z	O
|t	O
=	O
t	O
1	O
,	O
...	O
,	O
t	O
)	O
is	O
introduced	O
where	O
k	O
-	O
th	O
element	O
of	O
z	O
is	O
1	O
if	O
k	O
-	O
th	O
t	O
vi	O
.	O
k	O
-	O
means	O
clustering	B
:	O
the	O
k	O
-	O
smallest	O
eigenvalues	O
λ	O
,	O
λ	O
,	O
...	O
,	O
1	O
2	O
speaker	B
is	O
speaking	O
at	O
the	O
time	B
index	O
t	O
,	O
and	O
0	O
otherwise	O
.	O
at	O
the	O
λ	O
and	O
the	O
corresponding	O
eigenvectors	O
v	O
,	O
v	O
,	O
...	O
,	O
v	O
are	O
n	O
1	O
2	O
k	O
same	O
time	B
,	O
the	O
distribution	O
of	O
x	O
is	O
modeled	O
based	O
on	O
a	O
hidden	O
used	O
to	O
make	O
u	O
∈	O
rm×n	O
where	O
m	O
is	O
dimension	O
of	O
the	O
row	O
variable	O
y	O
=	O
{	O
y	O
|i	O
=	O
1	O
,	O
...	O
,	O
k	O
}	O
,	O
twhere	O
y	O
is	O
a	O
low	O
dimensional	O
k	O
k	O
vectors	O
in	O
u.	O
finally	O
,	O
the	O
row	O
vectors	O
u	O
,	O
u	O
,	O
...	O
,	O
u	O
are	O
clus-	O
1	O
2	O
n	O
vector	O
for	O
k	O
-	O
th	O
speaker	B
.	O
given	O
these	O
notation	O
,	O
the	O
joint	O
proba-	O
tered	O
by	O
k	O
-	O
means	O
algorithm	O
.	O
bility	O
of	O
x	O
,	O
y	O
,	O
and	O
z	O
is	O
decomposed	O
as	O
among	O
many	O
variations	O
of	O
spectral	O
clustering	B
algorithm	O
,	O
ng-	O
p(x	O
,	O
z	O
,	O
y	O
)	O
=	O
p(x|z	O
,	O
y)p(z)p(y	O
)	O
,	O
(	O
24	O
)	O
jordan	O
-	O
weiss	O
(	O
njw	O
)	O
algorithm	O
[	O
132	O
]	O
is	O
often	O
employed	O
for	O
speaker	B
diarization	I
task	O
.	O
njw	O
algorithm	O
employs	O
a	O
kernel	O
where	O
p(x|z	O
,	O
y	O
)	O
is	O
the	O
emission	O
probability	B
modeled	O
by	O
gmm	O
(	O
cid:16	O
)	O
(	O
cid:17	O
)	O
exp	O
−d2	O
/	O
σ2	O
where	O
d	O
is	O
a	O
raw	O
distance	B
for	O
calculating	O
an	O
aﬃn-	O
whose	O
mean	O
vector	O
is	O
represented	O
by	O
y	O
,	O
p(z	O
)	O
is	O
the	O
transition	O
ity	O
matrix	O
.	O
the	O
aﬃnity	O
matrix	O
is	O
used	O
for	O
calculating	O
a	O
nor-	O
probability	B
of	O
the	O
hmm	O
,	O
and	O
p(y	O
)	O
is	O
the	O
prior	O
distribution	O
of	O
y.	O
malized	O
graph	O
laplacian	O
.	O
in	O
addition	O
,	O
njw	O
algorithm	O
involves	O
because	O
z	O
represents	O
the	O
trajectory	O
of	O
speakers	O
,	O
the	O
diarization	B
renormalization	O
before	O
the	O
k	O
-	O
means	O
clustering	B
process	B
.	O
the	O
problem	O
can	O
be	O
expressed	O
as	O
the	O
inference	B
problem	O
of	O
z	O
that	O
(	O
cid:82	O
)	O
speaker	B
diarization	I
system	I
in	O
[	O
133	O
]	O
employed	O
njw	O
algorithm	O
maximize	O
the	O
posterior	O
distribution	O
p(z|x	O
)	O
=	O
p(z	O
,	O
y|x)dy	O
.	O
8since	O
it	O
is	O
intractable	O
to	O
directory	O
solve	O
this	O
problem	O
,	O
varia-	O
tional	O
bayes	O
method	B
is	O
used	O
to	O
estimate	O
the	O
model	B
parameters	O
that	O
approximate	O
p(z	O
,	O
y|x	O
)	O
[	O
139	O
,	O
141	O
]	O
.	O
the	O
vb	O
-	O
hmm	O
frame-	O
work	O
was	O
originally	O
designed	O
as	O
a	O
standalone	O
diarization	B
frame-	O
work	O
.	O
however	O
,	O
it	O
requires	O
the	O
parameter	O
initialization	O
to	O
start	O
vb	O
estimation	B
,	O
and	O
the	O
parameters	O
are	O
usually	O
initialized	O
based	O
on	O
the	O
result	O
of	O
speaker	B
clustering	B
.	O
in	O
that	O
context	O
,	O
vb	O
-	O
hmm	O
can	O
be	O
seen	O
as	O
a	O
resegmentation	B
method	B
,	O
and	O
widely	O
used	O
as	O
the	O
ﬁnal	O
step	O
of	O
speaker	B
diarization	I
(	O
e.g.	O
,	O
[	O
142	O
,	O
113	O
]	O
)	O
.	O
2.6.2	O
.	O
system	O
fusion	O
as	O
another	O
direction	O
of	O
post	O
processing	B
,	O
there	O
have	O
been	O
a	O
series	O
of	O
studies	O
on	O
the	O
fusion	O
method	B
of	O
multiple	O
diariza-	O
tion	O
results	B
to	O
improve	O
the	O
diarization	B
accuracy	O
.	O
while	O
it	O
is	O
widely	O
known	O
that	O
the	O
system	O
combination	O
generally	O
yields	O
bet-	O
ter	O
result	O
for	O
various	O
systems	O
(	O
e.g.	O
,	O
speech	B
recognition	I
[	O
143	O
]	O
or	O
speaker	B
recognition	O
[	O
144	O
]	O
)	O
,	O
combining	O
multiple	O
diarization	B
hy-	O
potheses	O
has	O
several	O
unique	O
problems	O
.	O
firstly	O
,	O
the	O
speaker	B
la-	O
beling	O
is	O
not	O
standardized	O
among	O
diﬀerent	O
diarization	B
systems	I
.	O
secondly	O
,	O
the	O
estimated	O
number	O
of	O
speakers	O
may	O
diﬀer	O
among	O
diﬀerent	O
diarization	B
systems	I
.	O
finally	O
,	O
the	O
estimated	O
time	B
bound-	O
aries	O
may	O
be	O
also	O
diﬀerent	O
among	O
multiple	O
diarization	B
systems	I
.	O
system	O
combination	O
methods	O
for	O
speaker	B
diarization	I
systems	I
fig	O
.	O
6	O
:	O
example	O
of	O
dover	O
system	O
.	O
need	O
to	O
handle	O
these	O
problems	O
during	O
the	O
fusion	O
process	B
of	O
mul-	O
tiple	O
hypotheses	B
.	O
in	O
[	O
145	O
]	O
,	O
a	O
method	B
to	O
select	O
the	O
best	O
diarization	B
result	O
among	O
proposed	O
a	O
method	B
called	O
dover	O
-	O
lap	O
,	O
in	O
which	O
the	O
speak-	O
multiple	O
diarization	B
systems	I
were	O
proposed	O
.	O
in	O
this	O
method	B
,	O
ers	O
of	O
multiple	O
hypothesis	B
are	O
aligned	O
by	O
a	O
weighted	O
k	O
-	O
partite	O
ahc	O
is	O
applied	O
on	O
the	O
set	B
of	O
diarization	B
results	B
where	O
the	O
dis-	O
graph	O
matching	O
,	O
and	O
the	O
number	O
of	O
speakers	O
k	O
for	O
each	O
small	O
tance	O
of	O
two	O
diarization	B
results	B
are	O
mesured	O
by	O
symmetric	O
der	O
.	O
segment	B
is	O
estimated	O
based	O
on	O
the	O
weighted	O
average	B
of	O
multi-	O
ahc	O
is	O
executed	O
until	O
the	O
number	O
of	O
groups	O
becomes	O
two	O
,	O
and	O
ple	O
systems	O
to	O
select	O
the	O
top	O
-	O
k	O
voted	O
speaker	B
labels	I
.	O
both	O
the	O
the	O
diarization	B
result	O
that	O
has	O
the	O
smallest	O
distance	B
to	O
all	O
other	O
modiﬁed	O
dover	O
and	O
dover	O
-	O
lap	O
showed	O
the	O
improvement	O
results	B
in	O
the	O
biggest	O
group	O
is	O
selected	O
as	O
the	O
ﬁnal	O
diarization	B
re-	O
of	O
der	O
for	O
the	O
speaker	B
diarization	I
result	O
with	O
speaker	B
overlaps	B
.	O
sult	O
.	O
in	O
[	O
146	O
]	O
,	O
two	O
diarization	B
systems	I
are	O
combined	O
by	O
ﬁnding	O
the	O
matching	O
between	O
two	O
speaker	B
clusters	O
,	O
and	O
then	O
perform-	O
3	O
.	O
recent	O
advances	O
in	O
speaker	B
diarization	I
using	O
deep	O
ing	O
the	O
resegementation	O
based	O
on	O
the	O
matching	O
result	O
.	O
learning	O
more	O
recently	O
,	O
dover	O
(	O
diarization	B
output	B
voting	O
error	O
re-	O
duction	O
)	O
method	B
[	O
147	O
]	O
was	O
proposed	O
to	O
combine	O
multiple	O
di-	O
this	O
section	O
introduces	O
various	O
recent	O
eﬀorts	O
toward	O
deep	O
arization	O
results	B
based	O
on	O
the	O
voting	O
scheme	O
.	O
in	O
the	O
dover	O
learning	O
-	O
based	B
speaker	I
diarization	B
techniques	B
.	O
firstly	O
,	O
meth-	O
method	B
,	O
speaker	B
labels	I
among	O
diﬀerent	O
diarization	B
systems	I
are	O
ods	O
that	O
incorporate	O
deep	B
learning	I
into	O
a	O
single	O
component	O
of	O
aligned	O
one	O
by	O
one	O
to	O
minimize	O
der	O
between	O
the	O
hypotheses	B
speaker	B
diarization	I
,	O
such	O
as	O
clustering	B
or	O
post	O
-	O
processing	B
,	O
are	O
(	O
the	O
processes	O
2	O
and	O
3	O
of	O
fig	O
.	O
6	O
)	O
.	O
after	O
every	O
hypotheses	B
are	O
introduced	O
in	O
section	O
3.1	O
,	O
then	O
,	O
methods	O
that	O
unify	O
several	O
aligned	O
,	O
each	O
system	O
votes	O
its	O
speaker	B
label	O
to	O
each	O
segmented	O
components	B
of	O
speaker	B
diarization	I
into	O
a	O
single	O
neural	B
network	I
region	O
(	O
each	O
system	O
may	O
have	O
diﬀerent	O
weight	B
for	O
voting	O
)	O
,	O
and	O
are	O
introduced	O
in	O
section	O
3.2	O
,	O
the	O
speaker	B
label	O
that	O
gains	O
the	O
highest	O
voting	O
weight	B
is	O
selected	O
3.1	O
.	O
single	O
-	O
module	O
optimization	O
for	O
each	O
segmented	O
region	O
(	O
the	O
process	B
4	O
of	O
fig	O
.	O
6	O
)	O
.	O
in	O
case	O
of	O
3.1.1	O
.	O
speaker	B
clustering	B
enhanced	O
by	O
deep	B
learning	I
multiple	O
speaker	B
labels	I
get	O
the	O
same	O
voting	O
weight	B
,	O
a	O
heuris-	O
several	O
methods	O
that	O
enhance	O
the	O
speaker	B
clustering	B
based	O
tic	O
to	O
break	O
the	O
ties	O
(	O
such	O
as	O
selecting	O
the	O
result	O
from	O
the	O
ﬁrst	O
on	O
deep	B
learning	I
were	O
proposed	O
.	O
a	O
deep	O
-	O
learning	O
based	O
clus-	O
system	O
)	O
is	O
used	O
.	O
tering	O
algorithm	O
,	O
called	O
improved	O
deep	O
embedded	O
clustering	B
the	O
dover	O
method	B
has	O
an	O
implicit	O
assumption	O
that	O
there	O
(	O
idec	O
)	O
is	O
proposed	O
in	O
[	O
149	O
]	O
.	O
the	O
goal	O
is	O
to	O
transform	O
the	O
input	B
is	O
no	O
overlapping	B
speech	I
,	O
i.e.	O
,	O
at	O
most	O
only	O
1	O
speaker	B
is	O
as-	O
features	O
,	O
herein	O
speaker	B
embeddings	I
,	O
to	O
become	O
more	O
separa-	O
signed	O
for	O
each	O
time	B
index	O
.	O
to	O
combine	O
the	O
diarization	B
hy-	O
ble	O
,	O
given	O
the	O
number	O
of	O
clusters	O
/	O
speakers	O
.	O
the	O
key	O
idea	O
is	O
that	O
potheses	O
with	O
overlapping	B
speakers	O
,	O
two	O
methods	O
were	O
recently	O
each	O
embedding	O
has	O
a	O
probability	B
of	O
“	O
belonging	O
”	O
to	O
each	O
of	O
the	O
proposed	O
.	O
in	O
[	O
104	O
]	O
,	O
the	O
authors	O
proposed	O
the	O
modiﬁed	O
dover	O
method	B
,	O
where	O
the	O
speaker	B
labels	I
in	O
diﬀerent	O
diarization	B
results	B
available	O
speaker	B
cluster	O
[	O
150	O
,	O
64	O
]	O
,	O
are	O
ﬁrst	O
aligned	O
with	O
a	O
root	O
hypothesis	B
,	O
and	O
the	O
speech	O
activ-	O
(	O
cid:16	O
)	O
(	O
cid:17)−	O
a+1	O
1	O
+	O
(	O
cid:107)z	O
−	O
µ	O
(	O
cid:107)2	O
/	O
a	O
a	O
q2	O
/	O
f	O
istcyoroef	O
feoarcehacsphesapkeearkiesr	O
efsotrimeaactehdsmbaasleldseognmtehnet.wreaigj	O
hetteadl.v[o1t4in8	O
g	O
]	O
qi	O
j	O
=	O
(	O
cid:80)l	O
(	O
cid:0)1	O
+	O
(	O
cid:107)izi	O
−	O
jµl(cid:107)2	O
/	O
a(cid:1)−	O
a+a1	O
,	O
pi	O
j	O
=	O
(	O
cid:80)liqj	O
2il	O
/	O
ifl	O
(	O
25	O
)	O
9and	O
σ	O
(	O
·	O
)	O
is	O
a	O
nonlinear	O
function	O
.	O
gnn	O
was	O
optimized	O
by	O
min-	O
imizing	O
the	O
distance	B
between	O
the	O
reference	B
aﬃnity	O
matrix	O
and	O
estimated	O
aﬃnity	O
matrix	O
,	O
where	O
the	O
distance	B
was	O
calculated	O
by	O
a	O
combination	O
of	O
histogram	O
loss	O
[	O
151	O
]	O
and	O
nuclear	O
norm	B
.	O
there	O
are	O
also	O
several	O
diﬀerent	O
approaches	O
to	O
generate	O
the	O
aﬃnity	O
matrix	O
.	O
in	O
[	O
152	O
]	O
,	O
self	O
-	O
attention	O
-	O
based	O
network	B
was	O
in-	O
troduced	O
to	O
directly	O
generate	O
a	O
similarity	B
matrix	O
from	O
a	O
se-	O
quence	O
of	O
speaker	B
embeddings	I
.	O
in	O
[	O
153	O
]	O
,	O
several	O
aﬃnity	O
ma-	O
trices	O
with	O
diﬀerent	O
temporal	O
resolutions	O
were	O
fused	O
into	O
single	O
aﬃnity	O
matrix	O
based	O
on	O
a	O
neural	B
network	I
.	O
3.1.2	O
.	O
learning	O
the	O
distance	B
estimator	O
data	B
-	O
driven	O
techniques	B
perform	O
remarkably	O
well	O
on	O
a	O
wide	O
variety	O
of	O
tasks	O
[	O
154	O
]	O
.	O
however	O
,	O
traditional	O
dl	O
architectures	O
may	O
fail	O
when	O
the	O
problem	O
involves	O
relational	O
information	B
be-	O
tween	O
observations	O
[	O
155	O
]	O
.	O
recently	O
,	O
relational	O
recurrent	O
neu-	O
fig	O
.	O
7	O
:	O
speaker	B
diarization	I
with	O
graph	O
neural	B
network	I
ral	O
networks	O
(	O
rrnn	O
)	O
were	O
introduced	O
by	O
[	O
155	O
,	O
156	O
,	O
157	O
]	O
to	O
solve	O
this	O
”	O
relational	O
information	B
learning	O
”	O
task	O
.	O
speaker	B
di-	O
where	O
z	O
are	O
the	O
bottleneck	O
features	O
,	O
µ	O
is	O
the	O
centroid	O
of	O
i	O
-	O
th	O
arization	O
can	O
be	O
seen	O
as	O
a	O
member	O
of	O
this	O
class	O
of	O
tasks	O
,	O
since	O
i	O
i	O
cluster	O
and	O
f	O
is	O
the	O
soft	O
cluster	O
frequency	B
with	O
f	O
=	O
(	O
cid:80	O
)	O
q	O
.	O
the	O
ﬁnal	O
decision	O
depends	O
on	O
the	O
distance	B
relations	O
between	O
i	O
i	O
i	O
j	O
the	O
clusters	O
are	O
iteratively	O
reﬁned	O
based	O
on	O
a	O
target	O
distribu-	O
speech	B
segments	I
and	O
speaker	B
proﬁles	O
or	O
centroids	O
.	O
tion	O
[	O
150	O
]	O
based	O
on	O
bottleneck	O
features	O
estimated	O
using	O
an	O
au-	O
the	O
challenges	B
of	O
audio	O
segmentation	B
are	O
detailed	O
in	O
sec-	O
toencoder	O
.	O
tion	O
2.3	O
.	O
further	O
,	O
speaker	B
embeddings	I
are	O
usually	O
extracted	O
the	O
initial	O
dec	O
approach	O
presented	O
some	O
problems	O
.	O
as	O
from	O
a	O
network	B
trained	O
to	O
distinguish	O
speakers	O
among	O
thou-	O
such	O
,	O
improved	O
versions	O
of	O
the	O
algorithm	O
have	O
been	O
proposed	O
,	O
sands	O
of	O
candidates	O
[	O
50	O
]	O
.	O
however	O
,	O
a	O
diﬀerent	O
level	B
of	O
granular-	O
where	O
the	O
possibility	O
of	O
trivial	O
(	O
empty	O
)	O
clusters	O
is	O
addressed	O
ity	O
in	O
the	O
speaker	B
space	O
is	O
required	O
,	O
since	O
only	O
a	O
small	O
number	O
(	O
under	O
the	O
assumption	O
that	O
the	O
distribution	O
of	O
speaker	B
turns	O
is	O
of	O
participants	B
is	O
typically	O
involved	O
in	O
an	O
interactive	O
meeting	O
uniform	O
across	O
all	O
speakers	O
,	O
i.e.	O
all	O
speakers	O
contribute	O
equally	O
scenario	O
.	O
in	O
addition	O
to	O
that	O
,	O
the	O
distance	B
metric	B
used	O
is	O
of-	O
to	O
the	O
session	O
)	O
.	O
this	O
assumption	O
is	O
not	O
realistic	O
in	O
real	O
meet-	O
ten	O
heuristic	O
and/or	O
dependent	O
on	O
certain	O
assumptions	O
which	O
do	O
ing	O
environments	O
but	O
it	O
constrains	O
the	O
solution	O
space	O
enough	O
to	O
not	O
necessarily	O
hold	O
,	O
e.g.	O
,	O
assuming	O
gaussianity	O
in	O
the	O
case	O
of	O
avoid	O
the	O
empty	O
clusters	O
without	O
aﬀecting	O
overall	O
performance	O
.	O
plda	B
[	O
158	O
]	O
,	O
etc	O
.	O
finally	O
,	O
the	O
audio	O
chunks	O
are	O
treated	O
indepen-	O
an	O
additional	O
loss	O
term	O
penalizes	O
the	O
distance	B
from	O
the	O
cen-	O
dently	O
and	O
any	O
temporal	O
information	B
about	O
the	O
past	O
and	O
future	O
troids	O
µ	O
,	O
bringing	O
the	O
behavior	O
of	O
the	O
algorithm	O
closer	O
to	O
k-	O
is	O
simply	O
ignored	O
.	O
most	O
of	O
these	O
issues	O
can	O
be	O
addressed	O
with	O
i	O
means	O
[	O
149	O
]	O
.	O
the	O
rrnns	O
in	O
[	O
159	O
]	O
,	O
where	O
a	O
data	B
-	O
driven	O
,	O
memory	O
-	O
based	O
ap-	O
based	O
on	O
these	O
improvements	B
,	O
the	O
loss	O
function	O
of	O
the	O
revis-	O
proach	O
is	O
bridging	O
the	O
performance	O
gap	O
between	O
the	O
heuristic	O
ited	O
dec	O
algorithm	O
consists	O
of	O
three	O
diﬀerent	O
loss	O
components	B
,	O
and	O
the	O
trainable	O
distance	B
estimating	O
approaches	O
.	O
the	O
rrnns	O
i.e.	O
l	O
the	O
clustering	B
error	O
,	O
l	O
the	O
uniform	O
“	O
speaker	B
air	O
-	O
time	B
”	O
have	O
shown	O
great	O
success	O
on	O
several	O
problems	O
requiring	O
rela-	O
c	O
u	O
distribution	O
constraint	O
and	O
l	O
the	O
distance	B
of	O
the	O
bottleneck	O
tional	O
reasoning	O
[	O
156	O
,	O
155	O
,	O
159	O
]	O
,	O
and	O
speciﬁcally	O
using	O
the	O
re-	O
ms	O
e	O
features	O
from	O
the	O
centroids	O
[	O
149	O
]	O
,	O
lational	O
memory	O
core	O
(	O
rmc	O
)	O
[	O
155	O
]	O
.	O
in	O
this	O
context	O
,	O
a	O
novel	O
approach	O
of	O
learning	O
the	O
distance	B
l	O
=	O
αlc	O
+	O
βlr	O
+	O
γlu	O
+	O
δlms	O
e	O
(	O
26	O
)	O
between	O
such	O
centroids	O
(	O
or	O
speaker	B
proﬁles	O
)	O
and	O
the	O
embed-	O
dings	O
was	O
proposed	O
in	O
[	O
159	O
]	O
(	O
fig	O
.	O
8)	O
.	O
the	O
diarization	B
pro-	O
allowing	O
for	O
the	O
diﬀerent	O
loss	O
functions	O
to	O
be	O
weighted	O
diﬀer-	O
cess	O
can	O
be	O
seen	O
as	O
a	O
classiﬁcation	O
task	O
on	O
already	O
segmented	O
ently	O
and	O
the	O
weights	O
α	O
,	O
β	O
,	O
γ	O
and	O
δ	O
can	O
be	O
ﬁne	O
-	O
tuned	O
on	O
some	O
audio	O
,	O
section	O
2.3	O
,	O
where	O
the	O
audio	O
signal	B
is	O
ﬁrst	O
segmented	O
held	O
-	O
out	O
data	B
.	O
either	O
uniformly	O
[	O
160	O
]	O
or	O
based	O
on	O
estimated	O
speaker	B
change	I
in	O
[	O
65	O
]	O
,	O
a	O
diﬀeent	O
approach	O
that	O
purify	O
the	O
similarity	B
matrix	O
points	O
[	O
161	O
]	O
.	O
as	O
these	O
segments	O
are	O
assumed	O
to	O
be	O
speaker-	O
for	O
the	O
spectral	O
clustering	B
based	O
on	O
the	O
graph	O
neural	B
network	I
homogeneous	O
,	O
speaker	B
embeddings	I
x	O
for	O
each	O
segment	B
are	O
ex-	O
(	O
gnn	O
)	O
was	O
proposed	O
(	O
fig	O
.	O
7	O
)	O
.	O
given	O
a	O
sequence	B
of	O
speaker	B
j	O
tracted	O
and	O
then	O
compared	O
against	O
all	O
the	O
available	O
speaker	B
pro-	O
embeddings	O
{	O
e	O
,	O
...	O
e	O
}	O
where	O
n	O
is	O
the	O
length	B
of	O
sequence	B
.	O
the	O
1	O
n	O
ﬁles	O
or	O
speaker	B
centroids	O
.	O
by	O
minimizing	O
a	O
particular	O
distance	B
ﬁrst	O
layer	B
of	O
the	O
gnn	O
takes	O
the	O
input	B
{	O
x0	O
=	O
e	O
|i	O
=	O
1	O
,	O
.	O
.	O
.	O
,	O
n	O
}	O
.	O
i	O
i	O
metric	B
,	O
the	O
most	O
suitable	O
speaker	B
label	O
is	O
assigned	O
to	O
the	O
seg-	O
the	O
gnn	O
then	O
computes	O
the	O
output	B
of	O
the	O
p	O
-	O
th	O
layer	B
{	O
x(p)|i	O
=	O
i	O
ment	O
.	O
the	O
ﬁnal	O
decision	O
relies	O
on	O
a	O
distance	B
estimation	B
,	O
ei-	O
1	O
,	O
.	O
.	O
.	O
,	O
n	O
}	O
as	O
followings	O
.	O
ther	O
the	O
cosine	O
[	O
51	O
]	O
or	O
the	O
plda	B
[	O
158	O
]	O
distance	B
,	O
or	O
the	O
distance	B
(	O
cid:88	O
)	O
based	O
on	O
rrnns	O
as	O
proposed	O
in	O
[	O
159	O
]	O
.	O
the	O
later	O
method	B
based	O
x(p	O
)	O
=	O
σ(w	O
l	O
x(p−1	O
)	O
)	O
,	O
(	O
27	O
)	O
i	O
i	O
,	O
j	O
j	O
on	O
memory	O
networks	O
has	O
shown	O
consistent	O
improvements	B
in	O
j	O
performance	O
.	O
where	O
l	O
represents	O
a	O
normalized	O
aﬃnity	O
matrix	O
added	O
by	O
self-	O
3.1.3	O
.	O
deep	B
learning	I
-	O
based	O
post	O
processing	B
connection	O
,	O
w	O
is	O
a	O
trainable	O
weight	B
matrix	O
for	O
the	O
p	O
-	O
th	O
layer	B
,	O
10ited	O
by	O
the	O
number	O
of	O
element	O
of	O
the	O
output	B
layer	B
.	O
as	O
a	O
diﬀerent	O
approach	O
,	O
horiguchi	O
et	O
al	O
.	O
proposed	O
to	O
apply	O
the	O
eend	O
model	B
(	O
detailed	O
in	O
section	O
3.2.4	O
)	O
to	O
reﬁne	O
the	O
result	O
of	O
a	O
clustering	B
-	O
based	B
speaker	I
diarization	B
[	O
162	O
]	O
.	O
a	O
clustering-	O
based	B
speaker	I
diarization	B
method	B
can	O
handle	O
a	O
large	O
number	O
of	O
speakers	O
while	O
it	O
is	O
not	O
good	O
at	O
handling	O
the	O
overlapped	B
speech	I
.	O
on	O
the	O
other	O
hand	O
,	O
eend	O
has	O
the	O
opposite	O
characteristics	B
.	O
to	O
fig	O
.	O
8	O
:	O
continuous	O
speaker	B
identiﬁcation	O
system	O
based	O
on	O
rmc	O
.	O
the	O
speech	O
complementary	O
use	O
two	O
methods	O
,	O
they	O
ﬁrst	O
apply	O
a	O
conven-	O
signal	B
is	O
segmented	O
uniformly	O
and	O
each	O
segment	B
xt	O
is	O
compared	O
against	O
all	O
the	O
available	O
speaker	B
proﬁles	O
according	O
to	O
a	O
distance	B
metric	B
d	O
(	O
·	O
,	O
·	O
)	O
.	O
a	O
speaker	B
label	O
tional	O
clustering	B
method	B
.	O
then	O
,	O
the	O
two	O
-	O
speaker	B
eend	O
model	B
st	O
,	O
j	O
is	O
assigned	O
to	O
each	O
xt	O
minimizing	O
this	O
metric	B
.	O
is	O
iteratively	O
applied	O
for	O
each	O
pair	O
of	O
detected	O
speakers	O
to	O
reﬁne	O
the	O
time	B
boundary	O
of	O
overlapped	O
regions	O
.	O
3.2	O
.	O
joint	O
optimization	O
for	O
speaker	B
diarization	I
3.2.1	O
.	O
joint	O
segmentation	B
and	O
clustering	B
a	O
model	B
called	O
unbounded	O
interleaved	O
-	O
state	O
recurrent	O
neu-	O
ral	O
networks	O
(	O
uis	O
-	O
rnn	O
)	O
was	O
proposed	O
that	O
replaces	O
the	O
seg-	O
mentation	O
and	O
clustering	B
procedure	O
into	O
a	O
trainable	O
model	B
[	O
55	O
]	O
.	O
given	O
the	O
input	B
sequence	B
of	O
embeddings	O
x	O
=	O
(	O
x	O
∈	O
rd|t	O
=	O
t	O
1	O
,	O
.	O
.	O
.	O
,	O
t	O
)	O
,	O
uis	O
-	O
rnn	O
generates	O
the	O
diarization	B
result	O
y	O
=	O
(	O
y	O
∈	O
t	O
n|t	O
=	O
1	O
,	O
.	O
.	O
.	O
,	O
t	O
)	O
as	O
a	O
sequence	B
of	O
speaker	B
index	O
for	O
each	O
time	B
frame	B
.	O
the	O
joint	O
probability	B
of	O
x	O
and	O
y	O
can	O
be	O
decomposed	O
by	O
the	O
chain	O
rule	O
as	O
follows	O
.	O
(	O
cid:89)t	O
p(x	O
,	O
y	O
)	O
=	O
p(x	O
,	O
y	O
)	O
p(x	O
,	O
y	O
|x	O
,	O
y	O
)	O
.	O
(	O
28	O
)	O
1	O
1	O
t	O
t	O
1	O
:	O
t−1	O
1	O
:	O
t−1	O
t=2	O
to	O
model	B
the	O
distribution	O
of	O
speaker	B
change	I
,	O
uis	O
-	O
rnn	O
then	O
in-	O
troduce	O
a	O
latent	O
variable	O
z	O
=	O
(	O
z	O
∈	O
{	O
0	O
,	O
1}|t	O
=	O
2	O
,	O
.	O
.	O
.	O
,	O
t	O
)	O
,	O
where	O
z	O
t	O
t	O
fig	O
.	O
9	O
:	O
target	O
speaker	B
voice	O
activity	O
detector	O
becomes	O
1	O
if	O
the	O
speaker	B
indices	O
at	O
time	B
t	O
−	O
1	O
and	O
t	O
are	O
diﬀer-	O
ent	O
,	O
and	O
0	O
otherwise	O
.	O
the	O
joint	O
probability	B
including	O
z	O
is	O
then	O
decomposed	O
as	O
follows	O
.	O
there	O
are	O
a	O
few	O
recent	O
studies	O
to	O
train	O
a	O
neural	B
network	I
that	O
is	O
applied	O
on	O
top	O
of	O
the	O
result	O
of	O
a	O
clustering	B
-	O
based	B
speaker	I
di-	O
(	O
cid:89)t	O
p(x	O
,	O
y	O
,	O
z	O
)	O
=	O
p(x	O
,	O
y	O
)	O
p(x	O
,	O
y	O
,	O
z	O
|x	O
,	O
y	O
,	O
z	O
)	O
(	O
29	O
)	O
arization	O
.	O
these	O
method	B
can	O
be	O
categorized	O
as	O
an	O
extension	O
of	O
1	O
1	O
t	O
t	O
t	O
1	O
:	O
t−1	O
1	O
:	O
t−1	O
1	O
:	O
t−1	O
t=2	O
the	O
post	O
processing	B
.	O
medennikov	O
et	O
al	O
.	O
proposed	O
the	O
target	O
-	O
speaker	B
voice	O
ac-	O
finally	O
,	O
the	O
term	O
p(x	O
,	O
y	O
,	O
z	O
|x	O
,	O
y	O
,	O
z	O
)	O
is	O
further	O
decom-	O
t	O
t	O
t	O
1	O
:	O
t−1	O
1	O
:	O
t−1	O
1	O
:	O
t−1	O
tivity	O
detection	B
(	O
ts	O
-	O
vad	O
)	O
to	O
achieve	O
accurate	O
speaker	B
diariza-	O
posed	O
into	O
three	O
components	B
.	O
tion	O
even	O
with	O
many	O
speaker	B
overlaps	B
noisy	O
conditions	O
[	O
91	O
,	O
66	O
]	O
.	O
as	O
shown	O
in	O
fig	O
.	O
9	O
,	O
ts	O
-	O
vad	O
takes	O
the	O
input	B
of	O
acoustic	O
fea-	O
p(xt	O
,	O
yt	O
,	O
zt|x1	O
:	O
t−1	O
,	O
y1	O
:	O
t−1	O
,	O
z1	O
:	O
t−1	O
)	O
ture	O
(	O
mfcc	O
)	O
as	O
well	O
as	O
the	O
i	O
-	O
vector	O
of	O
all	O
target	O
speakers	O
.	O
the	O
=	O
p(x	O
|x	O
,	O
y	O
)	O
p(y	O
|z	O
,	O
y	O
)	O
p(z	O
|z	O
)	O
(	O
30	O
)	O
t	O
1	O
:	O
t−1	O
1	O
:	O
t	O
t	O
t	O
1	O
:	O
t−1	O
t	O
1	O
:	O
t−1	O
model	B
has	O
an	O
output	B
layer	B
where	O
i	O
-	O
th	O
element	O
becomes	O
1	O
at	O
time	B
frame	B
t	O
if	O
i	O
-	O
th	O
speaker	B
is	O
speaking	O
at	O
the	O
time	B
frame	B
,	O
and	O
0	O
oth-	O
here	O
,	O
p(x	O
|x	O
,	O
y	O
)	O
represents	O
the	O
sequence	B
generation	O
proba-	O
t	O
1	O
:	O
t−1	O
1	O
:	O
t	O
erwise	O
.	O
to	O
convert	O
the	O
raw	O
output	B
into	O
a	O
sequence	B
of	O
segment	B
,	O
bility	O
,	O
and	O
modeled	O
by	O
gated	O
recurrent	O
unit	O
(	O
gru)-based	O
recur-	O
a	O
further	O
post	O
-	O
processing	B
based	O
on	O
heuristics	O
(	O
median	O
ﬁltering	O
,	O
rent	O
neural	B
network	I
.	O
p(y	O
|z	O
,	O
y	O
)	O
represents	O
the	O
speaker	B
as-	O
t	O
t	O
1	O
:	O
t−1	O
binarization	O
with	O
the	O
threshold	B
,	O
etc	O
.	O
)	O
or	O
hmm	O
-	O
based	O
decod-	O
signment	O
probability	B
,	O
and	O
modeled	O
by	O
a	O
distant	O
dependent	O
chi-	O
ing	O
with	O
states	O
representing	O
silence	B
,	O
non	O
-	O
overlapping	B
speech	I
of	O
nese	O
restaurant	O
process	B
[	O
163	O
]	O
,	O
which	O
can	O
model	B
the	O
distribution	O
each	O
speaker	B
,	O
and	O
overlapping	B
speech	I
from	O
all	O
possible	O
pairs	O
of	O
of	O
unbounded	O
number	O
of	O
speakers	O
.	O
finally	O
,	O
p(z	O
|z	O
)	O
repre-	O
t	O
1	O
:	O
t−1	O
speakers	O
is	O
used	O
.	O
prior	O
to	O
inference	B
,	O
ts	O
-	O
vad	O
requires	O
the	O
i-	O
sents	O
the	O
speaker	B
change	I
probability	B
,	O
and	O
modeled	O
by	O
bernoulli	O
vector	O
of	O
all	O
target	O
speakers	O
.	O
the	O
i	O
-	O
vectors	O
are	O
initialized	O
based	O
distribution	O
.	O
since	O
all	O
models	B
are	O
represented	O
by	O
trainable	O
mod-	O
on	O
the	O
conventional	O
clustering	B
-	O
based	B
speaker	I
diarization	B
result	O
.	O
els	O
,	O
the	O
uis	O
-	O
rnn	O
can	O
be	O
trained	O
in	O
a	O
supervised	O
way	O
by	O
ﬁnding	O
after	O
initializing	O
the	O
i	O
-	O
vector	O
,	O
the	O
inference	B
by	O
ts	O
-	O
vad	O
and	O
parameters	O
that	O
maximizes	O
log	B
p(x	O
,	O
y	O
,	O
z	O
)	O
over	O
training	B
data	I
.	O
reﬁnement	O
of	O
i	O
-	O
vector	O
based	O
on	O
the	O
ts	O
-	O
vad	O
result	O
can	O
be	O
re-	O
the	O
inference	B
can	O
be	O
conducted	O
by	O
ﬁnding	O
y	O
that	O
maximizes	O
peated	O
until	O
it	O
converges	O
.	O
ts	O
-	O
vad	O
showed	O
a	O
signiﬁcantly	O
bet-	O
log	B
p(x	O
,	O
y	O
)	O
given	O
x	O
based	O
on	O
the	O
beam	O
search	O
in	O
an	O
online	O
fash-	O
ter	O
der	O
compared	O
with	O
the	O
conventional	O
clustering	B
based	O
ap-	O
ion	O
.	O
while	O
uis	O
-	O
rnn	O
works	O
in	O
an	O
online	O
fashion	O
,	O
uis	O
-	O
rnn	O
proach	O
[	O
91	O
,	O
88	O
]	O
.	O
on	O
the	O
other	O
hand	O
,	O
it	O
has	O
a	O
constraint	O
that	O
the	O
showed	O
better	O
der	O
than	O
that	O
of	O
the	O
oﬄine	O
system	O
based	O
on	O
the	O
maximum	O
number	O
of	O
speakers	O
that	O
the	O
model	B
can	O
handle	O
is	O
lim-	O
spectral	O
clustering	B
.	O
11dsaepcteeticveticitoyhn	O
eemsxptbreeaadcktdieoinrng	O
rerfiengeimonent	O
remove	O
overlap	O
...	O
neural	B
network	I
ch	O
feature	O
map	O
anchor	O
freq	O
clustering	B
time	B
stft	O
feature	O
freq	O
rpn	O
time	B
...	O
audio	O
input	B
neural	B
network	I
neural	B
network	I
(	O
a	O
)	O
region	O
proposal	O
network	B
(	O
rpn	O
)	O
(	O
b	O
)	O
diarization	B
by	O
rpn	O
fig	O
.	O
10	O
:	O
(	O
a	O
)	O
rpn	O
for	O
speaker	B
diarization	I
,	O
(	O
b	O
)	O
diarization	B
procedure	O
based	O
on	O
rpn	O
.	O
...	O
neural	B
network	I
neural	B
network	I
3.2.2	O
.	O
joint	O
segmentation	B
,	O
embedding	O
extraction	B
,	O
and	O
re-	O
segmentation	B
a	O
speaker	B
diarization	I
method	B
based	O
on	O
the	O
region	O
proposal	O
...	O
networks	O
(	O
rpn	O
)	O
was	O
proposed	O
to	O
jointly	O
perform	O
segmenta-	O
tion	O
,	O
speaker	B
embedding	O
extraction	B
,	O
and	O
re	O
-	O
segmentation	B
proce-	O
audio	O
block	O
1	O
audio	O
block	O
2	O
dures	O
by	O
a	O
single	O
neural	B
network	I
[	O
75	O
]	O
.	O
the	O
rpn	O
was	O
originally	O
proposed	O
to	O
detect	O
multiple	O
objects	O
from	O
a	O
2-d	O
image	O
[	O
164	O
]	O
,	O
and	O
fig	O
.	O
11	O
:	O
joint	O
speech	B
separation	I
,	O
speaker	B
counting	O
,	O
and	O
speaker	B
diarization	I
1-d	O
variant	O
of	O
the	O
rpn	O
is	O
used	O
for	O
speaker	B
diarization	I
along	O
with	O
model	B
.	O
the	O
time	B
-	O
axis	O
.	O
rpn	O
works	O
on	O
the	O
short	O
-	O
term	O
fourier	O
transform	O
(	O
stft	O
)	O
features	O
.	O
a	O
neural	B
network	I
converts	O
the	O
stft	O
feature	O
speech	B
separation	I
based	O
on	O
the	O
spatial	O
covariance	O
model	B
with	O
into	O
the	O
feature	O
map	O
(	O
fig	O
.	O
10	O
(	O
a	O
)	O
)	O
.	O
then	O
,	O
for	O
each	O
candidates	O
non	O
-	O
negative	O
matrix	O
factorization	O
.	O
they	O
derived	O
the	O
em	O
algo-	O
of	O
time	B
region	O
of	O
speech	B
activity	I
,	O
called	O
an	O
anchor	O
,	O
the	O
neural	O
rithm	O
to	O
estimate	O
separated	O
speech	O
and	O
speech	B
activity	I
of	O
each	O
network	B
jointly	O
perform	O
three	O
tasks	O
to	O
(	O
i	O
)	O
estimate	O
whether	O
the	O
speaker	B
from	O
the	O
multi	O
-	O
channel	O
overlapped	B
speech	I
.	O
while	O
their	O
anchor	O
includes	O
speech	B
activity	I
or	O
not	O
,	O
(	O
ii	O
)	O
extract	O
a	O
speaker	B
em-	O
method	B
jointly	O
perform	O
speaker	B
diarization	I
and	O
speech	O
separa-	O
bedding	O
corresponding	O
to	O
the	O
anchor	O
,	O
and	O
(	O
iii	O
)	O
estimate	O
the	O
dif-	O
tion	O
,	O
their	O
method	B
is	O
based	O
on	O
a	O
statistical	O
modeling	O
,	O
and	O
estima-	O
ference	O
of	O
the	O
duration	O
and	O
center	O
position	O
of	O
the	O
anchor	O
and	O
the	O
tion	O
was	O
conducted	O
solely	O
based	O
on	O
the	O
observation	O
,	O
i.e.	O
without	O
reference	B
speech	B
activity	I
.	O
the	O
ﬁrst	O
,	O
second	O
,	O
and	O
third	O
tasks	O
cor-	O
any	O
model	B
training	O
.	O
responds	O
to	O
the	O
segmentation	B
,	O
speaker	B
embedding	O
extraction	B
,	O
neumann	O
et	O
al	O
.	O
[	O
76	O
,	O
167	O
]	O
later	O
proposed	O
a	O
trainable	O
model	B
,	O
and	O
re	O
-	O
segmentation	B
,	O
respectively	O
.	O
called	O
online	O
recurrent	O
selective	O
attention	O
network	B
(	O
online	O
the	O
inference	B
procedure	O
by	O
rpn	O
is	O
depected	O
in	O
fig	O
.	O
10	O
(	O
b	O
)	O
.	O
rsan	O
)	O
,	O
for	O
joint	O
speech	B
separation	I
,	O
speaker	B
counting	O
,	O
and	O
the	O
rpn	O
is	O
ﬁrstly	O
applied	O
to	O
every	O
anchors	O
on	O
the	O
test	B
audio	O
,	O
speaker	B
diarization	I
based	O
on	O
a	O
single	O
neural	B
network	I
(	O
fig	O
.	O
11	O
)	O
.	O
and	O
the	O
regions	O
with	O
speech	B
activity	I
probability	B
higher	O
than	O
a	O
their	O
neural	B
network	I
takes	O
the	O
input	B
of	O
spectrogram	O
x	O
∈	O
rt×f	O
,	O
pre	O
-	O
determined	O
threshold	B
are	O
listed	O
as	O
a	O
candidate	O
time	B
regions	O
.	O
a	O
speaker	B
embedding	O
e	O
∈	O
rd	O
,	O
and	O
a	O
residual	O
mask	O
r	O
∈	O
rt×f	O
,	O
estimated	O
regions	O
are	O
then	O
clustered	O
by	O
using	O
a	O
conventional	O
where	O
t	O
and	O
f	O
is	O
the	O
maximum	O
time	B
index	O
and	O
the	O
maximum	O
clustering	B
method	B
(	O
e.g.	O
,	O
k	O
-	O
means	O
)	O
based	O
on	O
the	O
speaker	B
embed-	O
frequency	B
bin	O
of	O
the	O
spectrogram	O
,	O
respectively	O
.	O
it	O
output	B
the	O
dings	O
corresponding	O
to	O
each	O
region	O
.	O
finally	O
,	O
a	O
procedure	O
called	O
speech	O
mask	O
m	O
∈	O
rt×f	O
and	O
an	O
updated	O
speaker	B
embedding	O
non	O
-	O
maximum	O
suppression	O
is	O
applied	O
to	O
remove	O
highly	O
over-	O
for	O
the	O
speaker	B
corresponding	O
to	O
e.	O
the	O
neural	B
network	I
is	O
lapped	O
segments	O
.	O
ﬁrstly	O
applied	O
with	O
r	O
whose	O
element	O
is	O
all	O
1	O
,	O
and	O
e	O
whose	O
el-	O
the	O
rpn	O
-	O
based	B
speaker	I
diarization	B
has	O
the	O
advantage	O
that	O
ement	O
is	O
all	O
0	O
.	O
after	O
the	O
ﬁrst	O
inference	B
of	O
m	O
,	O
r	O
is	O
updated	O
as	O
it	O
can	O
handle	O
overlapped	B
speech	I
with	O
possibly	O
any	O
number	O
of	O
r	O
←	O
max(r	O
−	O
m	O
,	O
0	O
)	O
,	O
and	O
the	O
neural	B
network	I
is	O
again	O
applied	O
speakers	O
.	O
also	O
,	O
it	O
is	O
much	O
simpler	O
than	O
the	O
conventional	O
speaker	B
with	O
the	O
updated	O
r.	O
this	O
procedure	O
is	O
repeated	O
until	O
sum	O
of	O
diarization	B
system	O
.	O
it	O
was	O
shown	O
in	O
multiple	O
dataset	O
that	O
the	O
r	O
becomes	O
less	O
than	O
a	O
threshold	B
.	O
a	O
separated	O
speech	O
can	O
be	O
rpn	O
-	O
based	B
speaker	I
diarization	B
system	O
achieved	O
signiﬁcantly	O
obtained	O
by	O
m	O
(	O
cid:12	O
)	O
x	O
where	O
(	O
cid:12	O
)	O
is	O
the	O
element	O
-	O
wise	O
multiplica-	O
better	O
der	O
than	O
the	O
conventional	O
clustering	B
-	O
based	B
speaker	I
di-	O
tion	O
.	O
the	O
speaker	B
embedding	O
is	O
used	O
to	O
keep	O
track	O
the	O
speaker	B
arization	O
system	O
[	O
75	O
,	O
88	O
]	O
.	O
of	O
adjacent	O
blocks	O
.	O
thanks	O
to	O
the	O
iterative	O
approach	O
,	O
this	O
neu-	O
ral	O
network	B
can	O
cope	O
with	O
variable	O
number	O
of	O
speakers	O
while	O
3.2.3	O
.	O
joint	O
speech	B
separation	I
and	O
diarization	B
jointly	O
performing	O
speech	B
separation	I
and	O
speaker	B
diarization	I
.	O
there	O
are	O
also	O
recent	O
researches	O
to	O
jointly	O
perform	O
speech	B
separation	I
and	O
speaker	B
diarization	I
.	O
kounades	O
-	O
bastian	O
et	O
al	O
.	O
3.2.4	O
.	O
fully	O
end	O
-	O
to	O
-	O
end	O
neural	O
diarization	B
[	O
165	O
,	O
166	O
]	O
proposed	O
to	O
incorporate	O
a	O
speech	B
activity	I
model	B
into	O
12diarization	O
result	O
attractor	O
existing	O
probability	B
1	O
1	O
1	O
1	O
0	O
sigmoid	O
linear	O
+	O
sigmoid	O
attractors	O
lstm	O
encoder	O
lstm	O
decoder	O
embedding	O
eend	O
audio	O
input	B
fig	O
.	O
13	O
:	O
eend	O
with	O
encoder	O
-	O
decoder	O
-	O
based	O
attractor	O
(	O
eda	O
)	O
.	O
forward	O
for	O
the	O
prior	O
works	O
.	O
on	O
the	O
other	O
hand	O
,	O
several	O
limi-	O
tations	O
are	O
also	O
known	O
for	O
eend	O
.	O
firstly	O
,	O
the	O
model	B
architec-	O
ture	O
constrains	O
the	O
maximum	O
number	O
of	O
speakers	O
that	O
the	O
model	B
can	O
cope	O
with	O
.	O
secondly	O
,	O
eend	O
consists	O
of	O
blstm	O
or	O
self-	O
attention	O
neural	B
networks	I
,	O
which	O
makes	O
it	O
diﬃcult	O
to	O
do	O
online	O
fig	O
.	O
12	O
:	O
two	O
-	O
speaker	B
end	O
-	O
to	O
-	O
end	O
neural	O
diarization	B
model	B
processing	B
.	O
thirdly	O
,	O
it	O
was	O
empirically	O
suggested	O
that	O
eend	O
tends	O
to	O
overﬁt	O
to	O
the	O
distribution	O
of	O
the	O
training	B
data	I
[	O
56	O
]	O
.	O
to	O
cope	O
with	O
an	O
unbounded	O
number	O
of	O
speakers	O
,	O
several	O
recently	O
,	O
the	O
framework	O
called	O
end	O
-	O
to	O
-	O
end	O
neural	O
diariza-	O
extensions	O
of	O
eend	O
have	O
been	O
investigated	O
.	O
horiguchi	O
et	O
tion	O
(	O
eend	O
)	O
was	O
proposed	O
[	O
56	O
,	O
57	O
]	O
,	O
which	O
performs	O
all	O
speaker	B
al	O
.	O
[	O
169	O
]	O
proposed	O
an	O
extension	O
of	O
eend	O
with	O
the	O
encoder-	O
diarization	B
procedure	O
based	O
on	O
a	O
single	O
neural	B
network	I
.	O
the	O
decoder	O
-	O
based	O
attractor	O
(	O
eda	O
)	O
(	O
fig	O
.	O
13	O
)	O
.	O
this	O
method	B
ap-	O
architecture	B
of	O
eend	O
is	O
shown	O
in	O
fig	O
.	O
12	O
.	O
an	O
input	B
to	O
the	O
plies	O
an	O
lstm	O
-	O
based	O
encoder	O
-	O
decoder	O
on	O
the	O
output	B
of	O
eend	O
eend	O
model	B
is	O
a	O
t	O
-length	O
sequence	B
of	O
acoustic	B
features	I
(	O
e.g.	O
,	O
to	O
generate	O
multiple	O
attractors	O
.	O
attractors	O
are	O
generated	O
until	O
log	B
mel	O
ﬁlterbank	O
)	O
,	O
x	O
=	O
(	O
x	O
∈	O
rf|t	O
=	O
1	O
,	O
.	O
.	O
.	O
,	O
t	O
)	O
.	O
a	O
neural	O
t	O
the	O
attractor	O
existing	O
probability	B
becomes	O
less	O
than	O
a	O
thresh-	O
network	B
then	O
outputs	O
the	O
corresponding	O
speaker	B
label	O
sequence	B
old	O
.	O
then	O
,	O
each	O
attractor	O
is	O
multiplied	O
with	O
the	O
embeddings	O
y	O
=	O
(	O
y	O
|t	O
=	O
1	O
,	O
.	O
.	O
.	O
,	O
t	O
)	O
where	O
y	O
=	O
[	O
y	O
∈	O
{	O
0	O
,	O
1}|k	O
=	O
1	O
,	O
.	O
.	O
.	O
,	O
k	O
]	O
.	O
t	O
t	O
t	O
,	O
k	O
generated	O
from	O
eend	O
to	O
calculate	O
the	O
speech	B
activity	I
for	O
each	O
here	O
,	O
y	O
=	O
1	O
represents	O
the	O
speech	B
activity	I
of	O
the	O
speaker	B
k	O
t	O
,	O
k	O
speaker	B
.	O
on	O
the	O
other	O
hand	O
,	O
fujita	O
et	O
al	O
.	O
[	O
170	O
]	O
proposed	O
an-	O
at	O
the	O
time	B
frame	B
t	O
,	O
and	O
k	O
is	O
the	O
maximum	O
number	O
of	O
speak-	O
other	O
approach	O
to	O
output	B
the	O
speech	B
activity	I
one	O
after	O
another	O
ers	O
that	O
the	O
neural	B
network	I
can	O
output	B
.	O
importantly	O
,	O
y	O
and	O
t	O
,	O
k	O
by	O
using	O
a	O
conditional	O
speaker	B
chain	O
rule	O
.	O
in	O
this	O
method	B
,	O
a	O
y	O
can	O
be	O
both	O
1	O
for	O
diﬀerent	O
speakers	O
k	O
and	O
k(cid:48	O
)	O
,	O
which	O
repre-	O
t	O
,	O
k(cid:48	O
)	O
neural	B
network	I
is	O
trained	O
to	O
produce	O
a	O
posterior	O
probability	B
sents	O
that	O
two	O
speakers	O
k	O
and	O
k(cid:48	O
)	O
is	O
speaking	O
simultaneously	O
(	O
i.e.	O
p(y	O
|y	O
,	O
.	O
.	O
.	O
,	O
y	O
,	O
x	O
)	O
,	O
where	O
y	O
=	O
(	O
y	O
∈	O
{	O
0	O
,	O
1}|t	O
=	O
1	O
,	O
.	O
.	O
.	O
,	O
t	O
)	O
k	O
1	O
k−1	O
k	O
t	O
,	O
k	O
overlapping	B
speech	I
)	O
.	O
the	O
neural	B
network	I
is	O
trained	O
to	O
maxi-	O
(	O
cid:80	O
)	O
(	O
cid:80	O
)	O
is	O
the	O
speech	B
activity	I
for	O
k	O
-	O
th	O
speaker	B
.	O
then	O
,	O
the	O
joint	O
speech	O
mize	O
log	B
p(y|x	O
)	O
∼	O
log	B
p(y	O
|x	O
)	O
over	O
the	O
training	B
data	I
by	O
t	O
k	O
t	O
,	O
k	O
activity	O
probability	B
of	O
all	O
speakers	O
can	O
be	O
estimated	O
from	O
the	O
assuming	O
the	O
conditional	O
independence	O
of	O
the	O
output	B
y	O
.	O
be-	O
t	O
,	O
k	O
following	O
speaker	B
-	O
wise	O
conditional	O
chain	O
rule	O
as	O
:	O
cause	O
there	O
can	O
be	O
multiple	O
candidates	O
of	O
the	O
reference	B
label	O
y	O
by	O
swapping	O
the	O
speaker	B
index	O
k	O
,	O
the	O
loss	O
function	O
is	O
calcu-	O
(	O
cid:89)k	O
lated	O
for	O
all	O
possible	O
reference	B
labels	O
and	O
the	O
reference	B
label	O
that	O
p(y1	O
,	O
.	O
.	O
.	O
,	O
yk|x	O
)	O
=	O
p(yk|y1	O
,	O
.	O
.	O
.	O
,	O
yk−1	O
,	O
x	O
)	O
.	O
(	O
31	O
)	O
has	O
the	O
minimum	O
loss	O
is	O
used	O
for	O
the	O
error	O
back	O
-	O
propagation	O
,	O
k=1	O
which	O
is	O
inspired	O
by	O
the	O
permutation	O
free	O
objective	O
used	O
in	O
during	O
inference	B
,	O
the	O
neural	B
network	I
is	O
repeatedly	O
applied	O
until	O
speech	B
separation	I
[	O
59	O
]	O
.	O
eend	O
was	O
initially	O
proposed	O
with	O
a	O
the	O
speech	B
activity	I
y	O
for	O
the	O
last	O
estimated	O
speaker	B
approaches	O
k	O
bidirectional	O
long	O
short	O
-	O
term	O
memory	O
(	O
blstm	O
)	O
network	B
[	O
56	O
]	O
,	O
zero	O
.	O
kinoshita	O
et	O
al	O
.	O
[	O
171	O
]	O
proposed	O
a	O
diﬀerent	O
approach	O
that	O
and	O
was	O
soon	O
extended	O
to	O
the	O
self	O
-	O
attention	O
-	O
based	O
network	B
[	O
57	O
]	O
combines	O
eend	O
and	O
speaker	B
clustering	B
.	O
in	O
their	O
method	B
,	O
a	O
neu-	O
by	O
showing	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
der	O
for	O
callhome	O
dataset	O
ral	O
network	B
is	O
trained	O
to	O
generate	O
speaker	B
embeddings	I
as	O
well	O
as	O
(	O
ldc2001s97	O
)	O
and	O
corpus	B
of	O
spontaneous	O
japanese	O
[	O
168	O
]	O
.	O
the	O
speech	B
activity	I
probability	B
.	O
speaker	B
clustering	B
constrained	O
there	O
are	O
multiple	O
advantages	O
of	O
eend	O
.	O
firstly	O
,	O
it	O
can	O
han-	O
by	O
the	O
estimated	O
speech	B
activity	I
by	O
eend	O
is	O
applied	O
to	O
align	O
dle	O
overlapping	B
speech	I
in	O
a	O
sound	O
way	O
.	O
secondly	O
,	O
the	O
network	B
the	O
estimated	O
speakers	O
among	O
diﬀerent	O
processing	B
blocks	O
.	O
is	O
directly	O
optimized	O
towards	O
maximizing	O
diarization	B
accuracy	O
,	O
there	O
are	O
also	O
a	O
few	O
recent	O
trials	O
to	O
extend	O
the	O
eend	O
for	O
by	O
which	O
we	O
can	O
expect	O
a	O
high	O
accuracy	O
.	O
thirdly	O
,	O
it	O
can	O
be	O
online	O
processing	B
.	O
xue	O
et	O
al	O
.	O
[	O
172	O
]	O
proposed	O
a	O
method	B
with	O
a	O
retrained	O
by	O
a	O
real	O
data	B
(	O
i.e.	O
not	O
synthetic	O
data	B
)	O
just	O
by	O
feed-	O
speaker	B
tracing	O
buﬀer	O
to	O
better	O
align	O
the	O
speaker	B
labels	I
of	O
adja-	O
ing	O
a	O
reference	B
diarization	B
label	O
while	O
it	O
is	O
often	O
not	O
strait-	O
cent	O
processing	B
blocks	O
.	O
han	O
et	O
al	O
.	O
[	O
173	O
]	O
proposed	O
a	O
block	O
on-	O
13line	O
version	O
of	O
eda	O
-	O
eend	O
[	O
169	O
]	O
by	O
carrying	O
the	O
hidden	O
state	O
of	O
the	O
lstm	O
-	O
encoder	O
to	O
generate	O
attractors	O
block	O
by	O
block	O
.	O
4	O
.	O
speaker	B
diarization	I
in	O
the	O
context	O
of	O
asr	B
from	O
a	O
conventional	O
perspective	O
,	O
speaker	B
diarization	I
is	O
con-	O
sidered	O
a	O
pre	O
-	O
processing	B
step	O
for	O
asr	B
.	O
in	O
the	O
traditional	O
system	O
structure	O
for	O
speaker	B
diarization	I
as	O
depicted	O
in	O
fig	O
.	O
1	O
,	O
speech	O
fig	O
.	O
14	O
:	O
integration	O
of	O
lexical	O
information	B
and	O
acoustic	O
information	B
.	O
inputs	O
are	O
processed	O
sequentially	O
across	O
the	O
diarization	B
com-	O
ponents	O
without	O
considering	O
the	O
asr	B
objective	O
,	O
which	O
corre-	O
sponds	O
to	O
minimize	O
word	B
error	B
rate	I
(	O
wer	O
)	O
.	O
one	O
issue	O
is	O
that	O
the	O
tight	O
boundaries	B
of	O
speech	B
segments	I
as	O
the	O
outcomes	O
of	O
speaker	B
diarization	I
have	O
a	O
high	O
chance	O
of	O
causing	O
unexpected	O
word	B
truncation	O
or	O
deletion	O
errors	B
in	O
asr	B
decoding	O
.	O
in	O
this	O
section	O
we	O
discuss	O
how	O
speaker	B
diarization	I
systems	I
have	O
been	O
developed	O
in	O
the	O
context	O
of	O
asr	B
,	O
not	O
only	O
resulting	O
in	O
better	O
wer	O
by	O
preventing	O
speaker	B
diarization	I
from	O
hurting	O
asr	B
per-	O
formance	O
,	O
but	O
also	O
beneﬁting	O
from	O
asr	B
artifacts	O
to	O
enhance	O
diarization	B
performance	O
.	O
more	O
recently	O
,	O
there	O
have	O
been	O
a	O
few	O
pioneering	O
proposals	O
made	O
for	O
joint	O
modeling	O
of	O
speaker	B
di-	O
arization	O
and	O
asr	B
,	O
which	O
we	O
will	O
introduce	O
in	O
the	O
section	O
as	O
well	O
.	O
4.1	O
.	O
early	O
works	O
the	O
lexical	O
information	B
from	O
asr	B
output	B
has	O
been	O
employed	O
for	O
speaker	B
diarization	I
system	I
in	O
a	O
few	O
diﬀerent	O
ways	O
.	O
first	O
,	O
the	O
earliest	O
approach	O
was	O
rt03	O
evaluation	B
[	O
1	O
]	O
which	O
used	O
word	B
boundary	O
information	B
for	O
segmentation	B
purpose	O
.	O
in	O
[	O
1	O
]	O
,	O
a	O
gen-	O
fig	O
.	O
15	O
:	O
integration	O
of	O
lexical	O
information	B
and	O
acoustic	O
information	B
.	O
eral	O
asr	B
system	O
for	O
broadcast	O
news	O
data	B
was	O
built	O
where	O
the	O
basic	O
components	B
are	O
segmentation	B
,	O
speaker	B
clustering	B
,	O
speaker	B
adaptation	O
and	O
system	O
combination	O
after	O
asr	B
decoding	O
from	O
“	O
this	O
is	O
[	O
name	O
]	O
”	O
indicates	O
who	O
was	O
the	O
speaker	B
of	O
the	O
broadcast	O
the	O
two	O
sub	O
-	O
systems	O
with	O
the	O
diﬀerent	O
adaptation	O
methods	O
.	O
to	O
news	O
section	O
.	O
although	O
the	O
early	O
speaker	B
diarization	I
studies	O
did	O
understand	O
the	O
impact	O
of	O
the	O
word	B
boundary	O
information	B
,	O
they	O
not	O
fully	O
leverage	O
the	O
lexical	O
information	B
to	O
drastically	O
improve	O
used	O
asr	B
outputs	O
to	O
replace	O
the	O
segmentation	B
part	O
and	O
com-	O
der	O
,	O
the	O
idea	O
of	O
integrating	O
the	O
information	B
from	O
asr	B
output	B
pared	O
the	O
diarization	B
performance	O
of	O
the	O
each	O
system	O
.	O
in	O
ad-	O
has	O
been	O
employed	O
by	O
many	O
studies	O
to	O
reﬁne	O
or	O
improve	O
the	O
dition	O
,	O
asr	B
result	O
was	O
also	O
used	O
for	O
reﬁning	O
sad	O
in	O
ibm	O
’s	O
speaker	B
diarizatiohn	O
output	B
.	O
submission	O
[	O
174	O
]	O
for	O
rt07	O
evaluation	B
.	O
the	O
system	O
appeared	O
in	O
[	O
174	O
]	O
incorporates	O
word	B
alignments	O
from	O
speaker	B
independent	O
4.2	O
.	O
using	O
lexical	O
information	B
from	O
asr	B
asr	B
module	O
and	O
reﬁnes	O
sad	O
result	O
to	O
reduce	O
false	O
alarms	O
so	O
that	O
the	O
speaker	B
diarization	I
system	I
can	O
have	O
better	O
clustering	B
the	O
more	O
recent	O
speaker	B
diarization	I
systems	I
that	O
take	O
ad-	O
quality	B
.	O
the	O
segmentation	B
system	O
in	O
[	O
175	O
]	O
also	O
takes	O
advantage	O
vantage	O
of	O
the	O
asr	B
transcript	O
have	O
employed	O
a	O
dnn	O
model	B
of	O
word	B
alignments	O
from	O
asr	B
.	O
the	O
authors	O
in	O
[	O
175	O
]	O
focused	O
to	O
capture	O
the	O
linguistic	O
pattern	O
in	O
the	O
given	O
asr	B
output	B
to	O
en-	O
on	O
the	O
word	B
-	O
breakage	O
problem	O
where	O
the	O
words	B
from	O
asr	B
out-	O
hance	O
the	O
speaker	B
diarization	I
result	O
.	O
the	O
authors	O
in	O
[	O
177	O
]	O
pro-	O
put	O
are	O
truncated	O
by	O
segmentation	B
results	B
since	O
segmentation	B
posed	O
a	O
way	O
of	O
using	O
the	O
linguistic	O
information	B
for	O
the	O
speaker	B
result	O
and	O
decoded	O
word	B
sequence	B
are	O
not	O
aligned	O
.	O
therefore	O
,	O
diarization	B
task	O
where	O
participants	B
have	O
distinct	O
roles	O
that	O
are	O
word	B
-	O
breakage	O
(	O
wb	O
)	O
ratio	O
was	O
proposed	O
to	O
measure	O
the	O
rate	O
of	O
known	O
to	O
the	O
speaker	B
diarization	I
system	I
.	O
fig	O
.	O
14	O
shows	O
the	O
change	B
-	O
points	O
that	O
are	O
detected	O
inside	O
intervals	O
corresponding	O
diagram	O
of	O
speaker	B
diarization	I
system	I
appeared	O
in	O
[	O
177	O
]	O
.	O
in	O
to	O
words	B
.	O
the	O
der	O
and	O
wb	O
were	O
reported	O
together	O
to	O
mea-	O
this	O
system	O
,	O
a	O
neural	O
text	O
-	O
based	B
speaker	I
change	B
detector	O
and	O
a	O
sure	O
the	O
inﬂuence	O
of	O
word	B
truncation	O
problem	O
.	O
while	O
the	O
fore-	O
text	O
-	O
based	O
role	O
recognizer	O
are	O
employed	O
.	O
by	O
employing	O
both	O
mentioned	O
early	O
works	O
of	O
speaker	B
diarization	I
systems	I
that	O
are	O
linguistic	O
and	O
acoustic	O
information	B
,	O
der	O
was	O
signiﬁcantly	O
im-	O
leveraging	O
asr	B
output	B
are	O
focusing	O
on	O
the	O
word	B
alignment	O
in-	O
proved	O
compared	O
to	O
the	O
acoustic	O
only	O
system	O
.	O
formation	O
to	O
reﬁne	O
the	O
sad	O
or	O
segmentation	B
resutl	O
,	O
the	O
speaker	B
lexical	O
information	B
from	O
asr	B
output	B
was	O
also	O
utilized	O
for	O
diarization	B
system	O
in	O
[	O
176	O
]	O
created	O
a	O
dictionary	O
for	O
the	O
phrases	O
speaker	B
segmentation	I
[	O
178	O
]	O
by	O
employing	O
a	O
sequence	B
to	O
se-	O
that	O
commonly	O
appear	O
in	O
broadcast	O
news	O
.	O
the	O
phrases	O
in	O
this	O
quence	O
model	B
that	O
outputs	O
speaker	B
turn	O
tokens	O
.	O
based	O
on	O
the	O
dictionary	O
provide	O
identity	O
of	O
who	O
is	O
speaking	O
,	O
who	O
will	O
speak	O
estimated	O
speaker	B
turn	O
,	O
the	O
input	B
utterance	O
is	O
segmented	O
accord-	O
and	O
who	O
spoke	O
in	O
the	O
broadcase	O
news	O
scenario	O
.	O
for	O
example	O
,	O
ingly	O
.	O
the	O
experimental	O
results	B
in	O
[	O
178	O
]	O
show	O
that	O
using	O
both	O
14word1	O
spk1	O
word2	O
word3	O
spk2	O
word4	O
spk1	O
word	B
hypothesis	B
 	O
speaker	B
(	O
with	O
silence	B
boundary	O
)	O
embeddings	O
(	O
*	O
)	O
colored	O
block	O
represents	O
non	O
-	O
silence	B
hypothesis	B
 	O
while	O
white	O
block	O
represents	O
silence	B
hypothesis	B
end	O
-	O
to	O
-	O
end	O
asr	B
estimation	B
and	O
diarization	B
audio	O
input	B
audio	O
input	B
fig	O
.	O
17	O
:	O
joint	O
decoding	O
framework	O
for	O
asr	B
and	O
speaker	B
diarization	I
.	O
diarization	B
in	O
their	O
experiments	O
.	O
on	O
the	O
other	O
hand	O
,	O
the	O
speaker	B
roles	O
or	O
speaker	B
identity	O
tags	O
needs	O
to	O
be	O
determined	O
and	O
ﬁxed	O
fig	O
.	O
16	O
:	O
joint	O
asr	B
and	O
diarization	B
by	O
inserting	O
a	O
speaker	B
tag	B
in	O
the	O
transcrip-	O
during	O
training	O
,	O
so	O
it	O
is	O
diﬃcult	O
to	O
cope	O
with	O
an	O
arbitrary	O
num-	O
tion	O
.	O
ber	O
of	O
speakers	O
with	O
this	O
approach	O
.	O
a	O
second	O
approach	O
is	O
a	O
map	O
-	O
based	O
joint	O
decoding	O
frame-	O
acoustic	O
and	O
lexical	O
information	B
can	O
get	O
an	O
extra	O
advantage	O
ow-	O
work	O
.	O
kanda	O
et	O
al	O
.	O
[	O
79	O
]	O
formulated	O
the	O
joint	O
decoding	O
of	O
ing	O
to	O
the	O
word	B
boundaries	B
we	O
get	O
from	O
the	O
asr	B
output	B
.	O
asr	B
and	O
speaker	B
diarization	I
as	O
followings	O
(	O
see	O
also	O
fig	O
.	O
17	O
)	O
.	O
[	O
179	O
]	O
presented	O
follow	O
-	O
up	O
research	B
within	O
the	O
above	O
thread	O
.	O
assume	O
that	O
a	O
sequence	B
of	O
observations	O
is	O
represented	O
by	O
unlike	O
the	O
system	O
in	O
[	O
178	O
]	O
,	O
lexical	O
information	B
from	O
the	O
asr	B
x	O
=	O
{	O
x	O
,	O
.	O
.	O
.	O
,	O
x	O
}	O
,	O
where	O
u	O
is	O
the	O
number	O
of	O
segments	O
(	O
e.g.	O
,	O
1	O
u	O
module	O
was	O
integrated	O
with	O
the	O
speech	B
segment	I
clustering	B
pro-	O
generated	O
by	O
applying	O
vad	O
on	O
a	O
long	O
audio	O
)	O
and	O
x	O
is	O
the	O
u	O
cess	O
by	O
employing	O
an	O
integrated	O
adjacency	O
matrix	O
.	O
the	O
adja-	O
acoustic	O
feature	O
sequence	B
of	O
the	O
u	O
-	O
th	O
segment	B
.	O
further	O
as-	O
cency	O
matrix	O
is	O
obtained	O
from	O
max	O
operation	O
between	O
acoustic	O
sume	O
that	O
word	B
hypotheses	B
with	O
time	B
boundary	O
information	B
is	O
information	B
created	O
from	O
aﬃnities	O
among	O
audio	O
segments	O
and	O
represented	O
by	O
w	O
=	O
{	O
w	O
,	O
.	O
.	O
.	O
,	O
w	O
}	O
where	O
w	O
is	O
the	O
speech	O
1	O
u	O
u	O
lexical	O
information	B
matrix	O
created	O
by	O
segmenting	O
the	O
word	B
se-	O
recognition	O
hypotheses	B
corresponding	O
to	O
the	O
segment	B
u.	O
here	O
,	O
quence	O
into	O
word	B
chunks	O
that	O
are	O
likely	O
to	O
be	O
spoken	O
by	O
the	O
w	O
=	O
(	O
w	O
,	O
...	O
,	O
w	O
)	O
contains	O
all	O
speakers	O
’	O
hypotheses	B
in	O
the	O
u	O
1,u	O
k	O
,	O
u	O
same	B
speaker	I
.	O
fig	O
.	O
15	O
shows	O
a	O
diagram	O
that	O
explains	O
how	O
lex-	O
segment	B
u	O
where	O
k	O
is	O
the	O
number	O
of	O
speakers	O
,	O
and	O
w	O
rep-	O
k	O
,	O
u	O
ical	O
information	B
is	O
integrated	O
in	O
an	O
aﬃnity	O
matrix	O
with	O
acous-	O
resents	O
the	O
speech	B
recognition	I
hypothesis	B
of	O
the	O
k	O
-	O
th	O
speaker	B
tic	O
information	B
.	O
the	O
integrated	O
adjacency	O
matrix	O
leads	O
to	O
an	O
of	O
the	O
segment	B
u.	O
finally	O
,	O
a	O
tuple	O
of	O
speaker	B
embeddings	I
improved	O
speaker	B
diarization	I
performance	O
for	O
callhome	O
e	O
=	O
(	O
e	O
,	O
.	O
.	O
.	O
,	O
e	O
)	O
,	O
where	O
e	O
∈	O
rd	O
is	O
d	O
-	O
dimensional	O
speaker	B
em-	O
1	O
k	O
j	O
american	O
english	O
dataset	O
.	O
beddings	O
of	O
k	O
-	O
th	O
speaker	B
,	O
is	O
also	O
assumed	O
.	O
with	O
all	O
these	O
nota-	O
tions	O
,	O
the	O
joint	O
decoding	O
framework	O
of	O
multi	O
-	O
speaker	B
asr	B
and	O
4.3	O
.	O
joint	O
asr	B
and	O
speaker	B
diarization	I
with	O
deep	B
learning	I
diarization	B
can	O
be	O
formulated	O
as	O
a	O
problem	O
to	O
ﬁnd	O
most	O
likely	O
wˆ	O
as	O
,	O
motivated	O
by	O
the	O
recent	O
success	O
of	O
deep	B
learning	I
and	O
end-	O
to	O
-	O
end	O
modeling	O
,	O
several	O
models	B
have	O
been	O
proposed	O
to	O
jointly	O
wˆ	O
=	O
argmax	O
p(w|x	O
)	O
(	O
32	O
)	O
perform	O
asr	B
and	O
speaker	B
diarization	I
.	O
as	O
with	O
the	O
previous	O
w	O
section	O
,	O
asr	B
results	B
contain	O
a	O
strong	O
cue	O
to	O
improve	O
speaker	B
(	O
cid:88	O
)	O
=	O
argmax	O
{	O
p(w	O
,	O
e|x	O
)	O
}	O
(	O
33	O
)	O
diarization	B
.	O
on	O
the	O
other	O
hand	O
,	O
speaker	B
diarization	I
results	B
can	O
w	O
e	O
be	O
used	O
to	O
improve	O
the	O
asr	B
accuracy	O
,	O
for	O
example	O
,	O
by	O
adapting	O
≈	O
argmax{max	O
p(w	O
,	O
e|x	O
)	O
}	O
,	O
(	O
34	O
)	O
the	O
asr	B
model	B
towards	O
each	O
estimated	O
speaker	B
.	O
joint	O
modeling	O
w	O
e	O
can	O
leverage	O
such	O
inter	O
-	O
dependency	O
to	O
improve	O
both	O
asr	B
and	O
speaker	B
diarization	I
.	O
in	O
the	O
evaluation	B
,	O
a	O
word	B
error	B
rate	I
(	O
wer	O
)	O
where	O
we	O
use	O
the	O
viterbi	O
approximation	O
to	O
obtain	O
the	O
ﬁnal	O
equa-	O
metric	B
that	O
is	O
aﬀected	O
by	O
both	O
asr	B
errors	B
and	O
speaker	B
attri-	O
tion	O
.	O
this	O
maximization	O
problem	O
is	O
further	O
decomposed	O
into	O
bution	O
errors	B
,	O
such	O
as	O
speaker	B
-	O
attributed	O
wer	O
[	O
180	O
]	O
or	O
cpwer	O
two	O
iterative	O
problems	O
as	O
,	O
[	O
89	O
]	O
,	O
is	O
often	O
used	O
.	O
asr	B
-	O
speciﬁc	O
metrics	O
(	O
e.g.	O
,	O
speaker	B
-	O
agnostic	O
wer	O
)	O
or	O
diarization	B
-	O
speciﬁc	O
metrics	O
(	O
e.g.	O
,	O
der	O
)	O
is	O
also	O
used	O
wˆ	O
(	O
i	O
)	O
=	O
argmax	O
p(w|eˆ(i−1	O
)	O
,	O
x	O
)	O
,	O
(	O
35	O
)	O
w	O
complementary	O
.	O
eˆ(i	O
)	O
=	O
argmax	O
p(e|wˆ	O
(	O
i	O
)	O
,	O
x	O
)	O
,	O
(	O
36	O
)	O
a	O
ﬁrst	O
line	O
of	O
approaches	O
is	O
introducing	O
a	O
speaker	B
tag	B
in	O
the	O
e	O
transcription	B
of	O
end	O
-	O
to	O
-	O
end	O
asr	B
models	B
(	O
fig	O
.	O
16	O
)	O
.	O
shafey	O
et	O
al	O
.	O
[	O
77	O
]	O
proposed	O
to	O
insert	O
a	O
speaker	B
role	O
tag	B
(	O
e.g.	O
,	O
(	O
cid:104)doctor(cid:105	O
)	O
where	O
i	O
is	O
the	O
iteration	O
index	O
of	O
the	O
procedure	O
.	O
in	O
[	O
79	O
]	O
,	O
eq	O
.	O
(	O
35	O
)	O
and	O
(	O
cid:104)patient(cid:105	O
)	O
)	O
in	O
the	O
output	B
of	O
a	O
recurrent	O
neural	O
network-	O
is	O
modeled	O
by	O
the	O
target	O
speaker	B
asr	B
[	O
181	O
,	O
182	O
,	O
183	O
,	O
71	O
]	O
and	O
transducer	O
(	O
rnn	O
-	O
t)-based	O
asr	B
system	O
.	O
similarly	O
,	O
mao	O
et	O
al	O
.	O
eq	O
.	O
(	O
36	O
)	O
is	O
modeled	O
by	O
the	O
overlap	O
-	O
aware	O
speaker	B
embedding	O
[	O
78	O
]	O
proposed	O
to	O
insert	O
a	O
speaker	B
identity	O
tag	B
in	O
the	O
output	B
of	O
an	O
estimation	B
.	O
this	O
method	B
shows	O
a	O
similar	O
speaker	B
-	O
attributed	O
attention	O
-	O
based	O
encoder	O
-	O
decoder	O
asr	B
system	O
.	O
these	O
method	B
wer	O
compared	O
to	O
that	O
of	O
the	O
target	O
speaker	B
asr	B
with	O
oracle	O
have	O
been	O
shown	O
to	O
be	O
able	O
to	O
perform	O
both	O
asr	B
and	O
speaker	B
speaker	B
embeddings	I
.	O
on	O
the	O
other	O
hand	O
,	O
it	O
requires	O
an	O
iterative	O
15label	O
prediction	O
speaker	B
prediction	O
arization	O
in	O
the	O
recent	O
papers	O
.	O
callhome	O
dataset	O
contains	O
500	O
sessions	O
of	O
multilingual	O
telephonic	O
speech	O
.	O
each	O
session	O
has	O
2	O
to	O
7	O
speakers	O
while	O
there	O
are	O
two	O
dominant	O
speakers	O
in	O
inventoryattention	O
each	O
conversation	O
.	O
decoderrnn	O
speaker	B
query	O
5.1.2	O
.	O
ami	O
decoderout	O
speakerqueryrnn	O
the	O
ami	O
database	O
[	O
187	O
]	O
includes	O
100	O
hours	B
of	O
meeting	O
attention	O
recordings	O
from	O
multiple	O
sites	O
in	O
171	O
meeting	O
sessions	O
.	O
ami	O
database	O
provides	O
audio	O
source	B
recorded	O
with	O
lapel	O
micro-	O
phones	O
which	O
are	O
separately	O
recoreded	O
and	O
ampliﬁed	O
for	O
each	O
speaker	B
.	O
another	O
audio	O
source	B
is	O
recorded	O
with	O
omnidirectional	O
microphone	O
arrays	O
that	O
are	O
mounted	O
on	O
the	O
table	O
while	O
meet-	O
asrencoder	O
speakerencoder	O
ing	O
.	O
ami	O
database	O
is	O
a	O
suitable	O
dataset	O
for	O
evaluating	O
speaker	B
diarization	I
system	I
integrated	O
with	O
asr	B
module	O
since	O
ami	O
pro-	O
vides	O
forced	O
alignment	O
data	B
which	O
contains	O
word	B
and	O
phoneme	O
1	O
2	O
3	O
4	O
5	O
level	B
timings	O
along	O
with	O
the	O
transcript	O
and	O
speaker	B
label	O
.	O
each	O
audio	O
input	B
speaker	B
profiles	O
meeting	O
session	O
contains	O
3	O
to	O
5	O
speakers	O
.	O
fig	O
.	O
18	O
:	O
end	O
-	O
to	O
-	O
end	O
speaker	B
-	O
attributed	O
asr	B
5.1.3	O
.	O
icsi	O
meeting	O
corpus	B
the	O
icsi	O
meeting	O
corpus	B
[	O
188	O
]	O
contains	O
75	O
meting	O
corpus	B
application	B
of	O
the	O
target	O
-	O
speaker	B
asr	B
and	O
speaker	B
embedding	O
with	O
4	O
meeting	O
types	O
.	O
icsi	O
meeting	O
corpus	B
provides	O
word	B
level	B
extraction	B
,	O
which	O
makes	O
it	O
challenging	O
to	O
apply	O
the	O
method	B
in	O
timing	O
along	O
with	O
the	O
transcript	O
and	O
speaker	B
label	O
.	O
the	O
au-	O
online	O
mode	O
.	O
dio	O
source	B
is	O
recorded	O
with	O
close	O
-	O
talking	O
individual	O
microphone	O
as	O
a	O
third	O
line	O
of	O
approaches	O
,	O
end	O
-	O
to	O
-	O
end	O
(	O
e2e	O
)	O
speaker-	O
and	O
six	O
tabletop	O
microphones	O
to	O
provide	O
speaker	B
-	O
speciﬁc	O
chan-	O
attributed	O
asr	B
(	O
sa	O
-	O
asr	B
)	O
model	B
was	O
recently	O
proposed	O
to	O
nel	O
and	O
multi	O
-	O
channel	O
recording	B
.	O
each	O
meeting	O
has	O
3	O
to	O
10	O
par-	O
jointly	O
perform	O
speaker	B
counting	O
,	O
multi	O
-	O
speaker	B
asr	B
,	O
and	O
ticipants	O
.	O
speaker	B
identiﬁcation	O
[	O
184	O
,	O
185	O
]	O
.	O
diﬀerent	O
from	O
the	O
ﬁrst	O
two	O
approaches	O
,	O
the	O
e2e	O
sa	O
-	O
asr	B
model	B
takes	O
the	O
additional	O
in-	O
5.1.4	O
.	O
dihard	B
challenge	I
dataset	O
put	O
of	O
speaker	B
proﬁles	O
and	O
identiﬁes	O
the	O
index	O
of	O
speaker	B
pro-	O
dihard	B
challenge	I
dataset	O
is	O
created	O
for	O
dihard	O
chal-	O
ﬁles	O
based	O
on	O
the	O
attention	O
mechanism	O
(	O
fig	O
.	O
18	O
)	O
.	O
thanks	O
to	O
lenge	O
1	O
,	O
2	O
and	O
3	O
[	O
189	O
,	O
85	O
,	O
190	O
]	O
while	O
focusing	O
on	O
very	O
challeng-	O
the	O
attention	O
mechanism	O
for	O
speaker	B
identiﬁcation	O
and	O
multi-	O
ing	O
domains	O
.	O
dihard	B
challenge	I
development	B
set	I
and	O
eval-	O
talker	O
asr	B
capability	O
based	O
on	O
serialized	O
output	B
training	O
[	O
186	O
]	O
,	O
uation	O
set	B
include	O
clinical	O
interviews	O
,	O
web	O
videos	B
,	O
speech	O
in	O
there	O
is	O
no	O
limitation	O
of	O
a	O
maximum	O
number	O
of	O
speakers	O
that	O
the	O
wild	O
(	O
e.g.	O
,	O
recordings	O
in	O
restaurants	O
)	O
.	O
dihard	B
challenge	I
the	O
model	B
can	O
cope	O
with	O
.	O
in	O
case	O
relevant	O
speaker	B
proﬁles	O
are	O
dataset	O
also	O
includes	O
relatively	O
less	O
challenging	O
datasets	B
such	O
supplied	O
in	O
the	O
inference	B
,	O
the	O
e2e	O
sa	O
-	O
asr	B
model	B
can	O
automat-	O
as	O
conversational	O
telephonic	O
speech	O
(	O
cts	O
)	O
and	O
audio	O
books	O
to	O
ically	O
transcribe	O
the	O
utterance	O
while	O
identifying	O
the	O
speaker	B
of	O
diversify	O
the	O
domains	O
in	O
development	B
set	I
and	O
evaluation	B
set	I
.	O
each	O
utterance	O
based	O
on	O
the	O
supplied	O
speaker	B
proﬁles	O
.	O
on	O
the	O
contrary	O
to	O
other	O
speaker	B
diarization	I
datasets	B
,	O
domains	O
such	O
other	O
hand	O
,	O
in	O
case	O
the	O
relevant	O
speaker	B
proﬁles	O
can	O
not	O
be	O
used	O
as	O
restaurant	O
conversation	O
and	O
web	O
videos	B
contain	O
signiﬁcantly	O
prior	O
to	O
the	O
inference	B
,	O
the	O
e2e	O
sa	O
-	O
asr	B
model	B
can	O
still	O
be	O
ap-	O
lower	O
signal	B
to	O
noise	O
ratio	O
(	O
snr	O
)	O
that	O
makes	O
der	O
way	O
higher	O
.	O
plied	O
with	O
example	O
proﬁles	O
,	O
and	O
speaker	B
clustering	B
on	O
the	O
inter-	O
the	O
ﬁrst	O
dihard	B
challenge	I
,	O
dihard	O
1	O
,	O
started	O
with	O
track	O
nal	O
speaker	B
embeddings	I
of	O
the	O
e2e	O
sa	O
-	O
asr	B
model	B
(	O
“	O
speaker	B
1	O
for	O
diarization	B
beginning	O
from	O
oracle	O
sad	O
and	O
track	O
2	O
di-	O
query	O
”	O
in	O
fig	O
.	O
18	O
)	O
is	O
used	O
to	O
diarize	O
the	O
speaker	B
[	O
80	O
]	O
.	O
arization	O
from	O
scratch	O
using	O
system	O
sad	O
.	O
unlike	O
dihard	O
1	O
,	O
dihard	O
2	O
included	O
multichannel	B
speaker	B
diarization	I
task	O
in	O
track	O
3	O
(	O
oracle	O
sad	O
)	O
and	O
track	O
4	O
(	O
system	O
sad	O
)	O
adding	O
the	O
5	O
.	O
evaluation	B
of	O
speaker	B
diarization	I
recordings	O
drawn	O
from	O
chime-5	O
corpus	B
[	O
191	O
]	O
.	O
in	O
the	O
latest	O
this	O
section	O
describes	O
the	O
evaluation	B
scheme	O
for	O
speaker	B
di-	O
dihard	B
challenge	I
,	O
dihard	O
3	O
,	O
cts	O
dataset	O
was	O
added	O
to	O
arization	O
.	O
the	O
dataset	O
that	O
is	O
widely	O
used	O
for	O
the	O
evaluation	B
dihard	O
3	O
dev	O
set	B
and	O
eval	O
set	B
and	O
dihard	O
3	O
removed	O
track	O
of	O
speaker	B
diarization	I
is	O
ﬁrst	O
introduced	O
in	O
section	O
5.1	O
.	O
then	O
,	O
3	O
and	O
track	O
4	O
while	O
keeping	O
only	O
track	O
1	O
(	O
oracle	O
sad	O
)	O
and	O
track	O
the	O
evaluation	B
metric	B
for	O
speaker	B
diarization	I
is	O
introduced	O
in	O
2	O
(	O
system	O
sad	O
)	O
.	O
section	O
5.2	O
.	O
finally	O
,	O
international	O
eﬀorts	O
to	O
evaluate	O
diariza-	O
tion	O
systems	O
are	O
introduced	O
in	O
section	O
5.3	O
.	O
the	O
summary	O
of	O
the	O
5.1.5	O
.	O
chime-5/6	O
challenge	B
corpus	B
dataset	O
is	O
shown	O
in	O
table	O
2	O
.	O
the	O
chime-5	O
corpus	B
[	O
191	O
]	O
includes	O
50	O
hours	B
of	O
multi	O
-	O
party	O
real	O
conversations	O
in	O
the	O
every	O
-	O
day	O
home	O
environment	O
.	O
it	O
con-	O
5.1	O
.	O
diarization	B
evaluation	B
datasets	B
tains	O
speaker	B
labels	I
,	O
segmentation	B
,	O
and	O
corresponding	O
tran-	O
5.1.1	O
.	O
callhome	O
:	O
nist	O
sre	O
2000	O
(	O
ldc2001s97	O
)	O
scriptions	O
.	O
all	O
of	O
them	O
are	O
manually	O
annotated	O
.	O
the	O
audio	O
nist	O
sre	O
2000	O
(	O
disk-8	O
)	O
,	O
often	O
referred	O
to	O
as	O
callhome	O
source	B
is	O
recorded	O
by	O
multiple	O
4-channel	O
microphone	O
arrays	O
lo-	O
dataset	O
,	O
has	O
been	O
the	O
most	O
widely	O
used	O
dataset	O
for	O
speaker	B
di-	O
cated	O
in	O
the	O
kitchen	O
and	O
dining	O
/	O
living	O
rooms	O
in	O
a	O
house	O
,	O
and	O
also	O
16table	O
2	O
:	O
diarization	B
evaluation	B
datasets	B
size	B
(	O
hr	O
)	O
style	O
#	O
speakers	O
callhome	O
20	O
conversation	O
2–7	O
ami	O
100	O
meeting	O
3–5	O
icsi	O
meeting	O
72	O
meeting	O
3–10	O
dihard	O
i	O
track	O
1,2	O
19(dev	O
)	O
,	O
21(eval	O
)	O
miscellaneous	O
1–7	O
dihard	O
ii	O
track	O
1,2	O
24(dev	O
)	O
,	O
22(eval	O
)	O
miscellaneous	O
1–8	O
dihard	O
ii	O
track	O
3,4	O
262(dev	O
)	O
,	O
31(eval	O
)	O
miscellaneous	O
4	O
dihard	O
iii	O
track	O
1,2	O
34(dev	O
)	O
,	O
33(eval	O
)	O
miscellaneous	O
1–7	O
chime-5/6	O
50	O
conversation	O
4	O
voxconverse	O
74	O
youtube	O
video	O
1–21	O
libricss	O
10	O
read	O
speech	O
8	O
recorded	O
by	O
binaural	O
microphones	O
worn	O
by	O
participants	B
.	O
the	O
diﬀerent	O
error	O
types	O
:	O
false	B
alarm	I
(	O
fa	O
)	O
of	O
speech	O
,	O
missed	O
detec-	O
number	O
of	O
participants	B
is	O
ﬁxed	O
as	O
four	O
.	O
the	O
chime-6	O
chal-	O
tion	O
of	O
speech	O
and	O
confusion	O
between	O
speaker	B
labels	I
.	O
lenge	O
uses	O
the	O
same	O
chime-5	O
corpus	B
,	O
but	O
track	O
2	O
includes	O
the	O
fa	O
+	O
missed	O
+	O
speaker	B
-	O
confusion	O
speaker	B
diarization	I
problem	O
in	O
the	O
challenge	B
(	O
i.e.	O
,	O
no	O
speaker	B
der	O
=	O
(	O
37	O
)	O
labels	O
and	O
segmentation	B
are	O
given	O
)	O
.	O
the	O
chime-5	O
corpus	B
was	O
total	O
duration	O
of	O
time	B
also	O
used	O
as	O
one	O
track	O
in	O
the	O
dihard	O
2	O
challenge	B
.	O
to	O
establish	O
a	O
one	O
-	O
to	O
-	O
one	O
mapping	O
between	O
the	O
hypothesis	B
out-	O
puts	O
and	O
the	O
reference	B
transcript	O
,	O
hungarian	O
algorithm	O
[	O
195	O
]	O
is	O
5.1.6	O
.	O
voxconverse	O
employed	O
.	O
in	O
rich	B
transcription	I
2006	O
evaluation	B
[	O
194	O
]	O
,	O
0.25	O
the	O
voxconverse	O
dataset	O
[	O
192	O
]	O
contains	O
74	O
hours	B
of	O
human	O
second	O
of	O
“	O
no	O
score	B
”	O
collar	O
is	O
set	B
around	O
every	O
boundary	O
of	O
conversation	O
extracted	O
from	O
youtube	O
video	O
.	O
the	O
dataset	O
is	O
di-	O
reference	B
segment	B
to	O
mitigate	O
the	O
eﬀect	O
of	O
inconsistent	O
annota-	O
vided	O
into	O
development	B
set	I
(	O
20.3	O
hours	B
,	O
216	O
recordings	O
)	O
,	O
and	O
tion	O
and	O
human	O
errors	B
in	O
reference	B
transcript	O
and	O
this	O
evaluation	B
test	B
set	B
(	O
53.5	O
hours	B
,	O
310	O
recordings	O
)	O
.	O
the	O
number	O
of	O
speakers	O
scheme	O
has	O
been	O
most	O
widely	O
used	O
in	O
speaker	B
diarization	I
stud-	O
in	O
each	O
recording	B
has	O
a	O
wide	O
range	O
of	O
variety	O
from	O
1	O
speaker	B
to	O
ies	O
.	O
21	O
speakers	O
.	O
the	O
audio	O
includes	O
various	O
types	O
of	O
noises	O
such	O
as	O
background	O
music	O
,	O
laughter	O
etc	O
.	O
it	O
also	O
contains	O
noticeable	O
por-	O
5.2.2	O
.	O
jer	O
tion	O
of	O
overlapping	B
speech	I
from	O
0	O
%	O
to	O
30.1	O
%	O
dependent	O
on	O
the	O
jaccard	B
error	I
rate	O
(	O
jer	O
)	O
was	O
ﬁrst	O
introduced	O
in	O
dihard	O
ii	O
recording	B
.	O
while	O
the	O
dataset	O
contains	O
the	O
visual	O
information	B
as	O
evaluation	B
.	O
the	O
goal	O
of	O
jer	O
is	O
to	O
evaluate	O
each	O
speaker	B
with	O
well	O
as	O
audio	O
,	O
as	O
of	O
january	O
2021	O
,	O
only	O
the	O
audio	O
of	O
the	O
devel-	O
equal	O
weight	B
.	O
unlike	O
der	O
,	O
jer	O
does	O
not	O
use	O
speaker	B
error	O
to	O
opment	O
set	B
is	O
released	O
under	O
a	O
creative	O
commons	O
attribution	O
obtain	O
the	O
error	O
value	O
.	O
4.0	O
international	O
license	O
for	O
research	B
purpose	O
.	O
the	O
audio	O
of	O
the	O
evaluation	B
set	I
was	O
used	O
at	O
the	O
track	O
4	O
of	O
the	O
voxceleb	O
speaker	B
1	O
(	O
cid:88)nref	O
fa	O
+	O
miss	B
recognition	O
challenge	B
2020	O
(	O
section	O
5.3	O
)	O
as	O
a	O
blind	O
test	B
set	B
.	O
jer	O
=	O
i	O
i	O
(	O
38	O
)	O
n	O
total	O
i	O
i	O
5.1.7	O
.	O
libricss	O
in	O
eq	O
.	O
(	O
38	O
)	O
,	O
total	O
is	O
union	O
of	O
i	O
-	O
th	O
speaker	B
’s	O
speaking	O
time	B
in	O
the	O
libricss	O
corpus	B
[	O
87	O
]	O
is	O
10	O
hours	B
of	O
multi	O
-	O
channel	O
reference	B
transcript	O
and	O
i	O
-	O
th	O
speaker	B
’s	O
speaking	O
time	B
in	O
the	O
hy-	O
recordings	O
designed	O
for	O
the	O
research	B
of	O
speech	B
separation	I
,	O
potheses	O
.	O
the	O
sum	O
of	O
fa	O
and	O
miss	B
divided	O
by	O
total	O
value	O
is	O
speech	B
recognition	I
,	O
and	O
speaker	B
diarization	I
.	O
it	O
was	O
made	O
by	O
then	O
averaged	O
over	O
nre	O
f	O
-speakers	O
in	O
the	O
reference	B
script	O
.	O
since	O
playing	O
back	O
the	O
audio	O
in	O
the	O
librispeech	O
corpus	B
[	O
193	O
]	O
in	O
a	O
real	O
jer	O
is	O
using	O
union	O
operation	O
between	O
reference	B
and	O
the	O
hy-	O
meeting	O
room	O
,	O
and	O
recorded	O
by	O
a	O
7-ch	O
microphone	O
array	O
.	O
it	O
con-	O
potheses	O
,	O
jer	O
never	O
exceeds	O
100	O
%	O
while	O
der	O
can	O
sometimes	O
sists	O
of	O
10	O
sessions	O
,	O
each	O
of	O
which	O
is	O
further	O
decomposed	O
to	O
six	O
reach	O
way	O
over	O
100	O
%	O
.	O
der	O
and	O
jer	O
are	O
highly	O
correlated	O
but	O
if	O
10-min	O
mini	O
-	O
sessions	O
.	O
each	O
mini	O
-	O
session	O
was	O
made	O
by	O
audio	O
a	O
subset	O
of	O
speakers	O
are	O
dominant	O
in	O
the	O
given	O
audio	O
recording	B
,	O
of	O
8	O
speakers	O
and	O
designed	O
to	O
have	O
diﬀerent	O
overlap	O
ratio	O
from	O
jer	O
tends	O
to	O
get	O
higher	O
than	O
ordinary	O
case	O
.	O
0	O
%	O
to	O
40	O
%	O
.	O
to	O
facilitate	O
the	O
research	B
,	O
the	O
baseline	B
system	I
for	O
speech	B
separation	I
and	O
asr	B
[	O
87	O
]	O
and	O
the	O
baseline	B
system	I
that	O
5.2.3	O
.	O
wder	O
integrates	O
speech	B
separation	I
,	O
speaker	B
diarization	I
and	O
asr	B
[	O
88	O
]	O
while	O
der	O
is	O
based	O
on	O
the	O
duration	O
of	O
speaking	O
time	B
of	O
each	O
has	O
been	O
developed	O
and	O
released	O
.	O
speaker	B
,	O
word	B
-	O
level	B
der	O
(	O
wder	O
)	O
is	O
designed	O
to	O
measure	O
the	O
error	O
that	O
is	O
caused	O
in	O
the	O
lexical(output	O
transcription	B
)	O
side	O
.	O
the	O
motivation	O
of	O
wder	O
is	O
the	O
discrepency	O
between	O
der	O
and	O
the	O
5.2	O
.	O
diarization	B
evaluation	B
metrics	I
accuracy	O
of	O
ﬁnal	O
transcript	O
output	B
since	O
der	O
relies	O
on	O
the	O
du-	O
5.2.1	O
.	O
der	O
ration	O
of	O
speaking	O
time	B
that	O
is	O
not	O
always	O
aligned	O
with	O
the	O
word	B
the	O
accuracy	O
of	O
speaker	B
diarization	I
system	I
is	O
measured	O
by	O
boundaries	B
.	O
the	O
concept	O
of	O
word	B
-	O
breakage	O
was	O
proposed	O
in	O
diarization	B
error	I
rate	I
(	O
der	O
)	O
[	O
194	O
]	O
where	O
der	O
is	O
sum	O
of	O
three	O
silovsky	O
et	O
al	O
.	O
[	O
175	O
]	O
where	O
wb	O
shares	O
the	O
similar	O
idea	O
with	O
17wder	O
.	O
unlike	O
wder	O
,	O
wb	O
measures	O
the	O
number	O
of	O
speaker	B
[	O
192	O
]	O
was	O
used	O
for	O
evaluation	B
with	O
der	O
as	O
a	O
primary	O
metric	B
change	B
point	O
occurs	O
inside	O
a	O
word	B
boundary	O
.	O
the	O
work	O
in	O
park	O
to	O
determine	O
the	O
ranking	O
of	O
submitted	O
systems	O
.	O
jer	O
was	O
also	O
and	O
georgiou	O
[	O
196	O
]	O
suggested	O
the	O
term	O
wder	O
,	O
evaluating	O
the	O
measured	O
as	O
a	O
secondary	O
metric	B
.	O
diarization	B
output	B
with	O
ground	B
-	O
truth	O
transcription	B
.	O
more	O
re-	O
cently	O
,	O
the	O
joint	O
asr	B
and	O
speaker	B
diarization	I
system	I
was	O
evalu-	O
6	O
.	O
applications	O
ated	O
in	O
wder	O
format	O
in	O
shafey	O
et	O
al	O
.	O
[	O
77	O
]	O
.	O
although	O
the	O
way	O
of	O
calculating	O
wder	O
would	O
diﬀer	O
over	O
the	O
studies	O
but	O
the	O
under-	O
6.1	O
.	O
meeting	O
transcription	B
lying	O
idea	O
is	O
that	O
the	O
diarization	B
error	I
is	O
calculated	O
by	O
counting	O
the	O
goal	O
of	O
meeting	O
transcription	B
is	O
to	O
automatically	O
generate	O
the	O
correctly	O
or	O
incorrectly	O
labeled	O
words	B
.	O
speaker	B
-	O
attributed	O
transcripts	B
during	O
real	O
-	O
life	O
meetings	O
based	O
on	O
their	O
audio	O
and	O
optionally	O
video	O
recordings	O
.	O
accurate	O
meeting	O
5.3	O
.	O
diarization	B
evaluation	B
series	O
transcriptions	B
are	O
the	O
one	O
of	O
the	O
processing	B
steps	B
in	O
a	O
pipeline	O
the	O
rich	B
transcription	I
(	O
rt	O
)	O
evaluation	B
[	O
20	O
]	O
is	O
the	O
pio-	O
for	O
several	O
tasks	O
like	O
summarization	O
,	O
topic	O
extraction	B
,	O
etc	O
.	O
sim-	O
neering	O
evaluation	B
series	O
of	O
initiating	O
deeper	O
investigation	O
on	O
ilarly	O
,	O
the	O
same	O
transcription	B
system	O
can	O
be	O
used	O
in	O
other	O
do-	O
speaker	B
diarization	I
in	O
relation	O
with	O
asr	B
.	O
the	O
main	O
purpose	O
of	O
mains	O
such	O
as	O
healthcare	O
[	O
198	O
]	O
.	O
although	O
this	O
task	O
was	O
in-	O
this	O
eﬀort	O
was	O
to	O
create	O
asr	B
technologies	O
that	O
would	O
produce	O
troduced	O
by	O
nist	O
in	O
the	O
rich	B
transcription	I
evaluation	B
series	O
transcriptions	B
with	O
descriptive	O
metadata	O
,	O
like	O
who	O
said	O
when	O
,	O
back	O
in	O
2003	O
[	O
180	O
,	O
188	O
,	O
199	O
]	O
,	O
the	O
initial	O
systems	O
had	O
very	O
poor	O
where	O
speaker	B
diarization	I
plays	O
in	O
.	O
thus	O
the	O
main	O
tasks	O
in	O
the	O
performance	O
,	O
and	O
consequently	O
commercialization	O
of	O
the	O
tech-	O
evaluation	B
were	O
naturally	O
asr	B
and	O
speaker	B
diarization	I
.	O
the	O
nology	O
was	O
not	O
possible	O
.	O
however	O
,	O
recent	O
advances	O
in	O
the	O
ar-	O
domains	O
of	O
the	O
data	B
of	O
interest	O
were	O
broadcast	O
news	O
,	O
cts	O
and	O
eas	O
of	O
speech	B
recognition	I
[	O
200	O
,	O
201	O
]	O
,	O
far-ﬁeld	O
speech	O
process-	O
meeting	O
recordings	O
with	O
multiple	O
participants	B
.	O
throughout	O
the	O
ing	O
[	O
202	O
,	O
203	O
,	O
204	O
]	O
,	O
speaker	B
i	O
d	O
and	O
diarization	B
[	O
205	O
,	O
206	O
,	O
113	O
]	O
,	O
period	O
2002	O
to	O
2009	O
,	O
the	O
rt	O
evaluation	B
series	O
promoted	O
and	O
have	O
greatly	O
improved	O
the	O
speaker	B
-	O
attributed	O
transcription	B
ac-	O
gauged	O
advances	O
in	O
speaker	B
diarization	I
as	O
well	O
as	O
asr	B
tech-	O
curacy	O
,	O
enabling	O
such	O
commercialization	O
.	O
bi	O
-	O
modal	O
process-	O
nology	O
.	O
ing	O
combining	O
cameras	O
with	O
microphone	O
arrays	O
has	O
further	O
im-	O
dihard	B
challenge	I
[	O
189	O
,	O
85	O
]	O
is	O
the	O
most	O
recent	O
evaluation	B
proved	O
the	O
overall	O
performance	O
[	O
207	O
,	O
208	O
]	O
.	O
as	O
such	O
,	O
these	O
latest	O
that	O
focuses	O
on	O
challenging	O
diarization	B
tasks	O
.	O
dihard	O
chal-	O
trends	O
motivated	O
us	O
to	O
include	O
an	O
end	O
-	O
to	O
-	O
end	O
audio	O
-	O
visual	O
meet-	O
lenge	O
data	B
contains	O
many	O
diﬀerent	O
challenging	O
and	O
diverse	O
do-	O
ing	O
transcription	B
system	O
overview	O
in	O
this	O
paper	O
.	O
mains	O
including	O
the	O
recordings	O
from	O
restaurants	O
,	O
meetings	O
,	O
in-	O
reﬂecting	O
the	O
variety	O
of	O
application	B
scenarios	O
,	O
customer	O
terview	O
videos	B
and	O
court	O
room	O
.	O
dihard	O
evaluation	B
focuses	O
on	O
needs	O
,	O
and	O
business	O
scope	O
,	O
diﬀerent	O
constraints	O
may	O
be	O
imposed	O
the	O
performance	O
gap	O
of	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
diarization	B
systems	I
on	O
on	O
meeting	O
transcription	B
systems	O
.	O
for	O
example	O
,	O
it	O
is	O
most	O
of-	O
challenging	O
domains	O
(	O
e.g.	O
recordings	O
from	O
outdoors	O
)	O
and	O
rel-	O
ten	O
required	O
to	O
provide	O
the	O
resulting	O
transcriptions	B
in	O
low	O
la-	O
atively	O
clean	O
speech	O
(	O
e.g.	O
telephonic	O
speech	O
)	O
.	O
dihard	O
chal-	O
tency	O
,	O
making	O
the	O
diarization	B
and	O
recognition	O
even	O
more	O
chal-	O
lenge	O
employs	O
a	O
stricter	O
evaluation	B
scheme	O
where	O
the	O
scoring	O
lenging	O
.	O
on	O
the	O
other	O
hand	O
,	O
the	O
architecture	B
of	O
the	O
transcription	B
rule	O
does	O
not	O
have	O
“	O
no	O
score	B
”	O
collar	O
and	O
also	O
evaluates	O
over-	O
system	O
can	O
substantially	O
improve	O
the	O
overall	O
performance	O
,	O
e.g.	O
,	O
lapped	O
regions	O
.	O
in	O
addition	O
,	O
dihard	B
challenge	I
also	O
employed	O
employing	O
microphone	O
arrays	O
of	O
known	O
geometry	O
as	O
the	O
input	B
jer	O
.	O
device	O
.	O
also	O
,	O
in	O
the	O
case	O
where	O
the	O
expected	O
meeting	O
attendees	O
the	O
chime-6	O
challenge	B
[	O
89	O
]	O
track	O
2	O
revisits	O
the	O
previous	O
are	O
known	O
beforehand	O
,	O
the	O
transcription	B
system	O
can	O
further	O
im-	O
chime-5	O
challenge	B
[	O
191	O
]	O
and	O
further	O
considers	O
the	O
problem	O
of	O
prove	O
speaker	B
attribution	O
,	O
all	O
while	O
providing	O
the	O
exact	O
name	O
of	O
distant	O
multi	O
-	O
microphone	O
conversational	O
speech	O
diarization	B
and	O
the	O
speaker	B
,	O
instead	O
of	O
a	O
randomly	O
generated	O
discrete	O
speaker	B
recognition	O
in	O
everyday	O
home	O
environments	O
.	O
although	O
the	O
ﬁnal	O
labels	O
.	O
evaluation	B
criterion	B
is	O
ranked	O
with	O
the	O
wer	O
,	O
the	O
challenge	B
par-	O
two	O
diﬀerent	O
scenarios	O
in	O
this	O
space	O
are	O
presented	O
:	O
ﬁrst	O
,	O
a	O
ticipants	O
in	O
this	O
track	O
also	O
need	O
to	O
submit	O
the	O
diarization	B
result	O
.	O
ﬁx	O
-	O
geometry	O
microphone	O
array	O
combined	O
with	O
a	O
ﬁsh	O
-	O
eye	O
cam-	O
the	O
evaluation	B
metrics	I
of	O
the	O
diarization	B
follow	O
the	O
dihard	O
era	O
system	O
,	O
and	O
second	O
,	O
an	O
ad	O
-	O
hoc	O
geometry	O
microphone	O
array	O
challenge	B
,	O
i.e	O
.	O
,“no	O
score	B
”	O
collar	O
and	O
it	O
also	O
evaluates	O
overlapped	O
system	O
without	O
a	O
camera	O
.	O
in	O
both	O
scenarios	O
,	O
a	O
“	O
non	O
-	O
binding	O
”	O
regions	O
when	O
computing	O
the	O
der	O
and	O
jer	O
.	O
list	O
of	O
participants	B
and	O
their	O
corresponding	O
speaker	B
proﬁles	O
are	O
the	O
voxceleb	O
speaker	B
recognition	O
challenge	B
(	O
voxsrc	O
)	O
is	O
considered	O
known	O
.	O
in	O
more	O
detail	O
,	O
the	O
transcription	B
system	O
has	O
the	O
recent	O
evaluation	B
series	O
for	O
speaker	B
recognition	O
systems	O
access	O
to	O
the	O
invitees	O
’	O
names	O
and	O
proﬁles	O
,	O
however	O
the	O
actual	O
at-	O
[	O
197	O
,	O
105	O
]	O
.	O
the	O
goal	O
of	O
voxsrc	O
is	O
to	O
probe	O
how	O
well	O
the	O
cur-	O
tendees	O
may	O
not	O
accurately	O
match	O
those	O
invited	O
.	O
as	O
such	O
,	O
there	O
rent	O
technology	O
can	O
cope	O
with	O
the	O
speech	O
“	O
in	O
the	O
wild	O
”	O
.	O
the	O
is	O
an	O
option	O
to	O
either	O
include	O
“	O
unannounced	O
”	O
participants	B
.	O
also	O
,	O
evaluation	B
data	B
is	O
obtained	O
from	O
youtube	O
videos	B
of	O
various	O
do-	O
some	O
of	O
the	O
invitees	O
may	O
not	O
have	O
proﬁles	O
.	O
in	O
both	O
scenarios	O
,	O
mains	O
,	O
such	O
as	O
celebrity	O
interviews	O
,	O
news	O
shows	O
,	O
talk	O
shows	O
,	O
there	O
is	O
a	O
constraint	O
of	O
low	O
-	O
latency	O
transcriptions	B
,	O
where	O
initial	O
and	O
debates	O
.	O
the	O
audio	O
includes	O
various	O
types	O
of	O
background	O
results	B
need	O
to	O
be	O
shown	O
with	O
low	O
latency	O
.	O
the	O
ﬁnalized	O
results	B
noises	O
,	O
laughter	O
as	O
well	O
as	O
noticeable	O
portion	O
of	O
overlapping	B
can	O
be	O
updated	O
later	O
in	O
an	O
oﬄine	O
fashion	O
.	O
speech	O
,	O
all	O
of	O
which	O
make	O
the	O
task	O
very	O
challenging	O
.	O
this	O
eval-	O
some	O
of	O
the	O
technical	O
challenges	B
to	O
overcome	O
are	O
[	O
209	O
]	O
:	O
uation	O
series	O
initially	O
started	O
with	O
a	O
pure	O
speaker	B
veriﬁcation	O
task	O
[	O
197	O
]	O
,	O
and	O
the	O
diarization	B
task	O
was	O
added	O
as	O
the	O
track	O
4	O
1	O
.	O
although	O
asr	B
on	O
overlapping	B
speech	I
is	O
one	O
of	O
the	O
main	O
at	O
the	O
latest	O
evaluation	B
at	O
the	O
voxceleb	O
speaker	B
recognition	O
challenges	B
in	O
meeting	O
transcription	B
,	O
limited	O
progress	O
has	O
challenge	B
2020	O
(	O
voxsrc-20	O
)	O
[	O
105	O
]	O
.	O
the	O
voxconverse	O
dataset	O
been	O
made	O
over	O
the	O
years	O
.	O
numerous	O
multi	O
-	O
channel	O
18speech	O
separation	O
methods	O
have	O
been	O
proposed	O
based	O
on	O
speech	O
and	O
spoken	B
language	I
are	O
central	O
to	O
conversational	O
in-	O
independent	O
component	O
analysis(ica	O
)	O
or	O
spatial	O
clus-	O
teractions	O
and	O
carry	O
crucial	O
information	B
about	O
a	O
speaker	B
’s	O
in-	O
tering	O
[	O
210	O
,	O
211	O
,	O
212	O
,	O
213	O
,	O
214	O
,	O
215	O
]	O
,	O
but	O
applying	O
them	O
tent	O
,	O
emotions	O
,	O
identity	O
,	O
age	O
and	O
other	O
individual	O
and	O
interper-	O
to	O
a	O
meeting	O
setup	B
had	O
limited	O
success	O
.	O
in	O
addition	O
,	O
neu-	O
sonal	O
trait	O
and	O
state	O
variables	O
including	O
health	O
state	O
,	O
and	O
compu-	O
ral	O
network	B
-	O
based	O
separation	O
methods	O
like	O
permutation	O
in-	O
tational	O
advances	O
are	O
increasingly	O
allowing	O
for	O
accessing	O
such	O
variant	O
training	O
(	O
pit	O
)	O
[	O
59	O
]	O
or	O
deep	O
clustering	B
(	O
dc	O
)	O
[	O
58	O
]	O
rich	O
information	B
[	O
219	O
,	O
220	O
]	O
.	O
for	O
example	O
,	O
knowing	O
how	O
much	O
,	O
can	O
not	O
adequately	O
address	O
reverberation	O
and	O
background	O
and	O
how	O
,	O
a	O
child	O
speaks	O
in	O
an	O
interaction	O
reveals	O
critical	O
infor-	O
noise	O
[	O
216	O
]	O
.	O
mation	O
about	O
the	O
developmental	O
state	O
,	O
and	O
oﬀers	O
clues	O
to	O
clini-	O
cians	O
in	O
diagnosing	O
disorders	O
such	O
as	O
autism	O
[	O
221	O
]	O
.	O
such	O
anal-	O
2	O
.	O
flexible	O
framework	O
:	O
it	O
is	O
desirable	O
that	O
the	O
transcription	B
yses	O
are	O
made	O
possible	O
by	O
capturing	O
and	O
processing	B
the	O
audio	O
system	O
can	O
process	B
all	O
the	O
available	O
information	B
,	O
such	O
as	O
recordings	O
of	O
the	O
interactions	O
,	O
often	O
involving	O
two	O
or	O
more	O
peo-	O
the	O
multi	O
-	O
channel	O
audio	O
and	O
the	O
visual	O
cues	O
.	O
the	O
system	O
ple	O
.	O
an	O
important	O
foundational	O
step	O
is	O
identifying	O
and	O
associ-	O
needs	O
to	O
process	B
a	O
dynamically	O
changing	O
number	O
of	O
au-	O
ating	O
the	O
speech	O
portions	O
belonging	O
to	O
speciﬁc	O
individuals	O
in-	O
dio	O
channels	B
without	O
loss	O
of	O
performance	O
.	O
as	O
such	O
,	O
the	O
volved	O
in	O
the	O
conversation	O
.	O
the	O
technologies	O
that	O
provide	O
this	O
architecture	B
needs	O
to	O
be	O
modular	O
enough	O
to	O
encompass	O
the	O
capability	O
are	O
speech	B
activity	I
detection	I
(	O
sad	O
)	O
and	O
speaker	B
di-	O
diﬀerent	O
settings	O
.	O
arization	O
.	O
speech	O
portions	O
segmented	O
with	O
speaker	B
-	O
speciﬁc	O
in-	O
formation	O
provided	O
by	O
speaker	B
diarization	I
,	O
by	O
itself	O
without	O
any	O
3	O
.	O
speaker	B
-	O
attributed	O
asr	B
of	O
natural	O
meetings	O
requires	O
on-	O
line	O
/	O
streaming	O
asr	B
,	O
audio	O
pre	O
-	O
processing	B
such	O
as	O
dere-	O
explicit	O
lexical	O
transcription	B
,	O
can	O
oﬀer	O
important	O
information	B
to	O
domain	B
experts	O
who	O
can	O
take	O
advantage	O
of	O
speaker	B
diarization	I
verberation	O
,	O
and	O
accurate	O
diarization	B
and	O
speaker	B
identi-	O
results	B
for	O
quantitative	O
turn	O
-	O
taking	O
analysis	B
.	O
ﬁcation	O
.	O
these	O
multiple	O
processing	B
steps	B
are	O
usually	O
op-	O
a	O
domain	B
that	O
is	O
the	O
most	O
relevant	O
such	O
analyses	O
of	O
spoken	O
timized	O
separately	O
and	O
thus	O
,	O
the	O
overall	O
pipeline	O
is	O
most	O
frequently	O
ineﬃcient	O
.	O
conversational	O
interactions	O
relates	O
to	O
behavioral	O
signal	B
process-	O
ing	O
(	O
bsp	O
)	O
[	O
222	O
,	O
219	O
]	O
which	O
refers	O
to	O
the	O
technology	O
and	O
algo-	O
4	O
.	O
using	O
multiple	O
,	O
not	O
-	O
synchronized	O
audio	O
streams	O
,	O
e.g.	O
,	O
au-	O
rithms	O
for	O
modeling	O
and	O
understanding	O
human	O
communicative	O
,	O
dio	O
capturing	O
with	O
mobile	O
devices	O
,	O
adds	O
complexity	O
to	O
the	O
aﬀective	O
and	O
social	O
behavior	O
.	O
for	O
example	O
,	O
these	O
may	O
include	O
meeting	O
setup	B
and	O
processing	B
.	O
in	O
return	O
,	O
we	O
gain	O
poten-	O
analyzing	O
how	O
positive	O
or	O
negative	O
a	O
person	O
is	O
,	O
how	O
empathic	O
tially	O
better	O
spatial	O
coverage	O
since	O
the	O
devices	O
are	O
usually	O
an	O
individual	O
toward	O
another	O
,	O
what	O
does	O
the	O
behavior	O
patterns	O
distributed	O
around	O
the	O
room	O
and	O
near	O
the	O
speakers	O
.	O
as	O
reveal	O
about	O
the	O
relationship	O
status	O
,	O
and	O
health	O
condition	B
of	O
an	O
part	O
of	O
the	O
application	B
scenario	O
,	O
the	O
meeting	O
participants	B
individual	O
[	O
220	O
]	O
.	O
bsp	O
involves	O
addressing	O
all	O
the	O
complexi-	O
bring	O
their	O
personal	O
devices	O
,	O
which	O
can	O
be	O
re	O
-	O
purposed	O
ties	O
of	O
spontaneous	O
interactions	O
in	O
conversations	O
with	O
additional	O
to	O
improve	O
the	O
overall	O
meeting	O
transcription	B
quality	B
.	O
on	O
challenges	B
involved	O
in	O
handling	O
and	O
understanding	O
emotional	O
,	O
the	O
other	O
hand	O
,	O
while	O
there	O
are	O
several	O
pioneering	O
stud-	O
social	O
and	O
interpersonal	O
behavioral	O
dynamics	O
revealed	O
through	O
ies	O
[	O
217	O
]	O
,	O
it	O
is	O
unclear	O
what	O
the	O
best	O
strategies	O
are	O
for	O
vocal	O
verbal	O
and	O
nonverbal	O
cues	O
of	O
the	O
interaction	O
participants	B
.	O
consolidating	O
multiple	O
asynchronous	O
audio	O
streams	O
and	O
to	O
therefore	O
,	O
the	O
knowledge	B
of	O
speaker	B
speciﬁc	O
vocal	O
informa-	O
what	O
extent	O
they	O
work	O
for	O
natural	O
meetings	O
in	O
online	O
and	O
tion	O
plays	O
a	O
signiﬁcant	O
role	O
in	O
bsp	O
,	O
requiring	O
highly	O
accurate	O
oﬄine	O
setups	O
.	O
speaker	B
diarization	I
performance	O
.	O
for	O
example	O
,	O
speaker	B
diariza-	O
tion	O
module	O
is	O
employed	O
as	O
a	O
pre	O
-	O
processing	B
module	O
for	O
analyz-	O
based	O
on	O
these	O
considerations	O
,	O
an	O
architecture	B
of	O
meeting	O
ing	O
psychotherapy	O
mechanisms	O
and	O
quality	B
[	O
223	O
]	O
,	O
and	O
suicide	O
transcription	B
system	O
with	O
asynchronous	O
distant	O
microphones	O
risk	O
assessment	O
[	O
224	O
]	O
.	O
have	O
been	O
proposed	O
in	O
[	O
161	O
]	O
.	O
in	O
this	O
work	O
,	O
various	O
fusion	O
another	O
popular	O
application	B
of	O
speaker	B
diarization	I
for	O
con-	O
strategies	O
have	O
been	O
investigating	O
:	O
from	O
early	O
fusion	O
beam-	O
versation	O
interaction	O
analysis	B
is	O
the	O
medical	O
doctor	O
-	O
patient	O
in-	O
forming	O
the	O
audio	O
signals	B
,	O
to	O
mid	O
-	O
fusion	O
combining	O
senones	O
teractions	O
.	O
in	O
the	O
system	O
described	O
in	O
[	O
225	O
]	O
,	O
the	O
nature	O
of	O
mem-	O
per	O
channel	O
,	O
to	O
late	O
fusion	O
combining	O
the	O
diarization	B
and	O
asr	B
ory	O
problem	O
of	O
a	O
patient	O
is	O
detected	O
from	O
the	O
conversations	O
be-	O
results	B
[	O
147	O
]	O
.	O
the	O
resulting	O
system	O
performance	O
was	O
bench-	O
tween	O
neurologists	O
and	O
patients	O
.	O
speech	O
and	O
language	O
features	O
marked	O
on	O
real	O
-	O
world	O
meeting	O
recordings	O
against	O
ﬁx	O
-	O
geometry	O
extracted	O
from	O
asr	B
transcripts	B
combined	O
with	O
speaker	B
diariza-	O
systems	O
.	O
as	O
mentioned	O
above	O
,	O
the	O
requirement	O
of	O
speaker-	O
tion	O
results	B
are	O
used	O
to	O
predict	O
the	O
type	O
of	O
disorder	O
.	O
an	O
au-	O
attributed	O
transcriptions	B
with	O
low	O
latency	O
was	O
adhered	O
,	O
as	O
well	O
.	O
tomated	O
assistant	O
system	O
for	O
medical	O
domain	B
transcription	B
is	O
in	O
addition	O
to	O
the	O
end	O
-	O
to	O
-	O
end	O
system	O
analysis	B
,	O
the	O
paper	O
[	O
161	O
]	O
proposed	O
in	O
[	O
226	O
]	O
which	O
includes	O
speaker	B
diarization	I
module	O
,	O
proposed	O
the	O
idea	O
of	O
“	O
leave	O
-	O
one	O
-	O
out	O
beamforming	O
”	O
in	O
the	O
asyn-	O
asr	B
module	O
and	O
natural	O
language	O
generation	O
(	O
nlg	O
)	O
module	O
.	O
chronous	O
multi	O
-	O
microphone	O
setup	B
,	O
enriching	O
the	O
“	O
diversity	O
”	O
of	O
the	O
automated	O
assistant	O
module	O
accepts	O
the	O
audio	O
clip	O
and	O
out-	O
the	O
resulting	O
signals	B
,	O
as	O
proposed	O
in	O
[	O
218	O
]	O
.	O
finally	O
,	O
it	O
is	O
de-	O
puts	O
grammatically	O
correct	O
sentences	O
that	O
describe	O
the	O
topic	O
of	O
scribed	O
how	O
an	O
online	O
,	O
incremental	O
version	O
of	O
rover	O
can	O
pro-	O
the	O
conversation	O
,	O
subject	O
and	O
subject	O
’s	O
symptom	O
.	O
cess	O
both	O
the	O
asr	B
and	O
diarization	B
outputs	O
,	O
enhancing	O
the	O
over-	O
all	O
speaker	B
-	O
attributed	O
asr	B
performance	O
.	O
6.3	O
.	O
audio	O
indexing	O
content	O
-	O
based	O
audio	O
indexing	O
is	O
a	O
well	O
known	O
application	B
6.2	O
.	O
conversational	O
interaction	O
analysis	B
and	O
behavioral	O
mod-	O
domain	B
for	O
speaker	B
diarization	I
.	O
it	O
can	O
provide	O
meta	O
information	B
eling	O
such	O
as	O
the	O
content	O
or	O
data	B
type	O
of	O
a	O
given	O
audio	O
data	B
to	O
make	O
19information	O
retrieval	O
eﬃcient	O
since	O
search	O
query	O
by	O
machines	O
more	O
and	O
more	O
advancements	O
have	O
been	O
made	O
for	O
speaker	B
di-	O
would	O
be	O
limited	O
by	O
such	O
metadata	O
.	O
the	O
more	O
diverse	O
infor-	O
arization	O
,	O
from	O
a	O
method	B
that	O
replaces	O
a	O
single	O
module	O
into	O
a	O
mation	O
were	O
available	O
,	O
the	O
better	O
eﬃciency	O
we	O
could	O
achieve	O
in	O
deep	O
-	O
learning	O
-	O
based	O
one	O
,	O
to	O
a	O
fully	O
end	O
-	O
to	O
-	O
end	O
neural	O
diariza-	O
retrieving	O
audio	O
contents	O
from	O
a	O
database	O
.	O
tion	O
.	O
furthermore	O
,	O
as	O
the	O
speech	B
recognition	I
technology	O
be-	O
one	O
useful	O
piece	O
of	O
information	B
for	O
the	O
audio	O
indexing	O
would	O
comes	O
more	O
accessible	O
,	O
a	O
trend	O
to	O
tightly	O
integrate	O
speaker	B
di-	O
be	O
asr	B
transcripts	B
to	O
understand	O
the	O
content	O
of	O
speech	O
por-	O
arization	O
and	O
asr	B
systems	O
has	O
emerged	O
,	O
such	O
as	O
beneﬁting	O
tions	O
in	O
the	O
audio	O
data	B
.	O
speaker	B
diarization	I
can	O
augment	O
those	O
from	O
the	O
asr	B
output	B
to	O
improve	O
speaker	B
diarization	I
accuracy	O
.	O
transcripts	B
in	O
terms	B
of	O
“	O
who	O
spoke	O
when	O
”	O
,	O
which	O
was	O
the	O
main	O
as	O
of	O
late	O
,	O
joint	O
modeling	O
for	O
speaker	B
diarization	I
and	O
speech	O
purpose	O
of	O
the	O
rich	B
transcription	I
evaluation	B
series	O
[	O
20	O
]	O
as	O
we	O
recognition	O
is	O
investigated	O
in	O
an	O
attempt	O
to	O
enhance	O
the	O
over-	O
discussed	O
in	O
sections	O
4.1	O
and	O
5.3	O
.	O
the	O
aggregated	O
spoken	O
ut-	O
all	O
performance	O
.	O
thanks	O
to	O
these	O
great	O
achievement	O
,	O
speaker	B
terances	O
from	O
speakers	O
by	O
a	O
speaker	B
diarization	I
system	I
also	O
diarization	B
systems	I
have	O
already	O
been	O
deployed	O
in	O
many	O
appli-	O
enable	O
per	O
-	O
speaker	B
summary	O
or	O
keyword	O
list	O
-	O
up	O
,	O
which	O
can	O
be	O
cations	O
,	O
including	O
meeting	O
transcription	B
,	O
conversational	O
inter-	O
used	O
for	O
another	O
query	O
values	B
to	O
retrieve	O
relevant	O
contents	O
from	O
action	O
analysis	B
,	O
audio	O
indexing	O
,	O
and	O
conversational	O
ai	O
systems	O
.	O
the	O
database	O
.	O
in	O
[	O
227	O
]	O
,	O
we	O
can	O
peek	O
a	O
view	O
of	O
how	O
speaker	B
as	O
we	O
have	O
seen	O
,	O
tremendous	O
progress	O
has	O
been	O
made	O
for	O
diarization	B
outputs	O
can	O
be	O
linked	O
for	O
information	B
searching	O
in	O
speaker	B
diarization	I
systems	I
.	O
nevertheless	O
,	O
there	O
are	O
still	O
much	O
consumer	O
facing	O
applications	O
.	O
room	O
for	O
improvement	O
.	O
as	O
the	O
ﬁnal	O
remark	O
,	O
we	O
conclude	O
this	O
paper	O
by	O
listing	O
up	O
the	O
remaining	O
challenges	B
for	O
speaker	B
diariza-	O
6.4	O
.	O
conversational	O
ai	O
tion	O
towards	O
future	O
research	B
and	O
development	O
.	O
thanks	O
to	O
the	O
advance	O
of	O
asr	B
technology	O
,	O
the	O
applications	O
online	O
processing	B
of	O
speaker	B
diarization	I
.	O
most	O
speaker	B
di-	O
of	O
asr	B
are	O
evolved	O
from	O
simple	O
voice	O
command	O
recognition	O
arization	O
methods	O
assume	O
that	O
an	O
entire	O
recording	B
can	O
be	O
ob-	O
systems	O
to	O
conversational	O
ai	O
systems	O
.	O
conversational	O
ai	O
sys-	O
served	O
to	O
execute	O
speaker	B
diarization	I
.	O
however	O
,	O
many	O
applica-	O
tems	O
,	O
as	O
opposed	O
to	O
voice	O
command	O
recognition	O
systems	O
,	O
have	O
tions	O
such	O
as	O
meeting	O
transcription	B
systems	O
or	O
smart	O
agents	O
re-	O
features	O
that	O
voice	O
command	O
recognition	O
systems	O
are	O
lack	O
of	O
.	O
quire	O
only	O
short	O
latency	O
for	O
assigning	O
the	O
speaker	B
.	O
while	O
there	O
the	O
fundamental	O
idea	O
of	O
conversational	O
ai	O
is	O
making	O
a	O
ma-	O
have	O
been	O
several	O
attempts	O
to	O
make	O
online	O
speaker	B
diarization	I
chine	O
that	O
humans	O
can	O
talk	O
to	O
and	O
interact	O
with	O
the	O
system	O
.	O
in	O
system	O
both	O
for	O
clustering	B
-	O
based	O
systems	O
(	O
e.g.	O
,	O
[	O
205	O
]	O
)	O
and	O
neu-	O
this	O
sense	O
,	O
focusing	O
on	O
an	O
interested	O
speaker	B
in	O
multi	O
-	O
party	O
set-	O
ral	O
network	B
-	O
based	O
diarization	B
systems	I
(	O
e.g.	O
,	O
[	O
55	O
,	O
172	O
,	O
173	O
]	O
)	O
,	O
it	O
’s	O
ting	O
is	O
one	O
of	O
the	O
most	O
important	O
feature	O
of	O
conversational	O
ai	O
still	O
remaining	O
as	O
a	O
challenging	O
problem	O
.	O
and	O
speaker	B
diarization	I
becomes	O
essential	O
feature	O
for	O
conver-	O
sational	O
ai	O
.	O
for	O
example	O
,	O
conversational	O
ai	O
equipped	O
in	O
a	O
car	O
domain	B
mismatch	O
.	O
a	O
model	B
that	O
is	O
trained	O
on	O
a	O
data	B
in	O
a	O
spe-	O
can	O
pay	O
attention	O
to	O
a	O
speciﬁc	O
speaker	B
that	O
is	O
demanding	O
a	O
piece	O
ciﬁc	O
domain	B
often	O
works	O
poorly	O
on	O
a	O
data	B
in	O
another	O
domain	B
.	O
of	O
information	B
from	O
the	O
navigation	O
system	O
by	O
applying	O
speaker	B
for	O
example	O
,	O
it	O
is	O
experimentally	O
known	O
that	O
the	O
eend	O
model	B
diarization	B
along	O
with	O
asr	B
.	O
tends	O
to	O
overﬁt	O
to	O
the	O
distribution	O
of	O
the	O
speaker	B
overlaps	B
of	O
the	O
smart	O
speakers	O
and	O
voice	O
assistants	O
are	O
the	O
most	O
popular	O
training	B
data	I
[	O
56	O
]	O
.	O
such	O
domain	B
mismatch	O
issue	O
is	O
universal	O
products	O
where	O
speaker	B
diarization	I
plays	O
a	O
signiﬁcant	O
role	O
for	O
for	O
any	O
training	O
-	O
based	O
method	B
.	O
given	O
the	O
growing	O
interest	O
for	O
conversational	O
ai	O
.	O
since	O
response	O
time	B
and	O
online	O
processing	B
trainable	O
speaker	B
diarization	I
systems	I
,	O
it	O
will	O
become	O
more	O
im-	O
are	O
the	O
crucial	O
factors	O
in	O
real	O
-	O
life	O
settings	O
,	O
the	O
demand	O
for	O
end-	O
portant	O
to	O
assess	O
the	O
ability	O
for	O
handling	O
the	O
variety	O
of	O
inputs	O
.	O
to	O
-	O
end	O
speaker	B
diarization	I
system	I
integrated	O
into	O
asr	B
pipeline	O
the	O
international	O
evaluation	B
eﬀorts	O
for	O
speaker	B
diarization	I
such	O
is	O
growing	O
.	O
the	O
performance	O
of	O
incremental	O
(	O
online	O
)	O
asr	B
and	O
as	O
the	O
dihard	B
challenge	I
[	O
189	O
,	O
85	O
,	O
190	O
]	O
or	O
voxsrc	O
[	O
197	O
,	O
105	O
]	O
speaker	B
diarization	I
of	O
the	O
commercial	O
asr	B
services	O
are	O
eval-	O
will	O
also	O
have	O
great	O
importance	O
for	O
that	O
direction	O
.	O
uated	O
and	O
compared	O
in	O
[	O
228	O
]	O
.	O
it	O
is	O
expected	O
that	O
the	O
real	O
-	O
time	B
and	O
low	O
latency	O
aspect	O
of	O
speaker	B
diarization	I
will	O
be	O
more	O
em-	O
speaker	B
overlap	O
.	O
overlap	O
of	O
multi	O
-	O
talker	O
speech	O
is	O
inevitable	O
phasized	O
in	O
the	O
speaker	B
diarization	I
systems	I
in	O
the	O
future	O
since	O
nature	O
of	O
conversation	O
.	O
for	O
example	O
,	O
average	B
12	O
%	O
to	O
15	O
%	O
the	O
performance	O
of	O
online	O
diarization	B
and	O
online	O
asr	B
still	O
have	O
of	O
speaker	B
overlap	O
was	O
observed	O
for	O
meeting	O
recordings	O
[	O
229	O
,	O
much	O
room	O
for	O
improvement	O
.	O
102	O
]	O
,	O
and	O
it	O
can	O
become	O
higher	O
for	O
daily	O
conversations	O
[	O
230	O
,	O
191	O
,	O
89	O
]	O
.	O
nevertheless	O
,	O
many	O
conventional	O
speaker	B
diarization	I
7	O
.	O
challenges	B
and	O
the	O
future	O
of	O
speaker	B
diarization	I
systems	I
,	O
especially	O
clustering	B
-	O
based	O
systems	O
,	O
treated	O
only	O
non-	O
overlapped	O
region	O
of	O
recordings	O
sometimes	O
even	O
for	O
the	O
evalua-	O
this	O
paper	O
has	O
provided	O
a	O
comprehensive	O
overview	O
of	O
tion	O
metric	B
.	O
while	O
the	O
topic	O
has	O
been	O
studied	O
for	O
long	O
years	O
(	O
e.g.	O
speaker	B
diarization	I
techniques	B
,	O
highlighting	O
the	O
recent	O
devel-	O
early	O
works	O
[	O
231	O
,	O
232	O
]	O
)	O
,	O
there	O
is	O
a	O
growing	O
interest	O
for	O
handling	O
opment	O
of	O
deep	B
learning	I
-	O
based	O
diarization	B
approaches	O
.	O
in	O
the	O
the	O
speaker	B
overlaps	B
towards	O
better	O
speaker	B
diarization	I
,	O
includ-	O
early	O
days	O
,	O
a	O
speaker	B
diarization	I
system	I
was	O
developed	O
as	O
a	O
ing	O
the	O
application	B
of	O
speech	B
separation	I
[	O
104	O
]	O
,	O
post	O
-	O
processing	B
pipeline	O
of	O
sub	O
-	O
modules	O
including	O
front	O
-	O
end	O
processing	B
,	O
speech	O
[	O
233	O
,	O
162	O
]	O
,	O
and	O
joint	O
modeling	O
of	O
speech	B
separation	I
and	O
speaker	B
activity	B
detection	I
,	O
segmentation	B
,	O
speaker	B
embedding	O
extraction	B
,	O
diarization	B
[	O
76	O
,	O
184	O
]	O
.	O
clustering	B
,	O
and	O
post	O
-	O
processing	B
,	O
leading	O
to	O
a	O
standalone	O
sys-	O
tem	O
without	O
much	O
connection	O
to	O
other	O
components	B
in	O
a	O
given	O
integration	O
with	O
asr	B
.	O
not	O
all	O
but	O
many	O
applications	O
require	O
speech	O
application	B
.	O
as	O
the	O
rise	O
of	O
the	O
deep	B
learning	I
technology	O
,	O
asr	B
results	B
along	O
with	O
speaker	B
diarization	I
results	B
.	O
in	O
the	O
line	O
of	O
20the	O
modular	O
combination	O
of	O
speaker	B
diarization	I
and	O
asr	B
,	O
some	O
[	O
10	O
]	O
m.	O
a.	O
siegler	O
,	O
u.	O
jain	O
,	O
b.	O
raj	O
,	O
r.	O
m.	O
stern	O
,	O
automatic	O
segmentation	B
,	O
systems	O
put	O
a	O
speaker	B
diarization	I
system	I
before	O
asr	B
[	O
91	O
]	O
while	O
classiﬁcation	O
and	O
clustering	B
of	O
broadcast	O
news	O
audio	O
,	O
in	O
:	O
proceedings	O
of	O
darpa	O
speech	B
recognition	I
workshop	O
,	O
1997	O
,	O
pp	O
.	O
97–99	O
.	O
some	O
systems	O
put	O
a	O
diarization	B
system	O
after	O
asr	B
[	O
209	O
]	O
.	O
both	O
[	O
11	O
]	O
h.	O
jin	O
,	O
f.	O
kubala	O
,	O
r.	O
schwartz	O
,	O
automatic	O
speaker	B
clustering	B
,	O
in	O
:	O
pro-	O
types	O
of	O
systems	O
showed	O
a	O
strong	O
performance	O
for	O
a	O
speciﬁc	O
ceedings	O
of	O
speech	B
recognition	I
workshop	O
,	O
1997	O
.	O
task	O
,	O
and	O
it	O
is	O
still	O
an	O
open	O
problem	O
that	O
what	O
kind	O
of	O
system	O
ar-	O
[	O
12	O
]	O
h.	O
s.	O
beigi	O
,	O
s.	O
h.	O
maes	O
,	O
speaker	B
,	O
channel	O
and	O
environment	O
change	B
chitecture	O
is	O
the	O
best	O
for	O
the	O
speaker	B
diarization	I
and	O
asr	B
tasks	O
detection	B
,	O
in	O
:	O
proceedings	O
of	O
world	O
congress	O
of	O
automation	O
,	O
1998	O
.	O
[	O
13	O
]	O
s.	O
s.	O
chen	O
,	O
p.	O
s.	O
gopalakrishnan	O
,	O
speaker	B
,	O
environment	O
and	O
channel	O
[	O
88	O
]	O
.	O
furthermore	O
,	O
there	O
is	O
another	O
line	O
of	O
research	B
to	O
jointly	O
change	B
detection	I
and	O
clustering	B
via	O
the	O
bayesian	O
information	B
criterion	B
,	O
perform	O
speaker	B
diarization	I
and	O
asr	B
[	O
77	O
,	O
78	O
,	O
79	O
,	O
184	O
]	O
as	O
intro-	O
in	O
:	O
tech	O
.	O
rep	O
.	O
,	O
ibm	O
t.	O
j.	O
watson	O
research	B
center	O
,	O
1998	O
,	O
pp	O
.	O
127–132	O
.	O
duced	O
in	O
section	O
4	O
.	O
the	O
joint	O
modeling	O
approach	O
could	O
leverage	O
[	O
14	O
]	O
a.	O
solomonoﬀ	O
,	O
a.	O
mielke	O
,	O
m.	O
schmidt	O
,	O
h.	O
gish	O
,	O
clustering	B
speakers	O
the	O
inter	O
-	O
dependency	O
between	O
speaker	B
diarization	I
and	O
asr	B
to	O
by	O
their	O
voices	O
,	O
in	O
:	O
proceedings	O
of	O
ieee	O
international	O
conference	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
,	O
1998	O
,	O
pp	O
.	O
757–760	O
.	O
better	O
perform	O
both	O
tasks	O
.	O
however	O
,	O
it	O
has	O
not	O
yet	O
fully	O
inves-	O
[	O
15	O
]	O
j.-l	O
.	O
gauvain	O
,	O
g.	O
adda	O
,	O
l.	O
lamel	O
,	O
m.	O
adda	O
-	O
decker	O
,	O
transcription	B
of	O
tigated	O
whether	O
such	O
joint	O
frameworks	O
perform	O
better	O
than	O
the	O
broadcast	O
news	O
:	O
the	O
limsi	O
nov	O
96	O
hub4	O
system	O
,	O
in	O
:	O
proceedings	O
of	O
well	O
-	O
tuned	O
modular	O
systems	O
.	O
overall	O
,	O
the	O
integration	O
of	O
speaker	B
arpa	O
speech	B
recognition	I
workshop	O
,	O
1997	O
,	O
pp	O
.	O
56–63	O
.	O
diarization	B
and	O
asr	B
is	O
one	O
of	O
the	O
hottest	O
topics	O
that	O
has	O
still	O
[	O
16	O
]	O
j.-l	O
.	O
gauvain	O
,	O
l.	O
lamel	O
,	O
g.	O
adda	O
,	O
the	O
limsi	O
1997	O
hub-4e	O
transcrip-	O
tion	O
system	O
,	O
in	O
:	O
proceedings	O
of	O
darpa	O
news	O
transcription	B
and	O
under-	O
been	O
pursued	O
.	O
standing	O
workshop	O
,	O
1998	O
,	O
pp	O
.	O
75–79	O
.	O
[	O
17	O
]	O
j.-l	O
.	O
gauvain	O
,	O
l.	O
lamel	O
,	O
g.	O
adda	O
,	O
partitioning	O
and	O
transcription	B
of	O
audio	O
visual	O
modeling	O
.	O
visual	O
information	B
contains	O
a	O
strong	O
broadcast	O
news	O
data	B
,	O
in	O
:	O
proceedings	O
of	O
the	O
international	O
conference	O
clue	O
to	O
identify	O
speakers	O
.	O
for	O
example	O
,	O
the	O
video	O
captured	O
by	O
on	O
spoken	B
language	I
processing	B
,	O
1998	O
,	O
pp	O
.	O
1335–1338	O
.	O
[	O
18	O
]	O
d.	O
liu	O
,	O
f.	O
kubala	O
,	O
fast	O
speaker	B
change	I
detection	B
for	O
broadcast	O
news	O
a	O
ﬁsheye	O
camera	O
was	O
used	O
to	O
improve	O
the	O
speaker	B
diarization	I
transcription	B
and	O
indexing	O
,	O
in	O
:	O
proceedings	O
of	O
the	O
international	O
confer-	O
accuracy	O
in	O
a	O
meeting	O
transcription	B
task	O
[	O
209	O
]	O
.	O
the	O
visual	O
in-	O
ence	O
on	O
spoken	B
language	I
processing	B
,	O
1999	O
,	O
pp	O
.	O
1031–1034	O
.	O
formation	O
was	O
also	O
used	O
to	O
signiﬁcantly	O
improve	O
the	O
speaker	B
[	O
19	O
]	O
ami	O
consortium	O
.	O
http://www.amiproject.org/index.html	O
.	O
diarization	B
accuracy	O
for	O
speaker	B
diarization	I
on	O
youtube	O
video	O
[	O
20	O
]	O
nist	O
,	O
rich	B
transcription	I
evaluation	B
.	O
https://www.nist.gov/itl/	O
[	O
192	O
]	O
.	O
while	O
these	O
studies	O
showed	O
the	O
eﬀectiveness	O
of	O
visual	O
iad	O
/	O
mig	O
/	O
rich	O
-	O
transcription	B
-	O
evaluation	B
.	O
[	O
21	O
]	O
j.	O
ajmera	O
,	O
c.	O
wooters	O
,	O
a	O
robust	B
speaker	I
clustering	B
algorithm	O
,	O
in	O
:	O
pro-	O
information	B
,	O
the	O
audio	O
-	O
visual	O
speaker	B
diarization	I
has	O
yet	O
been	O
ceedings	O
of	O
ieee	O
workshop	O
on	O
automatic	O
speech	B
recognition	I
and	O
un-	O
rarely	O
investigated	O
compared	O
with	O
audio	O
-	O
only	O
speaker	B
diariza-	O
derstanding	O
,	O
2003	O
,	O
pp	O
.	O
411–416	O
.	O
tion	O
,	O
and	O
there	O
will	O
be	O
many	O
rooms	O
for	O
the	O
improvement	O
.	O
[	O
22	O
]	O
s.	O
e.	O
tranter	O
,	O
d.	O
a.	O
reynolds	O
,	O
speaker	B
diarisation	O
for	O
broadcast	O
news	O
,	O
in	O
:	O
proceedings	O
of	O
odyssey	O
speaker	B
and	O
language	O
recognition	O
work-	O
shop	O
,	O
2004	O
,	O
pp	O
.	O
337–344	O
.	O
[	O
23	O
]	O
c.	O
wooters	O
,	O
j.	O
fung	O
,	O
b.	O
peskin	O
,	O
x.	O
anguera	O
,	O
toward	O
robust	B
speaker	I
seg-	O
references	B
mentation	O
:	O
the	O
icsi	O
-	O
sri	O
fall	O
2004	O
diarization	B
system	O
,	O
in	O
:	O
proceedings	O
of	O
fall	O
2004	O
rich	B
transcription	I
workshop	O
,	O
2004	O
,	O
pp	O
.	O
402–414	O
.	O
[	O
1	O
]	O
s.	O
e.	O
tranter	O
,	O
k.	O
yu	O
,	O
d.	O
a.	O
reynolds	O
,	O
g.	O
evermann	O
,	O
d.	O
y.	O
kim	O
,	O
p.	O
c.	O
[	O
24	O
]	O
d.	O
a.	O
reynolds	O
,	O
p.	O
torres	O
-	O
carrasquillo	O
,	O
the	O
mit	O
lincoln	O
laboratory	O
woodland	O
,	O
an	O
investigation	O
into	O
the	O
the	O
interactions	O
between	O
speaker	B
rt-04f	O
diarization	B
systems	I
:	O
applications	O
to	O
broadcast	O
audio	O
and	O
tele-	O
diarisation	O
systems	O
and	O
automatic	O
speech	O
transcription	B
,	O
cued	O
/	O
f-	O
phone	O
conversations	O
,	O
in	O
:	O
proceedings	O
of	O
fall	O
2004	O
rich	B
transcription	I
infeng	O
/	O
tr-464	O
(	O
2003	O
)	O
.	O
workshop	O
,	O
2004	O
.	O
[	O
2	O
]	O
s.	O
e.	O
tranter	O
,	O
d.	O
a.	O
reynolds	O
,	O
an	O
overview	O
of	O
automatic	O
speaker	B
di-	O
[	O
25	O
]	O
d.	O
a.	O
reynolds	O
,	O
p.	O
torres	O
-	O
carrasquillo	O
,	O
approaches	O
and	O
applications	O
of	O
arization	O
systems	O
,	O
ieee	O
transactions	O
on	O
audio	O
,	O
speech	O
,	O
and	O
language	O
audio	O
diarization	B
,	O
in	O
:	O
proceedings	O
of	O
ieee	O
international	O
conference	O
on	O
processing	B
14	O
(	O
2006	O
)	O
1557–1565	O
.	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
,	O
2005	O
,	O
pp	O
.	O
953–956	O
.	O
[	O
3	O
]	O
x.	O
anguera	O
,	O
s.	O
bozonnet	O
,	O
n.	O
evans	O
,	O
c.	O
fredouille	O
,	O
g.	O
friedland	O
,	O
[	O
26	O
]	O
x.	O
zhu	O
,	O
c.	O
barras	O
,	O
s.	O
meignier	O
,	O
j.-l	O
.	O
gauvain	O
,	O
combining	O
speaker	B
iden-	O
o.	O
vinyals	O
,	O
speaker	B
diarization	I
:	O
a	O
review	O
of	O
recent	O
research	B
,	O
ieee	O
tiﬁcation	O
and	O
bic	B
for	O
speaker	B
diarization	I
,	O
in	O
:	O
proceedings	O
of	O
the	O
an-	O
transactions	O
on	O
audio	O
,	O
speech	O
,	O
and	O
language	B
processing	I
20	O
(	O
2012	O
)	O
nual	O
conference	O
of	O
the	O
international	O
speech	B
communication	I
associa-	O
356–370	O
.	O
tion	O
,	O
2005	O
,	O
pp	O
.	O
2441–2444	O
.	O
[	O
4	O
]	O
h.	O
gish	O
,	O
m.	O
.	O
siu	O
,	O
r.	O
rohlicek	O
,	O
segregation	O
of	O
speakers	O
for	O
speech	O
[	O
27	O
]	O
c.	O
barras	O
,	O
xuan	O
zhu	O
,	O
s.	O
meignier	O
,	O
j.-l	O
.	O
gauvain	O
,	O
multistage	O
speaker	B
recognition	O
and	O
speaker	B
identiﬁcation	O
,	O
in	O
:	O
proceedings	O
of	O
ieee	O
inter-	O
diarization	B
of	O
broadcast	O
news	O
,	O
ieee	O
transactions	O
on	O
audio	O
,	O
speech	O
,	O
national	O
conference	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
,	O
1991	O
,	O
and	O
language	B
processing	I
14	O
(	O
2006	O
)	O
1505–1512	O
.	O
pp	O
.	O
873–876	O
.	O
[	O
28	O
]	O
n.	O
mirghafori	O
,	O
c.	O
wooters	O
,	O
nuts	O
and	O
ﬂakes	O
:	O
a	O
study	O
of	O
data	B
character-	O
[	O
5	O
]	O
m.-h	O
.	O
siu	O
,	O
y.	O
george	O
,	O
h.	O
gish	O
,	O
an	O
unsupervised	O
,	O
sequential	O
learning	O
al-	O
istics	O
in	O
speaker	B
diarization	I
,	O
in	O
:	O
proceedings	O
of	O
ieee	O
international	O
con-	O
gorithm	O
for	O
segmentation	B
for	O
speech	O
waveforms	O
with	O
multiple	O
speakers	O
,	O
ference	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
,	O
2006	O
,	O
pp	O
.	O
1017	O
–	O
in	O
:	O
proceedings	O
of	O
ieee	O
international	O
conference	O
on	O
acoustics	B
,	O
speech	O
1020	O
.	O
and	O
signal	B
processing	I
,	O
1992	O
,	O
pp	O
.	O
189–192	O
.	O
[	O
29	O
]	O
s.	O
meignier	O
,	O
d.	O
moraru	O
,	O
c.	O
fredouille	O
,	O
j.-f	O
.	O
bonastre	O
,	O
l.	O
besacier	O
,	O
step-	O
[	O
6	O
]	O
j.	O
r.	O
rohlicek	O
,	O
d.	O
ayuso	O
,	O
m.	O
bates	O
,	O
r.	O
bobrow	O
,	O
a.	O
boulanger	O
,	O
h.	O
gish	O
,	O
by	O
-	O
step	O
and	O
integrated	O
approaches	O
in	O
broadcast	O
news	O
speaker	B
diarization	I
,	O
p.	O
jeanrenaud	O
,	O
m.	O
meteer	O
,	O
m.	O
siu	O
,	O
gisting	O
conversational	O
speech	O
,	O
in	O
:	O
computer	B
,	O
speech	O
&	O
language	O
20	O
(	O
2006	O
)	O
303–330	O
.	O
proceedings	O
of	O
ieee	O
international	O
conference	O
on	O
acoustics	B
,	O
speech	O
and	O
[	O
30	O
]	O
a.	O
e.	O
rosenberg	O
,	O
a.	O
gorin	O
,	O
z.	O
liu	O
,	O
p.	O
parthasarathy	O
,	O
unsupervised	O
signal	B
processing	I
,	O
1992	O
,	O
pp	O
.	O
113–116	O
.	O
speaker	B
segmentation	I
of	O
telephone	O
conversations	O
,	O
in	O
:	O
proceedings	O
of	O
[	O
7	O
]	O
m.	O
sugiyama	O
,	O
j.	O
murakami	O
,	O
h.	O
watanabe	O
,	O
speech	O
segmentation	B
and	O
the	O
international	O
conference	O
on	O
spoken	B
language	I
processing	B
,	O
2002	O
,	O
pp	O
.	O
clustering	B
based	O
on	O
speaker	B
features	O
,	O
in	O
:	O
proceedings	O
of	O
ieee	O
interna-	O
565–568	O
.	O
tional	O
conference	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
,	O
1993	O
,	O
[	O
31	O
]	O
d.	O
liu	O
,	O
f.	O
kubala	O
,	O
a	O
cross	O
-	O
channel	O
modeling	O
approach	O
for	O
automatic	O
pp	O
.	O
395–398	O
.	O
segmentation	B
of	O
conversational	O
telephone	B
speech	I
,	O
in	O
:	O
proceedings	O
of	O
[	O
8	O
]	O
u.	O
jain	O
,	O
m.	O
a.	O
siegler	O
,	O
s.-j	O
.	O
doh	O
,	O
e.	O
gouvea	O
,	O
j.	O
huerta	O
,	O
p.	O
j.	O
moreno	O
,	O
ieee	O
workshop	O
on	O
automatic	O
speech	B
recognition	I
and	O
understanding	O
,	O
b.	O
raj	O
,	O
r.	O
m.	O
stern	O
,	O
recognition	O
of	O
continuous	O
broadcast	O
news	O
with	O
2003	O
,	O
pp	O
.	O
333–338	O
.	O
multiple	O
unknown	O
speakers	O
and	O
environments	O
,	O
in	O
:	O
proceedings	O
of	O
arpa	O
[	O
32	O
]	O
s.	O
e.	O
tranter	O
,	O
k.	O
yu	O
,	O
g.	O
evermann	O
,	O
p.	O
c.	O
woodland	O
,	O
generating	O
and	O
spoken	B
language	I
technology	O
workshop	O
,	O
1996	O
,	O
pp	O
.	O
61–66	O
.	O
evaluating	O
for	O
automatic	O
speech	B
recognition	I
of	O
conversational	O
telephone	O
[	O
9	O
]	O
m.	O
padmanabhan	O
,	O
l.	O
r.	O
bahl	O
,	O
d.	O
nahamoo	O
,	O
m.	O
a.	O
picheny	O
,	O
speaker	B
speech	O
,	O
in	O
:	O
proceedings	O
of	O
ieee	O
international	O
conference	O
on	O
acoustics	B
,	O
clustering	B
and	O
transformation	O
for	O
speaker	B
adaptation	O
in	O
large	O
-	O
vocabulary	O
speech	O
and	O
signal	B
processing	I
,	O
2004	O
,	O
pp	O
.	O
753–756	O
.	O
speech	B
recognition	I
systems	O
,	O
in	O
:	O
proceedings	O
of	O
ieee	O
international	O
con-	O
[	O
33	O
]	O
d.	O
a.	O
reynolds	O
,	O
p.	O
kenny	O
,	O
f.	O
castaldo	O
,	O
a	O
study	O
of	O
new	O
approaches	O
ference	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
,	O
1996	O
,	O
pp	O
.	O
701–704	O
.	O
21to	O
speaker	B
diarization	I
,	O
in	O
:	O
proceedings	O
of	O
the	O
annual	B
conference	I
of	O
annual	B
conference	I
of	O
the	O
international	O
speech	B
communication	I
associ-	O
the	O
international	O
speech	B
communication	I
association	O
,	O
2009	O
,	O
pp	O
.	O
1047	O
–	O
ation	O
,	O
2012	O
,	O
pp	O
.	O
2174–2177	O
.	O
1050	O
.	O
[	O
54	O
]	O
s.	O
h.	O
shum	O
,	O
n.	O
dehak	O
,	O
r.	O
dehak	O
,	O
j.	O
r.	O
glass	O
,	O
unsupervised	O
methods	O
for	O
[	O
34	O
]	O
p.	O
kenny	O
,	O
d.	O
reynolds	O
,	O
f.	O
castaldo	O
,	O
diarization	B
of	O
telephone	O
conversa-	O
speaker	B
diarization	I
:	O
an	O
integrated	O
and	O
iterative	O
approach	O
,	O
ieee	O
trans-	O
tions	O
using	O
factor	B
analysis	I
,	O
ieee	O
journal	O
of	O
selected	O
topics	O
in	O
signal	B
actions	O
on	O
audio	O
,	O
speech	O
,	O
and	O
language	B
processing	I
21	O
(	O
2013	O
)	O
.	O
processing	B
4	O
(	O
2010	O
)	O
1059–1070	O
.	O
[	O
55	O
]	O
a.	O
zhang	O
,	O
q.	O
wang	O
,	O
z.	O
zhu	O
,	O
j.	O
paisley	O
,	O
c.	O
wang	O
,	O
fully	O
supervised	O
[	O
35	O
]	O
t.	O
pfau	O
,	O
d.	O
ellis	O
,	O
a.	O
stolcke	O
,	O
multispeaker	O
speech	B
activity	I
detection	I
speaker	B
diarization	I
,	O
in	O
:	O
proceedings	O
of	O
ieee	O
international	O
conference	O
for	O
the	O
icsi	O
meeting	O
recorder	O
,	O
in	O
:	O
proceedings	O
of	O
ieee	O
workshop	O
on	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
,	O
2019	O
,	O
pp	O
.	O
6301–6305	O
.	O
automatic	O
speech	B
recognition	I
and	O
understanding	O
,	O
2001	O
,	O
pp	O
.	O
107–110	O
.	O
[	O
56	O
]	O
y.	O
fujita	O
,	O
n.	O
kanda	O
,	O
s.	O
horiguchi	O
,	O
k.	O
nagamatsu	O
,	O
s.	O
watanabe	O
,	O
end-	O
[	O
36	O
]	O
j.	O
ajmera	O
,	O
g.	O
lathoud	O
,	O
l.	O
mccowan	O
,	O
clustering	B
and	O
segmenting	O
speak-	O
to	O
-	O
end	O
neural	O
speaker	B
diarization	I
with	O
permutation	O
-	O
free	O
objectives	O
,	O
pro-	O
ers	O
and	O
their	O
locations	O
in	O
meetings	O
,	O
in	O
:	O
proceedings	O
of	O
ieee	O
interna-	O
ceedings	O
of	O
the	O
annual	B
conference	I
of	O
the	O
international	O
speech	O
commu-	O
tional	O
conference	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
,	O
2004	O
,	O
nication	O
association	O
(	O
2019	O
)	O
4300–4304	O
.	O
pp	O
.	O
605–608	O
.	O
[	O
57	O
]	O
y.	O
fujita	O
,	O
n.	O
kanda	O
,	O
s.	O
horiguchi	O
,	O
y.	O
xue	O
,	O
k.	O
nagamatsu	O
,	O
s.	O
watanabe	O
,	O
[	O
37	O
]	O
q.	O
jin	O
,	O
k.	O
laskowski	O
,	O
t.	O
schultz	O
,	O
a.	O
waibel	O
,	O
speaker	B
segmentation	I
and	O
end	O
-	O
to	O
-	O
end	O
neural	O
speaker	B
diarization	I
with	O
self	O
-	O
attention	O
,	O
in	O
:	O
proceed-	O
clustering	B
in	O
meetings	O
,	O
in	O
:	O
proceedings	O
of	O
the	O
international	O
conference	O
ings	O
of	O
ieee	O
workshop	O
on	O
automatic	O
speech	B
recognition	I
and	O
under-	O
on	O
spoken	B
language	I
processing	B
,	O
2004	O
,	O
pp	O
.	O
597–600	O
.	O
standing	O
,	O
ieee	O
,	O
2019	O
,	O
pp	O
.	O
296–303	O
.	O
[	O
38	O
]	O
x.	O
anguera	O
,	O
c.	O
wooters	O
,	O
b.	O
peskin	O
,	O
m.	O
aguilo	O
,	O
robust	B
speaker	I
seg-	O
[	O
58	O
]	O
j.	O
r.	O
hershey	O
,	O
z.	O
chen	O
,	O
j.	O
le	O
roux	O
,	O
s.	O
watanabe	O
,	O
deep	O
clustering	B
:	O
dis-	O
mentation	O
for	O
meetings	O
:	O
the	O
icsi	O
-	O
sri	O
spring	O
2005	O
diarization	B
system	O
,	O
criminative	O
embeddings	O
for	O
segmentation	B
and	O
separation	O
,	O
in	O
:	O
proceed-	O
in	O
:	O
proceedings	O
of	O
machine	O
learning	O
for	O
multimodal	O
interaction	O
work-	O
ings	O
of	O
ieee	O
international	O
conference	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
shop	O
,	O
2005	O
,	O
pp	O
.	O
402–414	O
.	O
processing	B
,	O
ieee	O
,	O
2016	O
,	O
pp	O
.	O
31–35	O
.	O
[	O
39	O
]	O
x.	O
anguera	O
,	O
c.	O
wooters	O
,	O
j.	O
hernando	O
,	O
purity	O
algorithms	O
for	O
speaker	B
di-	O
[	O
59	O
]	O
m.	O
kolbæk	O
,	O
d.	O
yu	O
,	O
z.-h	O
.	O
tan	O
,	O
j.	O
jensen	O
,	O
multitalker	O
speech	O
separa-	O
arization	O
of	O
meetings	O
data	B
,	O
in	O
:	O
proceedings	O
of	O
ieee	O
international	O
con-	O
tion	O
with	O
utterance	O
-	O
level	B
permutation	O
invariant	O
training	O
of	O
deep	O
recur-	O
ference	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
,	O
volume	O
i	O
,	O
2006	O
,	O
rent	O
neural	B
networks	I
,	O
ieee	O
/	O
acm	O
transactions	O
on	O
audio	O
,	O
speech	O
,	O
and	O
pp	O
.	O
1025–1028	O
.	O
language	B
processing	I
25	O
(	O
2017	O
)	O
1901–1913	O
.	O
[	O
40	O
]	O
d.	O
istrate	O
,	O
c.	O
fredouille	O
,	O
s.	O
meignier	O
,	O
l.	O
besacier	O
,	O
j.-f	O
.	O
bonastre	O
,	O
nist	O
[	O
60	O
]	O
y.	O
luo	O
,	O
n.	O
mesgarani	O
,	O
conv	O
-	O
tasnet	O
:	O
surpassing	O
ideal	O
time	B
–	O
frequency	B
rt05s	O
evaluation	B
:	O
pre	O
-	O
processing	B
techniques	B
and	O
speaker	B
diarization	I
on	O
magnitude	O
masking	O
for	O
speech	B
separation	I
,	O
ieee	O
/	O
acm	O
transactions	O
on	O
multiple	O
microphone	O
meetings	O
,	O
in	O
:	O
proceedings	O
of	O
machine	O
learning	O
for	O
audio	O
,	O
speech	O
,	O
and	O
language	B
processing	I
27	O
(	O
2019	O
)	O
1256–1266	O
.	O
multimodal	O
interaction	O
workshop	O
,	O
2006	O
.	O
[	O
61	O
]	O
e.	O
variani	O
,	O
x.	O
lei	O
,	O
e.	O
mcdermott	O
,	O
i.	O
l.	O
moreno	O
,	O
j.	O
gonzalez-	O
[	O
41	O
]	O
d.	O
a.	O
v.	O
leeuwen	O
,	O
m.	O
konecny	O
,	O
progress	O
in	O
the	O
amida	O
speaker	B
diariza-	O
dominguez	O
,	O
deep	O
neural	B
networks	I
for	O
small	O
footprint	O
text	O
-	O
dependent	O
tion	O
system	O
for	O
meeting	O
data	B
,	O
in	O
:	O
proceedings	O
of	O
international	O
evaluation	B
speaker	B
veriﬁcation	O
,	O
in	O
:	O
proceedings	O
of	O
ieee	O
international	O
conference	O
workshops	O
clear	O
2007	O
and	O
rt	O
2007	O
,	O
2007	O
,	O
pp	O
.	O
475–483	O
.	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
,	O
ieee	O
,	O
2014	O
,	O
pp	O
.	O
4052	O
–	O
[	O
42	O
]	O
x.	O
anguera	O
,	O
c.	O
wooters	O
,	O
j.	O
hernando	O
,	O
acoustic	O
beamforming	O
for	O
4056	O
.	O
speaker	B
diarization	I
of	O
meetings	O
,	O
ieee	O
transactions	O
on	O
audio	O
,	O
speech	O
,	O
[	O
62	O
]	O
d.	O
snyder	O
,	O
d.	O
garcia	O
-	O
romero	O
,	O
d.	O
povey	O
,	O
s.	O
khudanpur	O
,	O
deep	O
neural	O
and	O
language	B
processing	I
15	O
(	O
2007	O
)	O
2011–2023	O
.	O
network	B
embeddings	O
for	O
text	O
-	O
independent	O
speaker	B
veriﬁcation	O
.	O
,	O
in	O
:	O
pro-	O
[	O
43	O
]	O
x.	O
zhu	O
,	O
c.	O
barras	O
,	O
l.	O
lamel	O
,	O
j.-l	O
.	O
gauvain	O
,	O
multi	O
-	O
stage	B
speaker	B
di-	O
ceedings	O
of	O
the	O
annual	B
conference	I
of	O
the	O
international	O
speech	O
commu-	O
arization	O
for	O
conference	O
and	O
lecture	O
meetings	O
,	O
in	O
:	O
proceedings	O
of	O
inter-	O
nication	O
association	O
,	O
2017	O
,	O
pp	O
.	O
999–1003	O
.	O
national	O
evaluation	B
workshops	O
clear	O
2007	O
and	O
rt	O
2007	O
,	O
2007	O
,	O
pp	O
.	O
[	O
63	O
]	O
t.	O
drugman	O
,	O
y.	O
stylianou	O
,	O
y.	O
kida	O
,	O
m.	O
akamine	O
,	O
voice	O
activity	O
detec-	O
533–542	O
.	O
tion	O
:	O
merging	O
source	B
and	O
ﬁlter	O
-	O
based	O
information	B
,	O
ieee	O
signal	B
process-	O
[	O
44	O
]	O
d.	O
vijayasenan	O
,	O
f.	O
valente	O
,	O
h.	O
bourlard	O
,	O
an	O
information	B
theoretic	O
ap-	O
ing	O
letters	O
23	O
(	O
2015	O
)	O
252–256	O
.	O
proach	O
to	O
speaker	B
diarization	I
of	O
meeting	O
data	B
,	O
ieee	O
transactions	O
on	O
[	O
64	O
]	O
x.	O
guo	O
,	O
l.	O
gao	O
,	O
x.	O
liu	O
,	O
j.	O
yin	O
,	O
improved	O
deep	O
embedded	O
clustering	B
audio	O
,	O
speech	O
,	O
and	O
language	B
processing	I
17	O
(	O
2009	O
)	O
1382–1393	O
.	O
with	O
local	O
structure	O
preservation	O
,	O
in	O
:	O
proceedings	O
of	O
international	O
joint	O
[	O
45	O
]	O
f.	O
valente	O
,	O
p.	O
motlicek	O
,	O
d.	O
vijayasenan	O
,	O
variational	O
bayesian	O
speaker	B
conference	O
on	O
artiﬁcial	O
intelligence	O
,	O
2017	O
,	O
pp	O
.	O
1753–1759	O
.	O
diarization	B
of	O
meeting	O
recordings	O
,	O
in	O
:	O
proceedings	O
of	O
ieee	O
interna-	O
[	O
65	O
]	O
j.	O
wang	O
,	O
x.	O
xiao	O
,	O
j.	O
wu	O
,	O
r.	O
ramamurthy	O
,	O
f.	O
rudzicz	O
,	O
m.	O
brudno	O
,	O
tional	O
conference	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
,	O
2010	O
,	O
speaker	B
diarization	I
with	O
session	O
-	O
level	B
speaker	B
embedding	O
reﬁnement	O
pp	O
.	O
4954–4957	O
.	O
using	O
graph	O
neural	B
networks	I
,	O
in	O
:	O
proceedings	O
of	O
ieee	O
international	O
[	O
46	O
]	O
p.	O
kenny	O
,	O
g.	O
boulianne	O
,	O
p.	O
ouellet	O
,	O
p.	O
dumouchel	O
,	O
joint	O
factor	B
analy-	O
conference	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
,	O
ieee	O
,	O
2020	O
,	O
sis	O
versus	O
eigenchannels	O
in	O
speaker	B
recognition	O
,	O
ieee	O
transactions	O
on	O
pp	O
.	O
7109–7113	O
.	O
audio	O
,	O
speech	O
,	O
and	O
language	B
processing	I
15	O
(	O
2007	O
)	O
1435–1447	O
.	O
[	O
66	O
]	O
i.	O
medennikov	O
,	O
m.	O
korenevsky	O
,	O
t.	O
prisyach	O
,	O
y.	O
khokhlov	O
,	O
m.	O
ko-	O
[	O
47	O
]	O
e.	O
variani	O
,	O
x.	O
lei	O
,	O
e.	O
mcdermott	O
,	O
i.	O
l.	O
moreno	O
,	O
j.	O
g	O
-	O
dominguez	O
,	O
deep	O
renevskaya	O
,	O
i.	O
sorokin	O
,	O
t.	O
timofeeva	O
,	O
a.	O
mitrofanov	O
,	O
a.	O
andrusenko	O
,	O
neural	B
networks	I
for	O
small	O
footprint	O
text	O
-	O
dependent	O
speaker	B
veriﬁcation	O
,	O
i.	O
podluzhny	O
,	O
a.	O
laptev	O
,	O
a.	O
romanenko	O
,	O
target	O
-	O
speaker	B
voice	O
activ-	O
in	O
:	O
proceedings	O
of	O
ieee	O
international	O
conference	O
on	O
acoustics	B
,	O
speech	O
ity	O
detection	B
:	O
a	O
novel	O
approach	O
for	O
multi	O
-	O
speaker	B
diarization	I
in	O
a	O
dinner	O
and	O
signal	B
processing	I
,	O
2014	O
,	O
pp	O
.	O
4052–4056	O
.	O
party	O
scenario	O
,	O
in	O
:	O
proceedings	O
of	O
the	O
annual	B
conference	I
of	O
the	O
inter-	O
[	O
48	O
]	O
g.	O
heigold	O
,	O
i.	O
moreno	O
,	O
s.	O
bengio	O
,	O
n.	O
shazeer	O
,	O
end	O
-	O
to	O
-	O
end	O
text-	O
national	O
speech	B
communication	I
association	O
,	O
2020	O
,	O
pp	O
.	O
274–278	O
.	O
dependent	O
speaker	B
veriﬁcation	O
,	O
in	O
:	O
proceedings	O
of	O
ieee	O
international	O
[	O
67	O
]	O
d.	O
yu	O
,	O
x.	O
chang	O
,	O
y.	O
qian	O
,	O
recognizing	O
multi	O
-	O
talker	O
speech	O
with	O
permu-	O
conference	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
,	O
2016	O
,	O
pp	O
.	O
tation	O
invariant	O
training	O
,	O
proceedings	O
of	O
the	O
annual	B
conference	I
of	O
the	O
5115–5119	O
.	O
international	O
speech	B
communication	I
association	O
(	O
2017	O
)	O
2456–2460	O
.	O
[	O
49	O
]	O
q.	O
wang	O
,	O
c.	O
downey	O
,	O
l.	O
wan	O
,	O
p.	O
a.	O
mansﬁeld	O
,	O
i.	O
l.	O
moreno	O
,	O
speaker	B
di-	O
[	O
68	O
]	O
h.	O
seki	O
,	O
t.	O
hori	O
,	O
s.	O
watanabe	O
,	O
j.	O
le	O
roux	O
,	O
j.	O
r.	O
hershey	O
,	O
a	O
purely	O
end-	O
arization	O
with	O
lstm	O
,	O
in	O
:	O
proceedings	O
of	O
ieee	O
international	O
conference	O
to	O
-	O
end	O
system	O
for	O
multi	O
-	O
speaker	B
speech	B
recognition	I
,	O
2018	O
,	O
pp	O
.	O
2620	O
–	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
,	O
2018	O
,	O
pp	O
.	O
5239–5243	O
.	O
2630	O
.	O
[	O
50	O
]	O
d.	O
snyder	O
,	O
d.	O
garcia	O
-	O
romero	O
,	O
g.	O
sell	O
,	O
d.	O
povey	O
,	O
s.	O
khudanpur	O
,	O
x-	O
[	O
69	O
]	O
x.	O
chang	O
,	O
y.	O
qian	O
,	O
k.	O
yu	O
,	O
s.	O
watanabe	O
,	O
end	O
-	O
to	O
-	O
end	O
monaural	O
multi-	O
vectors	O
:	O
robust	O
dnn	O
embeddings	O
for	O
speaker	B
recognition	O
,	O
in	O
:	O
proceed-	O
speaker	B
asr	B
system	O
without	O
pretraining	O
,	O
in	O
:	O
proceedings	O
of	O
ieee	O
inter-	O
ings	O
of	O
ieee	O
international	O
conference	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
national	O
conference	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
,	O
2019	O
,	O
processing	B
,	O
2018	O
,	O
pp	O
.	O
5329–5333	O
.	O
pp	O
.	O
6256–6260	O
.	O
[	O
51	O
]	O
n.	O
dehak	O
,	O
p.	O
kenny	O
,	O
r.	O
dehak	O
,	O
p.	O
dumouchel	O
,	O
p.	O
ouellet	O
,	O
front	O
-	O
end	O
[	O
70	O
]	O
n.	O
kanda	O
,	O
y.	O
fujita	O
,	O
s.	O
horiguchi	O
,	O
r.	O
ikeshita	O
,	O
k.	O
nagamatsu	O
,	O
s.	O
watan-	O
factor	B
analysis	I
for	O
speaker	B
veriﬁcation	O
,	O
ieee	O
transactions	O
on	O
audio	O
,	O
abe	O
,	O
acoustic	O
modeling	O
for	O
distant	O
multi	O
-	O
talker	O
speech	B
recognition	I
with	O
speech	O
,	O
and	O
language	B
processing	I
19	O
(	O
2011	O
)	O
.	O
single	O
-	O
and	O
multi	O
-	O
channel	O
branches	O
,	O
in	O
:	O
proceedings	O
of	O
ieee	O
interna-	O
[	O
52	O
]	O
s.	O
shum	O
,	O
n.	O
dehak	O
,	O
j.	O
glass	O
,	O
on	O
the	O
use	O
of	O
spectral	O
and	O
iterative	O
methods	O
tional	O
conference	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
,	O
2019	O
,	O
for	O
speaker	B
diarization	I
,	O
in	O
:	O
proceedings	O
of	O
the	O
annual	B
conference	I
of	O
the	O
pp	O
.	O
6630–6634	O
.	O
international	O
speech	B
communication	I
association	O
,	O
2012	O
,	O
pp	O
.	O
482–485	O
.	O
[	O
71	O
]	O
n.	O
kanda	O
,	O
s.	O
horiguchi	O
,	O
r.	O
takashima	O
,	O
y.	O
fujita	O
,	O
k.	O
nagamatsu	O
,	O
[	O
53	O
]	O
g.	O
dupuy	O
,	O
m.	O
rouvier	O
,	O
s.	O
meignier	O
,	O
y.	O
esteve	O
,	O
i	O
-	O
vectors	O
and	O
ilp	O
clus-	O
s.	O
watanabe	O
,	O
auxiliary	O
interference	O
speaker	B
loss	O
for	O
target	O
-	O
speaker	B
tering	O
adapted	O
to	O
cross	O
-	O
show	O
speaker	B
diarization	I
,	O
in	O
:	O
proceedings	O
of	O
the	O
speech	B
recognition	I
,	O
in	O
:	O
proceedings	O
of	O
the	O
annual	B
conference	I
of	O
the	O
22international	O
speech	B
communication	I
association	O
,	O
2019	O
,	O
pp	O
.	O
236–240	O
.	O
proceedings	O
of	O
ieee	O
spoken	B
language	I
technology	O
workshop	O
,	O
2021	O
.	O
[	O
72	O
]	O
x.	O
wang	O
,	O
n.	O
kanda	O
,	O
y.	O
gaur	O
,	O
z.	O
chen	O
,	O
z.	O
meng	O
,	O
t.	O
yoshioka	O
,	O
ex-	O
[	O
89	O
]	O
s.	O
watanabe	O
,	O
m.	O
mandel	O
,	O
j.	O
barker	O
,	O
e.	O
vincent	O
,	O
a.	O
arora	O
,	O
x.	O
chang	O
,	O
ploring	O
end	O
-	O
to	O
-	O
end	O
multi	O
-	O
channel	O
asr	B
with	O
bias	O
information	B
for	O
meeting	O
s.	O
khudanpur	O
,	O
v.	O
manohar	O
,	O
d.	O
povey	O
,	O
d.	O
raj	O
,	O
et	O
al	O
.	O
,	O
chime-6	O
challenge	B
:	O
transcription	B
,	O
in	O
:	O
proceedings	O
of	O
ieee	O
workshop	O
on	O
automatic	O
speech	O
tackling	O
multispeaker	O
speech	B
recognition	I
for	O
unsegmented	O
recordings	O
,	O
recognition	O
and	O
understanding	O
,	O
2021	O
.	O
in	O
:	O
6th	O
international	O
workshop	O
on	O
speech	O
processing	B
in	O
everyday	O
envi-	O
[	O
73	O
]	O
p.	O
wang	O
,	O
z.	O
chen	O
,	O
x.	O
xiao	O
,	O
z.	O
meng	O
,	O
t.	O
yoshioka	O
,	O
t.	O
zhou	O
,	O
l.	O
lu	O
,	O
j.	O
li	O
,	O
ronments	O
(	O
chime	O
2020	O
)	O
,	O
2020	O
.	O
speech	B
separation	I
using	O
speaker	B
inventory	O
,	O
in	O
:	O
proceedings	O
of	O
ieee	O
[	O
90	O
]	O
a.	O
arora	O
,	O
d.	O
raj	O
,	O
a.	O
s.	O
subramanian	O
,	O
k.	O
li	O
,	O
b.	O
ben	O
-	O
yair	O
,	O
m.	O
maciejew-	O
workshop	O
on	O
automatic	O
speech	B
recognition	I
and	O
understanding	O
,	O
2019	O
,	O
ski	O
,	O
p.	O
z˙	O
elasko	O
,	O
p.	O
garcia	O
,	O
s.	O
watanabe	O
,	O
s.	O
khudanpur	O
,	O
the	O
jhu	O
multi-	O
pp	O
.	O
230–236	O
.	O
microphone	O
multi	O
-	O
speaker	B
asr	B
system	O
for	O
the	O
chime-6	O
challenge	B
,	O
arxiv	O
[	O
74	O
]	O
c.	O
han	O
,	O
y.	O
luo	O
,	O
c.	O
li	O
,	O
t.	O
zhou	O
,	O
k.	O
kinoshita	O
,	O
s.	O
watanabe	O
,	O
m.	O
delcroix	O
,	O
preprint	O
arxiv:2006.07898	O
(	O
2020	O
)	O
.	O
h.	O
erdogan	O
,	O
j.	O
r.	O
hershey	O
,	O
n.	O
mesgarani	O
,	O
et	O
al	O
.	O
,	O
continuous	O
speech	O
[	O
91	O
]	O
i.	O
medennikov	O
,	O
m.	O
korenevsky	O
,	O
t.	O
prisyach	O
,	O
y.	O
khokhlov	O
,	O
m.	O
ko-	O
separation	O
using	O
speaker	B
inventory	O
for	O
long	O
multi	O
-	O
talker	O
recording	B
,	O
arxiv	O
renevskaya	O
,	O
i.	O
sorokin	O
,	O
t.	O
timofeeva	O
,	O
a.	O
mitrofanov	O
,	O
a.	O
andrusenko	O
,	O
preprint	O
arxiv:2012.09727	O
(	O
2020	O
)	O
.	O
i.	O
podluzhny	O
,	O
et	O
al	O
.	O
,	O
the	O
stc	O
system	O
for	O
the	O
chime-6	O
challenge	B
,	O
in	O
:	O
[	O
75	O
]	O
z.	O
huang	O
,	O
s.	O
watanabe	O
,	O
y.	O
fujita	O
,	O
p.	O
garc´ıa	O
,	O
y.	O
shao	O
,	O
d.	O
povey	O
,	O
s.	O
khu-	O
chime	O
2020	O
workshop	O
on	O
speech	O
processing	B
in	O
everyday	O
environ-	O
danpur	O
,	O
speaker	B
diarization	I
with	O
region	O
proposal	O
network	B
,	O
in	O
:	O
proceed-	O
ments	O
,	O
2020	O
.	O
ings	O
of	O
ieee	O
international	O
conference	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
[	O
92	O
]	O
x.	O
lu	O
,	O
y.	O
tsao	O
,	O
s.	O
matsuda	O
,	O
c.	O
hori	O
,	O
speech	O
enhancement	O
based	O
on	O
processing	B
,	O
ieee	O
,	O
2020	O
,	O
pp	O
.	O
6514–6518	O
.	O
deep	O
denoising	O
autoencoder	O
.	O
,	O
in	O
:	O
proceedings	O
of	O
the	O
annual	B
conference	I
[	O
76	O
]	O
t.	O
von	O
neumann	O
,	O
k.	O
kinoshita	O
,	O
m.	O
delcroix	O
,	O
s.	O
araki	O
,	O
t.	O
nakatani	O
,	O
of	O
the	O
international	O
speech	B
communication	I
association	O
,	O
2013	O
,	O
pp	O
.	O
436	O
–	O
r.	O
haeb	O
-	O
umbach	O
,	O
all	O
-	O
neural	O
online	O
source	B
separation	O
,	O
counting	O
,	O
and	O
440	O
.	O
diarization	B
for	O
meeting	O
analysis	B
,	O
in	O
:	O
proceedings	O
of	O
ieee	O
international	O
[	O
93	O
]	O
y.	O
xu	O
,	O
j.	O
du	O
,	O
l.-r	O
.	O
dai	O
,	O
c.-h	O
.	O
lee	O
,	O
a	O
regression	B
approach	O
to	O
speech	O
conference	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
,	O
ieee	O
,	O
2019	O
,	O
enhancement	O
based	O
on	O
deep	O
neural	B
networks	I
,	O
ieee	O
/	O
acm	O
transactions	O
pp	O
.	O
91–95	O
.	O
on	O
audio	O
,	O
speech	O
,	O
and	O
language	B
processing	I
23	O
(	O
2014	O
)	O
7–19	O
.	O
[	O
77	O
]	O
l.	O
e.	O
shafey	O
,	O
h.	O
soltau	O
,	O
i.	O
shafran	O
,	O
joint	O
speech	B
recognition	I
and	O
[	O
94	O
]	O
h.	O
erdogan	O
,	O
j.	O
r.	O
hershey	O
,	O
s.	O
watanabe	O
,	O
j.	O
le	O
roux	O
,	O
phase	O
-	O
sensitive	O
and	O
speaker	B
diarization	I
via	O
sequence	B
transduction	O
,	O
in	O
:	O
proceedings	O
of	O
the	O
recognition	O
-	O
boosted	O
speech	B
separation	I
using	O
deep	O
recurrent	O
neural	O
net-	O
annual	B
conference	I
of	O
the	O
international	O
speech	B
communication	I
associ-	O
works	O
,	O
in	O
:	O
proceedings	O
of	O
ieee	O
international	O
conference	O
on	O
acoustics	B
,	O
ation	O
,	O
isca	O
,	O
2019	O
,	O
pp	O
.	O
396–400	O
.	O
speech	O
and	O
signal	B
processing	I
,	O
ieee	O
,	O
2015	O
,	O
pp	O
.	O
708–712	O
.	O
[	O
78	O
]	O
h.	O
h.	O
mao	O
,	O
s.	O
li	O
,	O
j.	O
mcauley	O
,	O
g.	O
cottrell	O
,	O
speech	B
recognition	I
and	O
[	O
95	O
]	O
p.	O
c.	O
loizou	O
,	O
speech	O
enhancement	O
:	O
theory	O
and	O
practice	O
,	O
crc	O
press	O
,	O
multi	O
-	O
speaker	B
diarization	I
of	O
long	O
conversations	O
,	O
in	O
:	O
proceedings	O
of	O
the	O
2013	O
.	O
annual	B
conference	I
of	O
the	O
international	O
speech	B
communication	I
associ-	O
[	O
96	O
]	O
t.	O
gao	O
,	O
j.	O
du	O
,	O
l.-r	O
.	O
dai	O
,	O
c.-h	O
.	O
lee	O
,	O
densely	O
connected	O
progressive	O
ation	O
,	O
2020	O
,	O
pp	O
.	O
691–695	O
.	O
learning	O
for	O
lstm	O
-	O
based	O
speech	O
enhancement	O
,	O
in	O
:	O
proceedings	O
of	O
ieee	O
[	O
79	O
]	O
n.	O
kanda	O
,	O
s.	O
horiguchi	O
,	O
y.	O
fujita	O
,	O
y.	O
xue	O
,	O
k.	O
nagamatsu	O
,	O
s.	O
watanabe	O
,	O
international	O
conference	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
,	O
simultaneous	O
speech	B
recognition	I
and	O
speaker	B
diarization	I
for	O
monaural	O
ieee	O
,	O
2018	O
,	O
pp	O
.	O
5054–5058	O
.	O
dialogue	O
recordings	O
with	O
target	O
-	O
speaker	B
acoustic	O
models	B
,	O
in	O
:	O
proceed-	O
[	O
97	O
]	O
j.	O
heymann	O
,	O
l.	O
drude	O
,	O
r.	O
haeb	O
-	O
umbach	O
,	O
neural	B
network	I
based	O
spectral	O
ings	O
of	O
ieee	O
workshop	O
on	O
automatic	O
speech	B
recognition	I
and	O
under-	O
mask	O
estimation	B
for	O
acoustic	O
beamforming	O
,	O
in	O
:	O
proceedings	O
of	O
ieee	O
standing	O
,	O
2019	O
,	O
pp	O
.	O
31–38	O
.	O
international	O
conference	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
,	O
[	O
80	O
]	O
n.	O
kanda	O
,	O
x.	O
chang	O
,	O
y.	O
gaur	O
,	O
x.	O
wang	O
,	O
z.	O
meng	O
,	O
z.	O
chen	O
,	O
t.	O
yosh-	O
ieee	O
,	O
2016	O
,	O
pp	O
.	O
196–200	O
.	O
ioka	O
,	O
investigation	O
of	O
end	O
-	O
to	O
-	O
end	O
speaker	B
-	O
attributed	O
asr	B
for	O
continu-	O
[	O
98	O
]	O
h.	O
erdogan	O
,	O
j.	O
r.	O
hershey	O
,	O
s.	O
watanabe	O
,	O
m.	O
i.	O
mandel	O
,	O
j.	O
le	O
roux	O
,	O
ous	O
multi	O
-	O
talker	O
recordings	O
,	O
in	O
:	O
proceedings	O
of	O
ieee	O
spoken	B
language	I
improved	O
mvdr	O
beamforming	O
using	O
single	O
-	O
channel	O
mask	O
prediction	O
technology	O
workshop	O
,	O
2021	O
.	O
networks	O
,	O
proceedings	O
of	O
the	O
annual	B
conference	I
of	O
the	O
international	O
[	O
81	O
]	O
r.	O
haeb	O
-	O
umbach	O
,	O
s.	O
watanabe	O
,	O
t.	O
nakatani	O
,	O
m.	O
bacchiani	O
,	O
speech	B
communication	I
association	O
(	O
2016	O
)	O
1981–1985	O
.	O
b.	O
hoﬀmeister	O
,	O
m.	O
l.	O
seltzer	O
,	O
h.	O
zen	O
,	O
m.	O
souden	O
,	O
speech	O
processing	B
for	O
[	O
99	O
]	O
t.	O
nakatani	O
,	O
t.	O
yoshioka	O
,	O
k.	O
kinoshita	O
,	O
m.	O
miyoshi	O
,	O
b.-h	O
.	O
juang	O
,	O
digital	O
home	O
assistants	O
:	O
combining	O
signal	B
processing	I
with	O
deep	O
-	O
learning	O
speech	O
dereverberation	O
based	O
on	O
variance	O
-	O
normalized	O
delayed	O
linear	O
techniques	B
,	O
ieee	O
signal	B
processing	I
magazine	O
36	O
(	O
2019	O
)	O
111–124	O
.	O
prediction	O
,	O
ieee	O
transactions	O
on	O
audio	O
,	O
speech	O
,	O
and	O
language	O
pro-	O
[	O
82	O
]	O
e.	O
vincent	O
,	O
t.	O
virtanen	O
,	O
s.	O
gannot	O
,	O
audio	O
source	B
separation	O
and	O
speech	O
cessing	O
18	O
(	O
2010	O
)	O
1717–1731	O
.	O
enhancement	O
,	O
john	O
wiley	O
&	O
sons	O
,	O
2018	O
.	O
[	O
100	O
]	O
t.	O
yoshioka	O
,	O
t.	O
nakatani	O
,	O
generalization	O
of	O
multi	O
-	O
channel	O
linear	O
predic-	O
[	O
83	O
]	O
d.	O
wang	O
,	O
j.	O
chen	O
,	O
supervised	O
speech	B
separation	I
based	O
on	O
deep	B
learning	I
:	O
tion	O
methods	O
for	O
blind	O
mimo	O
impulse	O
response	O
shortening	O
,	O
ieee	O
trans-	O
an	O
overview	O
,	O
ieee	O
/	O
acm	O
transactions	O
on	O
audio	O
,	O
speech	O
,	O
and	O
language	O
actions	O
on	O
audio	O
,	O
speech	O
,	O
and	O
language	B
processing	I
20	O
(	O
2012	O
)	O
2707	O
–	O
processing	B
26	O
(	O
2018	O
)	O
1702–1726	O
.	O
2720	O
.	O
[	O
84	O
]	O
g.	O
sell	O
,	O
d.	O
snyder	O
,	O
a.	O
mccree	O
,	O
d.	O
garcia	O
-	O
romero	O
,	O
j.	O
villalba	O
,	O
m.	O
ma-	O
[	O
101	O
]	O
l.	O
drude	O
,	O
j.	O
heymann	O
,	O
c.	O
boeddeker	O
,	O
r.	O
haeb	O
-	O
umbach	O
,	O
nara-	O
ciejewski	O
,	O
v.	O
manohar	O
,	O
n.	O
dehak	O
,	O
d.	O
povey	O
,	O
s.	O
watanabe	O
,	O
et	O
al	O
.	O
,	O
diariza-	O
wpe	O
:	O
a	O
python	O
package	O
for	O
weighted	O
prediction	O
error	O
dereverberation	O
tion	O
is	O
hard	O
:	O
some	O
experiences	O
and	O
lessons	O
learned	O
for	O
the	O
jhu	O
team	O
in	O
in	O
numpy	O
and	O
tensorﬂow	O
for	O
online	O
and	O
oﬄine	O
processing	B
,	O
in	O
:	O
speech	O
the	O
inaugural	O
dihard	B
challenge	I
.	O
,	O
in	O
:	O
proceedings	O
of	O
the	O
annual	O
con-	O
communication	B
;	O
13th	O
itg	O
-	O
symposium	O
,	O
vde	O
,	O
2018	O
,	O
pp	O
.	O
1–5	O
.	O
ference	O
of	O
the	O
international	O
speech	B
communication	I
association	O
,	O
2018	O
,	O
[	O
102	O
]	O
t.	O
yoshioka	O
,	O
h.	O
erdogan	O
,	O
z.	O
chen	O
,	O
x.	O
xiao	O
,	O
f.	O
alleva	O
,	O
recognizing	O
over-	O
pp	O
.	O
2808–2812	O
.	O
lapped	O
speech	O
in	O
meetings	O
:	O
a	O
multichannel	B
separation	O
approach	O
using	O
[	O
85	O
]	O
n.	O
ryant	O
,	O
k.	O
church	O
,	O
c.	O
cieri	O
,	O
a.	O
cristia	O
,	O
j.	O
du	O
,	O
s.	O
ganapathy	O
,	O
m.	O
liber-	O
neural	B
networks	I
,	O
in	O
:	O
proceedings	O
of	O
the	O
annual	B
conference	I
of	O
the	O
inter-	O
man	O
,	O
the	O
second	O
dihard	O
diarization	B
challenge	B
:	O
dataset	O
,	O
task	O
,	O
and	O
national	O
speech	B
communication	I
association	O
,	O
2018	O
,	O
pp	O
.	O
3038–3042	O
.	O
baselines	O
,	O
proceedings	O
of	O
the	O
annual	B
conference	I
of	O
the	O
international	O
[	O
103	O
]	O
c.	O
boeddecker	O
,	O
j.	O
heitkaemper	O
,	O
j.	O
schmalenstroeer	O
,	O
l.	O
drude	O
,	O
j.	O
hey-	O
speech	B
communication	I
association	O
(	O
2019	O
)	O
978–982	O
.	O
mann	O
,	O
r.	O
haeb	O
-	O
umbach	O
,	O
front	O
-	O
end	O
processing	B
for	O
the	O
chime-5	O
dinner	O
[	O
86	O
]	O
m.	O
diez	O
,	O
f.	O
landini	O
,	O
l.	O
burget	O
,	O
j.	O
rohdin	O
,	O
a.	O
silnova	O
,	O
k.	O
zmol´ıkova	O
´	O
,	O
party	O
scenario	O
,	O
in	O
:	O
proceedings	O
of	O
chime	O
2018	O
workshop	O
on	O
speech	O
o.	O
novotny	O
`	O
,	O
k.	O
vesely	O
`	O
,	O
o.	O
glembek	O
,	O
o.	O
plchot	O
,	O
et	O
al	O
.	O
,	O
but	O
system	O
for	O
processing	B
in	O
everyday	O
environments	O
,	O
2018	O
,	O
pp	O
.	O
35–40	O
.	O
dihard	O
speech	O
diarization	B
challenge	B
2018	O
.	O
,	O
in	O
:	O
proceedings	O
of	O
the	O
[	O
104	O
]	O
x.	O
xiao	O
,	O
n.	O
kanda	O
,	O
z.	O
chen	O
,	O
t.	O
zhou	O
,	O
t.	O
yoshioka	O
,	O
y.	O
zhao	O
,	O
g.	O
liu	O
,	O
annual	B
conference	I
of	O
the	O
international	O
speech	B
communication	I
associ-	O
j.	O
wu	O
,	O
j.	O
li	O
,	O
y.	O
gong	O
,	O
microsoft	O
speaker	B
diarization	I
system	I
for	O
ation	O
,	O
2018	O
,	O
pp	O
.	O
2798–2802	O
.	O
the	O
voxceleb	O
speaker	B
recognition	O
challenge	B
2020	O
,	O
arxiv	O
preprint	O
[	O
87	O
]	O
z.	O
chen	O
,	O
t.	O
yoshioka	O
,	O
l.	O
lu	O
,	O
t.	O
zhou	O
,	O
z.	O
meng	O
,	O
y.	O
luo	O
,	O
j.	O
wu	O
,	O
x.	O
xiao	O
,	O
arxiv:2010.11458	O
(	O
2020	O
)	O
.	O
j.	O
li	O
,	O
continuous	O
speech	B
separation	I
:	O
dataset	O
and	O
analysis	B
,	O
in	O
:	O
proceed-	O
[	O
105	O
]	O
a.	O
nagrani	O
,	O
j.	O
s.	O
chung	O
,	O
j.	O
huh	O
,	O
a.	O
brown	O
,	O
e.	O
coto	O
,	O
w.	O
xie	O
,	O
ings	O
of	O
ieee	O
international	O
conference	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
m.	O
mclaren	O
,	O
d.	O
a.	O
reynolds	O
,	O
a.	O
zisserman	O
,	O
voxsrc	O
2020	O
:	O
the	O
processing	B
,	O
ieee	O
,	O
2020	O
,	O
pp	O
.	O
7284–7288	O
.	O
second	O
voxceleb	O
speaker	B
recognition	O
challenge	B
,	O
arxiv	O
preprint	O
[	O
88	O
]	O
d.	O
raj	O
,	O
p.	O
denisov	O
,	O
z.	O
chen	O
,	O
h.	O
erdogan	O
,	O
z.	O
huang	O
,	O
m.	O
he	O
,	O
s.	O
watanabe	O
,	O
arxiv:2012.06867	O
(	O
2020	O
)	O
.	O
j.	O
du	O
,	O
t.	O
yoshioka	O
,	O
y.	O
luo	O
,	O
n.	O
kanda	O
,	O
j.	O
li	O
,	O
s.	O
wisdom	O
,	O
j.	O
r.	O
hershey	O
,	O
[	O
106	O
]	O
t.	O
ng	O
,	O
b.	O
zhang	O
,	O
l.	O
nguyen	O
,	O
s.	O
matsoukas	O
,	O
x.	O
zhou	O
,	O
n.	O
mesgarani	O
,	O
integration	O
of	O
speech	B
separation	I
,	O
diarization	B
,	O
and	O
recognition	O
for	O
multi-	O
k.	O
vesely	O
`	O
,	O
p.	O
mateˇjka	O
,	O
developing	O
a	O
speech	B
activity	I
detection	I
system	B
speaker	I
meetings	O
:	O
system	O
description	O
,	O
comparison	O
,	O
and	O
analysis	B
,	O
in	O
:	O
for	O
the	O
darpa	O
rats	O
program	O
,	O
in	O
:	O
proceedings	O
of	O
the	O
annual	B
conference	I
of	O
23the	O
international	O
speech	B
communication	I
association	O
,	O
2012	O
,	O
pp	O
.	O
1969	O
–	O
[	O
127	O
]	O
m.	O
senoussaoui	O
,	O
p.	O
kenny	O
,	O
p.	O
dumouchel	O
,	O
t.	O
stafylakis	O
,	O
eﬃcient	O
iter-	O
1972	O
.	O
ative	O
mean	O
shift	O
based	O
cosine	O
dissimilarity	O
for	O
multi	O
-	O
recording	B
speaker	B
[	O
107	O
]	O
r.	O
sarikaya	O
,	O
j.	O
h.	O
hansen	O
,	O
robust	O
detection	B
of	O
speech	B
activity	I
in	O
the	O
clustering	B
,	O
in	O
:	O
proceedings	O
of	O
ieee	O
international	O
conference	O
on	O
acous-	O
presence	B
of	O
noise	O
,	O
in	O
:	O
proceedings	O
of	O
the	O
international	O
conference	O
on	O
tics	O
,	O
speech	O
and	O
signal	B
processing	I
,	O
ieee	O
,	O
2013	O
,	O
pp	O
.	O
7712–7715	O
.	O
spoken	B
language	I
processing	B
,	O
volume	O
4	O
,	O
citeseer	O
,	O
1998	O
,	O
pp	O
.	O
1455–8	O
.	O
[	O
128	O
]	O
i.	O
salmun	O
,	O
i.	O
shapiro	O
,	O
i.	O
opher	O
,	O
i.	O
lapidot	O
,	O
plda	B
-	O
based	O
mean	O
shift	O
speak-	O
[	O
108	O
]	O
d.	O
haws	O
,	O
d.	O
dimitriadis	O
,	O
g.	O
saon	O
,	O
s.	O
thomas	O
,	O
m.	O
picheny	O
,	O
on	O
the	O
im-	O
ers	O
’	O
short	O
segments	O
clustering	B
,	O
computer	B
speech	O
and	O
language	O
45	O
portance	O
of	O
event	O
detection	B
for	O
asr	B
,	O
in	O
:	O
proceedings	O
of	O
ieee	O
international	O
(	O
2017	O
)	O
411–436	O
.	O
conference	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
,	O
2016	O
.	O
[	O
129	O
]	O
k.	O
j.	O
han	O
,	O
s.	O
s.	O
narayanan	O
,	O
a	O
robust	O
stopping	O
criterion	B
for	O
agglomera-	O
[	O
109	O
]	O
s.	O
meignier	O
,	O
d.	O
moraru	O
,	O
c.	O
fredouille	O
,	O
j.-f	O
.	O
bonastre	O
,	O
l.	O
besacier	O
,	O
step-	O
tive	O
hierarchical	O
clustering	B
in	O
a	O
speaker	B
diarization	I
system	I
,	O
in	O
:	O
proceed-	O
by	O
-	O
step	O
and	O
integrated	O
approaches	O
in	O
broadcast	O
news	O
speaker	B
diarization	I
,	O
ings	O
of	O
the	O
annual	B
conference	I
of	O
the	O
international	O
speech	O
communica-	O
computer	B
speech	O
and	O
language	O
20	O
(	O
2006	O
)	O
303–330	O
.	O
tion	O
association	O
,	O
2007	O
.	O
[	O
110	O
]	O
s.	O
chen	O
,	O
p.	O
gopalakrishnan	O
,	O
et	O
al	O
.	O
,	O
speaker	B
,	O
environment	O
and	O
channel	O
[	O
130	O
]	O
s.	O
novoselov	O
,	O
a.	O
gusev	O
,	O
a.	O
ivanov	O
,	O
t.	O
pekhovsky	O
,	O
a.	O
shulipa	O
,	O
change	B
detection	I
and	O
clustering	B
via	O
the	O
bayesian	O
information	B
criterion	B
,	O
a.	O
avdeeva	O
,	O
a.	O
gorlanov	O
,	O
a.	O
kozlov	O
,	O
speaker	B
diarization	I
with	O
deep	O
in	O
:	O
proceedings	O
darpa	O
broadcast	O
news	O
transcription	B
and	O
understanding	O
speaker	B
embeddings	I
for	O
dihard	B
challenge	I
ii	O
.	O
,	O
in	O
:	O
proceedings	O
of	O
the	O
workshop	O
,	O
volume	O
8	O
,	O
virginia	O
,	O
usa	O
,	O
1998	O
,	O
pp	O
.	O
127–132	O
.	O
annual	B
conference	I
of	O
the	O
international	O
speech	B
communication	I
associ-	O
[	O
111	O
]	O
p.	O
delacourt	O
,	O
c.	O
j.	O
wellekens	O
,	O
distbic	O
:	O
a	O
speaker	B
-	O
based	O
segmentation	B
ation	O
,	O
2019	O
,	O
pp	O
.	O
1003–1007	O
.	O
for	O
audio	O
data	B
indexing	O
,	O
speech	B
communication	I
32	O
(	O
2000	O
)	O
111–126	O
.	O
[	O
131	O
]	O
u.	O
von	O
luxburg	O
,	O
a	O
tutorial	O
on	O
spectral	O
clustering	B
,	O
statist	O
.	O
and	O
comput	O
.	O
[	O
112	O
]	O
m.	O
senoussaoui	O
,	O
p.	O
kenny	O
,	O
t.	O
stafylakis	O
,	O
p.	O
dumouchel	O
,	O
a	O
study	O
of	O
17	O
(	O
2007	O
)	O
395–416	O
.	O
the	O
cosine	O
distance	B
-	O
based	O
mean	O
shift	O
for	O
telephone	B
speech	I
diarization	B
,	O
[	O
132	O
]	O
a.	O
ng	O
,	O
m.	O
jordan	O
,	O
y.	O
weiss	O
,	O
on	O
spectral	O
clustering	B
:	O
analysis	B
and	O
an	O
al-	O
ieee	O
/	O
acm	O
transactions	O
on	O
audio	O
,	O
speech	O
,	O
and	O
language	B
processing	I
gorithm	O
,	O
advances	O
in	O
neural	O
information	B
processing	B
systems	O
14	O
(	O
2001	O
)	O
22	O
(	O
2013	O
)	O
217–227	O
.	O
849–856	O
.	O
[	O
113	O
]	O
g.	O
sell	O
,	O
d.	O
snyder	O
,	O
a.	O
mccree	O
,	O
d.	O
garcia	O
-	O
romero	O
,	O
j.	O
villalba	O
,	O
m.	O
ma-	O
[	O
133	O
]	O
h.	O
ning	O
,	O
m.	O
liu	O
,	O
h.	O
tang	O
,	O
t.	O
s.	O
huang	O
,	O
a	O
spectral	O
clustering	B
approach	O
ciejewski	O
,	O
v.	O
manohar	O
,	O
n.	O
dehak	O
,	O
d.	O
povey	O
,	O
s.	O
watanabe	O
,	O
s.	O
khudan-	O
to	O
speaker	B
diarization	I
,	O
in	O
:	O
proceedings	O
of	O
the	O
international	O
conference	O
pur	O
,	O
diarization	B
is	O
hard	O
:	O
some	O
experiences	O
and	O
lessons	O
learned	O
for	O
the	O
on	O
spoken	B
language	I
processing	B
,	O
2006	O
,	O
pp	O
.	O
2178–2181	O
.	O
jhu	O
team	O
in	O
the	O
inaugural	O
dihard	B
challenge	I
,	O
in	O
:	O
proceedings	O
of	O
the	O
[	O
134	O
]	O
j.	O
luque	O
,	O
j.	O
hernando	O
,	O
on	O
the	O
use	O
of	O
agglomerative	O
and	O
spectral	O
cluster-	O
annual	B
conference	I
of	O
the	O
international	O
speech	B
communication	I
associ-	O
ing	O
in	O
speaker	B
diarization	I
of	O
meetings	O
,	O
in	O
:	O
proceedings	O
of	O
odyssey	O
:	O
the	O
ation	O
,	O
2018	O
,	O
pp	O
.	O
2808–2812	O
.	O
speaker	B
and	O
language	O
recognition	O
workshop	O
,	O
2012	O
,	O
pp	O
.	O
130–137	O
.	O
[	O
114	O
]	O
w.-h	O
.	O
tsai	O
,	O
s.-s	O
.	O
cheng	O
,	O
h.-m	O
.	O
wang	O
,	O
speaker	B
clustering	B
of	O
speech	O
[	O
135	O
]	O
q.	O
lin	O
,	O
r.	O
yin	O
,	O
m.	O
li	O
,	O
h.	O
bredin	O
,	O
c.	O
barras	O
,	O
lstm	O
based	O
similarity	B
utterances	B
using	O
a	O
voice	O
characteristic	O
reference	B
space	O
,	O
in	O
:	O
proceedings	O
measurement	O
with	O
spectral	O
clustering	B
for	O
speaker	B
diarization	I
,	O
in	O
:	O
pro-	O
of	O
the	O
international	O
conference	O
on	O
spoken	B
language	I
processing	B
,	O
2004	O
.	O
ceedings	O
of	O
the	O
annual	B
conference	I
of	O
the	O
international	O
speech	O
commu-	O
[	O
115	O
]	O
j.	O
e.	O
rougui	O
,	O
m.	O
rziza	O
,	O
d.	O
aboutajdine	O
,	O
m.	O
gelgon	O
,	O
j.	O
martinez	O
,	O
fast	O
in-	O
nication	O
association	O
,	O
2019	O
,	O
pp	O
.	O
366–370	O
.	O
cremental	O
clustering	B
of	O
gaussian	O
mixture	O
speaker	B
models	B
for	O
scaling	O
up	O
[	O
136	O
]	O
t.	O
j.	O
park	O
,	O
k.	O
j.	O
han	O
,	O
m.	O
kumar	O
,	O
s.	O
narayanan	O
,	O
auto	O
-	O
tuning	O
spectral	O
retrieval	O
in	O
on	O
-	O
line	O
broadcast	O
,	O
in	O
:	O
proceedings	O
of	O
ieee	O
international	O
clustering	B
for	O
speaker	B
diarization	I
using	O
normalized	O
maximum	O
eigengap	O
,	O
conference	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
,	O
volume	O
5	O
,	O
ieee	O
signal	B
processing	I
letters	O
27	O
(	O
2019	O
)	O
381–385	O
.	O
ieee	O
,	O
2006	O
,	O
pp	O
.	O
v	O
–	O
v	O
.	O
[	O
137	O
]	O
p.	O
kenny	O
,	O
d.	O
reynolds	O
,	O
f.	O
castaldo	O
,	O
diarization	B
of	O
telephone	O
conversa-	O
[	O
116	O
]	O
d.	O
a.	O
reynolds	O
,	O
t.	O
f.	O
quatieri	O
,	O
r.	O
b.	O
dunn	O
,	O
speaker	B
veriﬁcation	O
using	O
tions	O
using	O
factor	B
analysis	I
,	O
ieee	O
journal	O
of	O
selected	O
topics	O
in	O
signal	B
adapted	O
gaussian	O
mixture	O
models	B
,	O
digital	O
signal	B
processing	I
10	O
(	O
2000	O
)	O
processing	B
4	O
(	O
2010	O
)	O
1059–1070	O
.	O
19–41	O
.	O
[	O
138	O
]	O
m.	O
diez	O
,	O
l.	O
burget	O
,	O
p.	O
matejka	O
,	O
speaker	B
diarization	I
based	O
on	O
bayesian	O
[	O
117	O
]	O
p.	O
kenny	O
,	O
g.	O
boulianne	O
,	O
p.	O
ouellet	O
,	O
p.	O
dumouchel	O
,	O
speaker	B
and	O
session	O
hmm	O
with	O
eigenvoice	O
priors	O
.	O
,	O
in	O
:	O
proceedings	O
of	O
odyssey	O
:	O
the	O
speaker	B
variability	O
in	O
gmm	O
-	O
based	B
speaker	I
veriﬁcation	O
,	O
ieee	O
transactions	O
on	O
and	O
language	O
recognition	O
workshop	O
,	O
2018	O
,	O
pp	O
.	O
147–154	O
.	O
audio	O
,	O
speech	O
,	O
and	O
language	B
processing	I
15	O
(	O
2007	O
)	O
1448–1460	O
.	O
[	O
139	O
]	O
m.	O
diez	O
,	O
l.	O
burget	O
,	O
f.	O
landini	O
,	O
j.	O
cˇ	O
ernocky	O
`	O
,	O
analysis	B
of	O
speaker	B
diariza-	O
[	O
118	O
]	O
p.	O
kenny	O
,	O
p.	O
ouellet	O
,	O
n.	O
dehak	O
,	O
v.	O
gupta	O
,	O
p.	O
dumouchel	O
,	O
a	O
study	O
of	O
tion	O
based	O
on	O
bayesian	O
hmm	O
with	O
eigenvoice	O
priors	O
,	O
ieee	O
/	O
acm	O
trans-	O
interspeaker	O
variability	O
in	O
speaker	B
veriﬁcation	O
,	O
ieee	O
transactions	O
on	O
actions	O
on	O
audio	O
,	O
speech	O
,	O
and	O
language	B
processing	I
28	O
(	O
2019	O
)	O
355–368	O
.	O
audio	O
,	O
speech	O
,	O
and	O
language	B
processing	I
16	O
(	O
2008	O
)	O
980–988	O
.	O
[	O
140	O
]	O
m.	O
diez	O
,	O
l.	O
burget	O
,	O
s.	O
wang	O
,	O
j.	O
rohdin	O
,	O
j.	O
cernocky	O
`	O
,	O
bayesian	O
hmm	O
[	O
119	O
]	O
p.	O
kenny	O
,	O
g.	O
boulianne	O
,	O
p.	O
dumouchel	O
,	O
eigenvoice	O
modeling	O
with	O
based	O
x	O
-	O
vector	O
clustering	B
for	O
speaker	B
diarization	I
.	O
,	O
in	O
:	O
proceedings	O
of	O
the	O
sparse	O
training	B
data	I
,	O
ieee	O
transactions	O
on	O
speech	O
and	O
audio	O
process-	O
annual	B
conference	I
of	O
the	O
international	O
speech	B
communication	I
associ-	O
ing	O
13	O
(	O
2005	O
)	O
345–354	O
.	O
ation	O
,	O
2019	O
,	O
pp	O
.	O
346–350	O
.	O
[	O
120	O
]	O
g.	O
sell	O
,	O
d.	O
garcia	O
-	O
romero	O
,	O
speaker	B
diarization	I
with	O
plda	B
i	O
-	O
vector	O
scor-	O
[	O
141	O
]	O
f.	O
landini	O
,	O
j.	O
profant	O
,	O
m.	O
diez	O
,	O
l.	O
burget	O
,	O
bayesian	O
hmm	O
clustering	B
of	O
ing	O
and	O
unsupervised	O
calibration	O
,	O
in	O
:	O
proceedings	O
of	O
ieee	O
spoken	O
lan-	O
x	O
-	O
vector	O
sequences	O
(	O
vbx	O
)	O
in	O
speaker	B
diarization	I
:	O
theory	O
,	O
implementation	O
guage	O
technology	O
workshop	O
,	O
ieee	O
,	O
2014	O
,	O
pp	O
.	O
413–417	O
.	O
and	O
analysis	B
on	O
standard	O
tasks	O
,	O
arxiv	O
preprint	O
arxiv:2006.07898	O
(	O
2020	O
)	O
.	O
[	O
121	O
]	O
w.	O
zhu	O
,	O
j.	O
pelecanos	O
,	O
online	O
speaker	B
diarization	I
using	O
adapted	O
i-	O
[	O
142	O
]	O
g.	O
sell	O
,	O
d.	O
garcia	O
-	O
romero	O
,	O
diarization	B
resegmentation	B
in	O
the	O
factor	B
vector	O
transforms	O
,	O
in	O
:	O
proceedings	O
of	O
ieee	O
international	O
conference	O
on	O
analysis	B
subspace	O
,	O
in	O
:	O
proceedings	O
of	O
ieee	O
international	O
conference	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
,	O
ieee	O
,	O
2016	O
,	O
pp	O
.	O
5045–5049	O
.	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
,	O
ieee	O
,	O
2015	O
,	O
pp	O
.	O
4794–4798	O
.	O
[	O
122	O
]	O
y.	O
sun	O
,	O
x.	O
wang	O
,	O
x.	O
tang	O
,	O
deep	B
learning	I
face	O
representation	O
from	O
pre-	O
[	O
143	O
]	O
j.	O
g.	O
fiscus	O
,	O
a	O
post	O
-	O
processing	B
system	O
to	O
yield	O
reduced	O
word	B
error	B
rates	I
:	O
dicting	O
10,000	O
classes	O
,	O
in	O
:	O
proceedings	O
of	O
the	O
ieee	O
conference	O
on	O
com-	O
recognizer	O
output	B
voting	O
error	O
reduction	O
(	O
rover	O
)	O
,	O
in	O
:	O
proceedings	O
of	O
puter	O
vision	O
and	O
pattern	O
recognition	O
,	O
2014	O
,	O
pp	O
.	O
1891–1898	O
.	O
ieee	O
workshop	O
on	O
automatic	O
speech	B
recognition	I
and	O
understanding	O
,	O
[	O
123	O
]	O
y.	O
taigman	O
,	O
m.	O
yang	O
,	O
m.	O
ranzato	O
,	O
l.	O
wolf	O
,	O
deepface	O
:	O
closing	O
the	O
gap	O
ieee	O
,	O
1997	O
,	O
pp	O
.	O
347–354	O
.	O
to	O
human	O
-	O
level	B
performance	O
in	O
face	O
veriﬁcation	O
,	O
in	O
:	O
proceedings	O
of	O
the	O
[	O
144	O
]	O
n.	O
brummer	O
,	O
l.	O
burget	O
,	O
j.	O
cernocky	O
,	O
o.	O
glembek	O
,	O
f.	O
grezl	O
,	O
m.	O
karaﬁat	O
,	O
ieee	O
conference	O
on	O
computer	B
vision	O
and	O
pattern	O
recognition	O
,	O
2014	O
,	O
pp	O
.	O
d.	O
a.	O
van	O
leeuwen	O
,	O
p.	O
matejka	O
,	O
p.	O
schwarz	O
,	O
a.	O
strasheim	O
,	O
fusion	O
of	O
1701–1708	O
.	O
heterogeneous	O
speaker	B
recognition	O
systems	O
in	O
the	O
stbu	O
submission	O
for	O
[	O
124	O
]	O
j.	O
villalba	O
,	O
n.	O
chen	O
,	O
d.	O
snyder	O
,	O
d.	O
garcia	O
-	O
romero	O
,	O
a.	O
mccree	O
,	O
g.	O
sell	O
,	O
the	O
nist	O
speaker	B
recognition	O
evaluation	B
2006	O
,	O
ieee	O
transactions	O
on	O
j.	O
borgstrom	O
,	O
f.	O
richardson	O
,	O
s.	O
shon	O
,	O
f.	O
grondin	O
,	O
et	O
al	O
.	O
,	O
state	O
-	O
of	O
-	O
the-	O
audio	O
,	O
speech	O
,	O
and	O
language	B
processing	I
15	O
(	O
2007	O
)	O
2072–2084	O
.	O
art	O
speaker	B
recognition	O
for	O
telephone	O
and	O
video	O
speech	O
:	O
the	O
jhu	O
-	O
mit	O
[	O
145	O
]	O
m.	O
huijbregts	O
,	O
d.	O
van	O
leeuwen	O
,	O
f.	O
jong	O
,	O
the	O
majority	O
wins	O
:	O
a	O
method	B
submission	O
for	O
nist	O
sre18	O
.	O
,	O
in	O
:	O
proceedings	O
of	O
the	O
annual	O
confer-	O
for	O
combining	O
speaker	B
diarization	I
systems	I
,	O
in	O
:	O
proceedings	O
of	O
the	O
an-	O
ence	O
of	O
the	O
international	O
speech	B
communication	I
association	O
,	O
2019	O
,	O
pp	O
.	O
nual	O
conference	O
of	O
the	O
international	O
speech	B
communication	I
associa-	O
1488–1492	O
.	O
tion	O
,	O
isca	O
,	O
2009	O
,	O
pp	O
.	O
924–927	O
.	O
[	O
125	O
]	O
d.	O
comaniciu	O
,	O
p.	O
meer	O
,	O
mean	O
shift	O
:	O
a	O
robust	O
approach	O
toward	O
feature	O
[	O
146	O
]	O
s.	O
bozonnet	O
,	O
n.	O
evans	O
,	O
x.	O
anguera	O
,	O
o.	O
vinyals	O
,	O
g.	O
friedland	O
,	O
c.	O
fre-	O
space	O
analysis	B
,	O
ieee	O
transactions	O
on	O
pattern	O
analysis	B
and	O
machine	O
in-	O
douille	O
,	O
system	O
output	B
combination	O
for	O
improved	O
speaker	B
diarization	I
,	O
telligence	O
24	O
(	O
2002	O
)	O
603–619	O
.	O
in	O
:	O
proceedings	O
of	O
the	O
annual	B
conference	I
of	O
the	O
international	O
speech	O
[	O
126	O
]	O
t.	O
stafylakis	O
,	O
v.	O
katsouros	O
,	O
g.	O
carayannis	O
,	O
speaker	B
clustering	B
via	O
the	O
communication	B
association	O
,	O
isca	O
,	O
2010	O
,	O
pp	O
.	O
2642–2645	O
.	O
mean	O
shift	O
algorithm	O
,	O
recall	O
2	O
(	O
2010	O
)	O
7	O
.	O
[	O
147	O
]	O
a.	O
stolcke	O
,	O
t.	O
yoshioka	O
,	O
dover	O
:	O
a	O
method	B
for	O
combining	O
diariza-	O
24tion	O
outputs	O
,	O
in	O
:	O
proceedings	O
of	O
ieee	O
workshop	O
on	O
automatic	O
speech	O
speaker	B
diarization	I
for	O
an	O
unknown	O
number	O
of	O
speakers	O
with	O
encoder-	O
recognition	O
and	O
understanding	O
,	O
ieee	O
,	O
2019	O
,	O
pp	O
.	O
757–763	O
.	O
decoder	O
based	O
attractors	O
,	O
in	O
:	O
proceedings	O
of	O
the	O
annual	B
conference	I
of	O
[	O
148	O
]	O
d.	O
raj	O
,	O
l.	O
p.	O
garcia	O
-	O
perera	O
,	O
z.	O
huang	O
,	O
s.	O
watanabe	O
,	O
d.	O
povey	O
,	O
a.	O
stol-	O
the	O
international	O
speech	B
communication	I
association	O
,	O
2020	O
,	O
pp	O
.	O
269	O
–	O
cke	O
,	O
s.	O
khudanpur	O
,	O
dover	O
-	O
lap	O
:	O
a	O
method	B
for	O
combining	O
overlap-	O
273	O
.	O
aware	O
diarization	B
outputs	O
,	O
in	O
:	O
proceedings	O
of	O
ieee	O
spoken	B
language	I
[	O
170	O
]	O
y.	O
fujita	O
,	O
s.	O
watanabe	O
,	O
s.	O
horiguchi	O
,	O
y.	O
xue	O
,	O
j.	O
shi	O
,	O
k.	O
nagamatsu	O
,	O
technology	O
workshop	O
,	O
2021	O
.	O
neural	O
speaker	B
diarization	I
with	O
speaker	B
-	O
wise	O
chain	O
rule	O
,	O
arxiv	O
preprint	O
[	O
149	O
]	O
d.	O
dimitriadis	O
,	O
enhancements	O
for	O
audio	O
-	O
only	O
diarization	B
systems	I
,	O
arxiv:2006.01796	O
(	O
2020	O
)	O
.	O
arxiv	O
preprint	O
arxiv:1909.00082	O
(	O
2019	O
)	O
.	O
[	O
171	O
]	O
k.	O
kinoshita	O
,	O
m.	O
delcroix	O
,	O
n.	O
tawara	O
,	O
integrating	O
end	O
-	O
to	O
-	O
end	O
neural	O
[	O
150	O
]	O
j.	O
xie	O
,	O
r.	O
girshick	O
,	O
a.	O
farhadi	O
,	O
unsupervised	O
deep	O
embedding	O
for	O
clus-	O
and	O
clustering	B
-	O
based	O
diarization	B
:	O
getting	O
the	O
best	O
of	O
both	O
worlds	O
,	O
arxiv	O
tering	O
analysis	B
,	O
in	O
:	O
proceedings	O
ofinternational	O
conference	O
on	O
machine	O
preprint	O
arxiv:2010.13366	O
(	O
2020	O
)	O
.	O
learning	O
,	O
2016	O
,	O
pp	O
.	O
478–487	O
.	O
[	O
172	O
]	O
y.	O
xue	O
,	O
s.	O
horiguchi	O
,	O
y.	O
fujita	O
,	O
s.	O
watanabe	O
,	O
k.	O
nagamatsu	O
,	O
online	O
[	O
151	O
]	O
e.	O
ustinova	O
,	O
v.	O
lempitsky	O
,	O
learning	O
deep	O
embeddings	O
with	O
histogram	O
end	O
-	O
to	O
-	O
end	O
neural	O
diarization	B
with	O
speaker	B
-	O
tracing	O
buﬀer	O
,	O
arxiv	O
preprint	O
loss	O
,	O
proceedings	O
of	O
advances	O
in	O
neural	O
information	B
processing	B
sys-	O
arxiv:2006.02616	O
(	O
2020	O
)	O
.	O
tems	O
29	O
(	O
2016	O
)	O
4170–4178	O
.	O
[	O
173	O
]	O
e.	O
han	O
,	O
c.	O
lee	O
,	O
a.	O
stolcke	O
,	O
bw	O
-	O
eda	O
-	O
eend	O
:	O
streaming	O
end	O
-	O
to	O
-	O
end	O
[	O
152	O
]	O
q.	O
lin	O
,	O
y.	O
hou	O
,	O
m.	O
li	O
,	O
self	O
-	O
attentive	O
similarity	B
measurement	O
strategies	O
neural	O
speaker	B
diarization	I
for	O
a	O
variable	O
number	O
of	O
speakers	O
,	O
arxiv	O
in	O
speaker	B
diarization	I
,	O
proceedings	O
of	O
the	O
annual	B
conference	I
of	O
the	O
preprint	O
arxiv:2011.02678	O
(	O
2020	O
)	O
.	O
international	O
speech	B
communication	I
association	O
(	O
2020	O
)	O
284–288	O
.	O
[	O
174	O
]	O
j.	O
huang	O
,	O
e.	O
marcheret	O
,	O
k.	O
visweswariah	O
,	O
g.	O
potamianos	O
,	O
the	O
ibm	O
[	O
153	O
]	O
t.	O
j.	O
park	O
,	O
m.	O
kumar	O
,	O
s.	O
narayanan	O
,	O
multi	O
-	O
scale	O
speaker	B
diarization	I
with	O
rt07	O
evaluation	B
systems	O
for	O
speaker	B
diarization	I
on	O
lecture	O
meetings	O
,	O
in	O
:	O
neural	O
aﬃnity	O
score	B
fusion	O
,	O
arxiv	O
preprint	O
arxiv:2011.10527	O
(	O
2020	O
)	O
.	O
multimodal	O
technologies	O
for	O
perception	O
of	O
humans	O
,	O
springer	O
,	O
2007	O
,	O
pp	O
.	O
[	O
154	O
]	O
y.	O
lecun	O
,	O
y.	O
bengio	O
,	O
g.	O
hinton	O
,	O
deep	B
learning	I
,	O
nature	O
521	O
(	O
2015	O
)	O
497–508	O
.	O
436	O
.	O
[	O
175	O
]	O
j.	O
silovsky	O
,	O
j.	O
zdansky	O
,	O
j.	O
nouza	O
,	O
p.	O
cerva	O
,	O
j.	O
prazak	O
,	O
incorporation	O
of	O
[	O
155	O
]	O
a.	O
santoro	O
,	O
r.	O
faulkner	O
,	O
d.	O
raposo	O
,	O
j.	O
rae	O
,	O
m.	O
chrzanowski	O
,	O
t.	O
weber	O
,	O
the	O
asr	B
output	B
in	O
speaker	B
segmentation	I
and	O
clustering	B
within	O
the	O
task	O
of	O
d.	O
wierstra	O
,	O
o.	O
vinyals	O
,	O
r.	O
pascanu	O
,	O
t.	O
lillicrap	O
,	O
relational	O
recurrent	O
speaker	B
diarization	I
of	O
broadcast	O
streams	O
,	O
in	O
:	O
international	O
workshop	O
on	O
neural	B
networks	I
,	O
in	O
:	O
proceedings	O
of	O
advances	O
in	O
neural	O
information	B
multimedia	O
signal	B
processing	I
,	O
ieee	O
,	O
2012	O
,	O
pp	O
.	O
118–123	O
.	O
processing	B
systems	O
,	O
2018	O
,	O
pp	O
.	O
7299–7310	O
.	O
[	O
176	O
]	O
l.	O
canseco	O
-	O
rodriguez	O
,	O
l.	O
lamel	O
,	O
j.-l	O
.	O
gauvain	O
,	O
speaker	B
diarization	I
[	O
156	O
]	O
a.	O
santoro	O
,	O
s.	O
bartunov	O
,	O
m.	O
botvinick	O
,	O
d.	O
wierstra	O
,	O
t.	O
lillicrap	O
,	O
meta-	O
from	O
speech	O
transcripts	B
,	O
in	O
:	O
proceedings	O
of	O
the	O
international	O
conference	O
learning	O
with	O
memory	O
-	O
augmented	O
neural	B
networks	I
,	O
in	O
:	O
proceedings	O
on	O
spoken	B
language	I
processing	B
,	O
volume	O
4	O
,	O
2004	O
,	O
pp	O
.	O
3–7	O
.	O
ofinternational	O
conference	O
on	O
machine	O
learning	O
,	O
2016	O
,	O
pp	O
.	O
1842—-	O
[	O
177	O
]	O
n.	O
flemotomos	O
,	O
p.	O
georgiou	O
,	O
s.	O
narayanan	O
,	O
linguistically	O
aided	O
speaker	B
1850	O
.	O
diarization	B
using	O
speaker	B
role	O
information	B
,	O
arxiv	O
(	O
2019	O
)	O
arxiv–1911	O
.	O
[	O
157	O
]	O
s.	O
sukhbaatar	O
,	O
j.	O
weston	O
,	O
r.	O
fergus	O
,	O
et	O
al	O
.	O
,	O
end	O
-	O
to	O
-	O
end	O
memory	O
net-	O
[	O
178	O
]	O
t.	O
j.	O
park	O
,	O
p.	O
georgiou	O
,	O
multimodal	O
speaker	B
segmentation	I
and	O
diariza-	O
works	O
,	O
in	O
:	O
proceedings	O
of	O
advances	O
in	O
neural	O
information	B
processing	B
tion	O
using	O
lexical	O
and	O
acoustic	O
cues	O
via	O
sequence	B
to	O
sequence	B
neural	O
systems	O
,	O
2015	O
,	O
pp	O
.	O
2440–2448	O
.	O
networks	O
,	O
proceedings	O
of	O
the	O
annual	B
conference	I
of	O
the	O
international	O
[	O
158	O
]	O
d.	O
garcia	O
-	O
romero	O
,	O
c.	O
y.	O
espy	O
-	O
wilson	O
,	O
analysis	B
of	O
i	O
-	O
vector	O
length	B
nor-	O
speech	B
communication	I
association	O
(	O
2018	O
)	O
1373–1377	O
.	O
malization	O
in	O
speaker	B
recognition	O
systems	O
,	O
in	O
:	O
proceedings	O
of	O
the	O
an-	O
[	O
179	O
]	O
t.	O
j.	O
park	O
,	O
k.	O
j.	O
han	O
,	O
j.	O
huang	O
,	O
x.	O
he	O
,	O
b.	O
zhou	O
,	O
p.	O
georgiou	O
,	O
nual	O
conference	O
of	O
the	O
international	O
speech	B
communication	I
associa-	O
s.	O
narayanan	O
,	O
speaker	B
diarization	I
with	O
lexical	O
information	B
,	O
proceed-	O
tion	O
,	O
2011	O
,	O
pp	O
.	O
249–252	O
.	O
ings	O
of	O
the	O
annual	B
conference	I
of	O
the	O
international	O
speech	O
communica-	O
[	O
159	O
]	O
n.	O
flemotomos	O
,	O
d.	O
dimitriadis	O
,	O
a	O
memory	O
augmented	O
architec-	O
tion	O
association	O
(	O
2019	O
)	O
391–395	O
.	O
ture	O
for	O
continuous	O
speaker	B
identiﬁcation	O
in	O
meetings	O
,	O
arxiv	O
preprint	O
[	O
180	O
]	O
j.	O
fiscus	O
,	O
j.	O
ajot	O
,	O
j.	O
garofolo	O
,	O
the	O
rich	B
transcription	I
2007	O
meeting	O
arxiv:2001.05118	O
(	O
2020	O
)	O
.	O
recognition	O
evaluation	B
,	O
2007	O
,	O
pp	O
.	O
373–389	O
.	O
[	O
160	O
]	O
z.	O
zaj´ıc	O
,	O
m.	O
kunesˇova	O
´	O
,	O
v.	O
radova	O
´	O
,	O
investigation	O
of	O
segmentation	B
in	O
i-	O
[	O
181	O
]	O
k.	O
zmolikova	O
,	O
m.	O
delcroix	O
,	O
k.	O
kinoshita	O
,	O
t.	O
higuchi	O
,	O
a.	O
ogawa	O
,	O
vector	O
based	B
speaker	I
diarization	B
of	O
telephone	B
speech	I
,	O
in	O
:	O
international	O
t.	O
nakatani	O
,	O
speaker	B
-	O
aware	O
neural	B
network	I
based	O
beamformer	O
for	O
conference	O
on	O
speech	O
and	O
computer	B
,	O
2016	O
,	O
pp	O
.	O
411–418	O
.	O
speaker	B
extraction	B
in	O
speech	O
mixtures	O
.	O
,	O
in	O
:	O
proceedings	O
of	O
the	O
an-	O
[	O
161	O
]	O
t.	O
yoshioka	O
,	O
d.	O
dimitriadis	O
,	O
a.	O
stolcke	O
,	O
w.	O
hinthorn	O
,	O
z.	O
chen	O
,	O
m.	O
zeng	O
,	O
nual	O
conference	O
of	O
the	O
international	O
speech	B
communication	I
associa-	O
h.	O
xuedong	O
,	O
meeting	O
transcription	B
using	O
asynchronous	O
distant	O
mi-	O
tion	O
,	O
2017	O
,	O
pp	O
.	O
2655–2659	O
.	O
crophones	O
,	O
in	O
:	O
proceedings	O
of	O
the	O
annual	B
conference	I
of	O
the	O
interna-	O
[	O
182	O
]	O
m.	O
delcroix	O
,	O
k.	O
zmolikova	O
,	O
k.	O
kinoshita	O
,	O
a.	O
ogawa	O
,	O
t.	O
nakatani	O
,	O
sin-	O
tional	O
speech	B
communication	I
association	O
,	O
2019	O
,	O
pp	O
.	O
2968–2972	O
.	O
gle	O
channel	O
target	O
speaker	B
extraction	B
and	O
recognition	O
with	O
speaker	B
beam	O
,	O
[	O
162	O
]	O
s.	O
horiguchi	O
,	O
p.	O
garcia	O
,	O
y.	O
fujita	O
,	O
s.	O
watanabe	O
,	O
k.	O
nagamatsu	O
,	O
in	O
:	O
proceedings	O
of	O
ieee	O
international	O
conference	O
on	O
acoustics	B
,	O
speech	O
end	O
-	O
to	O
-	O
end	O
speaker	B
diarization	I
as	O
post	O
-	O
processing	B
,	O
arxiv	O
preprint	O
and	O
signal	B
processing	I
,	O
ieee	O
,	O
2018	O
,	O
pp	O
.	O
5554–5558	O
.	O
arxiv:2012.10055	O
(	O
2020	O
)	O
.	O
[	O
183	O
]	O
m.	O
delcroix	O
,	O
s.	O
watanabe	O
,	O
t.	O
ochiai	O
,	O
k.	O
kinoshita	O
,	O
s.	O
karita	O
,	O
a.	O
ogawa	O
,	O
[	O
163	O
]	O
d.	O
m.	O
blei	O
,	O
p.	O
i.	O
frazier	O
,	O
distance	B
dependent	O
chinese	O
restaurant	O
pro-	O
t.	O
nakatani	O
,	O
end	O
-	O
to	O
-	O
end	O
speakerbeam	O
for	O
single	B
channel	I
target	O
speech	O
cesses	O
.	O
,	O
journal	O
of	O
machine	O
learning	O
research	B
12	O
(	O
2011	O
)	O
.	O
recognition	O
.	O
,	O
in	O
:	O
proceedings	O
of	O
the	O
annual	B
conference	I
of	O
the	O
interna-	O
[	O
164	O
]	O
s.	O
ren	O
,	O
k.	O
he	O
,	O
r.	O
girshick	O
,	O
j.	O
sun	O
,	O
faster	O
r	O
-	O
cnn	O
:	O
towards	O
real	O
-	O
time	B
tional	O
speech	B
communication	I
association	O
,	O
2019	O
,	O
pp	O
.	O
451–455	O
.	O
object	O
detection	B
with	O
region	O
proposal	O
networks	O
,	O
ieee	O
transactions	O
on	O
[	O
184	O
]	O
n.	O
kanda	O
,	O
y.	O
gaur	O
,	O
x.	O
wang	O
,	O
z.	O
meng	O
,	O
z.	O
chen	O
,	O
t.	O
zhou	O
,	O
t.	O
yoshioka	O
,	O
pattern	O
analysis	B
and	O
machine	O
intelligence	O
39	O
(	O
2016	O
)	O
1137–1149	O
.	O
joint	O
speaker	B
counting	O
,	O
speech	B
recognition	I
,	O
and	O
speaker	B
identiﬁcation	O
[	O
165	O
]	O
d.	O
kounades	O
-	O
bastian	O
,	O
l.	O
girin	O
,	O
x.	O
alameda	O
-	O
pineda	O
,	O
s.	O
gannot	O
,	O
r.	O
ho-	O
for	O
overlapped	B
speech	I
of	O
any	O
number	O
of	O
speakers	O
,	O
in	O
:	O
proceedings	O
of	O
the	O
raud	O
,	O
an	O
em	O
algorithm	O
for	O
joint	O
source	B
separation	O
and	O
diarisation	O
of	O
annual	B
conference	I
of	O
the	O
international	O
speech	B
communication	I
associ-	O
multichannel	B
convolutive	O
speech	O
mixtures	O
,	O
in	O
:	O
proceedings	O
of	O
ieee	O
ation	O
,	O
2020	O
,	O
pp	O
.	O
36–40	O
.	O
international	O
conference	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
,	O
[	O
185	O
]	O
n.	O
kanda	O
,	O
z.	O
meng	O
,	O
l.	O
lu	O
,	O
y.	O
gaur	O
,	O
x.	O
wang	O
,	O
z.	O
chen	O
,	O
t.	O
yosh-	O
ieee	O
,	O
2017	O
,	O
pp	O
.	O
16–20	O
.	O
ioka	O
,	O
minimum	O
bayes	O
risk	O
training	O
for	O
end	O
-	O
to	O
-	O
end	O
speaker	B
-	O
attributed	O
[	O
166	O
]	O
d.	O
kounades	O
-	O
bastian	O
,	O
l.	O
girin	O
,	O
x.	O
alameda	O
-	O
pineda	O
,	O
r.	O
horaud	O
,	O
s.	O
gan-	O
asr	B
,	O
arxiv	O
preprint	O
arxiv:2011.02921	O
(	O
2020	O
)	O
.	O
not	O
,	O
exploiting	O
the	O
intermittency	O
of	O
speech	O
for	O
joint	O
separation	O
and	O
di-	O
[	O
186	O
]	O
n.	O
kanda	O
,	O
y.	O
gaur	O
,	O
x.	O
wang	O
,	O
z.	O
meng	O
,	O
t.	O
yoshioka	O
,	O
serialized	O
output	B
arization	O
,	O
in	O
:	O
proceedings	O
of	O
ieee	O
workshop	O
on	O
applications	O
of	O
signal	B
training	O
for	O
end	O
-	O
to	O
-	O
end	O
overlapped	B
speech	I
recognition	O
,	O
in	O
:	O
proceedings	O
processing	B
to	O
audio	O
and	O
acoustics	B
,	O
ieee	O
,	O
2017	O
,	O
pp	O
.	O
41–45	O
.	O
of	O
the	O
annual	B
conference	I
of	O
the	O
international	O
speech	B
communication	I
[	O
167	O
]	O
k.	O
kinoshita	O
,	O
m.	O
delcroix	O
,	O
s.	O
araki	O
,	O
t.	O
nakatani	O
,	O
tackling	O
real	O
noisy	O
association	O
,	O
2020	O
,	O
pp	O
.	O
2797–2801	O
.	O
reverberant	O
meetings	O
with	O
all	O
-	O
neural	O
source	B
separation	O
,	O
counting	O
,	O
and	O
[	O
187	O
]	O
j.	O
carletta	O
,	O
s.	O
ashby	O
,	O
s.	O
bourban	O
,	O
m.	O
flynn	O
,	O
m.	O
guillemot	O
,	O
t.	O
hain	O
,	O
diarization	B
system	O
,	O
in	O
:	O
proceedings	O
of	O
ieee	O
international	O
conference	O
j.	O
kadlec	O
,	O
v.	O
karaiskos	O
,	O
w.	O
kraaij	O
,	O
m.	O
kronenthal	O
,	O
et	O
al	O
.	O
,	O
the	O
ami	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
,	O
ieee	O
,	O
2020	O
,	O
pp	O
.	O
381–385	O
.	O
meeting	O
corpus	B
:	O
a	O
pre	O
-	O
announcement	O
,	O
in	O
:	O
international	O
workshop	O
on	O
[	O
168	O
]	O
k.	O
maekawa	O
,	O
corpus	B
of	O
spontaneous	O
japanese	O
:	O
its	O
design	O
and	O
evalua-	O
machine	O
learning	O
for	O
multimodal	O
interaction	O
,	O
springer	O
,	O
2005	O
,	O
pp	O
.	O
28–39	O
.	O
tion	O
,	O
in	O
:	O
isca	O
&	O
ieee	O
workshop	O
on	O
spontaneous	O
speech	O
processing	B
[	O
188	O
]	O
a.	O
janin	O
,	O
d.	O
baron	O
,	O
j.	O
edwards	O
,	O
d.	O
ellis	O
,	O
d.	O
gelbart	O
,	O
n.	O
morgan	O
,	O
b.	O
pe-	O
and	O
recognition	O
,	O
2003	O
,	O
pp	O
.	O
7–12	O
.	O
skin	O
,	O
t.	O
pfau	O
,	O
e.	O
shriberg	O
,	O
a.	O
stolcke	O
,	O
c.	O
wooters	O
,	O
the	O
icsi	O
meeting	O
[	O
169	O
]	O
s.	O
horiguchi	O
,	O
y.	O
fujita	O
,	O
s.	O
watanabe	O
,	O
y.	O
xue	O
,	O
k.	O
nagamatsu	O
,	O
end	O
-	O
to	O
-	O
end	O
corpus	B
,	O
in	O
:	O
proceedings	O
of	O
ieee	O
international	O
conference	O
on	O
acoustics	B
,	O
25speech	O
and	O
signal	B
processing	I
,	O
2003	O
,	O
pp	O
.	O
i–364–i–367	O
.	O
tem	O
,	O
in	O
:	O
proceedings	O
of	O
the	O
annual	B
conference	I
of	O
the	O
international	O
[	O
189	O
]	O
n.	O
ryant	O
,	O
k.	O
church	O
,	O
c.	O
cieri	O
,	O
a.	O
cristia	O
,	O
j.	O
du	O
,	O
s.	O
ganapathy	O
,	O
m.	O
liber-	O
speech	B
communication	I
association	O
,	O
2017	O
,	O
pp	O
.	O
2739–2743	O
.	O
man	O
,	O
the	O
ﬁrst	O
dihard	O
speech	O
diarization	B
challenge	B
,	O
in	O
:	O
proceedings	O
of	O
[	O
206	O
]	O
a.	O
zhang	O
,	O
q.	O
wan	O
,	O
z.	O
zhu	O
,	O
j.	O
paisley	O
,	O
c.	O
wang	O
,	O
fully	O
supervised	O
speaker	B
the	O
annual	B
conference	I
of	O
the	O
international	O
speech	B
communication	I
as-	O
diarization	B
,	O
arxiv	O
preprint	O
arxiv:1810.04719	O
(	O
2018	O
)	O
.	O
sociation	O
,	O
2018	O
.	O
[	O
207	O
]	O
k.	O
he	O
,	O
x.	O
zhang	O
,	O
s.	O
ren	O
,	O
j.	O
sun	O
,	O
deep	O
residual	O
learning	O
for	O
image	O
recog-	O
[	O
190	O
]	O
n.	O
ryant	O
,	O
k.	O
church	O
,	O
c.	O
cieri	O
,	O
j.	O
du	O
,	O
s.	O
ganapathy	O
,	O
m.	O
liberman	O
,	O
third	O
nition	O
,	O
in	O
:	O
ieee	O
conf	O
.	O
computer	B
vision	O
,	O
pattern	O
recognition	O
,	O
2016	O
,	O
pp	O
.	O
dihard	B
challenge	I
evaluation	B
plan	I
,	O
arxiv	O
preprint	O
arxiv:2006.05815	O
770–778	O
.	O
doi:10.1109	O
/	O
cvpr.2016.90	O
.	O
(	O
2020	O
)	O
.	O
[	O
208	O
]	O
k.	O
he	O
,	O
g.	O
gkioxari	O
,	O
p.	O
dolla´r	O
,	O
r.	O
girshick	O
,	O
mask	O
r	O
-	O
cnn	O
,	O
[	O
191	O
]	O
j.	O
barker	O
,	O
s.	O
watanabe	O
,	O
e.	O
vincent	O
,	O
j.	O
trmal	O
,	O
the	O
ﬁfth	O
’	O
chime	O
’	O
speech	O
corr	O
abs/1703.06870	O
(	O
2017	O
)	O
.	O
url	O
:	O
http://arxiv.org/abs/1703	O
.	O
separation	O
and	O
recognition	O
challenge	B
:	O
dataset	O
,	O
task	O
and	O
baselines	O
,	O
pro-	O
06870	O
.	O
arxiv:1703.06870	O
.	O
ceedings	O
of	O
the	O
annual	B
conference	I
of	O
the	O
international	O
speech	O
commu-	O
[	O
209	O
]	O
t.	O
yoshioka	O
,	O
i.	O
abramovski	O
,	O
c.	O
aksoylar	O
,	O
z.	O
chen	O
,	O
m.	O
david	O
,	O
d.	O
dimi-	O
nication	O
association	O
(	O
2018	O
)	O
1561–1565	O
.	O
triadis	O
,	O
y.	O
gong	O
,	O
i.	O
gurvich	O
,	O
x.	O
huang	O
,	O
y.	O
huang	O
,	O
a.	O
hurvitz	O
,	O
l.	O
jiang	O
,	O
[	O
192	O
]	O
j.	O
s.	O
chung	O
,	O
j.	O
huh	O
,	O
a.	O
nagrani	O
,	O
t.	O
afouras	O
,	O
a.	O
zisserman	O
,	O
spot	O
the	O
s.	O
koubi	O
,	O
e.	O
krupka	O
,	O
i.	O
leichter	O
,	O
c.	O
liu	O
,	O
p.	O
parthasarathy	O
,	O
a.	O
vinnikov	O
,	O
conversation	O
:	O
speaker	B
diarisation	O
in	O
the	O
wild	O
,	O
in	O
:	O
proceedings	O
of	O
the	O
l.	O
wu	O
,	O
x.	O
xiao	O
,	O
w.	O
xiong	O
,	O
h.	O
wang	O
,	O
z.	O
wang	O
,	O
j.	O
zhang	O
,	O
y.	O
zhao	O
,	O
annual	B
conference	I
of	O
the	O
international	O
speech	B
communication	I
associ-	O
t.	O
zhou	O
,	O
advances	O
in	O
online	O
audio	O
-	O
visual	O
meeting	O
transcription	B
,	O
in	O
:	O
ation	O
,	O
2020	O
,	O
pp	O
.	O
299–303	O
.	O
proceedings	O
of	O
ieee	O
workshop	O
on	O
automatic	O
speech	B
recognition	I
and	O
[	O
193	O
]	O
v.	O
panayotov	O
,	O
g.	O
chen	O
,	O
d.	O
povey	O
,	O
s.	O
khudanpur	O
,	O
librispeech	O
:	O
an	O
asr	B
understanding	O
,	O
2019	O
,	O
pp	O
.	O
276–283	O
.	O
corpus	B
based	O
on	O
public	O
domain	B
audio	O
books	O
,	O
in	O
:	O
proceedings	O
of	O
ieee	O
[	O
210	O
]	O
h.	O
buchner	O
,	O
r.	O
aichner	O
,	O
w.	O
kellermann	O
,	O
a	O
generalization	O
of	O
blind	O
international	O
conference	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
,	O
source	B
separation	O
algorithms	O
for	O
convolutive	O
mixtures	O
based	O
on	O
second-	O
ieee	O
,	O
2015	O
,	O
pp	O
.	O
5206–5210	O
.	O
order	B
statistics	B
,	O
ieee	O
transactions	O
on	O
speech	O
and	O
audio	O
processing	B
13	O
[	O
194	O
]	O
j.	O
g.	O
fiscus	O
,	O
j.	O
ajot	O
,	O
m.	O
michel	O
,	O
j.	O
s.	O
garofolo	O
,	O
the	O
rich	B
transcription	I
(	O
2005	O
)	O
120–134	O
.	O
2006	O
spring	O
meeting	O
recognition	O
evaluation	B
,	O
in	O
:	O
proceedings	O
of	O
interna-	O
[	O
211	O
]	O
h.	O
sawada	O
,	O
s.	O
araki	O
,	O
s.	O
makino	O
,	O
measuring	O
dependence	O
of	O
bin	O
-	O
wise	O
tional	O
workshop	O
on	O
machine	O
learning	O
and	O
multimodal	O
interaction	O
,	O
may	O
separated	O
signals	B
for	O
permutation	O
alignment	O
in	O
frequency	B
-	O
domain	B
bss	O
,	O
2006	O
,	O
pp	O
.	O
309–322	O
.	O
in	O
:	O
int	O
.	O
symp	O
.	O
circ	O
.	O
,	O
syst	O
.	O
,	O
2007	O
,	O
pp	O
.	O
3247–3250	O
.	O
[	O
195	O
]	O
p.	O
e.	O
black	O
,	O
hungarian	O
algorithm	O
,	O
2019	O
.	O
[	O
212	O
]	O
f.	O
nesta	O
,	O
p.	O
svaizer	O
,	O
m.	O
omologo	O
,	O
convolutive	O
bss	O
of	O
short	O
mixtures	O
https://xlinux.nist.gov/dads/html/hungarianalgorithm.html	O
.	O
by	O
ica	O
recursively	O
regularized	O
across	O
frequencies	O
,	O
ieee	O
transactions	O
on	O
[	O
196	O
]	O
t.	O
j.	O
park	O
,	O
p.	O
georgiou	O
,	O
multimodal	O
speaker	B
segmentation	I
and	O
di-	O
audio	O
,	O
speech	O
,	O
and	O
language	B
processing	I
19	O
(	O
2011	O
)	O
624–639	O
.	O
arization	O
using	O
lexical	O
and	O
acoustic	O
cues	O
via	O
sequence	B
to	O
sequence	B
neu-	O
[	O
213	O
]	O
h.	O
sawada	O
,	O
s.	O
araki	O
,	O
s.	O
makino	O
,	O
underdetermined	O
convolutive	O
blind	O
ral	O
networks	O
,	O
in	O
:	O
proceedings	O
of	O
the	O
annual	B
conference	I
of	O
the	O
in-	O
source	B
separation	O
via	O
frequency	B
bin	O
-	O
wise	O
clustering	B
and	O
permutation	O
ternational	O
speech	B
communication	I
association	O
,	O
2018	O
,	O
pp	O
.	O
1373–1377	O
.	O
alignment	O
,	O
ieee	O
transactions	O
on	O
audio	O
,	O
speech	O
,	O
and	O
language	O
pro-	O
url	O
:	O
http://dx.doi.org/10.21437/interspeech.2018-1364	O
.	O
cessing	O
19	O
(	O
2011	O
)	O
516–527	O
.	O
doi:10.21437	O
/	O
interspeech.2018	O
-	O
1364	O
.	O
[	O
214	O
]	O
n.	O
ito	O
,	O
s.	O
araki	O
,	O
t.	O
yoshioka	O
,	O
t.	O
nakatani	O
,	O
relaxed	O
disjointness	O
based	O
[	O
197	O
]	O
j.	O
s.	O
chung	O
,	O
a.	O
nagrani	O
,	O
e.	O
coto	O
,	O
w.	O
xie	O
,	O
m.	O
mclaren	O
,	O
d.	O
a.	O
reynolds	O
,	O
clustering	B
for	O
joint	O
blind	O
source	B
separation	O
and	O
dereverberation	O
,	O
in	O
:	O
pro-	O
a.	O
zisserman	O
,	O
voxsrc	O
2019	O
:	O
the	O
ﬁrst	O
voxceleb	O
speaker	B
recognition	O
ceedings	O
of	O
international	O
workshop	O
on	O
acoustic	O
echo	O
and	O
noise	O
con-	O
challenge	B
,	O
arxiv	O
preprint	O
arxiv:1912.02522	O
(	O
2019	O
)	O
.	O
trol	O
,	O
2014	O
,	O
pp	O
.	O
268–272	O
.	O
[	O
198	O
]	O
c.	O
chiu	O
,	O
a.	O
tripathi	O
,	O
k.	O
chou	O
,	O
c.	O
co	O
,	O
n.	O
jaitly	O
,	O
d.	O
jaunzeikare	O
,	O
[	O
215	O
]	O
l.	O
drude	O
,	O
r.	O
haeb	O
-	O
umbach	O
,	O
tight	O
integration	O
of	O
spatial	O
and	O
spectral	O
a.	O
kannan	O
,	O
p.	O
nguyen	O
,	O
h.	O
sak	O
,	O
a.	O
sankar	O
,	O
j.	O
tansuwan	O
,	O
n.	O
wan	O
,	O
features	O
for	O
bss	O
with	O
deep	O
clustering	B
embeddings	O
,	O
in	O
:	O
proceedings	O
of	O
y.	O
wu	O
,	O
x.	O
zhang	O
,	O
speech	B
recognition	I
for	O
medical	O
conversations	O
,	O
the	O
annual	B
conference	I
of	O
the	O
international	O
speech	B
communication	I
as-	O
corr	O
abs/1711.07274	O
(	O
2017	O
)	O
.	O
url	O
:	O
http://arxiv.org/abs/1711	O
.	O
sociation	O
,	O
2017	O
,	O
pp	O
.	O
2650–2654	O
.	O
07274	O
.	O
arxiv:1711.07274	O
.	O
[	O
216	O
]	O
m.	O
maciejewski	O
,	O
g.	O
sell	O
,	O
l.	O
p.	O
garcia	O
-	O
perera	O
,	O
s.	O
watanabe	O
,	O
s.	O
khudan-	O
[	O
199	O
]	O
j.	O
carletta	O
,	O
s.	O
ashby	O
,	O
s.	O
bourban	O
,	O
m.	O
flynn	O
,	O
m.	O
guillemot	O
,	O
t.	O
hain	O
,	O
pur	O
,	O
building	O
corpora	B
for	O
single	O
-	O
channel	O
speech	B
separation	I
across	O
mul-	O
j.	O
kadlec	O
,	O
v.	O
karaiskos	O
,	O
w.	O
kraaij	O
,	O
m.	O
kronenthal	O
,	O
g.	O
lathoud	O
,	O
m.	O
lin-	O
tiple	O
domains	O
,	O
corr	O
abs/1811.02641	O
(	O
2018	O
)	O
.	O
url	O
:	O
http://arxiv	O
.	O
coln	O
,	O
a.	O
lisowska	O
,	O
i.	O
mccowan	O
,	O
w.	O
p.	O
andd	O
.	O
reidsma	O
,	O
p.	O
wellner	O
,	O
the	O
org	O
/	O
abs/1811.02641	O
.	O
arxiv:1811.02641	O
.	O
ami	O
meeting	O
corpus	B
:	O
a	O
pre	O
-	O
announcement	O
,	O
in	O
:	O
proceedings	O
of	O
int	O
.	O
[	O
217	O
]	O
s.	O
araki	O
,	O
n.	O
ono	O
,	O
k.	O
kinoshita	O
,	O
m.	O
delcroix	O
,	O
meeting	O
recognition	O
with	O
worksh	O
.	O
machine	O
learning	O
for	O
multimodal	O
interaction	O
,	O
2006	O
,	O
pp	O
.	O
28	O
–	O
asynchronous	O
distributed	O
microphone	O
array	O
using	O
block	O
-	O
wise	O
reﬁnement	O
39	O
.	O
of	O
mask	O
-	O
based	O
mvdr	O
beamformer	O
,	O
in	O
:	O
proceedings	O
of	O
ieee	O
interna-	O
[	O
200	O
]	O
w.	O
xiong	O
,	O
j.	O
droppo	O
,	O
x.	O
huang	O
,	O
f.	O
seide	O
,	O
m.	O
seltzer	O
,	O
a.	O
stolcke	O
,	O
d.	O
yu	O
,	O
tional	O
conference	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
,	O
2018	O
,	O
g.	O
zweig	O
,	O
achieving	O
human	O
parity	O
in	O
conversational	O
speech	B
recognition	I
,	O
pp	O
.	O
5694–5698	O
.	O
corr	O
abs/1610.05256	O
(	O
2016	O
)	O
.	O
url	O
:	O
http://arxiv.org/abs/1610	O
.	O
[	O
218	O
]	O
a.	O
stolcke	O
,	O
making	O
the	O
most	O
from	O
multiple	O
microphones	O
in	O
meeting	O
05256	O
.	O
arxiv:1610.05256	O
.	O
recordings	O
,	O
in	O
:	O
proceedings	O
of	O
ieee	O
international	O
conference	O
on	O
acous-	O
[	O
201	O
]	O
g.	O
saon	O
,	O
g.	O
kurata	O
,	O
t.	O
sercu	O
,	O
k.	O
audhkhasi	O
,	O
s.	O
thomas	O
,	O
d.	O
dimitriadis	O
,	O
tics	O
,	O
speech	O
and	O
signal	B
processing	I
,	O
2011	O
,	O
pp	O
.	O
4992–4995	O
.	O
x.	O
cui	O
,	O
b.	O
ramabhadran	O
,	O
m.	O
picheny	O
,	O
l.	O
lim	O
,	O
b.	O
roomi	O
,	O
p.	O
hall	O
,	O
english	O
[	O
219	O
]	O
s.	O
narayanan	O
,	O
p.	O
g.	O
georgiou	O
,	O
behavioral	O
signal	B
processing	I
:	O
deriving	O
conversational	O
telephone	B
speech	I
recognition	O
by	O
humans	O
and	O
machines	O
,	O
human	O
behavioral	O
informatics	O
from	O
speech	O
and	O
language	O
,	O
proceedings	O
corr	O
abs/1703.02136	O
(	O
2017	O
)	O
.	O
url	O
:	O
http://arxiv.org/abs/1703	O
.	O
of	O
the	O
ieee	O
101	O
(	O
2013	O
)	O
1203–1233	O
.	O
02136	O
.	O
arxiv:1703.02136	O
.	O
[	O
220	O
]	O
d.	O
bone	O
,	O
c.-c	O
.	O
lee	O
,	O
t.	O
chaspari	O
,	O
j.	O
gibson	O
,	O
s.	O
narayanan	O
,	O
signal	B
pro-	O
[	O
202	O
]	O
t.	O
yoshioka	O
,	O
n.	O
ito	O
,	O
m.	O
delcroix	O
,	O
a.	O
ogawa	O
,	O
k.	O
kinoshita	O
,	O
m.	O
fujimoto	O
,	O
cessing	O
and	O
machine	O
learning	O
for	O
mental	O
health	O
research	B
and	O
clinical	O
ap-	O
c.	O
yu	O
,	O
w.	O
fabian	O
,	O
m.	O
espi	O
,	O
t.	O
higuchi	O
,	O
s.	O
araki	O
,	O
t.	O
nakatani	O
,	O
the	O
ntt	O
plications	O
,	O
ieee	O
signal	B
processing	I
magazine	O
34	O
(	O
2017	O
)	O
189–196	O
.	O
chime-3	O
system	O
:	O
advances	O
in	O
speech	O
enhancement	O
and	O
recognition	O
for	O
[	O
221	O
]	O
m.	O
kumar	O
,	O
s.	O
h.	O
kim	O
,	O
c.	O
lord	O
,	O
s.	O
narayanan	O
,	O
speaker	B
diarization	I
for	O
mobile	O
multi	O
-	O
microphone	O
devices	O
,	O
in	O
:	O
proceedings	O
of	O
ieee	O
workshop	O
naturalistic	O
child	O
-	O
adult	O
conversational	O
interactions	O
using	O
contextual	O
in-	O
on	O
automatic	O
speech	B
recognition	I
and	O
understanding	O
,	O
2015	O
,	O
pp	O
.	O
436	O
–	O
formation	O
.	O
,	O
journal	O
of	O
the	O
acoustical	O
society	O
of	O
america	O
147	O
(	O
2020	O
)	O
443	O
.	O
el196–el200	O
.	O
doi:10.1121/10.0000736	O
.	O
[	O
203	O
]	O
j.	O
du	O
,	O
y.	O
tu	O
,	O
l.	O
sun	O
,	O
f.	O
ma	O
,	O
h.	O
wang	O
,	O
j.	O
pan	O
,	O
c.	O
liu	O
,	O
j.	O
chen	O
,	O
c.	O
lee	O
,	O
[	O
222	O
]	O
p.	O
g.	O
georgiou	O
,	O
m.	O
p.	O
black	O
,	O
s.	O
s.	O
narayanan	O
,	O
behavioral	O
signal	B
pro-	O
the	O
ustc	O
-	O
iflytek	O
system	O
for	O
chime-4	O
challenge	B
,	O
in	O
:	O
proceedings	O
of	O
cessing	O
for	O
understanding	O
(	O
distressed	O
)	O
dyadic	O
interactions	O
:	O
some	O
recent	O
chime-4	O
workshop	O
,	O
2016	O
,	O
pp	O
.	O
36–38	O
.	O
developments	O
,	O
in	O
:	O
proceedings	O
of	O
the	O
joint	O
acm	O
workshop	O
on	O
human	O
[	O
204	O
]	O
b.	O
li	O
,	O
t.	O
n.	O
sainath	O
,	O
a.	O
narayanan	O
,	O
j.	O
caroselli	O
,	O
m.	O
bacchiani	O
,	O
a.	O
misra	O
,	O
gesture	O
and	O
behavior	O
understanding	O
,	O
2011	O
,	O
pp	O
.	O
7–12	O
.	O
i.	O
shafran	O
,	O
h.	O
sak	O
,	O
g.	O
punduk	O
,	O
k.	O
chin	O
,	O
k.	O
c.	O
sim	O
,	O
r.	O
j.	O
weiss	O
,	O
k.	O
w.	O
[	O
223	O
]	O
b.	O
xiao	O
,	O
c.	O
huang	O
,	O
z.	O
e.	O
imel	O
,	O
d.	O
c.	O
atkins	O
,	O
p.	O
georgiou	O
,	O
s.	O
s.	O
wilson	O
,	O
e.	O
variani	O
,	O
c.	O
kim	O
,	O
o.	O
siohan	O
,	O
m.	O
weintrauba	O
,	O
e.	O
mcdermott	O
,	O
narayanan	O
,	O
a	O
technology	O
prototype	O
system	O
for	O
rating	O
therapist	O
empathy	O
r.	O
rose	O
,	O
m.	O
shannon	O
,	O
acoustic	O
modeling	O
for	O
google	O
home	O
,	O
in	O
:	O
pro-	O
from	O
audio	O
recordings	O
in	O
addiction	O
counseling	O
,	O
peerj	O
computer	B
science	O
ceedings	O
of	O
the	O
annual	B
conference	I
of	O
the	O
international	O
speech	O
commu-	O
2	O
(	O
2016	O
)	O
e59	O
.	O
nication	O
association	O
,	O
2017	O
,	O
pp	O
.	O
399–403	O
.	O
[	O
224	O
]	O
s.	O
n.	O
chakravarthula	O
,	O
m.	O
nasir	O
,	O
s.-y	O
.	O
tseng	O
,	O
h.	O
li	O
,	O
t.	O
j.	O
park	O
,	O
b.	O
bau-	O
[	O
205	O
]	O
d.	O
dimitriadis	O
,	O
p.	O
fousek	O
,	O
developing	O
on	O
-	O
line	O
speaker	B
diarization	I
sys-	O
com	O
,	O
c.	O
j.	O
bryan	O
,	O
s.	O
narayanan	O
,	O
p.	O
georgiou	O
,	O
automatic	O
prediction	O
26of	O
suicidal	O
risk	O
in	O
military	O
couples	O
using	O
multimodal	O
interaction	O
cues	O
from	O
couples	O
conversations	O
,	O
in	O
:	O
proceedings	O
of	O
ieee	O
international	O
con-	O
ference	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
,	O
ieee	O
,	O
2020	O
,	O
pp	O
.	O
6539–6543	O
.	O
[	O
225	O
]	O
b.	O
mirheidari	O
,	O
d.	O
blackburn	O
,	O
k.	O
harkness	O
,	O
t.	O
walker	O
,	O
a.	O
venneri	O
,	O
m.	O
reuber	O
,	O
h.	O
christensen	O
,	O
toward	O
the	O
automation	O
of	O
diagnostic	O
con-	O
versation	O
analysis	B
in	O
patients	O
with	O
memory	O
complaints	O
,	O
journal	O
of	O
alzheimer	O
’s	O
disease	O
58	O
(	O
2017	O
)	O
373–387	O
.	O
[	O
226	O
]	O
g.	O
p.	O
finley	O
,	O
e.	O
edwards	O
,	O
a.	O
robinson	O
,	O
n.	O
sadoughi	O
,	O
j.	O
fone	O
,	O
m.	O
miller	O
,	O
d.	O
suendermann	O
-	O
oeft	O
,	O
m.	O
brenndoerfer	O
,	O
n.	O
axtmann	O
,	O
an	O
automated	O
assistant	O
for	O
medical	O
scribes	O
.	O
,	O
in	O
:	O
proceedings	O
of	O
the	O
annual	O
confer-	O
ence	O
of	O
the	O
international	O
speech	B
communication	I
association	O
,	O
2018	O
,	O
pp	O
.	O
3212–3213	O
.	O
[	O
227	O
]	O
a.	O
guo	O
,	O
a.	O
faria	O
,	O
j.	O
riedhammer	O
,	O
remeeting	O
–	O
deep	O
insights	O
to	O
conver-	O
sations	O
,	O
in	O
:	O
proceedings	O
of	O
the	O
annual	B
conference	I
of	O
the	O
international	O
speech	B
communication	I
association	O
,	O
2016	O
,	O
pp	O
.	O
1964–1965	O
.	O
[	O
228	O
]	O
a.	O
addlesee	O
,	O
y.	O
yu	O
,	O
a.	O
eshghi	O
,	O
a	O
comprehensive	O
evaluation	B
of	O
incre-	O
mental	O
speech	B
recognition	I
and	O
diarization	B
for	O
conversational	O
ai	O
,	O
in	O
:	O
pro-	O
ceedings	O
of	O
the	O
international	O
conference	O
on	O
computational	O
linguistics	O
,	O
2020	O
,	O
pp	O
.	O
3492–3503	O
.	O
[	O
229	O
]	O
o.	O
cetin	O
,	O
e.	O
shriberg	O
,	O
speaker	B
overlaps	B
and	O
asr	B
errors	B
in	O
meetings	O
:	O
eﬀects	O
before	O
,	O
during	O
,	O
and	O
after	O
the	O
overlap	O
,	O
in	O
:	O
proceedings	O
of	O
ieee	O
international	O
conference	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
,	O
volume	O
1	O
,	O
ieee	O
,	O
2006	O
,	O
pp	O
.	O
357–360	O
.	O
[	O
230	O
]	O
n.	O
kanda	O
,	O
c.	O
boeddeker	O
,	O
j.	O
heitkaemper	O
,	O
y.	O
fujita	O
,	O
s.	O
horiguchi	O
,	O
k.	O
nagamatsu	O
,	O
r.	O
haeb	O
-	O
umbach	O
,	O
guided	O
source	B
separation	O
meets	O
a	O
strong	O
asr	B
backend	O
:	O
hitachi	O
/	O
paderborn	O
university	O
joint	O
investigation	O
for	O
dinner	O
party	O
asr	B
,	O
proceedings	O
of	O
the	O
annual	B
conference	I
of	O
the	O
international	O
speech	B
communication	I
association	O
(	O
2019	O
)	O
1248–1252	O
.	O
[	O
231	O
]	O
s.	O
otterson	O
,	O
m.	O
ostendorf	O
,	O
eﬃcient	O
use	O
of	O
overlap	O
information	B
in	O
speaker	B
diarization	I
,	O
in	O
:	O
proceedings	O
of	O
ieee	O
workshop	O
on	O
automatic	O
speech	B
recognition	I
and	O
understanding	O
,	O
ieee	O
,	O
2007	O
,	O
pp	O
.	O
683–686	O
.	O
[	O
232	O
]	O
k.	O
boakye	O
,	O
b.	O
trueba	O
-	O
hornero	O
,	O
o.	O
vinyals	O
,	O
g.	O
friedland	O
,	O
overlapped	B
speech	I
detection	B
for	O
improved	O
speaker	B
diarization	I
in	O
multiparty	O
meet-	O
ings	O
,	O
in	O
:	O
proceedings	O
of	O
ieee	O
international	O
conference	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
,	O
ieee	O
,	O
2008	O
,	O
pp	O
.	O
4353–4356	O
.	O
[	O
233	O
]	O
l.	O
bullock	O
,	O
h.	O
bredin	O
,	O
l.	O
p.	O
garcia	O
-	O
perera	O
,	O
overlap	O
-	O
aware	O
diarization	B
:	O
resegmentation	B
using	O
neural	O
end	O
-	O
to	O
-	O
end	O
overlapped	B
speech	I
detection	B
,	O
in	O
:	O
proceedings	O
of	O
ieee	O
international	O
conference	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
,	O
ieee	O
,	O
2020	O
,	O
pp	O
.	O
7114–7118	O

speaker	B
diarization	I
:	O
about	O
whom	O
the	O
speaker	B
is	O
talking	O
?	O
j	O
mauclair	O
,	O
s.	O
meignier	O
,	O
y	O
esteve	O
lium	O
,	O
universite	O
du	O
maine	O
le	O
mans	O
,	O
france	O
{	O
julie.mauclair	O
,	O
sylvain.meignier	O
,	O
yannick.esteve	O
}	O
glium.univ-lemans.fr	O
abstract	O
the	O
automatic	O
speaker	B
diarization	I
consists	O
in	O
splitting	O
the	O
signal	B
into	O
homogeneous	O
segments	O
and	O
clustering	B
them	O
by	O
speakers	O
.	O
however	O
the	O
speaker	B
segments	I
are	O
specified	O
with	O
anonymous	O
labels	O
.	O
this	O
pa-	O
per	O
suggests	O
a	O
solution	O
to	O
identify	O
those	O
speakers	O
by	O
extracting	O
their	O
ir	O
other	O
\	O
full	O
names	O
pronounced	O
in	O
french	O
broadcast	O
news	O
.	O
a	O
semantic	O
classi-	O
fication	O
tree	O
is	O
automatically	O
built	O
on	O
a	O
training	O
corpus	B
and	O
associate	O
-	O
another	O
speaker	B
ofthe	O
show	O
the	O
full	O
names	O
detected	O
in	O
the	O
transcription	B
of	O
a	O
segment	B
to	O
this	O
seg-	O
-	O
a	O
person	O
that	O
does	O
not	O
speak	O
in	O
the	O
show	O
ment	O
or	O
to	O
one	O
of	O
its	O
neighbors	O
.	O
then	O
,	O
a	O
merging	O
method	B
permits	O
to	O
associate	O
a	O
full	O
name	O
to	O
a	O
speaker	B
cluster	O
instead	O
of	O
an	O
anonymous	O
fig	O
.	O
1	O
.	O
tags	O
on	O
full	O
names	O
:	O
about	O
whom	O
the	O
speaker	B
is	O
talking	O
?	O
label	O
provided	O
by	O
the	O
diarization	B
.	O
the	O
experiments	O
are	O
carried	O
out	O
over	O
french	O
broadcast	O
news	O
records	O
from	O
the	O
ester	O
2005	O
evaluation	B
campaign	O
.	O
about	O
70	O
%	O
show	O
duration	O
is	O
correctly	O
processed	O
for	O
both	O
development	O
and	O
eval-	O
*	O
acoustic	O
based	O
systems	O
generally	O
rely	O
on	O
automatic	O
speaker	B
uation	O
corpora	B
.	O
on	O
the	O
evaluation	B
corpus	B
,	O
18.2	O
%	O
show	O
duration	O
is	O
recognition	O
methods	O
needing	O
additional	O
samples	O
of	O
the	O
voice	O
wrongly	O
named	O
and	O
no	O
decision	O
is	O
taken	O
for	O
11.9	O
%	O
show	O
duration	O
.	O
of	O
speakers	O
in	O
order	B
to	O
learn	O
acoustic	O
models	B
[	O
5	O
]	O
.	O
*	O
linguistic	O
based	O
systems	O
extract	O
speaker	B
identities	O
directly	O
from	O
the	O
speech	O
.	O
speakers	O
often	O
introduce	O
themselves	O
or	O
the	O
1	O
introduction	O
next	O
speaker	B
,	O
greet	O
the	O
next	O
or	O
the	O
previous	O
speaker	B
,	O
sign	O
off	O
at	O
the	O
end	O
of	O
their	O
report	O
...	O
the	O
true	O
name	O
of	O
the	O
speaker	B
and	O
his	O
large	O
collections	O
of	O
speech	O
data	B
are	O
now	O
available	O
but	O
unfortunately	O
,	O
localization	O
are	O
generally	O
present	O
in	O
the	O
pronounced	O
words	B
for	O
most	O
of	O
them	O
,	O
without	O
rich	B
transcription	I
.	O
manual	O
rich	O
transcrip-	O
and	O
can	O
be	O
used	O
to	O
identify	O
speakers	O
with	O
their	O
full	O
name	O
.	O
tions	O
of	O
audio	O
recordings	O
are	O
high	O
-	O
cost	B
,	O
especially	O
for	O
indexing	O
appli-	O
compared	O
to	O
the	O
previous	O
method	B
,	O
no	O
speaker	B
voice	O
sample	O
cations	O
based	O
on	O
specific	O
information	B
like	O
the	O
main	O
topic	O
,	O
keywords	O
,	O
is	O
needed	O
but	O
transcription	B
is	O
necessary	O
.	O
the	O
name	O
of	O
the	O
speaker	B
...	O
only	O
automatic	O
methods	O
produces	O
rich	O
recent	O
work	O
carried	O
out	O
on	O
english	O
broadcast	O
news	O
[	O
6,7	O
]	O
,	O
show	O
transcriptions	B
with	O
a	O
reasonable	O
cost	B
,	O
but	O
the	O
error	B
rate	I
due	O
to	O
the	O
that	O
a	O
speaker	B
full	O
name	O
occurring	O
in	O
a	O
linguistic	O
context	O
can	O
be	O
used	O
performances	O
ofthe	O
systems	O
must	O
be	O
sufficiently	O
low	O
to	O
be	O
exploited	O
.	O
to	O
identify	O
the	O
speaker	B
of	O
the	O
segment	B
with	O
his	O
true	O
name	O
.	O
the	O
lin-	O
in	O
this	O
article	O
,	O
the	O
indexing	O
key	O
is	O
the	O
speaker	B
identity	O
.	O
guistic	O
patterns	O
are	O
manually	O
defined	O
in	O
order	B
to	O
tag	B
one	O
of	O
the	O
cur-	O
the	O
first	O
step	O
to	O
automatically	O
get	O
rich	O
transcriptions	B
consists	O
in	O
rent	O
,	O
next	O
or	O
previous	O
segment	B
associated	O
to	O
the	O
detected	O
speaker	B
finding	O
the	O
beginning	O
and	O
the	O
end	O
of	O
each	O
homogeneous	O
audio	O
seg-	O
name	O
:	O
"	O
such	O
situations	O
mainly	O
correspond	O
to	O
announcements	O
of	O
who	O
ment	O
which	O
contains	O
the	O
voice	O
of	O
only	O
one	O
speaker	B
,	O
the	O
resulting	O
seg-	O
is	O
speaking	O
,	O
who	O
will	O
speak	O
or	O
who	O
just	O
spoke	O
"	O
(	O
sic	O
)	O
[	O
7	O
]	O
.	O
they	O
show	O
ments	O
are	O
then	O
clustered	O
by	O
speaker	B
.	O
this	O
step	O
is	O
called	O
diarization	B
that	O
the	O
error	B
rate	I
of	O
their	O
tagging	O
process	B
based	O
on	O
manual	O
rules	O
is	O
in	O
the	O
nist	O
terminology	O
;	O
it	O
is	O
also	O
known	O
as	O
speaker	B
segmentation	I
.	O
about	O
13	O
%	O
and	O
18	O
%	O
respectively	O
for	O
manual	O
transcriptions	B
and	O
for	O
the	O
diarization	B
is	O
performed	O
without	O
any	O
prior	O
information	B
:	O
neither	O
automatic	O
transcriptions	B
.	O
the	O
number	O
of	O
speakers	O
,	O
nor	O
the	O
identities	O
of	O
speakers	O
nor	O
samples	O
we	O
have	O
designed	O
an	O
automatic	O
speaker	B
naming	O
system	O
based	O
on	O
of	O
their	O
voice	O
are	O
needed	O
.	O
in	O
the	O
literature	O
,	O
the	O
main	O
recent	O
methods	O
the	O
use	O
of	O
a	O
semantic	O
classification	O
tree	O
which	O
automatically	O
learns	O
are	O
only	O
based	O
on	O
acoustic	B
features	I
[	O
1	O
-	O
4	O
]	O
.	O
the	O
next	O
step	O
consists	O
in	O
such	O
patterns	O
.	O
however	O
,	O
those	O
patterns	O
only	O
provide	O
a	O
local	O
decision	O
transcribing	O
automatically	O
the	O
resulting	O
segments	O
in	O
order	B
to	O
get	O
the	O
for	O
the	O
current	O
segment	B
and	O
the	O
contiguous	O
segments	O
.	O
then	O
,	O
the	O
sys-	O
pronounced	O
words	B
.	O
other	O
information	B
can	O
be	O
added	O
as	O
the	O
channel	O
tem	O
spreads	O
the	O
speaker	B
identity	O
on	O
the	O
entire	O
show	O
.	O
the	O
conflicts	O
type	O
,	O
the	O
gender	O
of	O
the	O
speaker	B
or	O
the	O
nature	O
of	O
the	O
background	O
.	O
are	O
taken	O
into	O
account	O
thanks	O
to	O
the	O
scores	O
provided	O
by	O
the	O
semantic	O
however	O
,	O
speaker	B
diarization	I
only	O
attributes	O
anonymous	O
labels	O
classification	O
tree	O
.	O
to	O
segments	O
,	O
whereas	O
the	O
speaker	B
identity	O
is	O
an	O
important	O
criterion	B
this	O
preliminary	O
study	O
presented	O
in	O
this	O
paper	O
is	O
made	O
to	O
evalu-	O
for	O
multimedia	O
audio	O
indexing	O
.	O
speaker	B
identification	O
should	O
be	O
ate	O
the	O
relevance	O
of	O
the	O
proposed	O
method	B
.	O
consequently	O
,	O
only	O
man-	O
done	O
after	O
the	O
diarization	B
and	O
transcription	B
processes	O
.	O
they	O
are	O
two	O
ual	O
diarization	B
and	O
manual	O
transcription	B
references	B
are	O
used	O
here	O
as	O
methods	O
that	O
associate	O
the	O
true	O
identity	O
(	O
full	O
name	O
)	O
of	O
a	O
speaker	B
to	O
an	O
input	B
of	O
the	O
system	O
,	O
as	O
it	O
is	O
known	O
that	O
errors	B
coming	O
from	O
au-	O
the	O
diarization	B
segments	O
:	O
tomatic	O
diarization	B
and	O
transcription	B
processes	O
reduce	O
the	O
perfor-	O
1	O
-	O
4244	O
-	O
0472-x/06/$20.00	O
(	O
®	O
)	O
2006	O
ieeeb	O
speaking	O
a	O
speaking	O
b	O
speaking	O
<	O
adv	O
>	O
spkl	O
is	O
called	O
ib	O
speaking	O
a	O
,	O
b	O
,	O
or	O
c	O
c	O
speaking	O
spkl	O
is	O
a	O
|c	O
speaking	O
i	O
_	O
spk2	O
is	O
b	O
|<music	O
>	O
spk2	O
is	O
called	O
a	O
or	O
b	O
spk3s	O
|spk4	O
b	O
speaking	O
bb	O
speaking	O
spk4	O
?	O
spk3	O
is	O
called	O
spk5	O
?	O
|	O
b	O
speaking	O
c	O
a	O
or	O
c	O
|a	O
speaking	O
ispeaking	O
spk4	O
spk5	O
segmentation	B
with	O
local	O
decisions	O
global	O
decisions	O
spreading	O
-	O
anonymous	O
speaker	B
labels	I
(	O
using	O
semantic	O
(	O
merging	O
local	O
(	O
replacing	O
local	O
-	O
transcription	B
classification	O
trees	O
)	O
decisions	O
)	O
decisions	O
)	O
name	O
detection	B
-	O
fig	O
.	O
2	O
.	O
speaker	B
identification	O
process	B
mances	O
of	O
speaker	B
identification	O
based	O
upon	O
a	O
lexical	O
stream	O
(	O
see	O
2.2	O
tags	O
on	O
full	O
name	O
occurrences	O
results	B
of	O
[	O
7	O
]	O
)	O
.	O
data	B
used	O
for	O
training	O
,	O
development	O
and	O
evaluation	B
are	O
com-	O
full	O
name	O
located	O
in	O
a	O
show	O
and	O
its	O
context	O
give	O
information	B
to	O
iden-	O
posed	O
by	O
french	O
broadcast	O
news	O
coming	O
from	O
the	O
french	O
2005	O
es-	O
tify	O
the	O
speaker	B
or	O
its	O
neighbor	O
speakers	O
.	O
in	O
fact	O
,	O
a	O
full	O
name	O
in	O
a	O
ter	O
evaluation	B
campaign	O
[	O
8,9	O
]	O
.	O
however	O
,	O
the	O
proposed	O
method	B
can	O
segment	B
can	O
be	O
associated	O
to	O
one	O
of	O
the	O
following	O
four	O
tags	O
:	O
current	O
,	O
next	O
,	O
previous	O
and	O
other	O
.	O
those	O
tags	O
determine	O
if	O
the	O
detected	O
full	O
easily	O
be	O
applied	O
to	O
english	O
corpora	B
thanks	O
to	O
the	O
full	O
automatic	O
pro-	O
cess	O
used	O
for	O
tagging	O
the	O
segments	O
and	O
for	O
speaker	B
naming	O
.	O
name	O
refers	O
to	O
the	O
speaker	B
of	O
the	O
previous	O
speech	B
segment	I
,	O
of	O
the	O
current	O
one	O
,	O
of	O
the	O
next	O
one	O
,	O
or	O
if	O
this	O
full	O
name	O
does	O
not	O
refer	O
to	O
this	O
paper	O
is	O
organized	O
as	O
follows	O
.	O
section	O
2	O
presents	O
the	O
such	O
speakers	O
(	O
see	O
figure	O
1	O
)	O
.	O
in	O
fact	O
,	O
the	O
other	O
tag	B
corresponds	O
to	O
speaker	B
information	B
used	O
in	O
the	O
study	O
.	O
section	O
3	O
describes	O
the	O
the	O
default	O
tag	B
when	O
the	O
full	O
name	O
can	O
not	O
be	O
attributed	O
to	O
one	O
of	O
the	O
method	B
and	O
section	O
4	O
the	O
experiments	O
carried	O
out	O
on	O
ester	O
cor-	O
three	O
first	O
tags	O
.	O
pora	O
.	O
3	O
method	B
2	O
speaker	B
information	B
given	O
a	O
set	B
of	O
segments	O
and	O
their	O
transcriptions	B
,	O
we	O
suggests	O
two	O
2.1	O
client	O
identity	O
main	O
processing	B
steps	B
to	O
associate	O
a	O
full	O
name	O
to	O
an	O
anonymous	O
speaker	B
label	O
provided	O
by	O
the	O
diarization	B
process	B
(	O
figure	O
2	O
,	O
part	O
lq	O
)	O
:	O
broadcast	O
news	O
speakers	O
are	O
mainly	O
composed	O
ofpublic	O
persons	O
like	O
1	O
.	O
lexical	O
context	O
analysis	B
into	O
each	O
speech	B
segment	I
contain-	O
journalists	O
,	O
politicians	O
,	O
artists	O
or	O
sportsmen	O
.	O
this	O
population	O
is	O
easily	O
recognizable	O
:	O
their	O
full	O
names	O
are	O
well	O
known	O
,	O
they	O
are	O
present	O
in	O
ing	O
a	O
full	O
name	O
(	O
figure	O
2	O
,	O
part	O
®	O
):	O
this	O
first	O
step	O
processes	O
several	O
broadcast	O
news	O
,	O
and	O
they	O
correspond	O
to	O
the	O
main	O
speakers	O
each	O
full	O
name	O
detected	O
in	O
the	O
transcription	B
of	O
a	O
speech	O
seg-	O
(	O
in	O
terms	B
of	O
speech	O
duration	O
)	O
.	O
these	O
speakers	O
are	O
identified	O
by	O
their	O
ment	O
.	O
it	O
determines	O
if	O
this	O
full	O
name	O
refers	O
to	O
the	O
previous	O
,	O
full	O
names	O
in	O
the	O
ester	O
or	O
ldc	O
transcription	B
conventions	O
and	O
they	O
current	O
,	O
next	O
or	O
another	O
speaker	B
.	O
only	O
the	O
segments	O
very	O
are	O
the	O
speakers	O
to	O
identify	O
in	O
the	O
proposed	O
task	O
.	O
close	O
to	O
a	O
full	O
name	O
detected	O
in	O
the	O
transcription	B
can	O
be	O
as-	O
sociated	O
to	O
this	O
full	O
name	O
.	O
moreover	O
,	O
some	O
segments	O
can	O
be	O
a	O
list	O
of	O
speaker	B
identities	O
is	O
extracted	O
from	O
the	O
reference	B
tran-	O
associated	O
to	O
different	O
full	O
names	O
:	O
processes	O
on	O
detected	O
full	O
scriptions	O
.	O
only	O
the	O
names	O
of	O
well	O
-	O
known	O
persons	O
are	O
kept	O
,	O
others	O
names	O
are	O
made	O
without	O
cooperation	O
and	O
can	O
provide	O
antag-	O
are	O
removed	O
.	O
1007	O
different	O
full	O
names	O
were	O
extracted	O
from	O
the	O
cor-	O
onistic	O
results	B
for	O
the	O
same	O
segment	B
.	O
pora	O
used	O
in	O
our	O
experiments	O
.	O
the	O
speaker	B
name	O
detection	B
process	B
relies	O
on	O
this	O
closed	O
list	O
.	O
2	O
.	O
speaker	B
naming	O
(	O
figure	O
2	O
,	O
part	O
(	O
0	O
)	O
)	O
:	O
the	O
second	O
step	O
consists	O
we	O
have	O
chosen	O
to	O
use	O
the	O
full	O
name	O
instead	O
of	O
the	O
last	O
name	O
to	O
in	O
merging	O
previous	O
hypotheses	B
to	O
assign	O
a	O
full	O
name	O
to	O
an	O
avoid	O
the	O
false	O
detections	O
introduced	O
by	O
the	O
speaker	B
name	O
detection	B
anonymous	O
speaker	B
label	O
.	O
this	O
step	O
spread	O
this	O
assignment	O
to	O
method	B
.	O
moreover	O
,	O
ambiguity	O
introduced	O
by	O
the	O
use	O
of	O
the	O
partial	O
all	O
the	O
segments	O
tagged	O
with	O
this	O
same	O
anonymous	O
speaker	B
la-	O
names	O
(	O
only	O
forename	O
or	O
family	O
name	O
)	O
leads	O
to	O
problems	O
which	O
we	O
bel	O
:	O
new	O
results	B
replace	O
first	O
hypotheses	B
obtained	O
at	O
segment	B
will	O
not	O
resolve	O
in	O
this	O
paper	O
.	O
level	B
from	O
the	O
previous	O
step	O
(	O
figure	O
2	O
,	O
part	O
®	O
)	O
.	O
2	O
2006	O
ieee	O
odyssey	O
-	O
the	O
speaker	B
and	O
language	O
recognition	O
workshop3.1	O
lexical	O
context	O
analysis	B
when	O
a	O
full	O
name	O
is	O
detected	O
,	O
the	O
lexical	O
context	O
of	O
the	O
transcription	B
is	O
analyzed	O
to	O
take	O
a	O
decision	O
about	O
a	O
possible	O
tag	B
of	O
this	O
full	O
name	O
.	O
this	O
tag	B
helps	O
for	O
naming	O
speaker	B
of	O
contiguous	O
speech	B
segments	I
.	O
this	O
analysis	B
is	O
made	O
by	O
using	O
a	O
binary	O
decision	O
tree	O
based	O
on	O
the	O
<	O
+	O
from+	O
>	O
principles	O
of	O
semantic	O
classification	O
trees	O
(	O
scts	O
)	O
[	O
10	O
]	O
.	O
ye	O
\fl	O
....	O
o	O
semantic	O
classification	O
tree	O
<	O
+	O
ilive	O
+	O
from	O
+	O
>	O
x	O
,	O
<	O
,	O
9	O
~~~~sub	O
-	O
tree	O
scts	O
can	O
be	O
very	O
useful	O
to	O
process	B
natural	O
language	O
.	O
for	O
exam-	O
yes	O
~no	O
ple	O
,	O
they	O
were	O
used	O
for	O
dialog	O
systems	O
[	O
10	O
]	O
,	O
for	O
hierarchical	O
n	O
-	O
gram	O
language	O
models	B
estimation	B
[	O
11	O
]	O
,	O
or	O
for	O
unknown	O
proper	O
names	O
tag-	O
p(previous)=0	O
.	O
18	O
p(previous)=0	O
.	O
12	O
ging	O
[	O
12	O
]	O
.	O
scts	O
are	O
based	O
on	O
the	O
use	O
of	O
regular	O
expressions	O
.	O
pairs	O
p(current)=0	O
.	O
72	O
p(current)=	O
0.30	O
composed	O
of	O
a	O
full	O
name	O
occurrence	O
and	O
its	O
lexical	O
context	O
are	O
clas-	O
p(next)=0	O
.	O
15	O
p(next)=0	O
.	O
18	O
sified	O
according	O
to	O
the	O
comparison	O
between	O
this	O
context	O
and	O
regular	O
p(other)=0.05	O
p(other)=0.50	O
expressions	O
.	O
our	O
aim	O
is	O
to	O
classify	O
these	O
pairs	O
into	O
four	O
tags	O
:	O
previ-	O
ous	O
,	O
current	O
,	O
next	O
and	O
other	O
(	O
see	O
leaves	O
in	O
figure	O
3	O
)	O
.	O
fig	O
.	O
3	O
.	O
example	O
of	O
branch	O
and	O
leaves	O
of	O
a	O
semantic	O
classification	O
sct	O
training	O
tree	O
:	O
for	O
each	O
leaf	O
,	O
a	O
probability	B
value	O
is	O
associated	O
to	O
each	O
tag	B
.	O
during	O
the	O
sct	O
building	O
process	B
,	O
each	O
node	O
is	O
associated	O
to	O
a	O
regular	O
expression	O
containing	O
words	B
and	O
special	O
characters	O
(	O
<	O
,	O
>	O
and	O
+	O
)	O
.	O
<	O
(	O
resp	O
.	O
>	O
)	O
refers	O
to	O
the	O
begin	O
(	O
resp	O
.	O
the	O
end	O
)	O
of	O
a	O
sentence	O
while	O
+	O
3.2	O
speaker	B
naming	O
refers	O
to	O
any	O
sequence	B
of	O
words	B
.	O
for	O
example	O
,	O
the	O
regular	O
expression	O
<	O
+	O
from	O
+	O
>	O
matches	O
every	O
sentence	O
containing	O
the	O
word	B
from	O
,	O
the	O
goal	O
of	O
this	O
work	O
is	O
to	O
bind	O
a	O
full	O
name	O
with	O
an	O
anonymous	O
while	O
<	O
+	O
live	O
+	O
from	O
+	O
>	O
matches	O
every	O
sentence	O
containing	O
the	O
speaker	B
label	O
when	O
it	O
is	O
possible	O
.	O
we	O
note	O
an	O
anonymous	O
speaker	B
:	O
words	B
live	O
andfrom	O
appearing	O
in	O
this	O
order	B
.	O
figure	O
3	O
shows	O
a	O
very	O
we	O
want	O
to	O
find	O
the	O
real	O
full	O
name	O
n(i	O
)	O
of	O
this	O
speaker	B
.	O
each	O
segment	B
of	O
speech	O
is	O
associated	O
to	O
its	O
speaker	B
represented	O
little	O
part	O
of	O
such	O
classification	O
tree	O
.	O
the	O
sct	O
building	O
process	B
has	O
to	O
choose	O
for	O
each	O
node	O
the	O
regu-	O
by	O
an	O
anonymous	O
speaker	B
label	O
(	O
for	O
example	O
in	O
figure	O
2	O
,	O
segment	B
1	O
lar	O
expression	O
which	O
minimizes	O
an	O
impurity	O
criterion	B
.	O
for	O
each	O
level	B
is	O
associated	O
to	O
spk	O
1	O
,	O
as	O
well	O
as	O
segments	O
9	O
and	O
11	O
;	O
segment	B
2	O
,	O
in	O
the	O
tree	O
,	O
this	O
building	O
process	B
can	O
only	O
add	O
one	O
word	B
to	O
the	O
cur-	O
4	O
,	O
8	O
,	O
10	O
are	O
associated	O
to	O
spk2	O
,	O
...	O
)	O
.	O
moreover	O
,	O
using	O
a	O
semantic	O
rent	O
regular	O
expression	O
.	O
the	O
impurity	O
criterion	B
permits	O
to	O
evaluate	O
classification	O
tree	O
on	O
full	O
names	O
detected	O
in	O
transcriptions	B
of	O
speech	O
the	O
degree	O
of	O
determinism	O
associated	O
to	O
a	O
node	O
:	O
lower	O
this	O
impurity	O
segments	O
,	O
a	O
list	O
of	O
full	O
names	O
corresponding	O
to	O
possible	O
speakers	O
for	O
criterion	B
is	O
,	O
more	O
the	O
classification	O
should	O
be	O
reliable	O
.	O
some	O
segments	O
is	O
available	O
(	O
figure	O
2	O
,	O
part	O
®	O
)	O
.	O
at	O
the	O
end	O
,	O
each	O
leaf	O
is	O
able	O
to	O
give	O
a	O
probability	B
to	O
each	O
possible	O
tag	B
(	O
here	O
:	O
previous	O
,	O
current	O
,	O
next	O
and	O
other	O
)	O
for	O
a	O
full	O
name	O
accord-	O
merging	O
sct	O
decisions	O
ing	O
to	O
the	O
lexical	O
context	O
of	O
the	O
segment	B
where	O
it	O
was	O
detected	O
.	O
let	O
be	O
k	O
the	O
set	B
of	O
all	O
the	O
full	O
names	O
of	O
the	O
client	O
speakers	O
.	O
let	O
be	O
vp	O
the	O
set	B
of	O
the	O
different	O
full	O
names	O
associated	O
by	O
local	O
local	O
decisions	O
sct	O
decisions	O
to	O
at	O
least	O
one	O
segment	B
pronounced	O
by	O
i	O
:	O
vp	O
is	O
the	O
list	O
of	O
full	O
name	O
candidates	O
for	O
x	O
and	O
vp	O
c	O
k.	O
for	O
a	O
given	O
full	O
name	O
occurrence	O
o	O
detected	O
into	O
a	O
lexical	O
context	O
let	O
us	O
define	O
the	O
function	O
v(o	O
)	O
which	O
associates	O
an	O
occurrence	O
w	O
,	O
(	O
o	O
)	O
associated	O
to	O
the	O
speech	B
segment	I
s	O
,	O
sct	O
is	O
able	O
to	O
give	O
the	O
o	O
of	O
the	O
full	O
name	O
n	O
to	O
this	O
full	O
name	O
n.	O
in	O
this	O
case	O
,	O
we	O
have	O
:	O
probability	B
p(tlw	O
(	O
o	O
)	O
)	O
for	O
each	O
possible	O
tag	B
t	O
from	O
tag	B
set	B
t	O
v(o	O
)	O
=	O
n.	O
{	O
previous	O
,	O
current	O
,	O
next	O
,	O
other	O
}	O
.	O
at	O
last	O
,	O
let	O
us	O
define	O
the	O
set	B
qp	O
of	O
occurrences	O
o	O
which	O
refer	O
by	O
let	O
us	O
define	O
the	O
tag	B
d(o	O
)	O
e	O
t	O
associated	O
to	O
the	O
full	O
name	O
occur-	O
local	O
sct	O
decisions	O
to	O
segments	O
pronounced	O
by	O
rence	O
o	O
in	O
the	O
speech	B
segment	I
s.	O
this	O
tag	B
is	O
given	O
by	O
the	O
formula	O
:	O
we	O
propose	O
to	O
find	O
the	O
full	O
name	O
n(o	O
)	O
of	O
the	O
speaker	B
x	O
using	O
the	O
following	O
formula	O
:	O
d(o	O
)	O
=	O
argmax	O
p(ti	O
w	O
,	O
(	O
o	O
)	O
)	O
(	O
1	O
)	O
s	O
r(o	O
)	O
t	O
in	O
our	O
actual	O
approach	O
,	O
beyond	O
the	O
four	O
possible	O
tags	O
for	O
w	O
,	O
(	O
o	O
)	O
,	O
n(0	O
)	O
=	O
argmax	O
5o	O
=	O
n	O
(	O
o	O
)	O
(	O
3	O
)	O
nek	O
e	O
r(o	O
)	O
only	O
tag	B
d(o	O
)	O
is	O
taken	O
into	O
account	O
for	O
the	O
process	B
continuation	O
.	O
fur-	O
thermore	O
,	O
if	O
more	O
than	O
one	O
tag	B
have	O
a	O
probability	B
value	O
equals	O
to	O
max	O
p(ti	O
w	O
,	O
(	O
o	O
)	O
)	O
,	O
no	O
local	O
decision	O
is	O
retained	O
.	O
=	O
argmax	O
5	O
i1(o	O
)	O
(	O
4	O
)	O
nek	O
(	O
v(o)=n)a(oeqp	O
)	O
let	O
us	O
define	O
the	O
value	O
f	O
(	O
o	O
)	O
as	O
:	O
so	O
,	O
the	O
full	O
name	O
associated	O
to	O
a	O
speaker	B
label	O
is	O
the	O
full	O
name	O
f(o	O
)	O
=	O
p(6(o	O
)	O
iw	O
,	O
(	O
o	O
)	O
)	O
(	O
2	O
)	O
whose	O
occurrences	O
maximize	O
the	O
sum	O
of	O
values	B
given	O
by	O
the	O
sct	O
about	O
these	O
occurrences	O
referring	O
to	O
segments	O
associated	O
to	O
this	O
2006	O
ieee	O
odyssey	O
-	O
the	O
speaker	B
and	O
language	O
recognition	O
workshop	O
3train	O
dev	O
eva	O
train	O
dev	O
eva	O
#	O
shows	O
150	O
26	O
18	O
#	O
detected	O
full	O
name	O
(	O
*	O
)	O
3297	O
920	O
507	O
#	O
channels	B
5	O
5	O
6	O
previous	O
14.3	O
%	O
12.6	O
%	O
18.6	O
%	O
duration	O
(	O
h	O
)	O
86	O
12.5	O
10	O
current	O
7.2	O
%	O
7.1	O
%	O
5.3	O
%	O
#	O
segments	O
8547	O
2294	O
1417	O
next	O
46.0	O
%	O
45.3	O
%	O
49.3	O
%	O
other	O
32.5	O
%	O
35.0	O
%	O
26.8	O
%	O
table	O
1	O
.	O
corpus	B
information	B
:	O
train	O
,	O
development	O
&	O
evaluation	B
from	O
french	O
broadcast	O
news	O
ester	O
evaluation	B
campaign	O
.	O
table	O
2	O
.	O
statistics	B
of	O
full	O
name	O
tags	O
on	O
training	O
,	O
development	O
&	O
evaluation	B
corpora	B
computed	O
over	O
the	O
manual	O
reference	B
.	O
-	O
(	O
*	O
)	O
:	O
the	O
number	O
of	O
speaker	B
full	O
name	O
detected	O
in	O
the	O
corpus	B
.	O
speaker	B
label	O
.	O
notice	O
that	O
as	O
explained	O
in	O
section	O
3.1	O
,	O
only	O
values	B
associated	O
to	O
valid	O
local	O
decisions	O
are	O
kept	O
.	O
this	O
simple	O
formula	O
permits	O
to	O
take	O
into	O
account	O
the	O
number	O
of	O
occurrences	O
observed	O
for	O
preparing	O
the	O
corpora	B
a	O
full	O
name	O
candidate	O
,	O
weighted	O
by	O
the	O
sct	O
scores	O
.	O
transcriptions	B
provided	O
by	O
the	O
corpora	B
are	O
designed	O
for	O
diarization	B
or	O
transcription	B
tasks	O
.	O
references	B
(	O
rich	O
transcriptions	B
)	O
have	O
to	O
be	O
transformed	O
and	O
adapted	O
to	O
be	O
used	O
with	O
a	O
semantic	O
classification	O
4	O
experiments	O
and	O
results	B
tree	O
and	O
to	O
evaluate	O
experiment	O
results	B
.	O
these	O
adaptations	O
are	O
:	O
*	O
the	O
definition	O
of	O
the	O
four	O
full	O
name	O
tags	O
supposes	O
that	O
the	O
4.1	O
data	B
previous	O
and	O
the	O
next	O
speakers	O
are	O
different	O
from	O
the	O
current	O
corpora	B
one	O
.	O
the	O
segmentation	B
must	O
rely	O
on	O
speaker	B
turns	O
and	O
does	O
not	O
rely	O
on	O
sentences	O
(	O
mostly	O
separated	O
by	O
breath	O
and	O
silence	B
)	O
the	O
methods	O
are	O
trained	O
and	O
evaluated	O
with	O
data	B
from	O
the	O
ester	O
as	O
it	O
was	O
done	O
in	O
the	O
manual	O
transcription	B
.	O
so	O
,	O
the	O
contigu-	O
evaluation	B
campaign	O
.	O
ester	O
is	O
an	O
evaluation	B
campaign	O
of	O
french	O
ous	O
segments	O
from	O
the	O
same	B
speaker	I
are	O
merged	O
to	O
obtain	O
a	O
broadcast	O
news	O
transcription	B
systems	O
which	O
started	O
in	O
2003	O
and	O
com-	O
segmentation	B
based	O
on	O
speaker	B
turns	O
.	O
pleted	O
in	O
january	O
2005	O
[	O
8	O
,	O
9	O
]	O
.	O
this	O
evaluation	B
campaign	O
was	O
or-	O
*	O
the	O
information	B
about	O
the	O
four	O
tags	O
are	O
needed	O
during	O
train-	O
ganized	O
within	O
the	O
framework	O
of	O
the	O
technolangue	O
project	O
ing	O
and	O
scoring	O
phases	O
.	O
we	O
tagged	O
the	O
reference	B
corpus	B
au-	O
funded	O
by	O
the	O
french	O
government	O
under	O
the	O
scientific	O
supervision	O
of	O
tomatically	O
by	O
extracting	O
speaker	B
full	O
names	O
in	O
the	O
speech	O
.	O
the	O
afcp	O
'	O
with	O
the	O
dga2	O
and	O
elda	O
.	O
each	O
full	O
name	O
is	O
compared	O
to	O
the	O
speaker	B
full	O
names	O
attached	O
the	O
data	B
were	O
recorded	O
from	O
six	O
radios	O
:	O
france	O
inter	O
,	O
france	O
to	O
the	O
segment	B
and	O
its	O
contiguous	O
neighbors	O
.	O
thus	O
,	O
this	O
au-	O
info	O
,	O
rfi	O
,	O
rtm	O
,	O
france	O
culture	O
and	O
radio	O
classique	O
.	O
the	O
data	B
are	O
tomatic	O
task	O
is	O
not	O
checked	O
manually	O
and	O
we	O
suppose	O
that	O
all	O
divided	O
into	O
three	O
sets	O
;	O
only	O
the	O
two	O
first	O
ones	O
are	O
annotated3	O
.	O
shows	O
speaker	B
identifications	O
are	O
correct	O
.	O
(	O
10	O
minutes	O
up	O
to	O
60	O
minutes	O
)	O
from	O
those	O
two	O
first	O
sets	O
contain	O
few	O
silence	B
,	O
music	O
and	O
advertisements	O
comparing	O
to	O
the	O
ldc	O
english	O
*	O
in	O
the	O
reference	B
transcription	B
,	O
sentences	O
contain	O
more	O
infor-	O
broadcast	O
news	O
corpus	B
[	O
13	O
]	O
.	O
the	O
majority	O
of	O
the	O
shows	O
contains	O
mation	O
than	O
those	O
produced	O
by	O
an	O
automatic	O
system	O
.	O
tran-	O
prepared	O
speech	O
like	O
news	O
and	O
few	O
conversational	O
speech	O
like	O
inter-	O
scriptions	O
are	O
then	O
normalized	O
to	O
be	O
as	O
close	O
as	O
possible	O
to	O
views	O
.	O
only	O
15	O
%	O
of	O
the	O
corpus	B
is	O
narrow	O
band	O
speech	O
.	O
those	O
data	B
the	O
ones	O
made	O
by	O
an	O
automatic	O
transcription	B
system	O
.	O
for	O
ex-	O
are	O
split	O
in	O
three	O
corpora	B
(	O
described	O
on	O
table	O
1	O
)	O
:	O
ample	O
,	O
all	O
the	O
punctuations	O
are	O
removed	O
,	O
the	O
upper	O
case	O
are	O
removed	O
,	O
and	O
so	O
on	O
.	O
*	O
the	O
training	O
corpus	B
called	O
train	O
corresponds	O
to	O
81h	O
(	O
150	O
shows	O
)	O
composed	O
of	O
8547	O
segments	O
in	O
which	O
3297	O
full	O
names	O
*	O
in	O
the	O
same	O
manner	O
,	O
the	O
definite	O
articles	O
(	O
le	O
,	O
la	O
,	O
les	O
)	O
and	O
the	O
are	O
detected	O
.	O
indefinite	O
articles	O
(	O
un	O
,	O
une	O
,	O
des	O
)	O
are	O
removed	O
from	O
the	O
sen-	O
tences	O
.	O
we	O
believe	O
that	O
they	O
are	O
not	O
informative	O
.	O
*	O
a	O
development	O
corpus4	O
,	O
denoted	O
dev	O
,	O
corresponds	O
to	O
12.5h	O
(	O
26	O
shows	O
)	O
split	O
into	O
2294	O
segments	O
containing	O
920	O
full	O
*	O
to	O
generalize	O
the	O
training	O
examples	O
during	O
the	O
building	O
ofthe	O
names	O
.	O
tree	O
,	O
each	O
speaker	B
full	O
name	O
is	O
replaced	O
by	O
a	O
generic	O
label	O
.	O
*	O
an	O
evaluation	B
corpus	B
,	O
denoted	O
eva	O
,	O
contains	O
1	O
oh	O
(	O
18	O
shows	O
)	O
*	O
the	O
semantic	O
classification	O
tree	O
learns	O
the	O
regular	O
expressions	O
split	O
into	O
1417	O
segments	O
in	O
which	O
507	O
full	O
names	O
are	O
de-	O
according	O
to	O
the	O
words	B
in	O
the	O
left	O
and	O
right	O
contexts	O
of	O
a	O
tected	O
.	O
eva	O
corresponds	O
to	O
the	O
official	O
ester	O
evaluation	B
cor-	O
speaker	B
full	O
name	O
occurrence	O
.	O
no	O
more	O
than	O
only	O
40	O
words	B
pus	O
.	O
this	O
corpus	B
contains	O
two	O
radios	O
which	O
are	O
not	O
present	O
in	O
around	O
the	O
speaker	B
full	O
name	O
are	O
kept	O
:	O
at	O
most	O
20	O
words	B
on	O
the	O
training	O
corpus	B
.	O
it	O
was	O
also	O
recorded	O
15	O
months	O
after	O
the	O
the	O
left	O
and	O
at	O
most	O
20	O
words	B
on	O
the	O
right	O
.	O
the	O
number	O
of	O
previous	O
data	B
.	O
words	B
on	O
the	O
left	O
and	O
on	O
the	O
right	O
was	O
fixed	O
over	O
the	O
dev	O
cor-	O
pus	O
in	O
order	B
to	O
maximize	O
the	O
number	O
of	O
true	O
local	O
detection	B
table	O
2	O
shows	O
the	O
a	O
priori	O
probabilities	O
of	O
the	O
four	O
full	O
names	O
of	O
the	O
four	O
tags	O
.	O
tags	O
computed	O
on	O
the	O
reference	B
manual	O
transcriptions	B
.	O
in	O
both	O
cases	O
,	O
the	O
next	O
tag	B
is	O
the	O
most	O
frequent	O
one	O
(	O
between	O
45	O
%	O
and	O
49	O
%	O
)	O
and	O
the	O
current	O
tag	B
is	O
the	O
least	O
frequent	O
one	O
(	O
between	O
5	O
%	O
and	O
7	O
%	O
)	O
.	O
sct	O
training	O
parameters	O
the	O
semantic	O
classification	O
tree	O
is	O
tuned	O
on	O
the	O
development	O
corpus	B
.	O
1afcp	O
:	O
association	O
francophone	O
de	O
la	O
communication	B
parlee	O
2dga	O
:	O
delegation	O
generale	O
de	O
l'armement	O
the	O
main	O
parameters	O
for	O
the	O
training	O
are	O
the	O
gini	O
criterion	B
[	O
14	O
]	O
as	O
3they	O
are	O
officially	O
denoted	O
phase	O
i	O
and	O
phase	O
ii	O
the	O
impurity	O
criterion	B
and	O
the	O
size	B
of	O
the	O
leaves	O
.	O
the	O
expansion	O
of	O
4it	O
is	O
the	O
official	O
ester	O
phase	O
i	O
development	O
corpus	B
merged	O
with	O
the	O
the	O
branches	O
stops	O
when	O
the	O
gini	O
criterion	B
is	O
not	O
reduced	O
or	O
when	O
official	O
ester	O
phase	O
ii	O
development	O
corpus	B
the	O
current	O
node	O
is	O
associated	O
to	O
less	O
than	O
five	O
sequences	O
of	O
words	B
.	O
4	O
2006	O
ieee	O
odyssey	O
-	O
the	O
speaker	B
and	O
language	O
recognition	O
workshop4.2	O
segment	B
speaker	B
tagging	O
speakers	O
naming	O
t	O
train	O
dev	O
eva	O
client	O
correct	O
63.68	O
%	O
64.82	O
%	O
66.35	O
%	O
client	O
wrong	O
3.19	O
%	O
5.48	O
%	O
14.36	O
%	O
train	O
dev	O
eva	O
client	O
unnamed	O
15.68	O
%	O
18.19	O
%	O
11.91	O
%	O
#	O
detected	O
full	O
name	O
3297	O
920	O
507	O
not	O
client	O
correct	O
(	O
unnamed	O
)	O
15.50	O
%	O
7.54	O
%	O
3.59	O
%	O
tagged	O
94.51	O
%	O
94.78	O
%	O
97.23	O
%	O
not	O
client	O
wrong	O
1.95	O
%	O
3.98	O
%	O
3.79	O
%	O
correctly	O
tagged	O
88.25	O
%	O
76.49	O
%	O
68.76	O
%	O
total	O
t	O
100%%	O
100	O
%	O
100	O
%	O
previous	O
88.98	O
%	O
71.67	O
%	O
82.98	O
%	O
current	O
94.76	O
%	O
90.14	O
%	O
85.71	O
%	O
next	O
89.32	O
%	O
80.67	O
%	O
75.29	O
%	O
table	O
4	O
.	O
speaker	B
naming	O
:	O
detailed	O
results	B
on	O
training	O
,	O
development	O
other	O
84.87	O
%	O
68.94	O
%	O
50.32	O
%	O
&	O
evaluation	B
corpora	B
(	O
all	O
the	O
rates	B
are	O
computed	O
in	O
terms	B
of	O
dura-	O
tion	O
)	O
.	O
-	O
speakers	O
:	O
this	O
defines	O
the	O
two	O
categories	O
ofspeakers	O
in	O
the	O
reference	B
,	O
those	O
table	O
3	O
.	O
scores	O
of	O
local	O
decisions	O
using	O
the	O
semantic	O
classification	O
which	O
are	O
the	O
clients	O
of	O
the	O
application	B
(	O
public	O
speakers	O
with	O
a	O
full	O
name	O
)	O
and	O
tree	O
on	O
training	O
,	O
development	O
&	O
evaluation	B
corpora	B
.	O
the	O
others	O
.	O
-	O
tagged	O
:	O
rate	O
of	O
detected	O
full	O
names	O
for	O
which	O
a	O
full	O
name	O
tag	B
is	O
proposed	O
c-	O
ansaemwihnegr	O
:	O
e	O
cthoerrpersopcoensdssistonottheabcloerrteocptroapnodsewraofnugllnnaammien.g	O
.	O
unnamed	O
is	O
the	O
using	O
the	O
local	O
decision	O
rule	O
.	O
-	O
correctly	O
tagged	O
:	O
rate	O
of	O
detected	O
full	O
names	O
that	O
are	O
correctly	O
tagged	O
.	O
-	O
previous	O
(	O
resp	O
.	O
for	O
the	O
other	O
tags	O
)	O
:	O
rate	O
of	O
detected	O
full	O
names	O
that	O
are	O
correctly	O
tagged	O
by	O
previous	O
tag	B
.	O
speech	O
/	O
non	O
speech	O
and	O
transcriptions	B
errors	B
can	O
not	O
exist	O
.	O
the	O
refer-	O
ence	O
and	O
hypotheses	B
segment	B
boundaries	B
are	O
equal	O
,	O
only	O
the	O
speaker	B
the	O
semantic	O
classification	O
tree	O
which	O
provides	O
the	O
results	B
on	O
names	O
differ	O
.	O
table	O
3	O
was	O
built	O
with	O
the	O
training	O
corpus	B
.	O
the	O
table	O
shows	O
the	O
results	B
in	O
the	O
framework	O
of	O
speaker	B
identification	O
,	O
the	O
errors	B
consist	O
of	O
the	O
local	O
decisions	O
taken	O
over	O
each	O
segment	B
containing	O
a	O
detected	O
in	O
identifying	O
the	O
speaker	B
with	O
a	O
wrong	O
identity	O
chosen	O
in	O
a	O
set	B
full	O
name	O
on	O
the	O
train	O
,	O
dev	O
and	O
eva	O
corpora	B
.	O
the	O
first	O
column	O
shows	O
of	O
known	O
speaker	B
identities	O
.	O
in	O
the	O
presented	O
task	O
,	O
only	O
the	O
pub-	O
the	O
scores	O
ofthe	O
train	O
data	B
used	O
as	O
a	O
test	B
corpus	B
.	O
the	O
second	O
and	O
third	O
lic	O
speaker	B
names	O
,	O
those	O
with	O
a	O
full	O
name	O
in	O
the	O
reference	B
,	O
are	O
the	O
column	O
report	O
the	O
results	B
on	O
dev	O
and	O
eva	O
.	O
clients	O
.	O
the	O
identities	O
of	O
the	O
others	O
can	O
not	O
be	O
found	O
.	O
94	O
%	O
detected	O
full	O
names	O
on	O
dev	O
and	O
97	O
%	O
on	O
eva	O
are	O
tagged	O
by	O
there	O
are	O
errors	B
when	O
the	O
process	B
gives	O
a	O
non	O
-	O
client	O
speaker	B
a	O
one	O
of	O
the	O
four	O
full	O
name	O
tags	O
.	O
the	O
correct	O
tagging	O
rate	O
is	O
above	O
full	O
name	O
and	O
when	O
the	O
process	B
does	O
not	O
give	O
a	O
client	O
speaker	B
(	O
a	O
76.4	O
%	O
on	O
dev	O
and	O
only	O
68.7	O
%	O
on	O
eva	O
:	O
these	O
values	B
can	O
be	O
consid-	O
public	O
speaker	B
)	O
a	O
full	O
name	O
(	O
table	O
4	O
lines	O
2	O
&	O
5	O
)	O
.	O
ered	O
as	O
the	O
precision	O
of	O
the	O
local	O
decision	O
method	B
on	O
each	O
corpus	B
.	O
moreover	O
,	O
the	O
process	B
can	O
not	O
propose	O
a	O
name	O
to	O
a	O
client	O
speaker	B
the	O
lowest	O
result	O
for	O
eva	O
(	O
808	O
%	O
less	O
)	O
can	O
be	O
explained	O
by	O
the	O
in	O
some	O
circumstances	O
:	O
presence	B
of	O
two	O
new	O
stations	O
and	O
which	O
are	O
not	O
present	O
in	O
the	O
train-	O
ing	O
and	O
development	O
corpora	B
.	O
the	O
eva	O
data	B
were	O
also	O
recorded	O
15	O
*	O
no	O
local	O
decision	O
affects	O
a	O
segment	B
of	O
this	O
client	O
speaker	B
.	O
ei-	O
months	O
later	O
.	O
about	O
6	O
%	O
detected	O
speaker	B
full	O
names	O
are	O
untagged	O
as	O
ther	O
no	O
local	O
decision	O
is	O
taken	O
for	O
the	O
detected	O
occurrences	O
of	O
well	O
as	O
in	O
the	O
training	O
corpus	B
.	O
the	O
full	O
name	O
of	O
this	O
client	O
speaker	B
,	O
or	O
all	O
the	O
existing	O
local	O
the	O
results	B
for	O
the	O
other	O
tag	B
are	O
the	O
weakest	O
.	O
this	O
tags	O
seems	O
decisions	O
are	O
wrong	O
;	O
to	O
be	O
associated	O
to	O
more	O
various	O
lexical	O
contexts	O
than	O
the	O
others	O
.	O
in	O
*	O
the	O
full	O
name	O
of	O
this	O
speaker	B
is	O
not	O
detected	O
in	O
the	O
transcrip-	O
this	O
case	O
,	O
the	O
names	O
can	O
be	O
associated	O
to	O
distant	O
(	O
not	O
contiguous	O
)	O
tions	O
.	O
segments	O
or	O
even	O
to	O
people	O
not	O
intervening	O
in	O
the	O
show	O
.	O
neverthe-	O
less	O
,	O
the	O
impact	O
of	O
this	O
results	B
is	O
low	O
as	O
this	O
tag	B
is	O
not	O
taken	O
directly	O
for	O
client	O
speakers	O
,	O
when	O
the	O
hypothesis	B
full	O
name	O
and	O
the	O
ref-	O
into	O
account	O
in	O
the	O
naming	O
process	B
.	O
erence	O
full	O
name	O
are	O
the	O
same	O
,	O
this	O
is	O
considered	O
as	O
a	O
correct	O
naming	O
by	O
always	O
simply	O
choosing	O
the	O
tag	B
having	O
the	O
strongest	O
prior	O
(	O
table	O
4	O
line	O
1	O
)	O
.	O
for	O
non	O
-	O
client	O
speakers	O
,	O
it	O
seems	O
reasonable	O
to	O
con-	O
probability	B
(	O
see	O
table	O
2	O
)	O
,	O
we	O
will	O
only	O
reach	O
a	O
score	B
of	O
-45.3	O
%	O
on	O
sider	O
correct	O
not	O
to	O
assign	O
a	O
full	O
name	O
of	O
a	O
client	O
speaker	B
to	O
speech	O
dev	O
corpus	B
(	O
respectively	O
-49.3	O
%	O
for	O
eva	O
)	O
.	O
with	O
the	O
method	B
pro-	O
pronounced	O
by	O
a	O
non	O
-	O
public	O
person.(table	O
4	O
line	O
4	O
)	O
.	O
posed	O
above	O
,	O
-76	O
%	O
correct	O
tagging	O
rate	O
for	O
dev	O
is	O
observed	O
(	O
-68	O
%	O
all	O
the	O
proposed	O
results	B
are	O
computed	O
in	O
terms	B
of	O
segment	B
du-	O
for	O
eva	O
)	O
.	O
these	O
results	B
show	O
that	O
the	O
semantic	O
classification	O
tree	O
is	O
ration	O
as	O
it	O
is	O
done	O
in	O
the	O
nist	O
evaluations	O
of	O
the	O
speaker	B
diariza-	O
well	O
adapted	O
to	O
this	O
task	O
,	O
permitting	O
to	O
exploit	O
them	O
in	O
the	O
speaker	B
tion	O
[	O
15	O
]	O
.	O
naming	O
process	B
,	O
as	O
shown	O
below	O
.	O
comments	O
4.3	O
speaker	B
naming	O
the	O
speaker	B
naming	O
process	B
gives	O
a	O
correct	O
decision	O
up	O
to	O
72	O
%	O
local	O
decisions	O
on	O
the	O
segments	O
are	O
merged	O
to	O
associate	O
one	O
full	O
speech	O
duration	O
(	O
64.82	O
%	O
+	O
7.54	O
%	O
)	O
over	O
dev	O
corpus	B
and	O
about	O
70	O
%	O
name	O
to	O
all	O
the	O
segments	O
pronounced	O
by	O
the	O
same	B
speaker	I
(	O
see	O
sec-	O
(	O
66.35	O
%	O
+	O
3.59	O
%	O
)	O
over	O
the	O
eva	O
corpus	B
as	O
shown	O
in	O
table	O
4	O
.	O
tion	O
3.2	O
)	O
.	O
the	O
detailed	O
results	B
of	O
this	O
second	O
step	O
are	O
reported	O
in	O
the	O
difference	O
on	O
correct	O
naming	O
rate	O
between	O
the	O
dev	O
corpus	B
table	O
4	O
.	O
and	O
the	O
eva	O
corpus	B
is	O
about	O
2	O
%	O
,	O
less	O
than	O
the	O
8	O
%	O
observed	O
for	O
the	O
local	O
decisions	O
in	O
table	O
3	O
.	O
even	O
if	O
there	O
are	O
less	O
local	O
decisions	O
in	O
evaluation	B
method	B
the	O
eva	O
corpus	B
,	O
those	O
decisions	O
are	O
relevant	O
for	O
finding	O
the	O
true	O
full	O
name	O
of	O
a	O
client	O
speaker	B
.	O
the	O
input	B
ofthe	O
system	O
is	O
based	O
upon	O
the	O
manual	O
transcription	B
refer-	O
ences	O
:	O
the	O
diarization	B
(	O
anonymous	O
speaker	B
labels	I
)	O
,	O
segmentation	B
in	O
2006	O
ieee	O
odyssey	O
-	O
the	O
speaker	B
and	O
language	O
recognition	O
workshop	O
55	O
conclusion	O
[	O
8	O
]	O
g.	O
gravier	O
,	O
j.-f	O
.	O
bonastre	O
,	O
s.	O
galliano	O
,	O
e.	O
geoffrois	O
,	O
k.	O
mc	O
tait	O
,	O
and	O
k.	O
choukri	O
,	O
"	O
the	O
ester	O
evaluation	B
campaign	O
in	O
the	O
framework	O
of	O
rich	B
transcription	I
,	O
we	O
propose	O
a	O
full	O
automatic	O
of	O
rich	B
transcription	I
of	O
french	O
broadcast	O
news	O
,	O
"	O
in	O
language	O
method	B
to	O
identify	O
the	O
speakers	O
by	O
their	O
full	O
names	O
extracted	O
from	O
evaluation	B
and	O
resources	O
conference	O
(	O
lrec	O
2004	O
)	O
,	O
lisbon	O
,	O
the	O
transcription	B
.	O
portugal	O
,	O
may	O
2004	O
.	O
the	O
process	B
is	O
firstly	O
based	O
upon	O
the	O
use	O
of	O
a	O
semantic	O
classifi-	O
[	O
9	O
]	O
s.	O
galliano	O
,	O
e.	O
geoffrois	O
,	O
d.	O
mostefa	O
,	O
k.	O
choukri	O
,	O
j.-f	O
.	O
bonas-	O
cation	O
tree	O
which	O
permits	O
to	O
qualify	O
the	O
detected	O
occurrences	O
of	O
full	O
tre	O
,	O
and	O
g.	O
gravier	O
,	O
"	O
the	O
ester	O
phase	O
ii	O
evaluation	B
campaign	O
names	O
:	O
this	O
first	O
step	O
consists	O
in	O
local	O
decisions	O
binding	O
each	O
ofthese	O
for	O
the	O
rich	B
transcription	I
of	O
french	O
broadcast	O
news	O
,	O
"	O
lisboa	O
,	O
occurrences	O
to	O
a	O
speech	B
segment	I
.	O
then	O
,	O
the	O
local	O
results	B
are	O
merged	O
sep	O
2005	O
,	O
pp	O
.	O
1149	O
-	O
1152	O
.	O
to	O
associate	O
a	O
full	O
name	O
to	O
all	O
the	O
segments	O
of	O
a	O
given	O
speaker	B
.	O
the	O
experiments	O
are	O
carried	O
out	O
over	O
french	O
broadcast	O
news	O
[	O
10	O
]	O
r.	O
kuhn	O
and	O
r.	O
de	O
mori	O
,	O
"	O
the	O
application	B
of	O
semantic	O
classif-	O
records	O
from	O
the	O
ester	O
2005	O
evaluation	B
campaign	O
.	O
about	O
70	O
%	O
ciation	O
trees	O
to	O
natural	O
language	O
understanding	O
,	O
"	O
ieee	O
trans-	O
show	O
duration	O
is	O
correctly	O
processed	O
for	O
both	O
development	O
and	O
eval-	O
actions	O
on	O
pattern	O
analysis	B
and	O
machine	O
intelligence	O
,	O
vol	O
.	O
17	O
,	O
uation	O
corpora	B
.	O
on	O
the	O
evaluation	B
corpus	B
,	O
18.2	O
%	O
show	O
is	O
wrongly	O
no	O
.	O
5	O
,	O
pp	O
.	O
449	O
-	O
460	O
,	O
1995	O
.	O
named	O
and	O
no	O
decision	O
is	O
taken	O
for	O
1h.9	O
%	O
show	O
.	O
[	O
11	O
]	O
y.	O
esteve	O
,	O
f.	O
bechet	O
,	O
a.	O
nasr	O
,	O
and	O
r.	O
de	O
mori	O
,	O
"	O
stochas-	O
the	O
main	O
goal	O
is	O
reached	O
:	O
the	O
results	B
validate	O
the	O
proposed	O
tic	O
finite	O
state	O
automata	O
language	O
model	B
triggered	O
by	O
dialogue	O
method	B
of	O
speaker	B
naming	O
processed	O
on	O
manual	O
diarization	B
and	O
states	O
,	O
"	O
in	O
proceedings	O
of	O
european	O
conference	O
on	O
speech	O
manual	O
transcription	B
.	O
further	O
work	O
will	O
focus	O
on	O
the	O
use	O
of	O
auto-	O
communication	B
and	O
technology	O
(	O
isca	O
,	O
eurospeech	O
2001	O
)	O
,	O
matic	O
diarization	B
and	O
transcription	B
in	O
which	O
errors	B
are	O
present	O
.	O
aalborg	O
,	O
denmark	O
,	O
2001	O
,	O
vol	O
.	O
1	O
,	O
pp	O
.	O
725	O
-	O
728	O
.	O
[	O
12	O
]	O
f.	O
bechet	O
,	O
a.	O
nasr	O
,	O
and	O
f.	O
genet	O
,	O
"	O
tagging	O
unknown	O
proper	O
names	O
using	O
decision	O
trees	O
,	O
"	O
in	O
38th	O
annual	O
meeting	O
ofthe	O
as-	O
6	O
acknowledgements	O
sociation	O
for	O
computational	O
linguistics	O
,	O
hong	O
kong	O
,	O
china	O
,	O
october	O
2000	O
,	O
pp	O
.	O
77	O
-	O
84	O
.	O
the	O
authors	O
would	O
like	O
to	O
thank	O
frederic	O
bechet	O
from	O
lia	O
(	O
com-	O
[	O
13	O
]	O
s.	O
e.	O
tranter	O
and	O
d.	O
a.	O
reynolds	O
,	O
"	O
speaker	B
diarisation	O
for	O
puter	O
science	O
lab	O
of	O
the	O
university	O
of	O
avignon	O
,	O
france	O
)	O
for	O
making	O
broadcast	O
news	O
,	O
"	O
in	O
2004	O
:	O
a	O
speaker	B
odyssey	O
.	O
the	O
speaker	B
lia_sct	O
tool	O
available	O
as	O
an	O
open	O
source	B
project	O
.	O
recognition	O
workshop	O
(	O
isca	O
,	O
odyssey	O
2004	O
)	O
,	O
toledo	O
,	O
spain	O
,	O
may	O
2004	O
.	O
7	O
references	B
[	O
14	O
]	O
l.	O
breiman	O
,	O
j.	O
friedman	O
,	O
r.	O
olshen	O
,	O
and	O
c.	O
stone	O
,	O
classifica-	O
tion	O
and	O
regression	B
trees	O
,	O
wadsworth	O
,	O
1984	O
.	O
[	O
1	O
]	O
j.	O
ajmera	O
and	O
c.	O
wooters	O
,	O
"	O
a	O
robust	B
speaker	I
clustering	B
algo-	O
[	O
15	O
]	O
nist	O
,	O
"	O
fall	O
2004	O
rich	B
transcription	I
(	O
rt-04f	O
)	O
evaluation	B
rithm	O
,	O
"	O
in	O
automatic	O
speech	B
recognition	I
and	O
understanding	O
plan	O
,	O
"	O
http://www.nist.gov/speech/tests/rt/	O
(	O
ieee	O
,	O
asru2003	O
)	O
,	O
st	O
.	O
thomas	O
,	O
u.s	O
.	O
virgin	O
islands	O
,	O
novem-	O
rt2oo4	O
/	O
fall	O
/	O
docs	O
/	O
rto4f	O
-	O
eval	O
-	O
plan	O
-	O
v%14	O
.	O
ber	O
2003	O
,	O
pp	O
.	O
411	O
-	O
416	O
.	O
pdf	O
,	O
august	O
2004	O
.	O
[	O
2	O
]	O
m.	O
ben	O
,	O
m.	O
betser	O
,	O
f.	O
bimbot	O
,	O
and	O
g.	O
gravier	O
,	O
"	O
speaker	B
diarization	I
using	O
bottom	O
-	O
up	O
clustering	B
based	O
on	O
a	O
parameter-	O
derived	O
distance	B
between	O
gmms	O
,	O
"	O
in	O
proceedings	O
of	O
inter-	O
national	O
conference	O
on	O
spoken	B
language	I
processing	B
(	O
isca	O
,	O
icslp	O
2004	O
)	O
,	O
jeju	O
,	O
korea	O
,	O
october	O
2004	O
.	O
[	O
3	O
]	O
c.	O
barras	O
,	O
x.	O
zhu	O
,	O
s.	O
meignier	O
,	O
and	O
j.-l	O
.	O
gauvain	O
,	O
"	O
improv-	O
ing	O
speaker	B
diarization	I
,	O
"	O
in	O
darpa	O
rt04	O
fall	O
,	O
palisades	O
,	O
ny	O
,	O
usa	O
,	O
2004	O
.	O
[	O
4	O
]	O
s.	O
meignier	O
,	O
d.	O
moraru	O
,	O
c.	O
fredouille	O
,	O
j.-f	O
.	O
bonastre	O
,	O
and	O
l.	O
besacier	O
,	O
"	O
step	O
-	O
by	O
-	O
step	O
and	O
integrated	O
approaches	O
in	O
broad-	O
cast	O
news	O
speaker	B
diarization	I
,	O
"	O
computer	B
speech	O
and	O
lan-	O
guage	O
,	O
2005	O
.	O
[	O
5	O
]	O
f.	O
bimbot	O
,	O
j.-f	O
.	O
bonastre	O
,	O
c.	O
fredouille	O
,	O
g.	O
gravier	O
,	O
i.	O
magrin-	O
chagnolleau	O
,	O
s.	O
meignier	O
,	O
t.	O
merlin	O
,	O
j.	O
ortega	O
-	O
garcia	O
,	O
d.	O
petrovska	O
,	O
and	O
d.	O
a.	O
reynolds	O
,	O
"	O
a	O
tutorial	O
on	O
text-	O
independent	O
speaker	B
verification	O
,	O
"	O
eurasip	O
journal	O
on	O
ap-	O
plied	O
signal	B
processing	I
,	O
special	O
issue	O
on	O
biometric	O
signalpro-	O
cessing	O
,	O
vol	O
.	O
4	O
,	O
pp	O
.	O
430	O
-	O
451	O
,	O
2004	O
.	O
[	O
6	O
]	O
l.	O
canseco	O
-	O
rodriguez	O
,	O
l.	O
lamel	O
,	O
and	O
j.-l	O
.	O
gauvain	O
,	O
"	O
speaker	B
diarization	I
from	O
speech	O
transcripts	B
,	O
"	O
in	O
proceedings	O
ofinter-	O
national	O
conference	O
on	O
spoken	B
language	I
processing	B
(	O
isca	O
,	O
icslp	O
2004	O
)	O
,	O
jeju	O
,	O
oct	O
2004	O
.	O
[	O
7	O
]	O
l.	O
canseco	O
-	O
rodriguez	O
,	O
l.	O
lamel	O
,	O
and	O
j.-l	O
.	O
gauvain	O
,	O
"	O
a	O
com-	O
parative	O
study	O
using	O
manual	O
and	O
automatic	O
transcriptions	B
for	O
diarization	B
,	O
"	O
jeju	O
,	O
oct	O
2005	O
.	O
6	O
2006	O
ieee	O
odyssey	O
-	O
the	O
speaker	B
and	O
language	O

msc	O
in	O
nlp	O
supervised	O
project	O
université	O
de	O
lorraine	O
idmc	O
speaker	B
diarization	I
with	O
overlapped	B
speech	I
bibliographical	O
report	O
authors	O
:	O
justine	O
diliberto	O
supervisor	O
:	O
cindy	O
pereira	O
md	O
sahidullah	O
anna	O
nikiforovskaja	O
december	O
18	O
,	O
2020abstract	O
in	O
this	O
thesis	O
,	O
we	O
report	O
the	O
work	O
done	O
in	O
the	O
ﬁrst	O
phase	O
of	O
our	O
project	O
,	O
aiming	O
at	O
improving	O
speaker	B
diarization	I
with	O
overlapped	B
speech	I
.	O
we	O
ﬁrst	O
discuss	O
the	O
speaker	B
diarization	I
in	O
general	O
and	O
speaker	B
diarization	I
with	O
the	O
overlapped	B
speech	I
in	O
particular	O
.	O
we	O
present	O
different	O
important	O
related	O
work	O
as	O
a	O
part	O
of	O
a	O
bibliographical	O
investigation	O
,	O
and	O
analyze	O
the	O
acoustic	O
characteristics	B
of	O
overlapped	B
speech	I
and	O
the	O
impact	O
of	O
overlapped	B
speech	I
on	O
speaker	B
diarization	I
.	O
then	O
,	O
we	O
perform	O
experiments	O
on	O
the	O
dataset	O
provided	O
for	O
the	O
second	O
dihard	O
diarization	B
challenge	B
.	O
the	O
main	O
cause	O
for	O
speaker	B
diarization	I
errors	B
has	O
been	O
found	O
to	O
be	O
overlapped	B
speech	I
,	O
especially	O
in	O
situations	O
with	O
background	B
noise	I
and	O
when	O
people	O
are	O
away	O
from	O
the	O
microphone	O
.	O
another	O
issue	O
is	O
that	O
a	O
system	O
performs	O
poorly	O
if	O
there	O
is	O
too	O
much	O
overlapped	B
speech	I
in	O
a	O
recording	B
,	O
even	O
for	O
the	O
non	O
-	O
overlap	O
segments	O
.	O
the	O
most	O
recent	O
diarization	B
methods	O
involve	O
using	O
neural	B
networks	I
,	O
which	O
are	O
even	O
more	O
effective	O
if	O
combined	O
with	O
some	O
signal	B
processing	I
techniques	B
.	O
these	O
ﬁndings	O
will	O
be	O
useful	O
for	O
the	O
next	O
phase	O
of	O
this	O
project	O
,	O
whose	O
purpose	O
is	O
to	O
suggest	O
an	O
innovative	O
method	B
to	O
solve	O
the	O
issues	O
raised	O
in	O
this	O
report.contents	O
1	O
introduction	O
4	O
1.1	O
speech	B
signal	I
and	O
speech	O
technology	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
4	O
1.2	O
what	O
is	O
speaker	B
diarization	I
?	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
4	O
1.3	O
components	B
of	O
speaker	B
diarization	I
system	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
5	O
1.4	O
application	B
of	O
speaker	B
diarization	I
technology	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
5	O
1.5	O
issues	O
and	O
challenges	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
6	O
1.6	O
scope	O
of	O
the	O
thesis	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
6	O
1.7	O
organization	O
of	O
the	O
thesis	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
6	O
2	O
experimental	O
setup	B
7	O
2.1	O
dataset	O
description	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
7	O
2.1.1	O
source	B
of	O
the	O
dataset	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
7	O
2.1.2	O
types	O
of	O
track	O
conditions	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
7	O
2.1.3	O
origins	O
of	O
the	O
tracks	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
7	O
2.2	O
evaluation	B
metrics	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
8	O
2.3	O
description	O
of	O
the	O
speaker	B
diarization	I
system	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
8	O
2.3.1	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
systems	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
8	O
2.3.2	O
baseline	B
system	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
9	O
3	O
review	O
of	O
overlapped	B
speech	I
detection	B
methods	O
10	O
3.1	O
overview	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
10	O
3.2	O
signal	B
processing	I
techniques	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
10	O
3.3	O
statistical	O
methods	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
11	O
3.4	O
neural	B
network	I
based	O
methods	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
12	O
3.5	O
summary	O
of	O
the	O
methods	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
14	O
4	O
acoustic	O
and	O
performance	O
analyses	O
15	O
4.1	O
acoustic	O
analysis	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
15	O
4.2	O
performance	O
analysis	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
17	O
4.3	O
impact	O
of	O
speech	O
overlap	O
in	O
full	O
dataset	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
19	O
5	O
conclusion	O
20	O
5.1	O
summary	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
20	O
5.2	O
future	O
work	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
20	O
2list	O
of	O
abbreviations	O
ann	O
artiﬁcial	O
neural	B
network	I
sad	O
speech	B
activity	I
detection	I
bic	B
bayesian	O
information	B
criterion	B
sd	O
speaker	B
diarization	I
blstm	O
bidirectional	O
long	O
short	O
-	O
term	O
memory	O
stlp	O
sum	O
of	O
ten	O
largest	O
peaks	B
cnn	O
convolutional	O
neural	B
network	I
vad	O
voice	O
activity	O
detector	O
der	O
diarization	B
error	I
rate	I
vb	O
-	O
hmm	O
variational	O
bayes	O
hidden	O
markov	O
model	B
dnn	O
deep	O
neural	B
network	I
ehmm	O
ergotic	O
hidden	O
markov	O
model	B
gmm	O
gaussian	O
mixture	O
model	B
hmm	O
hidden	O
markov	O
model	B
hsln	O
human	O
speech	O
-	O
like	O
noise	O
jer	O
jaccard	B
error	I
rate	O
lp	O
linear	O
prediction	O
lpc	O
linear	O
predictive	O
coding	O
mfb	O
melfilter	O
-	O
banks	O
mfcc	O
mel	O
-	O
frequency	B
cepstral	O
coefﬁcients	O
modse	O
modulation	O
spectrum	B
energy	O
nmf	O
non	O
-	O
negative	O
matrix	O
factorization	O
nms	O
non	O
-	O
maximum	O
suppression	O
pca	O
principal	O
component	O
analysis	B
plda	B
probabilistic	O
linear	O
discriminant	B
analysis	I
rmse	O
root	O
mean	O
square	O
energy	O
rpnsd	O
region	O
proposal	O
network	B
based	B
speaker	I
diarization	B
3chapter	O
1	O
introduction	O
the	O
aim	O
of	O
this	O
report	O
is	O
to	O
understand	O
the	O
topic	O
of	O
speaker	B
diarization	I
,	O
to	O
give	O
some	O
analysis	B
of	O
the	O
overlapped	B
speech	I
issue	O
,	O
and	O
also	O
to	O
discuss	O
prior	O
works	O
on	O
overlapped	B
speech	I
detection	B
.	O
this	O
ﬁrst	O
chapter	O
will	O
be	O
introducing	O
the	O
subject	O
of	O
this	O
report	O
by	O
shortly	O
explaining	O
speech	O
sig-	O
nal	O
and	O
speaker	B
diarization	I
(	O
sd	O
)	O
.	O
this	O
is	O
followed	O
by	O
a	O
discussion	O
on	O
the	O
components	B
,	O
applications	O
,	O
and	O
issues	O
of	O
sd	O
.	O
finally	O
,	O
the	O
scope	O
and	O
organization	O
of	O
this	O
report	O
will	O
be	O
presented	O
.	O
1.1	O
speech	B
signal	I
and	O
speech	O
technology	O
when	O
a	O
speech	O
sound	O
is	O
produced	O
,	O
it	O
is	O
,	O
in	O
fact	O
,	O
a	O
sequence	B
of	O
waves	O
of	O
energy	O
that	O
are	O
created	O
and	O
start	O
traveling	O
the	O
air	O
(	O
quatieri	O
,	O
2006	O
)	O
.	O
uttered	O
words	B
are	O
sequences	O
of	O
sound	O
waves	O
coming	O
from	O
our	O
phonatory	O
system	O
.	O
the	O
breath	O
ﬂow	O
is	O
altered	O
to	O
ﬁt	O
the	O
needs	O
of	O
the	O
speech	O
production	O
as	O
the	O
air	O
coming	O
from	O
the	O
lungs	O
is	O
used	O
for	O
speech	O
production	O
.	O
then	O
,	O
vocal	O
folds	O
can	O
be	O
vibrating	O
,	O
opening	O
or	O
closing	O
,	O
and	O
narrowing	O
the	O
gap	O
of	O
the	O
larynx	O
to	O
allow	O
different	O
volumes	O
of	O
air	O
to	O
pass	O
or	O
not	O
.	O
after	O
that	O
,	O
different	O
oral	O
cavity	O
elements	O
,	O
and	O
sometimes	O
also	O
nasal	O
cavity	O
,	O
have	O
a	O
role	O
in	O
altering	O
this	O
ﬂow	O
of	O
air	O
even	O
more	O
by	O
creating	O
resonance	O
.	O
the	O
speech	B
signal	I
is	O
stored	O
in	O
digital	O
storage	O
as	O
a	O
sequence	B
of	O
samples	O
encoded	O
in	O
different	O
formats	O
.	O
the	O
number	O
of	O
samples	O
per	O
second	O
is	O
known	O
as	O
sampling	O
rate	O
.	O
speech	O
technology	O
involves	O
the	O
processing	B
of	O
speech	O
signals	B
by	O
a	O
machine	O
.	O
speech	O
sounds	O
are	O
analyzed	O
by	O
computing	O
short	O
-	O
term	O
characteristics	B
representing	O
acoustic	O
and	O
prosodic	O
informa-	O
tion	O
.	O
these	O
components	B
are	O
then	O
compared	O
to	O
stored	O
patterns	O
to	O
recognize	O
spoken	O
words	B
,	O
speaker	B
,	O
emotion	O
,	O
and	O
language	O
.	O
1.2	O
what	O
is	O
speaker	B
diarization	I
?	O
speaker	B
diarization	I
designates	O
the	O
act	O
of	O
dividing	O
an	O
audio	O
input	B
into	O
different	O
segments	O
corre-	O
sponding	O
to	O
different	O
speakers	O
,	O
as	O
described	O
by	O
friedland	O
&	O
leeuwen	O
(	O
2010	O
)	O
.	O
in	O
other	O
words	B
,	O
it	O
is	O
the	O
task	O
of	O
ﬁnding	O
who	O
spoke	O
when	O
in	O
an	O
audio	O
recording	B
containing	O
several	O
speakers	O
’	O
voices	O
.	O
this	O
involves	O
the	O
unsupervised	O
identiﬁcation	O
of	O
each	O
speaker	B
within	O
an	O
audio	O
stream	O
and	O
of	O
the	O
durations	O
during	O
which	O
each	O
speaker	B
is	O
speaking	O
(	O
anguera	O
et	O
al	O
.	O
,	O
2012	O
)	O
.	O
speaker	B
diarization	I
is	O
a	O
relatively	O
new	O
ﬁeld	O
and	O
thus	O
is	O
still	O
in	O
need	O
of	O
research	B
and	O
improve-	O
ments	O
.	O
some	O
competitions	O
such	O
as	O
dihard	O
(	O
ryant	O
et	O
al	O
.	O
,	O
2019b	O
)	O
,	O
the	O
rich	B
transcription	I
evalua-	O
tion	O
by	O
the	O
american	O
national	O
institute	O
of	O
standards	O
and	O
technologies	O
(	O
sadjadi	O
et	O
al	O
.	O
,	O
2017	O
)	O
are	O
organized	O
to	O
promote	O
research	B
in	O
this	O
ﬁeld	O
.	O
41.3	O
.	O
components	B
of	O
speaker	B
diarization	I
system	I
chapter	O
1	O
.	O
introduction	O
1.3	O
components	B
of	O
speaker	B
diarization	I
system	I
as	O
explained	O
by	O
anguera	O
et	O
al	O
.	O
(	O
2012	O
)	O
,	O
the	O
general	O
architecture	B
of	O
speaker	B
diarization	I
systems	I
can	O
be	O
summarized	O
with	O
different	O
steps	B
as	O
shown	O
in	O
fig	O
.	O
1.1	O
.	O
first	O
,	O
the	O
audio	O
data	B
given	O
as	O
input	B
is	O
preprocessed	O
.	O
the	O
preprocessing	O
tasks	O
aim	O
at	O
improving	O
the	O
quality	B
of	O
the	O
input	B
,	O
and	O
they	O
can	O
vary	O
greatly	O
according	O
to	O
the	O
domain	B
.	O
they	O
often	O
consist	O
in	O
a	O
voice	O
activity	O
detector	O
,	O
among	O
other	O
tasks	O
.	O
next	O
,	O
segmentation	B
is	O
achieved	O
and	O
speaker	B
embeddings	I
,	O
which	O
are	O
speaker	B
representations	O
,	O
are	O
extracted	O
.	O
then	O
,	O
cluster	O
initialization	O
is	O
performed	O
.	O
it	O
depends	O
on	O
which	O
type	O
of	O
approach	O
is	O
used	O
by	O
the	O
system	O
,	O
which	O
can	O
be	O
bottom	O
-	O
up	O
or	O
top	O
-	O
down	O
.	O
if	O
the	O
system	O
has	O
a	O
bottom	O
-	O
up	O
approach	O
,	O
a	O
set	B
of	O
clusters	O
will	O
be	O
selected	O
at	O
this	O
step	O
.	O
on	O
the	O
contrary	O
,	O
if	O
this	O
is	O
a	O
top	O
-	O
down	O
approach	O
system	O
a	O
unique	O
segment	B
will	O
be	O
chosen	O
.	O
after	O
that	O
,	O
the	O
distances	O
between	O
clusters	O
are	O
calculated	O
,	O
in	O
addition	O
to	O
applying	O
splitting	O
or	O
merging	O
tools	O
times	O
,	O
either	O
to	O
merge	O
clusters	O
or	O
add	O
new	O
ones	O
,	O
as	O
explained	O
by	O
d.	O
reynolds	O
,	O
kenny	O
&	O
castaldo	O
(	O
2009	O
)	O
.	O
the	O
ﬁnal	O
step	O
is	O
called	O
stopping	O
criterion	B
as	O
it	O
determines	O
when	O
the	O
iteration	O
of	O
the	O
two	O
previous	O
steps	B
should	O
stop	O
.	O
figure	O
1.1	O
:	O
components	B
of	O
a	O
typical	O
speaker	B
diarization	I
system	I
.	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
speaker	B
diarization	I
system	I
uniform	O
segmentation	B
is	O
followed	O
by	O
speaker	B
embedding	O
extractions	O
.	O
commonly	O
,	O
x	O
-	O
vector	O
embeddings	O
are	O
extracted	O
and	O
they	O
are	O
used	O
with	O
clus-	O
tering	O
technique	B
called	O
agglomerative	O
hierarchical	O
clustering	B
.	O
in	O
addition	O
,	O
often	O
,	O
re	O
-	O
segmentation	B
is	O
also	O
applied	O
for	O
frame	B
-	O
level	B
reﬁnements	O
of	O
results	B
.	O
the	O
majority	O
of	O
the	O
clustering	B
approach	O
used	O
in	O
diarization	B
systems	I
belongs	O
to	O
one	O
of	O
the	O
two	O
following	O
types	O
:	O
top	O
-	O
down	O
or	O
bottom	O
-	O
up	O
approach	O
.	O
the	O
most	O
common	O
one	O
is	O
the	O
bottom	O
-	O
up	O
ap-	O
proach	O
and	O
consists	O
of	O
the	O
generation	O
of	O
several	O
clusters	O
that	O
will	O
be	O
merged	O
until	O
one	O
remains	O
for	O
each	O
speaker	B
.	O
the	O
top	O
-	O
down	O
approach	O
is	O
the	O
opposite	O
,	O
as	O
one	O
cluster	O
is	O
examined	O
at	O
the	O
begin-	O
ning	O
and	O
split	O
into	O
several	O
ones	O
.	O
a	O
bottom	O
-	O
up	O
strategy	O
called	O
agglomerative	O
hierarchical	O
clustering	B
(	O
ahc	O
)	O
technique	B
is	O
predominantly	O
used	O
in	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
speaker	B
diarization	I
systems	I
(	O
ryant	O
et	O
al	O
.	O
,	O
2019b	O
)	O
.	O
1.4	O
application	B
of	O
speaker	B
diarization	I
technology	O
speaker	B
diarization	I
is	O
a	O
useful	O
tool	O
and	O
has	O
many	O
applications	O
as	O
evoked	O
by	O
tranter	O
&	O
d.	O
a.	O
reynolds	O
,	O
2006	O
,	O
for	O
instance	O
:	O
•	O
enabling	O
automatic	O
speaker	B
-	O
attributed	O
speech	O
-	O
to	O
-	O
text	O
transcription	B
for	O
interviews	O
,	O
meetings	O
,	O
conferences	O
or	O
courtroom	O
audiences	O
;	O
•	O
ameliorating	O
the	O
task	O
of	O
searching	O
and	O
indexing	O
audio	O
archives	O
;	O
5	O
51.5	O
.	O
issues	O
and	O
challenges	B
chapter	O
1	O
.	O
introduction	O
•	O
improving	O
accuracy	O
and	O
reducing	O
computational	O
cost	B
of	O
automatic	O
speech	B
recognition	I
,	O
when	O
used	O
as	O
a	O
pre	O
-	O
processing	B
step	O
;	O
•	O
speaker	B
spotting	O
in	O
voice	O
assistant	O
technology	O
.	O
1.5	O
issues	O
and	O
challenges	B
the	O
state	O
-	O
of	O
-	O
art	O
-	O
speaker	B
diarization	I
systems	I
show	O
reasonably	O
well	O
performance	O
in	O
controlled	O
con-	O
ditions	O
.	O
however	O
,	O
the	O
performance	O
is	O
degraded	O
in	O
realistic	O
conditions	O
due	O
to	O
the	O
following	O
reasons	O
:	O
•	O
overlapping	B
speech	I
where	O
speech	O
signals	B
of	O
two	O
or	O
more	O
speakers	O
are	O
overlapped	O
;	O
•	O
background	B
noise	I
where	O
speech	B
signal	I
is	O
degraded	O
by	O
environmental	O
sounds	O
;	O
•	O
distance	B
variations	O
between	O
speakers	O
and	O
microphone	O
.	O
1.6	O
scope	O
of	O
the	O
thesis	O
this	O
thesis	O
will	O
focus	O
on	O
the	O
particular	O
issue	O
of	O
speaker	B
diarization	I
with	O
overlapped	B
speech	I
,	O
by	O
providing	O
performance	O
analysis	B
to	O
determine	O
the	O
effects	O
of	O
overlaps	B
,	O
as	O
well	O
as	O
acoustic	O
analysis	B
to	O
understand	O
causes	O
for	O
poor	O
diarization	B
results	B
.	O
it	O
will	O
also	O
be	O
aiming	O
at	O
presenting	O
a	O
list	O
of	O
bibli-	O
ographical	O
references	B
of	O
methods	O
for	O
detecting	O
overlapping	B
areas	O
.	O
these	O
insights	O
will	O
be	O
gathered	O
with	O
the	O
objective	O
of	O
developing	O
a	O
new	O
effective	O
method	B
for	O
detecting	O
overlapped	B
speech	I
during	O
the	O
second	O
phase	O
of	O
our	O
project	O
.	O
1.7	O
organization	O
of	O
the	O
thesis	O
the	O
next	O
chapter	O
,	O
chapter	O
2	O
,	O
will	O
be	O
focusing	O
on	O
the	O
method	B
,	O
aiming	O
at	O
describing	O
the	O
dataset	O
,	O
the	O
metrics	O
,	O
and	O
the	O
system	O
used	O
for	O
our	O
research	B
.	O
then	O
,	O
in	O
chapter	O
3	O
,	O
several	O
speech	B
detection	I
methods	O
will	O
be	O
reviewed	O
,	O
classiﬁed	O
according	O
to	O
their	O
category	O
.	O
the	O
acoustic	O
and	O
performance	O
analyses	O
of	O
overlapped	B
speech	I
will	O
be	O
presented	O
in	O
the	O
chapter	O
4	O
.	O
finally	O
,	O
a	O
summary	O
followed	O
by	O
our	O
objectives	O
for	O
the	O
next	O
phase	O
of	O
this	O
work	O
will	O
be	O
presented	O
in	O
the	O
chapter	O
5	O
.	O
6	O
6chapter	O
2	O
experimental	O
setup	B
2.1	O
dataset	O
description	O
2.1.1	O
source	B
of	O
the	O
dataset	O
the	O
dataset	O
used	O
for	O
our	O
experimentation	O
is	O
the	O
second	O
dihard	O
diarization	B
challenge	B
dataset	O
,	O
as	O
explained	O
by	O
ryant	O
et	O
al	O
.	O
(	O
2019a	O
)	O
and	O
sahidullah	O
et	O
al	O
.	O
(	O
2019	O
)	O
.	O
the	O
dihard	O
speech	O
diarization	B
challenges	B
are	O
a	O
series	O
of	O
yearly	O
challenges	B
on	O
speaker	B
diarization	I
.	O
to	O
be	O
more	O
precise	O
,	O
the	O
task	O
is	O
to	O
automatically	O
determine	O
who	O
spoke	O
when	O
in	O
a	O
multi	O
-	O
speaker	B
environment	O
and	O
using	O
only	O
audio	O
recordings	O
.	O
these	O
challenges	B
are	O
aiming	O
at	O
improving	O
the	O
ﬁeld	O
by	O
suggesting	O
datasets	B
deemed	O
to	O
yield	O
poor	O
results	B
in	O
the	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
.	O
indeed	O
,	O
development	O
and	O
evaluation	B
datasets	B
are	O
provided	O
by	O
the	O
organizers	O
of	O
the	O
challenge	B
,	O
their	O
goal	O
being	O
to	O
support	O
research	B
and	O
measure	O
performance	O
.	O
2.1.2	O
types	O
of	O
track	O
conditions	O
the	O
tracks	B
used	O
as	O
input	B
can	O
be	O
single	O
channels	B
or	O
multichannels	O
.	O
for	O
the	O
former	O
,	O
the	O
channel	O
can	O
be	O
coming	O
from	O
a	O
single	O
distant	O
microphone	O
,	O
a	O
distant	O
microphone	O
array	O
,	O
a	O
combination	O
of	O
head	O
-	O
mounted	O
and	O
array	O
microphones	O
,	O
or	O
a	O
combination	O
of	O
binaural	O
microphones	O
.	O
concerning	O
multichannel	B
tracks	B
,	O
each	O
audio	O
track	O
is	O
composed	O
of	O
the	O
output	B
from	O
one	O
or	O
several	O
distant	O
mi-	O
crophone	O
arrays	O
,	O
having	O
multiple	O
channels	B
.	O
in	O
this	O
multichannel	B
condition	B
,	O
each	O
array	O
has	O
to	O
be	O
computed	O
separately	O
.	O
two	O
different	O
speech	B
activity	I
detection	I
(	O
sad	O
)	O
are	O
included	O
in	O
the	O
dataset	O
:	O
reference	B
sad	O
and	O
system	O
sad	O
.	O
the	O
reference	B
sad	O
condition	B
characterizes	O
systems	O
that	O
are	O
supplied	O
with	O
a	O
refer-	O
ence	O
speech	O
segmentation	B
.	O
this	O
segmentation	B
has	O
been	O
obtained	O
through	O
human	O
annotation	O
,	O
by	O
merging	O
overlapping	B
speech	I
segments	O
and	O
removing	O
speaker	B
identiﬁcation	O
resulting	O
from	O
this	O
an-	O
notation	O
.	O
on	O
the	O
contrary	O
,	O
systems	O
sad	O
are	O
supplied	O
with	O
the	O
unprocessed	O
audio	O
input	B
,	O
thus	O
the	O
speech	O
segmentation	B
has	O
to	O
be	O
generated	O
.	O
these	O
four	O
conditions	O
result	O
in	O
four	O
different	O
evaluation	B
tracks	B
(	O
single	B
channel	I
using	O
reference	B
sad	O
;	O
single	B
channel	I
using	O
system	O
sad	O
;	O
multichannel	B
using	O
reference	B
sad	O
;	O
multichannel	B
using	O
system	O
sad	O
)	O
.	O
2.1.3	O
origins	O
of	O
the	O
tracks	B
both	O
the	O
training	O
and	O
evaluation	B
data	B
for	O
single	B
channel	I
tracks	B
are	O
taken	O
from	O
eleven	O
different	O
domains	O
such	O
as	O
audiobooks	O
,	O
broadcast	O
interviews	O
,	O
child	O
language	O
,	O
clinical	O
,	O
courtroom	O
,	O
map	O
task	O
,	O
meeting	O
,	O
restaurant	O
,	O
socio	O
-	O
linguistic	O
ﬁeld	O
and	O
lab	O
,	O
or	O
web	O
videos	B
.	O
the	O
combination	O
of	O
the	O
tracks	B
belonging	O
to	O
each	O
domain	B
is	O
approximately	O
as	O
long	O
as	O
two	O
hours	B
.	O
the	O
multichannel	B
data	B
comes	O
from	O
the	O
chime-5	O
dinner	O
party	O
corpus	B
.	O
this	O
corpus	B
is	O
composed	O
72.2	O
.	O
evaluation	B
metrics	I
chapter	O
2	O
.	O
experimental	O
setup	B
of	O
real	O
conversational	O
speech	O
,	O
recorded	O
in	O
the	O
homes	O
of	O
the	O
participants	B
during	O
dinner	O
parties	O
.	O
twenty	O
parties	O
were	O
organized	O
,	O
each	O
lasting	O
2	O
to	O
3	O
hours	B
and	O
to	O
which	O
attended	O
2	O
hosts	O
and	O
2	O
guests	O
.	O
the	O
recordings	O
were	O
performed	O
by	O
microsoft	O
kinect	O
devices	O
(	O
producing	O
4	O
channel	O
linear	O
arrays	O
)	O
.	O
the	O
locations	O
were	O
divided	O
in	O
three	O
areas	O
,	O
and	O
each	O
had	O
two	O
of	O
these	O
devices	O
,	O
which	O
produces	O
24	O
channels	B
in	O
total	O
.	O
every	O
segment	B
containing	O
personal	O
identifying	O
information	B
was	O
removed	O
before	O
the	O
publishing	O
of	O
the	O
dataset	O
.	O
the	O
ﬁles	O
are	O
16	O
bit	O
flac	O
type	O
for	O
single	B
channel	I
and	O
wav	O
type	O
for	O
multichannel	B
,	O
sampled	O
at	O
16khz	O
.	O
concerning	O
the	O
reference	B
sad	O
ﬁles	O
for	O
the	O
development	B
set	I
,	O
they	O
are	O
given	O
as	O
rich	B
transcription	I
time	B
marked	O
ﬁles	O
.	O
2.2	O
evaluation	B
metrics	I
the	O
results	B
of	O
the	O
diarization	B
are	O
compared	O
to	O
those	O
of	O
a	O
human	O
segmentation	B
,	O
which	O
is	O
called	O
ground	B
truth	I
.	O
when	O
the	O
results	B
are	O
different	O
from	O
the	O
ground	B
truth	I
,	O
an	O
error	O
is	O
identiﬁed	O
.	O
three	O
kinds	O
of	O
error	O
can	O
occur	O
:	O
speaker	B
error	O
,	O
false	B
alarm	I
,	O
and	O
missed	O
speech	O
.	O
speaker	B
error	O
refers	O
to	O
the	O
assignment	O
of	O
a	O
segment	B
to	O
the	O
wrong	O
speaker	B
.	O
a	O
false	B
alarm	I
occurs	O
when	O
a	O
segment	B
has	O
been	O
assigned	O
to	O
a	O
speaker	B
but	O
actually	O
contains	O
no	O
speech	O
.	O
missed	O
speech	O
is	O
the	O
term	O
for	O
a	O
segment	B
of	O
speech	O
that	O
has	O
not	O
been	O
assigned	O
any	O
speaker	B
.	O
two	O
kinds	O
of	O
error	B
rates	I
are	O
usually	O
computed	O
to	O
consider	O
the	O
results	B
of	O
a	O
diarization	B
task	O
.	O
diarization	B
error	I
rate	I
(	O
der	O
)	O
is	O
the	O
most	O
famous	O
one	O
and	O
is	O
used	O
to	O
determine	O
the	O
proportion	O
of	O
reference	B
speaker	I
time	B
that	O
is	O
not	O
correctly	O
attributed	O
to	O
a	O
speaker	B
.	O
it	O
is	O
obtained	O
by	O
adding	O
the	O
segments	O
having	O
one	O
of	O
the	O
three	O
kinds	O
of	O
errors	B
(	O
false	B
alarm	I
,	O
missed	O
speech	O
,	O
and	O
speaker	B
error	O
)	O
and	O
dividing	O
their	O
result	O
by	O
the	O
total	O
speaker	B
time	I
.	O
fa	O
+	O
miss	B
+	O
error	O
der	O
=	O
total	O
jaccard	B
error	I
rate	O
(	O
jer	O
)	O
is	O
based	O
on	O
the	O
jaccard	O
index	O
,	O
aiming	O
at	O
computing	O
the	O
optimal	O
mapping	O
between	O
a	O
reference	B
and	O
system	B
speaker	I
pair	O
.	O
for	O
each	O
reference	B
speaker	I
,	O
a	O
speciﬁc	O
jer	O
can	O
be	O
drawn	O
by	O
dividing	O
the	O
sum	O
of	O
false	O
alarms	O
and	O
missed	O
speeches	O
by	O
the	O
union	O
of	O
reference	B
and	O
system	B
speaker	I
segments	O
.	O
the	O
jer	O
is	O
simply	O
the	O
average	B
of	O
every	O
speciﬁc	O
jers	O
.	O
fa	O
+	O
miss	B
1	O
(	O
cid:88	O
)	O
jer	O
=	O
jer	O
=	O
jer	O
ref	O
total	O
n	O
ref	O
ref	O
2.3	O
description	O
of	O
the	O
speaker	B
diarization	I
system	I
2.3.1	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
systems	O
the	O
current	O
state	O
of	O
the	O
art	O
for	O
speaker	B
diarization	I
systems	I
,	O
as	O
explained	O
by	O
snyder	O
et	O
al	O
.	O
(	O
2017	O
)	O
,	O
is	O
turning	O
away	O
from	O
previously	O
used	O
i	O
-	O
vectors	O
to	O
obtain	O
speaker	B
characteristics	B
for	O
the	O
embedding	O
extraction	B
step	O
.	O
this	O
new	O
kind	O
of	O
system	O
is	O
focusing	O
on	O
the	O
use	O
deep	O
neural	B
network	I
embeddings	O
to	O
distinguish	O
speaker	B
differences	O
,	O
by	O
mapping	O
variable	O
-	O
length	B
utterances	B
to	O
ﬁxed	O
-	O
dimensional	O
em-	O
beddings	O
called	O
x	O
-	O
vectors	O
,	O
however	O
the	O
challenge	B
is	O
to	O
gather	O
enough	O
training	B
data	I
.	O
snyder	O
et	O
al	O
.	O
(	O
2018	O
)	O
introduce	O
a	O
method	B
to	O
expand	O
the	O
dataset	O
by	O
adding	O
noise	O
and	O
reverbera-	O
tion	O
to	O
an	O
existent	O
dataset	O
,	O
and	O
this	O
method	B
made	O
the	O
system	O
become	O
powerful	O
enough	O
.	O
after	O
that	O
a	O
probabilistic	O
linear	O
discriminant	B
analysis	I
classiﬁer	O
is	O
used	O
to	O
compare	O
the	O
newly	O
created	O
embed-	O
dings	O
.	O
the	O
results	B
of	O
this	O
new	O
method	B
are	O
further	O
discussed	O
in	O
snyder	O
et	O
al	O
.	O
(	O
2019	O
)	O
,	O
where	O
it	O
is	O
annouced	O
that	O
the	O
error	B
rate	I
for	O
multiple	O
speakers	O
dropped	O
and	O
the	O
performance	O
for	O
single	B
speaker	I
audios	O
stayed	O
the	O
same	O
.	O
a	O
successful	O
method	B
to	O
remove	O
domain	B
sensitive	O
threshold	B
during	O
the	O
clustering	B
stage	B
is	O
also	O
presented	O
.	O
8	O
82.3	O
.	O
description	O
of	O
the	O
speaker	B
diarization	I
system	I
chapter	O
2	O
.	O
experimental	O
setup	B
2.3.2	O
baseline	B
system	I
the	O
system	O
we	O
used	O
is	O
the	O
baseline	B
system	I
supplied	O
by	O
the	O
second	O
dihard	O
diarization	B
challenge	B
,	O
as	O
deﬁned	O
by	O
ryant	O
et	O
al	O
.	O
(	O
2019b	O
)	O
.	O
four	O
different	O
tasks	O
are	O
performed	O
,	O
that	O
is	O
to	O
say	O
speech	O
en-	O
hancement	O
,	O
beamforming	O
,	O
speech	B
activity	I
detection	I
and	O
diarization	B
.	O
firstly	O
,	O
a	O
model	B
is	O
trained	O
to	O
forecast	O
the	O
ideal	O
ratio	O
masks	O
from	O
log	B
-	O
power	O
spectra	O
features	O
us-	O
ing	O
a	O
densely	O
-	O
connected	O
long	O
short	O
-	O
term	O
memory	O
architecture	B
,	O
which	O
is	O
a	O
kind	O
of	O
deep	O
neural	B
network	I
model	B
particularly	O
useful	O
to	O
make	O
predictions	O
.	O
then	O
,	O
weighted	O
delay	O
-	O
and	O
-	O
sum	O
beamforming	O
,	O
a	O
mathematical	O
technique	B
to	O
identify	O
the	O
distance	B
and	O
orientation	O
of	O
sound	O
waves	O
caught	O
by	O
a	O
microphone	O
,	O
is	O
carried	O
out	O
.	O
after	O
that	O
,	O
speech	B
activity	I
detection	I
for	O
tracks	B
2	O
and	O
4	O
is	O
completed	O
thanks	O
to	O
webrtc	O
’s	O
sad	O
,	O
as	O
found	O
in	O
the	O
py	O
-	O
webrtc	O
python	O
package	O
(	O
see	O
2.1.2	O
)	O
.	O
finally	O
,	O
the	O
diarization	B
is	O
achieved	O
by	O
isolating	O
each	O
recording	B
into	O
small	O
overlapping	B
segments	O
,	O
extracting	O
x	O
-	O
vectors	O
,	O
scoring	O
using	O
probabilistic	O
linear	O
discriminant	B
analysis	I
,	O
and	O
clustering	B
with	O
agglomerative	O
hierarchical	O
clustering	B
(	O
see	O
1.3	O
)	O
.	O
9	O
9chapter	O
3	O
review	O
of	O
overlapped	B
speech	I
detection	B
methods	O
3.1	O
overview	O
this	O
chapter	O
aims	O
at	O
providing	O
a	O
bibliographical	O
review	O
of	O
some	O
overlapped	B
speech	I
detection	B
meth-	O
ods	O
,	O
belonging	O
to	O
three	O
main	O
categories	O
that	O
are	O
either	O
signal	B
processing	I
,	O
statistics	B
,	O
or	O
neural	O
net-	O
works	O
methods	O
.	O
the	O
signal	B
processing	I
techniques	B
are	O
the	O
ﬁrst	O
to	O
have	O
been	O
invented	O
,	O
but	O
some	O
methods	O
are	O
still	O
employed	O
and	O
improved	O
nowadays	O
.	O
the	O
statistical	O
methods	O
belong	O
to	O
the	O
second	O
generation	O
of	O
speaker	B
diarization	I
techniques	B
,	O
they	O
were	O
most	O
utilized	O
and	O
developed	O
during	O
the	O
period	O
between	O
2000	O
and	O
2013	O
.	O
the	O
neural	B
network	I
-	O
based	O
methods	O
are	O
the	O
most	O
recent	O
as	O
they	O
appeared	O
in	O
the	O
early	O
2010s	O
and	O
belong	O
to	O
the	O
last	O
generation	O
of	O
speaker	B
diarization	I
techniques	B
.	O
3.2	O
signal	B
processing	I
techniques	B
kobayashi	O
et	O
al	O
.	O
(	O
1996	O
)	O
explore	O
the	O
domain	B
of	O
human	O
speech	O
-	O
like	O
noise	O
(	O
hsln	O
)	O
hoping	O
to	O
ﬁnd	O
a	O
physical	O
measurement	O
inherent	O
feature	O
of	O
a	O
speech	B
signal	I
that	O
would	O
help	O
the	O
problem	O
of	O
over-	O
lapped	O
speech	O
in	O
automatic	O
speech	B
detection	I
.	O
to	O
generate	O
hsln	O
,	O
they	O
normalize	O
ﬁfty	O
sentences	O
of	O
phonetically	O
balanced	O
speech	O
,	O
they	O
fold	O
speech	B
segments	I
and	O
superimpose	O
those	O
signals	B
more	O
than	O
a	O
thousand	O
times	O
.	O
they	O
found	O
that	O
by	O
combining	O
static	O
parameters	O
along	O
with	O
dynamic	O
parameters	O
,	O
they	O
could	O
discriminate	O
speech	O
from	O
background	O
bubble	O
noise	O
more	O
efﬁciently	O
.	O
in	O
their	O
paper	O
,	O
boakye	O
,	O
vinyals	O
&	O
friedland	O
(	O
2011	O
)	O
want	O
to	O
improve	O
the	O
previous	O
work	O
they	O
had	O
done	O
with	O
overlapped	B
speech	I
in	O
speaker	B
diarization	I
,	O
using	O
feature	O
analysis	B
.	O
to	O
do	O
so	O
,	O
they	O
analyze	O
the	O
following	O
speech	O
features	O
in	O
order	B
to	O
select	O
the	O
essential	O
ones	O
for	O
overlapped	B
speech	I
to	O
in-	O
corporate	O
them	O
into	O
their	O
segmentation	B
system	O
:	O
12th	O
-	O
order	B
mel	O
-	O
frequency	B
cepstral	O
coefﬁcients	O
(	O
mfccs	O
)	O
,	O
root	O
mean	O
square	O
energy	O
(	O
rmse	O
)	O
,	O
linear	O
predictive	O
coding	O
(	O
lpc	O
)	O
residual	O
energy	O
,	O
diarization	B
posterior	O
entropy	O
,	O
spectral	O
ﬂatness	O
,	O
harmonic	O
energy	O
ratio	O
,	O
modulation	O
spectrogram	O
features	O
,	O
kurtosis	O
,	O
zero	O
-	O
crossing	O
rate	O
,	O
and	O
harmonicity	O
.	O
compared	O
to	O
their	O
previous	O
work	O
,	O
they	O
obtained	O
a	O
signiﬁcant	O
improvement	O
in	O
der	O
through	O
the	O
feature	O
analysis	B
technique	B
.	O
the	O
article	O
by	O
zelenák	O
&	O
hernando	O
(	O
2011	O
)	O
investigates	O
a	O
complementary	O
method	B
to	O
a	O
system	O
based	O
on	O
short	O
-	O
term	O
spectral	O
parameters	O
to	O
handle	O
the	O
detection	B
of	O
overlapped	B
speech	I
regions	O
,	O
as	O
measuring	O
prosody	O
features	O
can	O
bring	O
some	O
knowledge	B
about	O
the	O
speakers	O
and	O
should	O
help	O
to	O
differentiate	O
them	O
.	O
the	O
pitch	B
,	O
intensity	O
,	O
and	O
four	O
formant	O
measures	O
are	O
selected	O
by	O
an	O
algorithm	O
with	O
minimal	O
-	O
redundancy	O
-	O
maximal	O
-	O
relevance	O
criterion	B
and	O
used	O
to	O
build	O
a	O
feature	O
-	O
set	B
model	B
for	O
the	O
system	O
.	O
the	O
analysis	B
shows	O
that	O
this	O
method	B
has	O
slightly	O
better	O
results	B
in	O
terms	B
of	O
overlapped	B
speech	I
detection	B
error	O
,	O
precision	O
,	O
and	O
recall	O
.	O
in	O
their	O
article	O
,	O
heittola	O
et	O
al	O
.	O
(	O
2013	O
)	O
explain	O
how	O
they	O
tackle	O
the	O
problem	O
of	O
overlapping	B
acous-	O
tic	O
sound	O
event	O
detection	B
by	O
preprocessing	O
the	O
signal	B
with	O
unsupervised	O
source	B
separation	O
.	O
they	O
use	O
a	O
non	O
-	O
negative	O
matrix	O
factorization	O
(	O
nmf)-based	O
method	B
to	O
separate	O
the	O
given	O
audio	O
,	O
they	O
103.3	O
.	O
statistical	O
methods	O
chapter	O
3	O
.	O
review	O
of	O
overlapped	B
speech	I
detection	B
methods	O
apply	O
a	O
continuous	O
-	O
density	O
hidden	O
markov	O
model	B
(	O
hmm	O
)	O
to	O
model	B
sound	O
-	O
event	O
-	O
conditional	O
fea-	O
ture	O
distributions	O
,	O
and	O
ﬁnally	O
they	O
apply	O
viterbi	O
algorithm	O
to	O
detect	O
the	O
sound	O
event	O
.	O
this	O
method	B
allows	O
a	O
signiﬁcant	O
increase	O
in	O
performance	O
compared	O
to	O
previous	O
work	O
using	O
sound	O
source	B
sepa-	O
ration	O
.	O
charlet	O
,	O
barras	O
&	O
liénard	O
(	O
2013	O
)	O
present	O
a	O
way	O
to	O
deal	O
with	O
overlapping	B
speech	I
segments	O
for	O
the	O
diarization	B
of	O
broadcast	O
news	O
and	O
debate	O
videos	B
.	O
the	O
general	O
idea	O
is	O
to	O
detect	O
the	O
overlapping	B
segments	O
to	O
postpone	O
their	O
analysis	B
to	O
the	O
moment	O
after	O
the	O
labeling	O
of	O
the	O
single	B
speaker	I
segments	O
is	O
done	O
,	O
the	O
overlapping	B
segments	O
are	O
then	O
assigned	O
the	O
same	B
speaker	I
labels	O
as	O
their	O
surrounding	O
single	B
speaker	I
segments	O
.	O
two	O
different	O
systems	O
have	O
been	O
developed	O
using	O
cepstral	O
features	O
or	O
a	O
multi	O
-	O
pitch	B
analysis	B
,	O
and	O
their	O
results	B
were	O
approximately	O
similar	O
with	O
a	O
26	O
%	O
decrease	O
of	O
the	O
der	O
in	O
the	O
best	O
situation	O
when	O
compared	O
to	O
methods	O
involving	O
no	O
overlapping	B
speech	I
detection	B
.	O
shokouhi	O
&	O
hansen	O
(	O
2017	O
)	O
present	O
a	O
novel	O
method	B
to	O
detect	O
speech	O
overlaps	B
in	O
monophonic	O
recordings	O
.	O
they	O
base	O
their	O
method	B
on	O
pyknograms	O
,	O
which	O
are	O
harmonically	O
enhanced	O
spectro-	O
grams	O
ﬁrst	O
introduced	O
in	O
the	O
paper	O
by	O
potamianos	O
&	O
maragos	O
(	O
1996	O
)	O
.	O
to	O
detect	O
the	O
speech	O
over-	O
laps	O
they	O
count	O
the	O
euclidean	O
distance	B
between	O
consequent	O
pyknogram	O
frames	O
and	O
afterward	O
they	O
introduce	O
a	O
segment	B
-	O
based	O
score	B
which	O
is	O
simply	O
a	O
mean	O
distance	B
between	O
consequent	O
frames	O
on	O
a	O
speciﬁc	O
segment	B
of	O
the	O
recording	B
.	O
finally	O
,	O
they	O
separate	O
classes	O
based	O
on	O
the	O
segment	B
-	O
based	O
score	B
,	O
and	O
classes	O
with	O
a	O
higher	O
score	B
were	O
considered	O
to	O
be	O
overlap	O
speeches	O
.	O
evaluation	B
showed	O
promising	O
results	B
and	O
they	O
also	O
made	O
a	O
few	O
experiments	O
to	O
show	O
that	O
this	O
method	B
for	O
overlap	B
detection	I
helps	O
in	O
a	O
speaker	B
veriﬁcation	O
task	O
.	O
the	O
method	B
suggested	O
by	O
baghel	O
,	O
prasanna	O
&	O
guhal	O
(	O
2020	O
)	O
aims	O
at	O
detecting	O
transition	O
points	O
between	O
overlapped	O
and	O
non	O
-	O
overlapped	B
speech	I
segments	O
by	O
using	O
bag	O
-	O
of	O
-	O
audio	O
-	O
words	B
.	O
more	O
precisely	O
,	O
the	O
characteristics	B
of	O
three	O
distributions	O
are	O
computed	O
:	O
the	O
sum	O
of	O
ten	O
largest	O
peaks	B
(	O
stlp	O
)	O
of	O
the	O
spectrum	B
and	O
mel	O
-	O
frequency	B
cepstral	O
coefﬁcients	O
(	O
mfcc	O
)	O
are	O
used	O
for	O
estimating	O
the	O
vocal	O
tract	O
,	O
the	O
excitation	O
source	B
is	O
evaluated	O
through	O
the	O
hilbert	O
envelope	O
of	O
linear	O
prediction	O
(	O
lp	O
)	O
residual	O
signal	B
,	O
and	O
the	O
modulation	O
spectrum	B
is	O
assessed	O
thanks	O
to	O
the	O
modulation	O
spectrum	B
energy	O
(	O
modse	O
)	O
.	O
three	O
features	O
compose	O
this	O
analysis	B
(	O
3d	O
,	O
13d	O
,	O
16d	O
)	O
and	O
the	O
16d	O
feature	O
scored	O
the	O
best	O
result	O
with	O
an	O
identiﬁcation	O
rate	O
close	O
to	O
75	O
%	O
.	O
3.3	O
statistical	O
methods	O
in	O
their	O
paper	O
,	O
wrigley	O
et	O
al	O
.	O
(	O
2005	O
)	O
offer	O
a	O
method	B
to	O
achieve	O
reliable	O
detection	B
of	O
speakers	O
in	O
multichannel	B
audio	O
.	O
they	O
use	O
an	O
ergodic	O
hidden	O
markov	O
model	B
(	O
ehmm	O
)	O
with	O
four	O
states	O
:	O
speaker	B
alone	O
,	O
speaker	B
plus	O
crosstalk	O
,	O
crosstalk	O
,	O
and	O
silence	B
to	O
increase	O
the	O
ﬂexibility	O
of	O
their	O
system	O
in	O
comparison	O
to	O
previous	O
work	O
.	O
they	O
obtained	O
a	O
system	O
that	O
can	O
distinguish	O
between	O
the	O
four	O
states	O
of	O
a	O
recording	B
,	O
and	O
which	O
is	O
particularly	O
reliable	O
for	O
ﬁnding	O
speaker	B
alone	O
activity	O
.	O
hu	O
,	O
chieh	O
-	O
cheng	O
&	O
wei	O
-	O
han	O
(	O
2007	O
)	O
proposes	O
an	O
enhancement	O
to	O
previous	O
work	O
using	O
the	O
gaussian	O
mixture	O
model	B
(	O
gmm	O
)	O
to	O
ﬁnd	O
a	O
suitable	O
speaker	B
’s	O
location	O
detection	B
algorithm	O
that	O
can	O
detect	O
multiple	O
speech	O
sources	O
.	O
they	O
use	O
the	O
gaussian	O
mixture	O
location	O
model	B
and	O
a	O
location	O
detection	B
method	B
to	O
obtain	O
a	O
threshold	B
of	O
the	O
probability	B
of	O
speaker	B
for	O
each	O
location	O
.	O
this	O
system	O
has	O
been	O
proved	O
to	O
detect	O
properly	O
speaker	B
’s	O
location	O
and	O
to	O
reduce	O
the	O
average	B
error	B
rates	I
.	O
boakye	O
et	O
al	O
.	O
(	O
2008	O
)	O
presents	O
a	O
hidden	O
markov	O
model	B
(	O
hmm)-based	O
method	B
to	O
create	O
an	O
overlap	B
detection	I
system	O
along	O
with	O
a	O
diarization	B
segment	B
post	O
-	O
processing	B
procedure	O
.	O
they	O
model	B
state	O
emission	O
probabilities	O
with	O
a	O
multivariate	O
gmm	O
and	O
they	O
compute	O
the	O
frame	B
-	O
level	B
speaker	B
posterior	O
probability	B
which	O
they	O
sum	O
to	O
obtain	O
a	O
score	B
for	O
each	O
speaker	B
,	O
the	O
highest	O
one	O
being	O
the	O
one	O
assigned	O
to	O
the	O
segment	B
.	O
the	O
proposed	O
method	B
provided	O
key	O
directions	O
to	O
follow	O
for	O
future	O
work	O
on	O
overlapped	O
detection	B
systems	O
.	O
huijbregts	O
,	O
van	O
leeuwen	O
&	O
jong	O
(	O
2009	O
)	O
develop	O
an	O
overlapped	B
speech	I
detection	B
model	B
and	O
use	O
it	O
in	O
two	O
separate	O
ways	O
.	O
they	O
assume	O
that	O
the	O
overlapping	B
speech	I
can	O
be	O
represented	O
in	O
gmm	O
and	O
that	O
at	O
each	O
speaker	B
change	I
there	O
is	O
a	O
higher	O
probability	B
of	O
having	O
an	O
overlap	O
.	O
so	O
they	O
train	O
their	O
model	B
to	O
predict	O
500ms	O
before	O
and	O
after	O
the	O
speaker	B
change	I
.	O
afterwards	O
they	O
use	O
their	O
model	B
with	O
hmm	O
and	O
viterbi	O
iterations	O
and	O
run	O
diarization	B
with	O
and	O
without	O
overlap	O
model	B
,	O
choosing	O
the	O
results	B
with	O
the	O
best	O
likelihood	B
.	O
they	O
also	O
use	O
this	O
overlapping	B
model	B
as	O
a	O
ﬁnal	O
run	O
to	O
detect	O
overlapping	B
regions	O
.	O
this	O
overlapping	B
speech	I
detection	B
model	B
improved	O
all	O
of	O
their	O
results	B
in	O
terms	B
11	O
113.4	O
.	O
neural	B
network	I
based	O
methods	O
chapter	O
3	O
.	O
review	O
of	O
overlapped	B
speech	I
detection	B
methods	O
of	O
der	O
,	O
even	O
though	O
the	O
number	O
of	O
false	O
alarms	O
of	O
this	O
score	B
increased	O
,	O
and	O
also	O
this	O
approach	O
is	O
considered	O
to	O
be	O
domain	B
-	O
independent	O
.	O
in	O
their	O
paper	O
,	O
shum	O
et	O
al	O
.	O
(	O
2011	O
)	O
explore	O
the	O
low	O
-	O
dimensional	O
total	O
variability	O
subspace	O
ap-	O
proach	O
to	O
speaker	B
clustering	B
.	O
first	O
,	O
they	O
segment	B
the	O
speech	O
with	O
a	O
modulation	O
frequency	B
-	O
based	O
voice	O
activity	O
detector	O
(	O
vad	O
)	O
.	O
then	O
they	O
apply	O
principal	O
component	O
analysis	B
(	O
pca)-based	O
projec-	O
tions	O
in	O
the	O
total	O
variability	O
space	O
,	O
which	O
adds	O
to	O
a	O
speaker-	O
and	O
session	O
-	O
dependent	O
supervector	O
a	O
rectangular	O
matrix	O
of	O
low	O
rank	O
along	O
with	O
a	O
total	O
factor	B
vector	O
,	O
in	O
order	B
to	O
better	O
represent	O
speaker	B
variabilities	O
and	O
compensate	O
for	O
channel	O
inconsistencies	O
.	O
this	O
way	O
,	O
they	O
simpliﬁed	O
the	O
previous	O
systems	O
and	O
still	O
achieved	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
.	O
silovsky	O
et	O
al	O
.	O
(	O
2011	O
)	O
submits	O
a	O
probabilistic	O
linear	O
discriminant	B
analysis	I
(	O
plda)-based	O
method	B
to	O
improve	O
the	O
clustering	B
module	O
for	O
broadcast	O
streams	O
speaker	B
diarization	I
.	O
the	O
common	O
baseline	B
is	O
composed	O
of	O
the	O
following	O
steps	B
:	O
feature	O
extraction	B
,	O
sad	O
using	O
both	O
an	O
energy	O
-	O
based	O
detector	O
with	O
adaptive	O
threshold	B
and	O
a	O
gaussian	O
mixture	O
model	B
(	O
gmm	O
)	O
based	O
detector	O
,	O
speaker	B
segmen-	O
tation	O
using	O
bayesian	O
information	B
criterion	B
(	O
bic	B
)	O
technique	B
,	O
and	O
segment	B
clustering	B
involving	O
bic	B
.	O
the	O
proposed	O
system	O
brought	O
innovative	O
segment	B
clustering	B
modules	O
,	O
that	O
are	O
multifold-	O
and	O
onefold	O
-	O
plda	B
based	O
,	O
and	O
the	O
latter	O
obtained	O
a	O
higher	O
improvement	O
when	O
compared	O
to	O
the	O
baseline	B
system	I
,	O
with	O
42	O
%	O
less	O
speaker	B
error	B
rate	I
for	O
the	O
case	O
of	O
2-stage	O
clustering	B
.	O
yella	O
&	O
bourlard	O
(	O
2013	O
)	O
introduce	O
the	O
interesting	O
idea	O
that	O
it	O
may	O
be	O
better	O
to	O
ﬁnd	O
overlap	O
segments	O
by	O
using	O
not	O
only	O
short	O
-	O
term	O
features	O
of	O
the	O
small	O
segments	O
but	O
also	O
long	O
-	O
term	O
ones	O
.	O
to	O
add	O
long	O
-	O
term	O
features	O
they	O
train	O
also	O
a	O
poisson	O
distribution	O
model	B
to	O
predict	O
the	O
number	O
of	O
overlaps	B
based	O
on	O
the	O
number	O
of	O
speaker	B
changes	O
in	O
a	O
given	O
bigger	O
time	B
segment	B
.	O
this	O
poisson	O
distribution	O
model	B
is	O
incorporated	O
into	O
the	O
baseline	B
hmm	O
/	O
gmm	O
overlap	B
detection	I
model	B
,	O
which	O
leads	O
to	O
a	O
baseline	B
diarization	B
model	B
quality	B
increase	O
in	O
terms	B
of	O
der	O
.	O
3.4	O
neural	B
network	I
based	O
methods	O
snyder	O
et	O
al	O
.	O
(	O
2017	O
)	O
examines	O
a	O
deep	O
neural	B
network	I
(	O
dnn	O
)	O
method	B
consisting	O
of	O
replacing	O
i-	O
vectors	O
with	O
embeddings	O
generated	O
by	O
a	O
feedforward	O
dnn	O
to	O
differentiate	O
speakers	O
from	O
segments	O
with	O
variable	O
lengths	O
.	O
a	O
temporal	O
pooling	O
layer	B
is	O
added	O
in	O
the	O
dnn	O
and	O
gathers	O
long	O
-	O
term	O
speaker	B
characteristics	B
before	O
the	O
speaker	B
and	O
speech	B
segment	I
pairs	O
are	O
put	O
together	O
using	O
a	O
plda	B
-	O
based	O
feature	O
.	O
this	O
method	B
greatly	O
enhances	O
results	B
for	O
short	O
speech	B
segments	I
,	O
and	O
a	O
lesser	O
improvement	O
is	O
noted	O
for	O
long	O
speech	B
segments	I
.	O
a	O
new	O
system	O
using	O
convolutional	O
neural	B
network	I
(	O
cnn	O
)	O
is	O
given	O
by	O
zajíc	O
,	O
hrúz	O
&	O
müller	O
(	O
2017	O
)	O
to	O
enable	O
statistics	B
accumulation	O
reﬁnement	O
.	O
the	O
purpose	O
is	O
for	O
the	O
cnn	O
to	O
output	B
a	O
probability	B
value	O
for	O
a	O
speaker	B
change	I
in	O
a	O
given	O
segment	B
,	O
and	O
to	O
this	O
end	O
,	O
each	O
input	B
is	O
cut	O
into	O
small	O
segments	O
represented	O
by	O
i	O
-	O
vectors	O
.	O
this	O
technique	B
allows	O
a	O
better	O
speaker	B
representation	O
in	O
the	O
last	O
i	O
-	O
vector	O
,	O
as	O
a	O
notable	O
improvement	O
is	O
acknowledged	O
in	O
the	O
article	O
proving	O
that	O
the	O
der	O
decreased	O
by	O
16	O
%	O
when	O
compared	O
to	O
the	O
baseline	B
.	O
yoshioka	O
et	O
al	O
.	O
(	O
2018	O
)	O
deal	O
with	O
the	O
overlapping	B
speech	I
introducing	O
an	O
unmixing	O
transducer	O
,	O
which	O
separates	O
a	O
multichannel	B
recording	B
into	O
a	O
ﬁxed	O
number	O
of	O
time	B
-	O
synchronous	O
audio	O
streams	O
.	O
they	O
base	O
their	O
unmixing	O
transducer	O
on	O
windowed	O
bi	O
-	O
directional	O
long	O
short	O
-	O
term	O
memory	O
(	O
blstm	O
)	O
recurrent	O
neural	O
layers	O
,	O
this	O
model	B
can	O
be	O
trained	O
on	O
short	O
recordings	O
.	O
they	O
tested	O
this	O
model	B
on	O
the	O
meeting	O
transcription	B
task	O
and	O
on	O
real	O
-	O
life	O
meetings	O
.	O
the	O
model	B
showed	O
better	O
results	B
than	O
other	O
meeting	O
transcription	B
models	B
.	O
the	O
article	O
by	O
hogg	O
,	O
evers	O
&	O
naylor	O
(	O
2019	O
)	O
offers	O
a	O
method	B
to	O
perform	O
multiple	O
hypothesis	B
tracking	O
to	O
segment	B
overlapping	B
areas	O
.	O
the	O
main	O
goal	O
is	O
to	O
use	O
the	O
harmonic	O
structure	O
in	O
relation	O
to	O
the	O
pitch	B
.	O
this	O
method	B
involves	O
steps	B
such	O
as	O
harmonic	O
subset	O
generation	O
,	O
tracking	O
multiple	O
hypotheses	B
with	O
maximum	O
weighted	O
clique	O
,	O
and	O
multiple	O
kalman	O
ﬁlters	O
for	O
pitch	B
tracking	O
.	O
to	O
conclude	O
,	O
it	O
is	O
indeed	O
possible	O
to	O
detect	O
the	O
presence	B
of	O
overlapped	B
speech	I
and	O
the	O
results	B
are	O
comparable	O
to	O
recent	O
machine	O
learning	O
methods	O
.	O
kunešová	O
et	O
al	O
.	O
(	O
2019	O
)	O
use	O
generated	O
data	B
to	O
train	O
a	O
cnn	O
for	O
overlap	B
detection	I
.	O
they	O
took	O
several	O
corpora	B
with	O
recordings	O
of	O
single	O
phrases	O
and	O
combined	O
them	O
into	O
recordings	O
with	O
overlap	O
with	O
different	O
volume	O
levels	O
and	O
some	O
background	B
noise	I
.	O
the	O
model	B
performed	O
well	O
on	O
clean	O
and	O
noise	O
-	O
free	O
data	B
,	O
however	O
it	O
did	O
not	O
perform	O
that	O
well	O
on	O
noised	O
data	B
.	O
overall	O
an	O
approach	O
using	O
12	O
123.4	O
.	O
neural	B
network	I
based	O
methods	O
chapter	O
3	O
.	O
review	O
of	O
overlapped	B
speech	I
detection	B
methods	O
generated	O
data	B
seems	O
promising	O
.	O
andrei	O
,	O
cucu	O
&	O
burileanu	O
(	O
2019	O
)	O
want	O
to	O
train	O
several	O
neural	B
networks	I
to	O
detect	O
overlapped	B
speech	I
and	O
estimate	O
the	O
number	O
of	O
competing	O
speakers	O
at	O
a	O
given	O
time	B
on	O
english	O
language	O
based	O
on	O
human	O
capacity	O
.	O
they	O
use	O
their	O
previous	O
work	O
to	O
detect	O
overlapped	O
segments	O
but	O
target	O
to	O
count	O
speech	O
sources	O
on	O
short	O
signal	B
fragments	O
(	O
25ms	O
)	O
,	O
using	O
the	O
single	B
speaker	I
periods	O
to	O
build	O
voice	O
proﬁles	O
and	O
they	O
train	O
a	O
new	O
cnn	O
model	B
for	O
each	O
targeted	O
timeframe	O
.	O
finally	O
,	O
they	O
got	O
better	O
results	B
than	O
current	O
literature	O
and	O
their	O
system	O
has	O
a	O
higher	O
performance	O
than	O
humans	O
.	O
in	O
the	O
paper	O
by	O
bullock	O
,	O
bredin	O
&	O
garcia	O
-	O
perera	O
(	O
2020	O
)	O
they	O
use	O
bidirectional	O
long	O
short-	O
term	O
memory	O
(	O
blstm	O
)	O
recurrent	O
neural	O
layers	O
in	O
their	O
neural	B
network	I
architecture	B
to	O
distinguish	O
speech	B
segments	I
with	O
overlap	O
.	O
afterwards	O
they	O
perform	O
resegmentation	B
and	O
ﬁnal	O
diarization	B
using	O
an	O
i	O
-	O
vector	O
-	O
based	O
variational	O
bayes	O
hidden	O
markov	O
model	B
(	O
vb	O
-	O
hmm	O
)	O
.	O
as	O
a	O
result	O
,	O
their	O
model	B
for	O
overlap	B
detection	I
beats	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
for	O
several	O
datasets	B
and	O
sets	O
the	O
baseline	B
for	O
future	O
experimentation	O
on	O
dihard	O
ii	O
.	O
moreover	O
,	O
their	O
experiments	O
with	O
speaker	B
diarization	I
showed	O
that	O
using	O
oracle	O
overlapped	B
speech	I
detection	B
provided	O
in	O
the	O
dataset	O
only	O
made	O
minor	O
improvements	B
on	O
der	O
,	O
which	O
means	O
that	O
their	O
model	B
for	O
diarization	B
may	O
be	O
more	O
likely	O
improved	O
by	O
better	O
speaker	B
assignment	O
,	O
not	O
overlap	B
detection	I
.	O
in	O
their	O
paper	O
,	O
huang	O
et	O
al	O
.	O
(	O
2020	O
)	O
introduce	O
a	O
new	O
speaker	B
diarization	I
method	B
called	O
re-	O
gion	O
proposal	O
network	B
based	B
speaker	I
diarization	B
(	O
rpnsd	O
)	O
.	O
with	O
this	O
method	B
,	O
they	O
combine	O
the	O
segmentation	B
,	O
embedding	O
extraction	B
,	O
and	O
re	O
-	O
segmentation	B
(	O
every	O
step	O
of	O
a	O
standard	O
diarization	B
system	O
)	O
into	O
one	O
neural	B
network	I
,	O
and	O
the	O
only	O
task	O
left	O
after	O
this	O
nn	O
application	B
is	O
to	O
apply	O
clus-	O
tering	O
and	O
non	O
-	O
maximum	O
suppression	O
(	O
nms	O
)	O
to	O
predict	O
the	O
diarization	B
.	O
they	O
obtained	O
good	O
im-	O
provements	O
over	O
the	O
actual	O
results	B
and	O
still	O
have	O
a	O
shorter	O
pipeline	O
working	O
well	O
with	O
overlapped	O
segments	O
.	O
kanda	O
et	O
al	O
.	O
(	O
2020	O
)	O
developed	O
a	O
method	B
for	O
overlapped	B
speech	I
recognition	O
,	O
based	O
on	O
attention-	O
based	O
encoder	O
decoder	O
.	O
they	O
use	O
d	O
-	O
vectors	O
,	O
which	O
are	O
speaker	B
proﬁle	O
vectors	O
,	O
they	O
represent	O
the	O
voices	O
of	O
the	O
speaker	B
who	O
can	O
possibly	O
be	O
in	O
the	O
recording	B
.	O
their	O
model	B
extracts	O
recording	B
features	O
and	O
speaker	B
features	O
using	O
encoders	O
,	O
keeping	O
in	O
mind	O
the	O
possible	O
speaker	B
proﬁles	O
with	O
attention	O
mechanism	O
.	O
afterwards	O
they	O
apply	O
a	O
decoder	O
to	O
get	O
a	O
transcript	O
of	O
the	O
recording	B
.	O
their	O
model	B
beats	O
the	O
baseline	B
they	O
had	O
.	O
in	O
the	O
article	O
by	O
kinoshita	O
,	O
delcroix	O
&	O
tawara	O
(	O
2020	O
)	O
an	O
innovative	O
approach	O
is	O
considered	O
and	O
consists	O
in	O
bringing	O
together	O
two	O
existing	O
approaches	O
with	O
the	O
aim	O
to	O
keep	O
the	O
advantages	O
of	O
both	O
and	O
to	O
cast	O
aside	O
their	O
imperfections	O
.	O
by	O
mixing	O
a	O
clustering	B
-	O
based	O
approach	O
,	O
which	O
performs	O
greatly	O
for	O
long	O
audios	O
but	O
fails	O
if	O
overlap	O
speech	O
is	O
present	O
,	O
and	O
an	O
end	O
-	O
to	O
-	O
end	O
neural	O
diarization	B
approach	O
,	O
which	O
handles	O
overlap	O
speech	O
accurately	O
but	O
its	O
ﬂaws	O
are	O
dealing	O
with	O
long	O
audios	O
as	O
they	O
require	O
a	O
huge	O
amount	B
of	O
computational	O
memory	O
and	O
time	B
.	O
when	O
considering	O
results	B
,	O
there	O
has	O
been	O
a	O
signiﬁcant	O
improvement	O
of	O
the	O
proposed	O
method	B
if	O
the	O
test	B
data	I
is	O
longer	O
than	O
5	O
minutes	O
,	O
and	O
if	O
it	O
is	O
shorter	O
both	O
the	O
new	O
method	B
and	O
regular	O
end	O
-	O
to	O
-	O
end	O
neural	O
method	B
are	O
equal	O
.	O
málek	O
&	O
žd’ánsky	O
(	O
2020	O
)	O
explore	O
the	O
idea	O
of	O
using	O
x	O
-	O
vectors	O
not	O
only	O
to	O
differentiate	O
speakers	O
in	O
a	O
recording	B
as	O
it	O
is	O
currently	O
done	O
,	O
but	O
also	O
to	O
extract	O
other	O
features	O
from	O
a	O
front	O
-	O
end	O
x	O
-	O
vector	O
network	B
.	O
the	O
theory	O
that	O
front	O
-	O
end	O
x	O
-	O
vectors	O
enclose	O
more	O
information	B
than	O
only	O
speaker	B
informa-	O
tion	O
is	O
tested	O
,	O
such	O
as	O
voice	O
activity	B
detection	I
,	O
overlapped	B
speech	I
detection	B
,	O
speaker	B
identiﬁcation	O
,	O
and	O
absence	O
of	O
speech	O
.	O
this	O
would	O
considerably	O
reduce	O
the	O
computational	O
needs	O
,	O
as	O
the	O
differ-	O
ent	O
tasks	O
evoked	O
earlier	O
are	O
usually	O
done	O
separately	O
.	O
this	O
method	B
surpasses	O
the	O
usual	O
features	O
,	O
however	O
the	O
accuracy	O
is	O
lessened	O
if	O
there	O
is	O
too	O
much	O
background	B
noise	I
.	O
in	O
their	O
article	O
,	O
raj	O
,	O
huang	O
&	O
khudanpur	O
(	O
2020	O
)	O
use	O
another	O
approach	O
for	O
overlapped	O
speaker	B
diarization	I
which	O
uses	O
an	O
external	O
overlap	O
detector	O
to	O
apply	O
the	O
clustering	B
of	O
the	O
segment	B
-	O
level	B
embeddings	O
.	O
their	O
clustering	B
rely	O
on	O
the	O
following	O
two	O
steps	B
:	O
ﬁrst	O
they	O
ignore	O
the	O
discrete	O
con-	O
straints	O
to	O
relax	O
the	O
non	O
-	O
deterministic	O
polynomial	O
-	O
time	B
hardness	O
discrete	O
clustering	B
into	O
a	O
contin-	O
uous	O
version	O
,	O
and	O
generate	O
a	O
solution	O
set	B
through	O
orthonormal	O
transformations	O
of	O
eigenvectors	O
of	O
the	O
normalized	O
laplacian	O
.	O
finally	O
they	O
ﬁnd	O
a	O
discrete	O
solution	O
close	O
to	O
any	O
of	O
the	O
solutions	O
obtained	O
and	O
modify	O
the	O
"	O
sum	O
-	O
to	O
-	O
one	O
"	O
constraint	O
in	O
the	O
discretization	O
stage	B
to	O
introduce	O
overlap	O
awareness	O
while	O
self	O
-	O
tuning	O
the	O
clustering	B
process	B
with	O
p	O
-	O
binarization	O
and	O
normalized	O
maximum	O
eigengap	O
techniques	B
.	O
their	O
method	B
provided	O
an	O
improvement	O
over	O
standard	O
single	O
-	O
speaker	B
clus-	O
tering	O
models	B
and	O
was	O
even	O
competitive	O
with	O
other	O
overlapped	O
diarization	B
methods	O
.	O
raj	O
et	O
al	O
.	O
(	O
2020	O
)	O
introduce	O
a	O
method	B
,	O
called	O
dover	O
-	O
lap	O
,	O
for	O
speaker	B
assignment	O
to	O
the	O
over-	O
13	O
133.5	O
.	O
summary	O
of	O
the	O
methods	O
chapter	O
3	O
.	O
review	O
of	O
overlapped	B
speech	I
detection	B
methods	O
lapped	O
speech	O
regions	O
which	O
combines	O
an	O
output	B
from	O
several	O
diarization	B
systems	I
.	O
they	O
have	O
two	O
stages	O
in	O
this	O
method	B
.	O
there	O
is	O
a	O
label	O
mapping	O
stage	B
to	O
match	O
the	O
hypotheses	B
’	O
speakers	O
from	O
each	O
diarization	B
system	O
,	O
and	O
a	O
label	O
voting	O
stage	B
to	O
ﬁnally	O
decide	O
who	O
was	O
speaking	O
during	O
a	O
particular	O
segment	B
.	O
for	O
the	O
label	O
mapping	O
stage	B
,	O
they	O
build	O
a	O
weighted	O
k	O
-	O
partite	O
graph	O
of	O
hypotheses	B
,	O
where	O
k	O
is	O
the	O
number	O
of	O
hypotheses	B
,	O
and	O
ﬁnd	O
a	O
maximum	O
matching	O
there	O
.	O
these	O
stages	O
are	O
processed	O
repeatedly	O
,	O
considering	O
all	O
the	O
weights	O
with	O
a	O
greedy	O
approximation	O
algorithm	O
.	O
as	O
for	O
voting	O
stage	B
they	O
decide	O
that	O
the	O
amount	B
of	O
speakers	O
in	O
the	O
given	O
region	O
is	O
a	O
weighted	O
mean	O
number	O
of	O
speakers	O
in	O
the	O
hypotheses	B
,	O
and	O
then	O
they	O
perform	O
a	O
majority	O
voting	O
to	O
choose	O
those	O
speakers	O
.	O
they	O
per-	O
formed	O
an	O
evaluation	B
combining	O
different	O
diarization	B
system	O
and	O
the	O
methods	O
showed	O
a	O
consistent	O
and	O
signiﬁcant	O
improvement	O
.	O
youseﬁ	O
&	O
hansen	O
(	O
2020	O
)	O
use	O
cnn	O
to	O
classify	O
speech	O
as	O
overlap	O
or	O
non	O
-	O
overlap	O
,	O
based	O
on	O
sev-	O
eral	O
different	O
features	O
.	O
they	O
explore	O
the	O
effects	O
of	O
different	O
features	O
such	O
as	O
spectral	O
magnitude	O
,	O
pyknogram	O
,	O
melfilter	O
-	O
banks	O
(	O
mfb	O
)	O
,	O
and	O
mfcc	O
.	O
it	O
turned	O
out	O
that	O
using	O
pyknograms	O
as	O
features	O
provides	O
the	O
best	O
performance	O
,	O
giving	O
an	O
increase	O
of	O
10	O
%	O
in	O
accuracy	O
and	O
15	O
%	O
in	O
f1-score	O
,	O
com-	O
paring	O
to	O
the	O
previous	O
results	B
.	O
however	O
,	O
pyknogram	O
based	O
model	B
is	O
computationally	O
less	O
efﬁcient	O
than	O
models	B
using	O
mfb	O
and	O
mfcc	O
features	O
.	O
3.5	O
summary	O
of	O
the	O
methods	O
many	O
different	O
methods	O
for	O
overlapped	B
speech	I
detection	B
were	O
introduced	O
in	O
the	O
last	O
years	O
.	O
these	O
overlapped	B
speech	I
detection	B
methods	O
are	O
used	O
not	O
only	O
in	O
speech	O
diarization	B
but	O
also	O
in	O
other	O
speech	O
-	O
related	O
tasks	O
.	O
even	O
though	O
some	O
of	O
the	O
methods	O
were	O
only	O
applied	O
for	O
overlapped	B
speech	I
for	O
non	O
-	O
diarization	B
tasks	O
,	O
the	O
ideas	O
from	O
those	O
methods	O
could	O
still	O
be	O
used	O
in	O
our	O
own	O
methods	O
.	O
even	O
though	O
,	O
fully	O
signal	B
processing	I
techniques	B
are	O
not	O
that	O
popular	O
anymore	O
,	O
they	O
are	O
still	O
used	O
in	O
the	O
most	O
successful	O
deep	B
learning	I
methods	O
,	O
for	O
example	O
they	O
used	O
pyknograms	O
in	O
youseﬁ	O
&	O
hansen	O
(	O
2020	O
)	O
.	O
the	O
same	O
goes	O
for	O
statistical	O
methods	O
.	O
even	O
though	O
they	O
are	O
not	O
really	O
devel-	O
oped	O
solely	O
nowadays	O
,	O
they	O
are	O
used	O
as	O
pre	O
-	O
processing	B
or	O
post	O
-	O
processing	B
to	O
boost	O
deep	B
learning	I
methods	O
,	O
it	O
is	O
noticeable	O
that	O
hmm	O
and	O
gmm	O
are	O
used	O
a	O
lot	O
.	O
another	O
interesting	O
thing	O
in	O
the	O
methods	O
is	O
that	O
some	O
used	O
self	O
-	O
generated	O
data	B
or	O
even	O
no	O
data	B
at	O
all	O
.	O
it	O
deﬁnitely	O
leads	O
to	O
domain	B
-	O
independent	O
methods	O
and	O
it	O
may	O
be	O
useful	O
,	O
even	O
if	O
those	O
new	O
methods	O
may	O
not	O
be	O
as	O
efﬁcient	O
as	O
domain	B
-	O
dependent	O
ones	O
.	O
finally	O
,	O
there	O
are	O
also	O
methods	O
to	O
combine	O
the	O
output	B
of	O
several	O
diarization	B
methods	O
to	O
increase	O
the	O
performance	O
,	O
like	O
dover	O
-	O
lap	O
.	O
this	O
method	B
can	O
also	O
be	O
useful	O
in	O
our	O
future	O
work	O
.	O
it	O
is	O
clear	O
that	O
currently	O
blstm	O
and	O
cnn	O
based	O
techniques	B
are	O
the	O
most	O
effective	O
in	O
terms	B
of	O
quality	B
of	O
overlapped	B
speech	I
detection	B
.	O
however	O
,	O
there	O
is	O
still	O
room	O
both	O
in	O
terms	B
of	O
quality	B
performance	O
and	O
computational	O
efﬁciency	O
.	O
there	O
are	O
several	O
ways	O
of	O
improving	O
the	O
baseline	B
we	O
have	O
mentioned	O
in	O
2.3	O
,	O
using	O
described	O
methods	O
.	O
for	O
example	O
we	O
could	O
ﬁrst	O
perform	O
overlap	B
detection	I
described	O
in	O
bullock	O
,	O
bredin	O
&	O
garcia	O
-	O
perera	O
(	O
2020	O
)	O
and	O
then	O
remove	O
the	O
overlapped	O
regions	O
and	O
the	O
resulting	O
recordings	O
pass	O
to	O
the	O
baseline	B
model	B
.	O
finally	O
,	O
we	O
could	O
return	O
the	O
overlapped	B
speech	I
regions	O
and	O
provide	O
a	O
speaker	B
reassignment	O
based	O
on	O
x	O
-	O
vectors	O
representation	O
.	O
another	O
way	O
we	O
could	O
train	O
the	O
blstm	O
on	O
mfcc	O
features	O
,	O
which	O
are	O
anyway	O
extracted	O
in	O
our	O
baseline	B
method	B
and	O
then	O
make	O
an	O
overlap	O
-	O
aware	O
resegmentation	B
from	O
the	O
same	O
paper	O
using	O
the	O
vb	O
-	O
hmm	O
module	O
,	O
leaving	O
the	O
initial	O
segmentation	B
from	O
the	O
baseline	B
method	B
.	O
14	O
14chapter	O
4	O
analysis	B
of	O
overlapped	B
speech	I
and	O
its	O
impact	O
on	O
speaker	B
diarization	I
performance	O
4.1	O
acoustic	O
analysis	B
we	O
have	O
conducted	O
some	O
analysis	B
of	O
various	O
audios	O
using	O
praat1	O
software	O
so	O
that	O
we	O
could	O
un-	O
derstand	O
what	O
are	O
the	O
possible	O
variables	O
that	O
lead	O
to	O
an	O
unclear	O
signal	B
.	O
we	O
have	O
chosen	O
to	O
use	O
recordings	O
of	O
ourselves	O
because	O
we	O
were	O
able	O
to	O
control	O
these	O
variables	O
.	O
first	O
,	O
we	O
have	O
tried	O
to	O
distinguish	O
the	O
differences	O
between	O
a	O
recording	B
of	O
two	O
people	O
speaking	O
at	O
the	O
same	O
time	B
and	O
an	O
audio	O
ﬁle	O
with	O
only	O
one	O
person	O
speaking	O
.	O
we	O
encountered	O
many	O
problems	O
in	O
the	O
analysis	B
because	O
more	O
than	O
one	O
variable	O
was	O
evaluated	O
there	O
:	O
the	O
pronounced	O
sentences	O
were	O
n’t	O
the	O
same	O
and	O
the	O
overlapped	B
speech	I
was	O
produced	O
with	O
people	O
from	O
different	O
genders	O
.	O
figure	O
4.1	O
:	O
the	O
ﬁrst	O
ﬁgure	O
shows	O
the	O
spectrogram	O
of	O
a	O
male	O
voice	O
.	O
the	O
second	O
ﬁgure	O
shows	O
the	O
spectogram	O
of	O
a	O
female	O
voice	O
.	O
the	O
ﬁrst	O
variable	O
we	O
could	O
control	O
and	O
detect	O
was	O
the	O
gender	O
of	O
the	O
speaker	B
.	O
we	O
recorded	O
the	O
same	O
french	O
word	B
"	O
bonjour	O
"	O
told	O
by	O
a	O
man	O
and	O
a	O
woman	O
in	O
a	O
quiet	O
environment	O
.	O
both	O
of	O
them	O
spoke	O
near	O
the	O
microphone	O
and	O
conditions	O
were	O
optimal	O
.	O
one	O
can	O
notice	O
in	O
ﬁg	O
.	O
4.1	O
that	O
the	O
male	O
recording	B
has	O
a	O
lower	O
pitch	B
(	O
115.3	O
hz	O
)	O
than	O
the	O
female	O
one	O
(	O
155.8	O
hz	O
)	O
.	O
knowing	O
that	O
,	O
we	O
used	O
1https://fr.wikipedia.org/wiki/praat	O
154.1	O
.	O
acoustic	O
analysis	B
chapter	O
4	O
.	O
acoustic	O
and	O
performance	O
analyses	O
only	O
female	O
recordings	O
for	O
the	O
developments	O
of	O
analysis	B
.	O
we	O
have	O
generated	O
an	O
overlapped	B
speech	I
composed	O
of	O
two	O
single	O
recordings	O
(	O
ﬁg	O
.	O
4.2	O
:	O
122.4	O
hz	O
and	O
ﬁg	O
.	O
4.3	O
:	O
121.1	O
hz	O
)	O
using	O
computer	B
tools	O
to	O
add	O
them	O
,	O
such	O
as	O
audacity	O
mix	O
option	O
or	O
python	O
’s	O
pydub	O
library2	O
.	O
in	O
each	O
single	O
audio	O
,	O
a	O
different	O
woman	O
was	O
telling	O
the	O
same	O
english	O
sentence	O
:	O
"	O
nevermind	O
how	O
long	O
"	O
.	O
the	O
environment	O
was	O
quiet	O
,	O
both	O
of	O
them	O
were	O
speaking	O
near	O
their	O
microphone	O
,	O
and	O
the	O
conditions	O
were	O
optimal	O
.	O
we	O
have	O
noticed	O
that	O
when	O
there	O
are	O
two	O
really	O
clear	O
audios	O
with	O
no	O
noise	O
and	O
people	O
speaking	O
near	O
their	O
microphone	O
saying	O
the	O
same	O
sentence	O
,	O
the	O
computer	B
-	O
generated	O
overlapped	B
speech	I
(	O
ﬁg	O
.	O
4.4	O
:	O
117.3	O
hz	O
)	O
is	O
quite	O
clear	O
and	O
looks	O
like	O
the	O
mean	O
of	O
the	O
two	O
audios	O
.	O
the	O
only	O
difference	O
is	O
the	O
fact	O
that	O
the	O
pitch	B
seems	O
to	O
be	O
slightly	O
lower	O
than	O
in	O
both	O
single	O
recordings	O
.	O
unfortunately	O
,	O
the	O
conditions	O
are	O
never	O
that	O
great	O
in	O
real	O
life	O
,	O
and	O
two	O
people	O
never	O
say	O
the	O
same	O
sentence	O
at	O
the	O
same	O
time	B
.	O
figure	O
4.2	O
:	O
a	O
spectrogram	O
of	O
the	O
ﬁrst	O
speaker	B
.	O
figure	O
4.3	O
:	O
a	O
spectrogram	O
of	O
the	O
second	O
speaker	B
.	O
however	O
,	O
when	O
we	O
record	O
someone	O
speaking	O
over	O
other	O
people	O
chatting	O
or	O
in	O
a	O
noisy	O
environ-	O
ment	O
,	O
the	O
signal	B
becomes	O
really	O
unclear	O
and	O
it	O
is	O
way	O
more	O
difﬁcult	O
to	O
detect	O
clear	O
information	B
,	O
as	O
one	O
can	O
see	O
in	O
ﬁg	O
.	O
4.5	O
,	O
which	O
is	O
the	O
spectogram	O
of	O
an	O
english	O
conversation	O
with	O
more	O
than	O
three	O
people	O
speaking	O
and	O
laughing	O
at	O
the	O
same	O
time	B
.	O
2https://github.com/jiaaro/pydub	O
16	O
164.2	O
.	O
performance	O
analysis	B
chapter	O
4	O
.	O
acoustic	O
and	O
performance	O
analyses	O
figure	O
4.4	O
:	O
a	O
spectrogram	O
of	O
a	O
computer	B
-	O
generated	O
overlapped	B
speech	I
.	O
figure	O
4.5	O
:	O
a	O
spectogram	O
of	O
an	O
overlapping	B
speech	I
with	O
many	O
people	O
talking	O
at	O
the	O
same	O
time	B
.	O
thus	O
,	O
speaker	B
diarization	I
becomes	O
really	O
difﬁcult	O
when	O
handling	O
overlapped	B
speech	I
because	O
signals	B
undergo	O
huge	O
changes	O
in	O
comparison	O
to	O
single	O
-	O
speaker	B
audio	O
.	O
4.2	O
performance	O
analysis	B
we	O
have	O
performed	O
an	O
analysis	B
of	O
the	O
quality	B
of	O
the	O
speaker	B
diarization	I
and	O
what	O
possibly	O
led	O
to	O
a	O
lack	O
of	O
quality	B
on	O
some	O
recordings	O
.	O
this	O
performance	O
analysis	B
was	O
held	O
on	O
the	O
dihard	O
ii	O
dataset	O
using	O
the	O
baseline	B
for	O
the	O
year	O
2019	O
3	O
,	O
described	O
in	O
2.1	O
.	O
particularly	O
we	O
have	O
taken	O
the	O
web	O
video	O
group	O
of	O
recordings	O
from	O
the	O
dataset	O
for	O
the	O
analysis	B
because	O
this	O
group	O
contains	O
diverse	O
recordings	O
both	O
with	O
a	O
small	O
and	O
huge	O
amount	B
of	O
speakers	O
,	O
and	O
both	O
with	O
little	O
to	O
a	O
huge	O
amount	B
of	O
distortion	O
.	O
after	O
running	O
track	O
1	O
baseline	B
solutions	O
we	O
studied	O
the	O
resulting	O
der	O
values	B
.	O
let	O
’s	O
ﬁrst	O
look	O
into	O
the	O
properties	O
of	O
the	O
recording	B
with	O
a	O
big	O
der	O
value	O
(	O
particularly	O
recording	B
dh_0156	O
with	O
der	O
value	O
equal	O
to	O
70.22	O
)	O
.	O
one	O
can	O
see	O
the	O
visualization	O
of	O
when	O
speakers	O
were	O
talking	O
according	O
to	O
the	O
original	O
recording	B
compared	O
to	O
the	O
diarization	B
results	B
in	O
ﬁg	O
.	O
4.6	O
.	O
it	O
is	O
noticeable	O
that	O
in	O
the	O
taken	O
recording	B
ﬁle	O
there	O
were	O
a	O
lot	O
of	O
speech	O
overlaps	B
,	O
which	O
makes	O
it	O
harder	O
for	O
the	O
diarization	B
algorithm	O
to	O
perform	O
well	O
.	O
as	O
a	O
result	O
of	O
this	O
experiment	O
,	O
we	O
have	O
decided	O
to	O
check	O
how	O
important	O
the	O
amount	B
of	O
overlaps	B
is	O
to	O
the	O
performance	O
of	O
the	O
model	B
.	O
to	O
see	O
how	O
important	O
the	O
overlaps	B
for	O
the	O
performance	O
are	O
,	O
we	O
have	O
calculated	O
the	O
amount	B
of	O
the	O
overlaps	B
and	O
then	O
the	O
quality	B
of	O
the	O
diarization	B
without	O
overlaps	B
.	O
we	O
present	O
the	O
results	B
of	O
these	O
calculations	O
in	O
ﬁg	O
.	O
4.7	O
.	O
full	O
results	B
are	O
in	O
the	O
table	O
4.1	O
.	O
percent	O
of	O
overlaps	B
is	O
calculated	O
as	O
3https://github.com/iiscleap/dihard_2019_baseline_alltracks	O
17	O
174.2	O
.	O
performance	O
analysis	B
chapter	O
4	O
.	O
acoustic	O
and	O
performance	O
analyses	O
figure	O
4.6	O
:	O
a	O
graph	O
showing	O
when	O
each	O
speaker	B
was	O
speaking	O
in	O
the	O
original	O
recording	B
and	O
the	O
resulting	O
speaker	B
diarization	I
.	O
a	O
ratio	O
of	O
seconds	B
of	O
overlapped	B
speech	I
to	O
number	O
of	O
seconds	B
in	O
the	O
whole	O
recording	B
(	O
including	O
silence	B
,	O
if	O
there	O
is	O
any	O
)	O
.	O
figure	O
4.7	O
:	O
the	O
ﬁrst	O
ﬁgure	O
shows	O
the	O
dependence	O
of	O
der	O
value	O
on	O
the	O
percent	O
of	O
the	O
overlap	O
.	O
the	O
second	O
ﬁgure	O
shows	O
the	O
dependence	O
of	O
the	O
improvement	O
of	O
der	O
score	B
on	O
non	O
-	O
overlap	O
regions	O
of	O
the	O
recording	B
.	O
as	O
can	O
be	O
seen	O
from	O
the	O
ﬁgures	O
,	O
the	O
der	O
value	O
tends	O
to	O
increase	O
when	O
the	O
amount	B
of	O
overlap	O
is	O
bigger	O
.	O
moreover	O
,	O
the	O
der	O
value	O
on	O
the	O
non	O
-	O
overlap	O
regions	O
is	O
strictly	O
less	O
than	O
on	O
overlap	O
regions	O
and	O
also	O
is	O
dependent	O
on	O
the	O
amount	B
of	O
overlap	O
.	O
it	O
means	O
,	O
that	O
when	O
an	O
amount	B
of	O
overlap	O
is	O
big	O
,	O
it	O
makes	O
it	O
harder	O
for	O
the	O
model	B
even	O
to	O
perform	O
diarization	B
on	O
the	O
non	O
-	O
overlap	O
regions	O
,	O
even	O
though	O
those	O
regions	O
are	O
usually	O
easier	O
for	O
the	O
model	B
.	O
it	O
seems	O
like	O
an	O
issue	O
,	O
which	O
we	O
should	O
deal	O
with	O
while	O
developing	O
our	O
own	O
diarization	B
meth-	O
ods	O
.	O
to	O
do	O
this	O
we	O
can	O
implement	O
modern	O
overlap	O
-	O
detection	B
techniques	B
based	O
on	O
blstm	O
and	O
cnn	O
we	O
described	O
in	O
3	O
.	O
moreover	O
,	O
we	O
can	O
combine	O
different	O
diarization	B
systems	I
with	O
dover	O
-	O
lap	O
to	O
increase	O
the	O
quality	B
.	O
18	O
184.3	O
.	O
impact	O
of	O
speech	O
overlap	O
in	O
full	O
dataset	O
chapter	O
4	O
.	O
acoustic	O
and	O
performance	O
analyses	O
file	O
%	O
of	O
overlap	O
der	O
,	O
full	O
jer	O
,	O
full	O
der	O
,	O
non	O
overlap	O
jer	O
,	O
non	O
overlap	O
dh_0149	O
1.49	O
63.02	O
90.39	O
62.33	O
90.57	O
dh_0150	O
0.19	O
29.07	O
58.39	O
28.92	O
58.42	O
dh_0151	O
14.03	O
53.41	O
90.51	O
48.59	O
91.43	O
dh_0152	O
10.69	O
40.77	O
76.74	O
36.16	O
68.08	O
dh_0153	O
27.57	O
51.28	O
78.50	O
40.77	O
77.59	O
dh_0154	O
75.52	O
65.61	O
83.64	O
34.70	O
84.61	O
dh_0155	O
0.94	O
3.69	O
41.35	O
2.47	O
39.75	O
dh_0156	O
36.46	O
70.22	O
89.64	O
56.03	O
91.21	O
dh_0157	O
0.0	O
0.00	O
0.00	O
0.00	O
0.00	O
dh_0158	O
9.44	O
45.20	O
84.34	O
34.09	O
83.52	O
dh_0159	O
11.07	O
43.25	O
82.99	O
30.04	O
82.94	O
dh_0160	O
13.42	O
24.25	O
40.96	O
13.42	O
36.73	O
dh_0161	O
4.97	O
14.78	O
75.13	O
9.57	O
67.57	O
dh_0162	O
70.66	O
66.81	O
72.33	O
35.91	O
79.12	O
dh_0163	O
4.18	O
39.47	O
77.92	O
37.27	O
79.10	O
dh_0164	O
8.81	O
59.56	O
84.51	O
55.86	O
84.55	O
dh_0165	O
26.51	O
53.96	O
78.24	O
50.79	O
83.58	O
dh_0166	O
19.49	O
62.14	O
82.48	O
59.72	O
85.72	O
dh_0167	O
43.47	O
53.47	O
91.21	O
38.68	O
91.23	O
dh_0168	O
5.17	O
34.44	O
69.41	O
28.97	O
68.54	O
dh_0169	O
0.0	O
0.00	O
0.00	O
0.00	O
0.00	O
dh_0170	O
58.06	O
79.34	O
90.10	O
72.71	O
94.35	O
dh_0171	O
43.6	O
65.57	O
90.83	O
50.02	O
90.00	O
dh_0172	O
30.01	O
54.85	O
87.40	O
45.68	O
86.43	O
dh_0173	O
27.94	O
46.27	O
72.19	O
42.39	O
74.76	O
dh_0174	O
1.83	O
6.30	O
68.89	O
3.87	O
69.27	O
dh_0175	O
0.0	O
0.00	O
0.00	O
0.00	O
0.00	O
dh_0176	O
0.0	O
1.67	O
9.53	O
1.67	O
9.53	O
dh_0177	O
10.65	O
17.41	O
21.16	O
6.90	O
12.60	O
dh_0178	O
11.0	O
22.39	O
31.66	O
13.46	O
27.49	O
dh_0179	O
0.0	O
26.99	O
26.99	O
26.99	O
26.99	O
dh_0180	O
0.0	O
2.59	O
51.29	O
2.59	O
51.29	O
table	O
4.1	O
:	O
all	O
the	O
statistics	B
for	O
ﬁles	O
from	O
webvideo	O
group	O
,	O
including	O
percent	O
of	O
overlap	O
and	O
der	O
and	O
jer	O
calculated	O
both	O
on	O
full	O
recordings	O
and	O
non	O
-	O
overlap	O
regions	O
.	O
4.3	O
impact	O
of	O
speech	O
overlap	O
in	O
full	O
dataset	O
in	O
a	O
separate	O
experiment	O
,	O
we	O
have	O
computed	O
sd	O
performance	O
in	O
terms	B
of	O
der	O
with	O
and	O
without	O
overlap	O
on	O
the	O
full	O
development	B
set	I
of	O
the	O
dihard	O
ii	O
corpus	B
.	O
the	O
experiment	O
was	O
done	O
with	O
all	O
192	O
speech	O
ﬁles	O
and	O
the	O
same	O
baseline	B
system	I
as	O
used	O
in	O
the	O
previous	O
section	O
.	O
the	O
results	B
are	O
shown	O
in	O
table	O
4.2	O
.	O
the	O
der	O
is	O
reduced	O
by	O
more	O
than	O
40	O
%	O
compared	O
to	O
the	O
condition	B
that	O
includes	O
overlap	O
.	O
this	O
conﬁrms	O
that	O
sd	O
performance	O
can	O
be	O
substantially	O
improved	O
if	O
sd	O
system	O
is	O
capable	O
to	O
accurately	O
handle	O
the	O
overlapped	B
speech	I
.	O
overlap	O
der	O
(	O
%	O
)	O
yes	O
(	O
baseline	B
)	O
23.74	O
no	O
14.08	O
table	O
4.2	O
:	O
speaker	B
diarization	I
performance	O
on	O
full	O
dihard	O
ii	O
dataset	O
(	O
development	O
)	O
for	O
with	O
and	O
without	O
overlapped	B
speech	I
.	O
19	O
19chapter	O
5	O
conclusion	O
5.1	O
summary	O
this	O
thesis	O
has	O
presented	O
the	O
outcome	O
of	O
the	O
preliminary	O
part	O
of	O
a	O
project	O
intended	O
to	O
improve	O
speaker	B
diarization	I
with	O
overlapped	B
speech	I
.	O
speech	O
formation	O
comes	O
from	O
the	O
phonatory	O
system	O
,	O
and	O
consists	O
of	O
sound	O
waves	O
.	O
speech	O
technology	O
has	O
been	O
deﬁned	O
as	O
the	O
analysis	B
of	O
components	B
from	O
these	O
sound	O
waves	O
.	O
a	O
description	O
of	O
speaker	B
diarization	I
has	O
been	O
given	O
,	O
which	O
is	O
the	O
task	O
of	O
deﬁning	O
"	O
who	O
spoke	O
when	O
"	O
,	O
before	O
illustrating	O
it	O
with	O
its	O
ﬁve	O
most	O
common	O
components	B
:	O
preprocessing	O
,	O
cluster	O
initialization	O
,	O
splitting	O
or	O
merging	O
tools	O
,	O
cluster	O
distance	B
calculation	O
,	O
and	O
stopping	O
criterion	B
.	O
some	O
applications	O
and	O
issues	O
for	O
speaker	B
diarization	I
have	O
then	O
been	O
exposed	O
.	O
the	O
dataset	O
used	O
for	O
our	O
performance	O
analysis	B
has	O
been	O
taken	O
from	O
the	O
second	O
dihard	O
di-	O
arization	O
challenge	B
,	O
which	O
is	O
composed	O
of	O
four	O
types	O
of	O
tracks	B
coming	O
from	O
various	O
domains	O
,	O
and	O
that	O
can	O
be	O
single	O
or	O
multichannel	B
and	O
with	O
reference	B
or	O
system	O
sad	O
.	O
the	O
der	O
and	O
jer	O
evaluation	B
metrics	I
have	O
been	O
explained	O
.	O
lastly	O
,	O
the	O
baseline	B
for	O
the	O
second	O
dihard	O
diarization	B
challenge	B
is	O
the	O
system	O
we	O
used	O
for	O
our	O
analyses	O
.	O
we	O
have	O
studied	O
several	O
articles	O
to	O
give	O
an	O
outline	O
of	O
the	O
method	B
for	O
speaker	B
diarization	I
they	O
are	O
offering	O
.	O
these	O
methods	O
have	O
been	O
classiﬁed	O
into	O
three	O
chronologically	O
ordered	O
categories	O
:	O
signal	B
processing	I
techniques	B
,	O
statistical	O
methods	O
,	O
and	O
neural	B
network	I
methods	O
.	O
there	O
has	O
been	O
an	O
evolution	O
in	O
the	O
use	O
of	O
these	O
categories	O
,	O
which	O
appeared	O
at	O
different	O
times	O
.	O
thus	O
the	O
most	O
recent	O
one	O
is	O
the	O
most	O
commonly	O
used	O
,	O
however	O
the	O
oldest	O
ones	O
were	O
not	O
abandoned	O
,	O
as	O
they	O
are	O
still	O
applied	O
in	O
addition	O
to	O
neural	B
network	I
methods	O
and	O
in	O
pre	O
-	O
processing	B
or	O
post	O
-	O
processing	B
steps	B
.	O
finally	O
,	O
the	O
acoustic	O
analysis	B
focused	O
on	O
perceiving	O
the	O
physical	O
causes	O
for	O
speaker	B
diarization	I
errors	B
,	O
which	O
are	O
the	O
presence	B
of	O
background	B
noise	I
and	O
a	O
variation	O
in	O
the	O
distance	B
from	O
the	O
micro-	O
phone	O
between	O
two	O
speakers	O
.	O
the	O
performance	O
analysis	B
proved	O
that	O
the	O
der	O
values	B
increase	O
when	O
there	O
is	O
overlapped	B
speech	I
in	O
the	O
audio	O
,	O
and	O
even	O
the	O
non	O
-	O
overlapped	B
speech	I
segments	O
from	O
this	O
same	O
audio	O
are	O
affected	O
.	O
however	O
it	O
needs	O
to	O
be	O
indicated	O
that	O
this	O
analysis	B
was	O
not	O
performed	O
on	O
the	O
full	O
dataset	O
,	O
as	O
we	O
focused	O
on	O
web	O
videos	B
taken	O
from	O
track	O
1	O
.	O
5.2	O
future	O
work	O
in	O
the	O
second	O
phase	O
of	O
our	O
work	O
,	O
an	O
innovative	O
approach	O
will	O
be	O
developed	O
based	O
on	O
the	O
knowledge	B
we	O
gathered	O
during	O
this	O
phase	O
.	O
this	O
method	B
will	O
be	O
based	O
on	O
deep	B
learning	I
techniques	B
,	O
which	O
have	O
become	O
more	O
prominent	O
these	O
last	O
few	O
years	O
,	O
and	O
possibly	O
by	O
combining	O
them	O
with	O
other	O
methods	O
to	O
obtain	O
an	O
improvement	O
of	O
performances	O
,	O
as	O
we	O
have	O
seen	O
that	O
combined	O
methods	O
are	O
more	O
effective	O
.	O
to	O
be	O
precise	O
,	O
we	O
describe	O
our	O
plan	O
for	O
the	O
next	O
phase	O
in	O
the	O
following	O
paragraph	O
.	O
first	O
,	O
we	O
should	O
try	O
modern	O
speech	O
overlap	B
detection	I
methods	O
to	O
improve	O
the	O
baseline	B
method	B
we	O
have	O
and	O
compare	O
the	O
results	B
.	O
we	O
think	O
that	O
this	O
would	O
take	O
about	O
two	O
months	O
in	O
total	O
.	O
205.2	O
.	O
future	O
work	O
chapter	O
5	O
.	O
conclusion	O
afterwards	O
it	O
would	O
be	O
interesting	O
to	O
improve	O
the	O
quality	B
of	O
speaker	B
assignment	O
by	O
using	O
such	O
methods	O
as	O
dover	O
-	O
lap	O
,	O
described	O
in	O
raj	O
et	O
al	O
.	O
(	O
2020	O
)	O
,	O
and	O
compare	O
the	O
results	B
.	O
we	O
think	O
,	O
this	O
part	O
will	O
take	O
about	O
one	O
month	O
of	O
work	O
.	O
then	O
we	O
leave	O
a	O
month	O
to	O
ﬁnd	O
any	O
possible	O
problems	O
with	O
the	O
solutions	O
we	O
have	O
and	O
to	O
probably	O
improve	O
the	O
diarization	B
methods	O
itself	O
.	O
finally	O
,	O
a	O
month	O
will	O
be	O
left	O
for	O
the	O
project	O
ﬁnalization	O
and	O
running	O
the	O
results	B
on	O
a	O
different	O
dataset	O
.	O
for	O
example	O
,	O
during	O
the	O
last	O
phase	O
we	O
can	O
also	O
compare	O
out	O
new	O
method	B
to	O
the	O
baseline	B
on	O
dihard	O
iii	O
,	O
introduced	O
in	O
ryant	O
et	O
al	O
.	O
(	O
2020	O
)	O
.	O
the	O
challenge	B
for	O
dihard	O
iii	O
contains	O
only	O
two	O
tracks	B
,	O
one	O
with	O
sad	O
and	O
one	O
for	O
diarization	B
from	O
scratch	O
.	O
as	O
we	O
are	O
mostly	O
focused	O
on	O
the	O
track	O
with	O
sad	O
in	O
dihard	O
ii	O
,	O
we	O
will	O
evaluate	O
our	O
resulting	O
method	B
on	O
the	O
ﬁrst	O
track	O
of	O
dihard	O
iii	O
dataset	O
.	O
21	O
21bibliography	O
andrei	O
,	O
v.	O
,	O
cucu	O
,	O
h.	O
&	O
burileanu	O
,	O
c.	O
(	O
august	O
2019	O
)	O
overlapped	B
speech	I
detection	B
and	O
compet-	O
ing	O
speaker	B
counting	O
—	O
humans	O
versus	O
deep	B
learning	I
.	O
ieee	O
journal	O
of	O
selected	O
topics	O
in	O
signal	B
processing	I
.	O
13	O
,	O
850–862	O
.	O
available	O
from	O
:	O
doi:10.1109	O
/	O
jstsp.2019.2910759	O
.	O
anguera	O
,	O
x.	O
,	O
bozonnet	O
,	O
s.	O
,	O
evans	O
,	O
n.	O
,	O
fredouille	O
,	O
c.	O
,	O
friedland	O
,	O
g.	O
&	O
vinyals	O
,	O
o.	O
(	O
2012	O
)	O
speaker	B
diarization	I
:	O
a	O
review	O
of	O
recent	O
research	B
.	O
ieee	O
transactions	O
on	O
audio	O
,	O
speech	O
,	O
and	O
language	O
pro-	O
cessing	O
.	O
20	O
(	O
2	O
)	O
,	O
356–370	O
.	O
available	O
from	O
:	O
doi:10.1109	O
/	O
tasl.2011.2125954	O
.	O
baghel	O
,	O
s.	O
,	O
prasanna	O
,	O
s.	O
m.	O
&	O
guhal	O
,	O
p.	O
(	O
july	O
2020	O
)	O
overlapped	O
/	O
non	O
-	O
overlapped	B
speech	I
transition	O
point	B
detection	I
using	O
bag	O
-	O
of	O
-	O
audio	O
-	O
words	B
.	O
2020	O
international	O
conference	O
on	O
signal	B
processing	I
and	O
communications	O
(	O
spcom	O
)	O
.	O
ieee	O
,	O
1–5	O
.	O
available	O
from	O
:	O
doi:10.1109	O
/	O
spcom50965.2020.9179591	O
.	O
boakye	O
,	O
k.	O
,	O
trueba	O
-	O
hornero	O
,	O
b.	O
,	O
vinyals	O
,	O
o.	O
&	O
friedland	O
,	O
g.	O
(	O
2008	O
)	O
overlapped	B
speech	I
detection	B
for	O
improved	O
speaker	B
diarization	I
in	O
multiparty	O
meetings	O
.	O
2008	O
ieee	O
international	O
conference	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
,	O
4353–4356	O
.	O
available	O
from	O
:	O
doi:10.1109	O
/	O
icassp.2008	O
.	O
4518619	O
.	O
boakye	O
,	O
k.	O
,	O
vinyals	O
,	O
o.	O
&	O
friedland	O
,	O
g.	O
(	O
january	O
2011	O
)	O
improved	O
overlapped	B
speech	I
handling	O
for	O
speaker	B
diarization	I
.	O
interspeech	O
,	O
941–944	O
.	O
bullock	O
,	O
l.	O
,	O
bredin	O
,	O
h.	O
&	O
garcia	O
-	O
perera	O
,	O
l.	O
p.	O
(	O
may	O
2020	O
)	O
overlap	O
-	O
aware	O
diarization	B
:	O
resegmenta-	O
tion	O
using	O
neural	O
end	O
-	O
to	O
-	O
end	O
overlapped	B
speech	I
detection	B
.	O
icassp	O
2020	O
-	O
2020	O
ieee	O
international	O
conference	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
(	O
icassp	O
)	O
.	O
ieee	O
.	O
barcelona	O
,	O
spain	O
,	O
7114–7118	O
.	O
available	O
from	O
:	O
doi:10.1109	O
/	O
icassp40776.2020.9053096	O
.	O
charlet	O
,	O
d.	O
,	O
barras	O
,	O
c.	O
&	O
liénard	O
,	O
j.-s	O
.	O
(	O
2013	O
)	O
impact	O
of	O
overlapping	B
speech	I
detection	B
on	O
speaker	B
diarization	I
for	O
broadcast	O
news	O
and	O
debates	O
.	O
2013	O
ieee	O
international	O
conference	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
.	O
ieee	O
.	O
vancouver	O
,	O
canada	O
,	O
7707–7711	O
.	O
available	O
from	O
:	O
doi:10.1109	O
/	O
icassp	O
.	O
2013.6639163	O
.	O
friedland	O
,	O
g.	O
&	O
leeuwen	O
,	O
d.	O
van	O
(	O
2010	O
)	O
speaker	B
recognition	O
and	O
diarization	B
.	O
semantic	O
computing	O
,	O
115–129	O
.	O
available	O
from	O
:	O
doi:10.1002/9780470588222.ch7	O
.	O
heittola	O
,	O
t.	O
,	O
mesaros	O
,	O
a.	O
,	O
virtanen	O
,	O
t.	O
&	O
gabbouj	O
,	O
m.	O
(	O
october	O
2013	O
)	O
supervised	O
model	B
training	O
for	O
overlapping	B
sound	O
events	O
based	O
on	O
unsupervised	O
source	B
separation	O
.	O
2013	O
ieee	O
international	O
conference	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
,	O
8677–8681	O
.	O
available	O
from	O
:	O
doi:10.1109/	O
icassp.2013.6639360	O
.	O
hogg	O
,	O
a.	O
o.	O
,	O
evers	O
,	O
c.	O
&	O
naylor	O
,	O
p.	O
a.	O
(	O
2019	O
)	O
multiple	O
hypothesis	B
tracking	O
for	O
overlapping	B
speaker	B
segmentation	I
.	O
2019	O
ieee	O
workshop	O
on	O
applications	O
of	O
signal	B
processing	I
to	O
audio	O
and	O
acoustics	B
(	O
waspaa	O
)	O
.	O
ieee	O
,	O
195–199	O
.	O
available	O
from	O
:	O
doi:10.1109	O
/	O
waspaa.2019.8937185	O
.	O
hu	O
,	O
j.-s	O
.	O
,	O
chieh	O
-	O
cheng	O
,	O
c.	O
&	O
wei	O
-	O
han	O
,	O
l.	O
(	O
january	O
2007	O
)	O
a	O
robust	O
statistical	O
-	O
based	B
speaker	I
’s	O
location	O
detection	B
algorithm	O
in	O
a	O
vehicular	O
environment	O
.	O
eurasip	O
journal	O
on	O
advances	O
in	O
signal	B
processing	I
.	O
2007	O
.	O
available	O
from	O
:	O
doi:10.1109	O
/	O
coase.2006.326893	O
.	O
huang	O
,	O
z.	O
,	O
watanabe	O
,	O
s.	O
,	O
fujita	O
,	O
y.	O
,	O
garcía	O
,	O
p.	O
,	O
shao	O
,	O
y.	O
,	O
povey	O
,	O
d.	O
&	O
khudanpur	O
,	O
s.	O
(	O
2020	O
)	O
speaker	B
diarization	I
with	O
region	O
proposal	O
network	B
.	O
icassp	O
2020	O
-	O
2020	O
ieee	O
international	O
conference	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
(	O
icassp	O
)	O
,	O
6514–6518	O
.	O
available	O
from	O
:	O
doi:10	O
.	O
1109/	O
icassp40776.2020.9053760	O
.	O
22bibliography	O
bibliography	O
huijbregts	O
,	O
m.	O
,	O
van	O
leeuwen	O
,	O
d.	O
a.	O
&	O
jong	O
,	O
f.	O
(	O
january	O
2009	O
)	O
speech	O
overlap	B
detection	I
in	O
a	O
two-	O
pass	O
speaker	B
diarization	I
system	I
,	O
1063–1066	O
.	O
kanda	O
,	O
n.	O
,	O
gaur	O
,	O
y.	O
,	O
wang	O
,	O
x.	O
,	O
meng	O
,	O
z.	O
,	O
chen	O
,	O
z.	O
,	O
zhou	O
,	O
t.	O
&	O
yoshioka	O
,	O
t.	O
(	O
june	O
2020	O
)	O
joint	O
speaker	B
counting	O
,	O
speech	B
recognition	I
,	O
and	O
speaker	B
identiﬁcation	O
for	O
overlapped	B
speech	I
of	O
any	O
number	O
of	O
speakers	O
.	O
arxiv	O
preprint	O
arxiv:2006.10930	O
.	O
kinoshita	O
,	O
k.	O
,	O
delcroix	O
,	O
m.	O
&	O
tawara	O
,	O
n.	O
(	O
october	O
2020	O
)	O
integrating	O
end	O
-	O
to	O
-	O
end	O
neural	O
and	O
clustering-	O
based	O
diarization	B
:	O
getting	O
the	O
best	O
of	O
both	O
worlds	O
.	O
arxiv	O
preprint	O
arxiv:2010.13366	O
.	O
abs/2010.13366	O
.	O
kobayashi	O
,	O
d.	O
,	O
kajita	O
,	O
s.	O
,	O
takeda	O
,	O
k.	O
&	O
itakura	O
,	O
f.	O
(	O
1996	O
)	O
extracting	O
speech	O
features	O
from	O
human	O
speech	O
like	O
noise	O
.	O
proceeding	O
of	O
fourth	O
international	O
conference	O
on	O
spoken	B
language	I
processing	B
.	O
icslp	O
’	O
96	O
.	O
vol	O
.	O
1	O
,	O
418–421	O
vol.1	O
.	O
available	O
from	O
:	O
doi:10.1109	O
/	O
icslp.1996.607143	O
.	O
kunešová	O
,	O
m.	O
,	O
hrúz	O
,	O
m.	O
,	O
zajíc	O
,	O
z.	O
&	O
radová	O
,	O
v.	O
(	O
2019	O
)	O
detection	B
of	O
overlapping	B
speech	I
for	O
the	O
purposes	O
of	O
speaker	B
diarization	I
.	O
international	O
conference	O
on	O
speech	O
and	O
computer	B
.	O
springer	O
,	O
247	O
–	O
257	O
.	O
málek	O
,	O
j.	O
&	O
žd’ánsky	O
,	O
j.	O
(	O
2020	O
)	O
voice	O
-	O
activity	O
and	O
overlapped	B
speech	I
detection	B
using	O
x	O
-	O
vectors	O
.	O
international	O
conference	O
on	O
text	O
,	O
speech	O
,	O
and	O
dialogue	O
.	O
springer	O
,	O
366–376	O
.	O
potamianos	O
,	O
a.	O
&	O
maragos	O
,	O
p.	O
(	O
1996	O
)	O
speech	O
formant	O
frequency	B
and	O
bandwidth	O
tracking	O
using	O
multiband	O
energy	O
demodulation	O
.	O
the	O
journal	O
of	O
the	O
acoustical	O
society	O
of	O
america	O
.	O
99	O
(	O
6	O
)	O
,	O
3795	O
–	O
3806	O
.	O
available	O
from	O
:	O
doi:10.1121/1.414997	O
.	O
quatieri	O
,	O
t.	O
f.	O
(	O
2006	O
)	O
discrete	O
-	O
time	B
speech	B
signal	I
processing	B
:	O
principles	O
and	O
practice	O
.	O
pearson	O
ed-	O
ucation	O
,	O
781	O
.	O
raj	O
,	O
d.	O
,	O
garcia	O
-	O
perera	O
,	O
l.	O
p.	O
,	O
huang	O
,	O
z.	O
,	O
watanabe	O
,	O
s.	O
,	O
povey	O
,	O
d.	O
,	O
stolcke	O
,	O
a.	O
&	O
khudanpur	O
,	O
s.	O
(	O
november	O
2020	O
)	O
dover	O
-	O
lap	O
:	O
a	O
method	B
for	O
combining	O
overlap	O
-	O
aware	O
diarization	B
outputs	O
.	O
arxiv	O
preprint	O
arxiv:2011.01997	O
.	O
abs/2011.01997	O
.	O
raj	O
,	O
d.	O
,	O
huang	O
,	O
z.	O
&	O
khudanpur	O
,	O
s.	O
(	O
november	O
2020	O
)	O
multi	O
-	O
class	O
spectral	O
clustering	B
with	O
overlaps	B
for	O
speaker	B
diarization	I
.	O
arxiv	O
.	O
arxiv-2011.02900	O
.	O
reynolds	O
,	O
d.	O
,	O
kenny	O
,	O
p.	O
&	O
castaldo	O
,	O
f.	O
(	O
january	O
2009	O
)	O
a	O
study	O
of	O
new	O
approaches	O
to	O
speaker	B
di-	O
arization	O
.	O
tenth	O
annual	B
conference	I
of	O
the	O
international	O
speech	B
communication	I
association	O
,	O
1047	O
–	O
1050	O
.	O
ryant	O
,	O
n.	O
,	O
church	O
,	O
k.	O
,	O
cieri	O
,	O
c.	O
,	O
cristia	O
,	O
a.	O
,	O
du	O
,	O
j.	O
,	O
ganapathy	O
,	O
s.	O
&	O
liberman	O
,	O
m.	O
(	O
2019a	O
)	O
second	O
dihard	B
challenge	I
evaluation	B
plan	I
.	O
linguistic	O
data	B
consortium	O
,	O
tech	O
.	O
rep	O
.	O
available	O
from	O
:	O
doi:10	O
.	O
5281	O
/	O
zenodo.3872390	O
.	O
—	O
(	O
2019b	O
)	O
the	O
second	O
dihard	O
diarization	B
challenge	B
:	O
dataset	O
,	O
task	O
,	O
and	O
baselines	O
.	O
proc	O
.	O
in-	O
terspeech	O
2019	O
,	O
978–982	O
.	O
available	O
from	O
:	O
doi:10	O
.	O
21437	O
/	O
interspeech	O
.	O
2019	O
-	O
1268	O
[	O
accessed	O
december	O
18	O
,	O
2020	O
]	O
.	O
ryant	O
,	O
n.	O
,	O
singh	O
,	O
p.	O
,	O
krishnamohan	O
,	O
v.	O
,	O
varma	O
,	O
r.	O
,	O
church	O
,	O
k.	O
,	O
cieri	O
,	O
c.	O
,	O
du	O
,	O
j.	O
,	O
ganapathy	O
,	O
s.	O
&	O
liberman	O
,	O
m.	O
(	O
2020	O
)	O
the	O
third	O
dihard	O
diarization	B
challenge	B
.	O
arxiv	O
preprint	O
arxiv:2012.01477	O
.	O
sadjadi	O
,	O
s.	O
o.	O
,	O
kheyrkhah	O
,	O
t.	O
,	O
tong	O
,	O
a.	O
,	O
greenberg	O
,	O
c.	O
s.	O
,	O
reynolds	O
,	O
d.	O
a.	O
,	O
singer	O
,	O
e.	O
,	O
mason	O
,	O
l.	O
p.	O
&	O
hernandez	O
-	O
cordero	O
,	O
j.	O
(	O
2017	O
)	O
the	O
2016	O
nist	O
speaker	B
recognition	O
evaluation	B
.	O
proc	O
.	O
interspeech	O
2017	O
,	O
1353–1357	O
.	O
available	O
from	O
:	O
doi:10	O
.	O
21437	O
/	O
interspeech	O
.	O
2017	O
-	O
458	O
[	O
accessed	O
decem-	O
ber	O
18	O
,	O
2020	O
]	O
.	O
sahidullah	O
,	O
m.	O
et	O
al	O
.	O
(	O
2019	O
)	O
the	O
speed	O
submission	O
to	O
dihard	O
ii	O
:	O
contributions	O
&	O
lessons	O
learned	O
.	O
arxiv	O
preprint	O
arxiv:1911.02388	O
.	O
shokouhi	O
,	O
n.	O
&	O
hansen	O
,	O
j.	O
h.	O
l.	O
(	O
2017	O
)	O
teager	O
–	O
kaiser	O
energy	O
operators	O
for	O
overlapped	B
speech	I
detection	B
.	O
ieee	O
/	O
acm	O
transactions	O
on	O
audio	O
,	O
speech	O
,	O
and	O
language	B
processing	I
.	O
25	O
(	O
5	O
)	O
,	O
1035–1047	O
.	O
available	O
from	O
:	O
doi:10.1109	O
/	O
taslp.2017.2678684	O
.	O
shum	O
,	O
s.	O
,	O
dehak	O
,	O
n.	O
,	O
chuangsuwanich	O
,	O
e.	O
,	O
reynolds	O
,	O
d.	O
&	O
glass	O
,	O
j.	O
r.	O
(	O
2011	O
)	O
exploiting	O
intra-	O
conversation	O
variability	O
for	O
speaker	B
diarization	I
.	O
twelfth	O
annual	B
conference	I
of	O
the	O
international	O
speech	B
communication	I
association	O
.	O
available	O
from	O
:	O
https://www.isca-	O
speech.org/archive/	O
interspeech_2011	O
/	O
i11_0945.html	O
[	O
accessed	O
december	O
18	O
,	O
2020	O
]	O
.	O
23	O
23bibliography	O
bibliography	O
silovsky	O
,	O
j.	O
,	O
prazak	O
,	O
j.	O
,	O
cerva	O
,	O
p.	O
,	O
zdansky	O
,	O
j.	O
&	O
nouza	O
,	O
j.	O
(	O
2011	O
)	O
plda	B
-	O
based	O
clustering	B
for	O
speaker	B
diarization	I
of	O
broadcast	O
streams	O
.	O
twelfth	O
annual	B
conference	I
of	O
the	O
international	O
speech	O
communica-	O
tion	O
association	O
.	O
available	O
from	O
:	O
https://www.isca-speech.org/archive/interspeech_2011/	O
i11_2909.html	O
[	O
accessed	O
december	O
18	O
,	O
2020	O
]	O
.	O
snyder	O
,	O
d.	O
,	O
garcia	O
-	O
romero	O
,	O
d.	O
,	O
povey	O
,	O
d.	O
&	O
khudanpur	O
,	O
s.	O
(	O
2017	O
)	O
deep	O
neural	B
network	I
em-	O
beddings	O
for	O
text	O
-	O
independent	O
speaker	B
veriﬁcation	O
.	O
interspeech	O
2017	O
,	O
999–1003	O
.	O
available	O
from	O
:	O
doi:10.21437	O
/	O
interspeech.2017	O
-	O
620	O
.	O
snyder	O
,	O
d.	O
,	O
garcia	O
-	O
romero	O
,	O
d.	O
,	O
sell	O
,	O
g.	O
,	O
mccree	O
,	O
a.	O
,	O
povey	O
,	O
d.	O
&	O
khudanpur	O
,	O
s.	O
(	O
2019	O
)	O
speaker	B
recognition	O
for	O
multi	O
-	O
speaker	B
conversations	O
using	O
x	O
-	O
vectors	O
.	O
icassp	O
2019	O
-	O
2019	O
ieee	O
international	O
conference	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
(	O
icassp	O
)	O
.	O
ieee	O
,	O
5796–5800	O
.	O
available	O
from	O
:	O
doi:10.1109	O
/	O
icassp.2019.8683760	O
.	O
snyder	O
,	O
d.	O
,	O
garcia	O
-	O
romero	O
,	O
d.	O
,	O
sell	O
,	O
g.	O
,	O
povey	O
,	O
d.	O
&	O
khudanpur	O
,	O
s.	O
(	O
2018	O
)	O
x	O
-	O
vectors	O
:	O
robust	O
dnn	O
embeddings	O
for	O
speaker	B
recognition	O
.	O
2018	O
ieee	O
international	O
conference	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
(	O
icassp	O
)	O
.	O
ieee	O
,	O
5329–5333	O
.	O
available	O
from	O
:	O
doi:10.1109	O
/	O
icassp.2019.8683760	O
.	O
tranter	O
,	O
s.	O
e.	O
&	O
reynolds	O
,	O
d.	O
a.	O
(	O
2006	O
)	O
an	O
overview	O
of	O
automatic	O
speaker	B
diarization	I
systems	I
.	O
ieee	O
transactions	O
on	O
audio	O
,	O
speech	O
,	O
and	O
language	B
processing	I
.	O
14	O
(	O
5	O
)	O
,	O
1557–1565	O
.	O
available	O
from	O
:	O
doi:10.1109	O
/	O
tasl.2006.878256	O
.	O
wrigley	O
,	O
s.	O
n.	O
,	O
brown	O
,	O
g.	O
j.	O
,	O
wan	O
,	O
v.	O
&	O
renals	O
,	O
s.	O
(	O
2005	O
)	O
speech	O
and	O
crosstalk	O
detection	B
in	O
mul-	O
tichannel	O
audio	O
.	O
ieee	O
transactions	O
on	O
speech	O
and	O
audio	O
processing	B
.	O
13	O
(	O
1	O
)	O
,	O
84–91	O
.	O
available	O
from	O
:	O
doi:10.1109	O
/	O
tsa.2004.838531	O
.	O
yella	O
,	O
s.	O
h.	O
&	O
bourlard	O
,	O
h.	O
(	O
2013	O
)	O
improved	O
overlap	O
speech	O
diarization	B
of	O
meeting	O
recordings	O
using	O
long	O
-	O
term	O
conversational	O
features	O
.	O
2013	O
ieee	O
international	O
conference	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
.	O
ieee	O
,	O
7746–7750	O
.	O
available	O
from	O
:	O
doi:10.1109	O
/	O
icassp.2013.6639171	O
.	O
yoshioka	O
,	O
t.	O
,	O
erdogan	O
,	O
h.	O
,	O
chen	O
,	O
z.	O
,	O
xiao	O
,	O
x.	O
&	O
alleva	O
,	O
f.	O
(	O
2018	O
)	O
recognizing	O
overlapped	B
speech	I
in	O
meetings	O
:	O
a	O
multichannel	B
separation	O
approach	O
using	O
neural	B
networks	I
.	O
proc	O
.	O
interspeech	O
2018	O
,	O
3038–3042	O
.	O
available	O
from	O
:	O
doi:10.21437	O
/	O
interspeech.2018	O
-	O
2284	O
.	O
youseﬁ	O
,	O
m.	O
&	O
hansen	O
,	O
j.	O
h.	O
l.	O
(	O
2020	O
)	O
frame	B
-	O
based	O
overlapping	B
speech	I
detection	B
using	O
convo-	O
lutional	O
neural	B
networks	I
.	O
icassp	O
2020	O
-	O
2020	O
ieee	O
international	O
conference	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
(	O
icassp	O
)	O
,	O
6744–6748	O
.	O
available	O
from	O
:	O
doi:10.1109	O
/	O
icassp40776.2020	O
.	O
9053108	O
.	O
zajíc	O
,	O
z.	O
,	O
hrúz	O
,	O
m.	O
&	O
müller	O
,	O
l.	O
(	O
2017	O
)	O
speaker	B
diarization	I
using	O
convolutional	O
neural	B
network	I
for	O
statistics	B
accumulation	O
reﬁnement	O
.	O
proc	O
.	O
interspeech	O
2017	O
,	O
3562–3566	O
.	O
available	O
from	O
:	O
doi:10	O
.	O
21437	O
/	O
interspeech.2017	O
-	O
51	O
.	O
zelenák	O
,	O
m.	O
&	O
hernando	O
,	O
j.	O
(	O
2011	O
)	O
the	O
detection	B
of	O
overlapping	B
speech	I
with	O
prosodic	B
features	I
for	O
speaker	B
diarization	I
.	O
twelfth	O
annual	B
conference	I
of	O
the	O
international	O
speech	B
communication	I
associa-	O
tion	O
,	O
1041–1044	O
.	O
available	O
from	O
:	O
https://www.isca-speech.org/archive/interspeech_2011/	O
i11_1041.html	O
[	O
accessed	O
december	O
18	O
,	O
2020	O
]	O
.	O

msc	O
in	O
nlp	O
supervised	O
project	O
université	O
de	O
lorraine	O
idmc	O
speaker	B
diarization	I
with	O
overlapped	B
speech	I
realization	O
report	O
authors	O
:	O
supervisor	O
:	O
justine	O
diliberto	O
md	O
sahidullah	O
,	O
multispeech	O
cindy	O
pereira	O
reviewer	O
:	O
anna	O
nikiforovskaja	O
imran	O
sheikh	O
,	O
multispeech	O
june	O
21	O
,	O
2021abstract	O
our	O
project	O
aims	O
at	O
improving	O
speaker	B
diarization	I
with	O
overlapped	B
speech	I
.	O
this	O
report	O
describes	O
the	O
second	O
part	O
of	O
our	O
project	O
,	O
the	O
experimentation	O
phase	O
,	O
whereas	O
the	O
ﬁrst	O
phase	O
was	O
focused	O
on	O
the	O
comprehension	O
of	O
the	O
subject	O
and	O
the	O
bibliographical	O
research	B
.	O
we	O
ﬁrst	O
discuss	O
the	O
speaker	B
diarization	I
in	O
general	O
,	O
and	O
speaker	B
diarization	I
with	O
overlapped	B
speech	I
in	O
particular	O
.	O
we	O
also	O
an-	O
alyze	O
the	O
acoustic	O
characteristics	B
of	O
overlapped	B
speech	I
and	O
the	O
impact	O
of	O
overlapped	B
speech	I
on	O
speaker	B
diarization	I
.	O
then	O
,	O
we	O
investigate	O
this	O
impact	O
both	O
in	O
terms	B
of	O
performance	O
and	O
inﬂuence	O
on	O
acoustic	B
features	I
.	O
finally	O
,	O
several	O
models	B
based	O
on	O
x	O
-	O
vector	O
analysis	B
are	O
explored	O
for	O
identiﬁca-	O
tion	O
of	O
overlapped	B
speech	I
.	O
we	O
state	O
the	O
problem	O
through	O
classiﬁcation	O
and	O
regression	B
,	O
and	O
we	O
ﬁnd	O
out	O
that	O
in	O
the	O
case	O
of	O
our	O
imbalanced	O
data	B
,	O
classiﬁcation	O
methods	O
work	O
better	O
and	O
can	O
be	O
further	O
improved	O
to	O
have	O
better	O
results.acknowledgement	O
we	O
would	O
like	O
to	O
express	O
our	O
gratitude	O
to	O
our	O
supervisor	O
for	O
his	O
assistance	O
at	O
every	O
stage	B
of	O
the	O
project	O
.	O
experiments	O
presented	O
in	O
this	O
paper	O
were	O
partially	O
carried	O
out	O
using	O
the	O
grid’5000	O
testbed1	O
,	O
supported	O
by	O
a	O
scientiﬁc	O
interest	O
group	O
hosted	O
by	O
inria	O
and	O
including	O
cnrs	O
,	O
renater	O
and	O
several	O
universities	O
as	O
well	O
as	O
other	O
organizations	O
.	O
1https://www.grid5000.fr	O
2contents	O
1	O
introduction	O
6	O
1.1	O
speech	B
signal	I
and	O
speech	O
technology	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
6	O
1.2	O
what	O
is	O
speaker	B
diarization	I
?	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
6	O
1.3	O
components	B
of	O
speaker	B
diarization	I
system	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
6	O
1.4	O
applications	O
of	O
speaker	B
diarization	I
technology	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
7	O
1.5	O
issues	O
and	O
challenges	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
7	O
1.6	O
scope	O
of	O
the	O
project	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
8	O
1.7	O
contributions	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
8	O
1.8	O
organization	O
of	O
the	O
project	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
8	O
2	O
experimental	O
setup	B
9	O
2.1	O
dataset	O
description	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
9	O
2.1.1	O
source	B
of	O
the	O
dataset	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
9	O
2.1.2	O
types	O
of	O
track	O
conditions	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
9	O
2.1.3	O
origins	O
of	O
the	O
tracks	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
9	O
2.2	O
evaluation	B
metrics	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
10	O
2.3	O
description	O
of	O
the	O
speaker	B
diarization	I
system	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
10	O
2.3.1	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
systems	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
10	O
2.3.2	O
baseline	B
system	I
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
10	O
2.4	O
libraries	O
and	O
tools	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
11	O
3	O
performance	O
impact	O
12	O
3.1	O
finding	O
and	O
removing	O
overlapped	B
speech	I
segments	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
12	O
3.2	O
results	B
on	O
the	O
new	O
data	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
12	O
3.3	O
understanding	O
the	O
results	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
13	O
3.4	O
summary	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
15	O
4	O
acoustic	O
impact	O
16	O
4.1	O
splitting	O
audio	O
ﬁles	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
16	O
4.2	O
calculated	O
features	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
16	O
4.3	O
visual	O
results	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
18	O
4.4	O
statistical	O
results	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
19	O
4.5	O
discriminative	O
features	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
19	O
4.6	O
summary	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
20	O
3contents	O
contents	O
5	O
overlap	O
detectors	O
22	O
5.1	O
introduction	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
22	O
5.2	O
classiﬁcation	O
methods	O
idea	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
22	O
5.3	O
experimental	O
setup	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
22	O
5.3.1	O
data	B
organization	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
22	O
5.3.2	O
architecture	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
23	O
5.3.3	O
evaluation	B
methods	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
23	O
5.4	O
models	B
tested	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
24	O
5.5	O
evaluation	B
results	B
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
25	O
5.6	O
summary	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
26	O
6	O
conclusion	O
27	O
6.1	O
summary	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
27	O
6.2	O
limitations	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
28	O
6.3	O
future	O
work	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
.	O
28	O
4	O
4list	O
of	O
abbreviations	O
blstm	O
bidirectional	O
long	O
short	O
-	O
term	O
memory	O
cnn	O
convolutional	O
neural	B
network	I
der	O
diarization	B
error	I
rate	I
error	O
speaker	B
error	O
fa	O
false	B
alarm	I
gru	O
gated	O
recurrent	O
unit	O
jer	O
jaccard	B
error	I
rate	O
mfcc	O
mel	O
-	O
frequency	B
cepstral	O
coefﬁcients	O
miss	B
missed	O
speech	O
nov	O
non	O
-	O
overlapped	B
speech	I
ov	O
overlapped	B
speech	I
sad	O
speech	B
activity	I
detection	I
sd	O
speaker	B
diarization	I
sgd	O
stochastic	O
gradient	O
descent	O
svc	O
support	O
vector	O
machine	O
classiﬁer	O
tdnn	O
time	B
delay	O
neural	B
networks	I
uar	O
unweighted	O
average	B
recall	O
5chapter	O
1	O
introduction	O
the	O
aim	O
of	O
this	O
report	O
is	O
to	O
experiment	O
with	O
overlapping	B
speech	I
,	O
a	O
recurrent	O
issue	O
in	O
speaker	B
di-	O
arization	O
,	O
by	O
exploring	O
the	O
consequences	O
on	O
performance	O
,	O
on	O
acoustic	B
features	I
,	O
and	O
by	O
evaluating	O
overlap	O
detector	O
methods	O
with	O
x	O
-	O
vectors	O
(	O
snyder	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O
this	O
ﬁrst	O
chapter	O
recalls	O
the	O
deﬁnitions	O
of	O
speech	B
signal	I
and	O
speaker	B
diarization	I
(	O
sd	O
)	O
.	O
then	O
the	O
components	B
,	O
applications	O
,	O
and	O
issues	O
of	O
sd	O
are	O
exposed	O
.	O
finally	O
,	O
the	O
contribution	O
,	O
scope	O
,	O
and	O
organization	O
of	O
this	O
report	O
are	O
presented	O
.	O
1.1	O
speech	B
signal	I
and	O
speech	O
technology	O
the	O
sound	O
is	O
a	O
sequence	B
of	O
vibrations	O
(	O
diliberto	O
,	O
pereira	O
&	O
nikiforovskaja	O
,	O
2021	O
)	O
.	O
sound	O
coming	O
from	O
our	O
phonatory	O
system	O
constitutes	O
the	O
speech	O
.	O
the	O
speech	B
signal	I
is	O
stored	O
as	O
a	O
sequence	B
of	O
samples	O
,	O
encoded	O
in	O
different	O
formats	O
.	O
the	O
number	O
of	O
samples	O
per	O
second	O
is	O
known	O
as	O
the	O
sampling	O
rate	O
.	O
speech	O
technology	O
involves	O
the	O
processing	B
of	O
speech	B
signal	I
by	O
a	O
machine	O
(	O
rudnicky	O
,	O
haupt-	O
mann	O
&	O
lee	O
,	O
1994	O
)	O
.	O
speech	O
sounds	O
are	O
analyzed	O
by	O
computing	O
short	O
-	O
term	O
characteristics	B
which	O
represent	O
acoustic	O
and	O
prosodic	O
information	B
.	O
these	O
components	B
are	O
then	O
compared	O
to	O
stored	O
pat-	O
terns	O
to	O
recognize	O
spoken	O
words	B
,	O
speakers	O
,	O
emotions	O
,	O
and	O
language	O
.	O
1.2	O
what	O
is	O
speaker	B
diarization	I
?	O
speaker	B
diarization	I
designates	O
the	O
task	O
of	O
ﬁnding	O
who	O
spoke	O
when	O
in	O
an	O
audio	O
recording	B
containing	O
several	O
speakers	O
’	O
voices	O
.	O
this	O
is	O
the	O
unsupervised	O
identiﬁcation	O
of	O
each	O
speaker	B
within	O
an	O
audio	O
stream	O
and	O
the	O
durations	O
during	O
which	O
each	O
speaker	B
is	O
speaking	O
(	O
anguera	O
et	O
al	O
.	O
,	O
2012	O
)	O
.	O
speaker	B
diarization	I
is	O
a	O
relatively	O
new	O
ﬁeld	O
and	O
thus	O
is	O
still	O
in	O
need	O
of	O
research	B
and	O
improve-	O
ment	O
.	O
some	O
competitions	O
such	O
as	O
dihard	O
(	O
ryant	O
et	O
al	O
.	O
,	O
2019b	O
)	O
and	O
the	O
rich	B
transcription	I
evalu-	O
ation	O
by	O
the	O
american	O
national	O
institute	O
of	O
standards	O
and	O
technologies	O
(	O
sadjadi	O
et	O
al	O
.	O
,	O
2017	O
)	O
are	O
organized	O
to	O
promote	O
research	B
in	O
this	O
ﬁeld	O
.	O
[	O
paragraph	O
taken	O
from	O
our	O
previous	O
report	O
(	O
diliberto	O
,	O
pereira	O
&	O
nikiforovskaja	O
,	O
2021	O
)	O
]	O
1.3	O
components	B
of	O
speaker	B
diarization	I
system	I
as	O
a	O
reminder	O
,	O
the	O
components	B
of	O
a	O
typical	O
speaker	B
diarization	I
system	I
are	O
shown	O
in	O
fig	O
.	O
1.1	O
.	O
the	O
main	O
steps	B
are	O
:	O
preprocessing	O
,	O
segmentation	B
,	O
embedding	O
extraction	B
,	O
cluster	O
initialization	O
,	O
splitting	O
or	O
merging	O
tools	O
&	O
cluster	O
distance	B
calculation	O
,	O
and	O
stopping	O
criterion	B
.	O
each	O
step	O
is	O
explained	O
in	O
more	O
details	O
in	O
our	O
previous	O
report	O
(	O
diliberto	O
,	O
pereira	O
&	O
nikiforovskaja	O
,	O
2021	O
)	O
.	O
61.4	O
.	O
applications	O
of	O
speaker	B
diarization	I
technology	O
chapter	O
1	O
.	O
introduction	O
figure	O
1.1	O
:	O
components	B
of	O
a	O
typical	O
speaker	B
diarization	I
system	I
.	O
[	O
figure	O
taken	O
from	O
our	O
previous	O
report	O
(	O
diliberto	O
,	O
pereira	O
&	O
nikiforovskaja	O
,	O
2021	O
)	O
]	O
the	O
uniform	O
segmentation	B
for	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
speaker	B
diarization	I
systems	I
is	O
followed	O
by	O
speaker	B
embedding	O
extractions	O
.	O
commonly	O
,	O
x	O
-	O
vector	O
embeddings	O
are	O
extracted	O
and	O
they	O
are	O
used	O
with	O
a	O
clustering	B
technique	B
called	O
agglomerative	O
hierarchical	O
clustering	B
.	O
in	O
addition	O
,	O
re	O
-	O
segmentation	B
is	O
often	O
applied	O
for	O
frame	B
-	O
level	B
reﬁnements	O
of	O
results	B
.	O
1.4	O
applications	O
of	O
speaker	B
diarization	I
technology	O
speaker	B
diarization	I
is	O
a	O
useful	O
tool	O
and	O
has	O
many	O
applications	O
,	O
such	O
as	O
(	O
tranter	O
&	O
reynolds	O
,	O
2006	O
)	O
:	O
•	O
enabling	O
automatic	O
speaker	B
-	O
attributed	O
speech	O
-	O
to	O
-	O
text	O
transcription	B
for	O
interviews	O
,	O
meetings	O
,	O
conferences	O
or	O
courtroom	O
audiences	O
;	O
•	O
ameliorating	O
the	O
task	O
of	O
searching	O
and	O
indexing	O
audio	O
archives	O
;	O
•	O
improving	O
accuracy	O
and	O
reducing	O
computational	O
cost	B
of	O
automatic	O
speech	B
recognition	I
,	O
when	O
used	O
as	O
a	O
preprocessing	O
step	O
;	O
•	O
speaker	B
spotting	O
in	O
voice	O
assistant	O
technology	O
.	O
[	O
paragraph	O
taken	O
from	O
our	O
previous	O
report	O
(	O
diliberto	O
,	O
pereira	O
&	O
nikiforovskaja	O
,	O
2021	O
)	O
]	O
1.5	O
issues	O
and	O
challenges	B
the	O
state	O
-	O
of	O
-	O
art	O
speaker	B
diarization	I
systems	I
show	O
reasonably	O
good	O
results	B
in	O
controlled	O
conditions	O
.	O
however	O
,	O
the	O
performance	O
is	O
degraded	O
in	O
realistic	O
conditions	O
due	O
to	O
the	O
following	O
reasons	O
:	O
•	O
overlapping	B
speech	I
;	O
•	O
background	B
noise	I
;	O
•	O
distance	B
variations	O
between	O
speakers	O
and	O
microphones	O
.	O
[	O
paragraph	O
taken	O
from	O
our	O
previous	O
report	O
(	O
diliberto	O
,	O
pereira	O
&	O
nikiforovskaja	O
,	O
2021	O
)	O
]	O
7	O
71.6	O
.	O
scope	O
of	O
the	O
project	O
chapter	O
1	O
.	O
introduction	O
1.6	O
scope	O
of	O
the	O
project	O
this	O
project	O
aims	O
at	O
studying	O
sd	O
with	O
the	O
particular	O
issue	O
of	O
overlapped	B
speech	I
.	O
we	O
provide	O
perfor-	O
mance	O
analyses	O
to	O
determine	O
the	O
effects	O
of	O
speech	O
overlaps	B
,	O
and	O
acoustic	O
analyses	O
to	O
understand	O
audio	O
features	O
and	O
ﬁnd	O
discriminating	O
ones	O
.	O
we	O
also	O
develop	O
methods	O
to	O
detect	O
overlapping	B
speech	I
through	O
classiﬁcation	O
and	O
regression	B
.	O
1.7	O
contributions	O
the	O
experiments	O
in	O
the	O
following	O
chapters	O
of	O
this	O
report	O
are	O
contributions	O
to	O
the	O
scientiﬁc	O
commu-	O
nity	O
,	O
as	O
they	O
shed	O
a	O
new	O
light	O
on	O
the	O
old	O
problematic	O
of	O
speech	O
overlap	O
.	O
the	O
performance	O
experiment	O
deals	O
with	O
the	O
impact	O
of	O
overlap	O
on	O
performance	O
based	O
on	O
the	O
dihard	O
ii	O
dataset	O
.	O
after	O
removing	O
audio	O
segments	O
containing	O
overlap	O
,	O
the	O
baseline	B
is	O
run	O
and	O
its	O
performances	O
are	O
calculated	O
.	O
this	O
experiment	O
shows	O
the	O
impact	O
of	O
overlap	O
on	O
non	O
-	O
overlapping	B
segments	O
on	O
sd	O
performance	O
.	O
we	O
investigate	O
the	O
impact	O
of	O
overlap	O
on	O
acoustic	B
features	I
that	O
can	O
weaken	O
diarization	B
results	B
.	O
90	O
different	O
acoustic	B
features	I
are	O
computed	O
on	O
the	O
dihard	O
ii	O
development	O
dataset	O
ﬁles	O
,	O
which	O
we	O
divided	O
between	O
overlap	O
and	O
non	O
-	O
overlap	O
segments	O
.	O
the	O
study	O
conﬁrms	O
that	O
some	O
features	O
are	O
useful	O
to	O
discriminate	O
overlap	O
from	O
non	O
overlap	O
speech	O
.	O
the	O
performance	O
of	O
overlap	B
detection	I
methods	O
based	O
on	O
x	O
-	O
vectors	O
is	O
studied	O
.	O
we	O
build	O
a	O
system	O
for	O
training	O
and	O
testing	O
them	O
and	O
implement	O
both	O
classical	O
machine	O
learning	O
and	O
deep	O
learning-	O
based	O
methods	O
.	O
we	O
apply	O
both	O
these	O
methods	O
to	O
the	O
classiﬁcation	O
and	O
the	O
regression	B
interpretation	O
of	O
the	O
problem	O
.	O
we	O
show	O
that	O
classiﬁcation	O
interpretation	O
of	O
the	O
problem	O
works	O
better	O
,	O
and	O
x-	O
vectors	O
can	O
display	O
some	O
information	B
for	O
overlap	B
detection	I
.	O
1.8	O
organization	O
of	O
the	O
project	O
the	O
second	O
chapter	O
,	O
chapter	O
2	O
,	O
focuses	O
on	O
the	O
method	B
,	O
aiming	O
at	O
describing	O
the	O
dataset	O
,	O
the	O
met-	O
rics	O
,	O
the	O
system	O
,	O
and	O
the	O
tools	O
used	O
for	O
our	O
study	O
.	O
then	O
,	O
the	O
performance	O
analysis	B
,	O
consisting	O
in	O
the	O
removal	O
of	O
overlapping	B
segments	O
,	O
is	O
described	O
in	O
chapter	O
3	O
.	O
the	O
acoustic	O
impact	O
experiments	O
follow	O
,	O
aiming	O
at	O
identifying	O
acoustic	B
features	I
,	O
in	O
chapter	O
4	O
.	O
chapter	O
5	O
deals	O
with	O
the	O
development	O
of	O
overlap	O
detectors	O
based	O
on	O
x	O
-	O
vectors	O
.	O
lastly	O
,	O
a	O
conclusion	O
is	O
given	O
in	O
chapter	O
6	O
with	O
a	O
summary	O
and	O
limitations	O
of	O
this	O
report	O
,	O
as	O
well	O
as	O
future	O
work	O
suggestions	O
.	O
8	O
8chapter	O
2	O
experimental	O
setup	B
[	O
part	O
of	O
this	O
chapter	O
has	O
been	O
taken	O
from	O
our	O
previous	O
report	O
(	O
diliberto	O
,	O
pereira	O
&	O
nikiforovskaja	O
,	O
2021	O
)	O
]	O
2.1	O
dataset	O
description	O
2.1.1	O
source	B
of	O
the	O
dataset	O
the	O
dataset	O
used	O
for	O
our	O
experimentations	O
is	O
the	O
second	O
dihard	O
diarization	B
challenge	B
dataset	O
(	O
ryant	O
et	O
al	O
.	O
,	O
2019a	O
;	O
sahidullah	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
the	O
dihard	O
speech	O
diarization	B
challenge	B
is	O
a	O
series	O
of	O
yearly	O
challenges	B
on	O
speaker	B
diarization	I
.	O
to	O
be	O
more	O
precise	O
,	O
the	O
task	O
is	O
to	O
automatically	O
determine	O
who	O
spoke	O
when	O
in	O
a	O
multi	O
-	O
speaker	B
environment	O
and	O
using	O
only	O
audio	O
recordings	O
.	O
2.1.2	O
types	O
of	O
track	O
conditions	O
the	O
tracks	B
used	O
as	O
input	B
can	O
be	O
single	O
channels	B
or	O
multi	O
-	O
channels	B
.	O
more	O
information	B
on	O
how	O
these	O
channel	O
types	O
are	O
recorded	O
can	O
be	O
found	O
in	O
our	O
previous	O
report	O
(	O
diliberto	O
,	O
pereira	O
&	O
nikiforovskaja	O
,	O
2021	O
)	O
.	O
two	O
different	O
speech	B
activity	I
detection	I
(	O
sad	O
)	O
are	O
included	O
in	O
the	O
dataset	O
:	O
reference	B
sad	O
and	O
system	O
sad	O
.	O
the	O
reference	B
sad	O
condition	B
means	O
that	O
a	O
speech	O
segmentation	B
is	O
supplied	O
,	O
whereas	O
system	O
sad	O
stands	O
for	O
unprocessed	O
audio	O
.	O
these	O
four	O
conditions	O
result	O
in	O
four	O
different	O
evaluation	B
tracks	B
:	O
single	B
channel	I
using	O
reference	B
sad	O
;	O
single	O
-	O
channel	O
using	O
system	O
sad	O
;	O
multichannel	B
using	O
reference	B
sad	O
;	O
multichannel	B
using	O
system	O
sad	O
.	O
2.1.3	O
origins	O
of	O
the	O
tracks	B
both	O
the	O
training	O
and	O
evaluation	B
data	B
for	O
single	O
-	O
channel	O
tracks	B
are	O
taken	O
from	O
eleven	O
different	O
domains	O
such	O
as	O
audiobooks	O
,	O
broadcast	O
interviews	O
,	O
child	O
language	O
,	O
clinical	O
,	O
courtroom	O
,	O
map	O
task	O
,	O
meeting	O
,	O
restaurant	O
,	O
socio	O
-	O
linguistic	O
ﬁeld	O
and	O
lab	O
,	O
and	O
web	O
videos	B
.	O
the	O
combination	O
of	O
the	O
tracks	B
belonging	O
to	O
each	O
domain	B
is	O
approximately	O
two	O
hours	B
long	O
.	O
the	O
multichannel	B
data	B
comes	O
from	O
the	O
chime-5	O
dinner	O
party	O
corpus	B
.	O
this	O
corpus	B
is	O
composed	O
of	O
real	O
conversational	O
speech	O
,	O
recorded	O
in	O
the	O
homes	O
of	O
the	O
participants	B
during	O
dinner	O
parties	O
.	O
twenty	O
parties	O
were	O
organized	O
,	O
each	O
lasting	O
2	O
to	O
3	O
hours	B
and	O
to	O
which	O
attended	O
2	O
hosts	O
and	O
2	O
guests	O
.	O
the	O
recordings	O
were	O
performed	O
by	O
microsoft	O
kinect	O
devices	O
(	O
producing	O
4	O
channel	O
linear	O
arrays	O
)	O
.	O
the	O
locations	O
were	O
divided	O
into	O
three	O
areas	O
,	O
and	O
each	O
had	O
two	O
of	O
these	O
devices	O
,	O
which	O
produces	O
24	O
channels	B
in	O
total	O
.	O
92.2	O
.	O
evaluation	B
metrics	I
chapter	O
2	O
.	O
experimental	O
setup	B
every	O
segment	B
containing	O
personal	O
identifying	O
information	B
was	O
removed	O
before	O
the	O
publishing	O
of	O
the	O
dataset	O
.	O
the	O
ﬁles	O
are	O
16	O
bit	O
flac	O
type	O
for	O
single	O
-	O
channel	O
and	O
wav	O
type	O
for	O
multichannel	B
,	O
sampled	O
at	O
16	O
khz	O
.	O
concerning	O
the	O
reference	B
sad	O
ﬁles	O
for	O
the	O
development	B
set	I
,	O
they	O
are	O
given	O
as	O
rich	B
transcription	I
time	B
marked	O
ﬁles	O
.	O
2.2	O
evaluation	B
metrics	I
the	O
results	B
of	O
the	O
diarization	B
are	O
compared	O
to	O
those	O
of	O
a	O
human	O
segmentation	B
,	O
which	O
is	O
called	O
ground	B
truth	I
.	O
when	O
the	O
results	B
are	O
different	O
from	O
the	O
ground	B
truth	I
,	O
an	O
error	O
is	O
identiﬁed	O
.	O
three	O
kinds	O
of	O
error	O
can	O
occur	O
:	O
speaker	B
error	O
,	O
false	B
alarm	I
,	O
and	O
missed	O
speech	O
.	O
speaker	B
error	O
(	O
error	O
)	O
refers	O
to	O
the	O
assignment	O
of	O
a	O
segment	B
to	O
the	O
wrong	O
speaker	B
.	O
a	O
false	B
alarm	I
(	O
fa	O
)	O
occurs	O
when	O
a	O
segment	B
has	O
been	O
assigned	O
to	O
a	O
speaker	B
but	O
actually	O
contains	O
no	O
speech	O
.	O
missed	O
speech	O
(	O
miss	B
)	O
is	O
the	O
term	O
for	O
a	O
segment	B
of	O
speech	O
that	O
has	O
not	O
been	O
assigned	O
to	O
any	O
speaker	B
.	O
two	O
kinds	O
of	O
error	B
rates	I
are	O
usually	O
computed	O
to	O
consider	O
the	O
results	B
of	O
a	O
diarization	B
task	O
.	O
diarization	B
error	I
rate	I
(	O
der	O
)	O
is	O
the	O
most	O
famous	O
one	O
and	O
is	O
used	O
to	O
determine	O
the	O
proportion	O
of	O
reference	B
speaker	I
time	B
that	O
is	O
not	O
correctly	O
attributed	O
to	O
a	O
speaker	B
.	O
it	O
is	O
obtained	O
by	O
adding	O
the	O
segments	O
having	O
one	O
of	O
the	O
three	O
kinds	O
of	O
errors	B
(	O
false	B
alarm	I
,	O
missed	O
speech	O
,	O
and	O
speaker	B
error	O
)	O
and	O
dividing	O
their	O
result	O
by	O
the	O
total	O
speaker	B
time	I
.	O
fa	O
+	O
miss	B
+	O
error	O
der	O
=	O
total	O
jaccard	B
error	I
rate	O
(	O
jer	O
)	O
is	O
based	O
on	O
the	O
jaccard	O
index	O
,	O
which	O
aims	O
at	O
computing	O
the	O
optimal	O
mapping	O
between	O
a	O
reference	B
and	O
a	O
system	B
speaker	I
pair	O
.	O
for	O
each	O
reference	B
speaker	I
,	O
a	O
speciﬁc	O
jer	O
can	O
be	O
drawn	O
by	O
dividing	O
the	O
sum	O
of	O
false	O
alarms	O
and	O
missed	O
speeches	O
by	O
the	O
union	O
of	O
reference	B
and	O
system	B
speaker	I
segments	O
.	O
the	O
jer	O
is	O
simply	O
the	O
average	B
of	O
every	O
speciﬁc	O
jers	O
.	O
fa	O
+	O
miss	B
1	O
(	O
cid:88	O
)	O
jer	O
=	O
jer	O
=	O
jer	O
ref	O
total	O
n	O
ref	O
ref	O
2.3	O
description	O
of	O
the	O
speaker	B
diarization	I
system	I
2.3.1	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
systems	O
the	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
for	O
speaker	B
diarization	I
systems	I
is	O
turning	O
away	O
from	O
previously	O
used	O
i	O
-	O
vectors	O
to	O
obtain	O
speaker	B
characteristics	B
for	O
the	O
embedding	O
extraction	B
step	O
(	O
snyder	O
et	O
al	O
.	O
,	O
2017	O
)	O
.	O
this	O
new	O
kind	O
of	O
system	O
is	O
focusing	O
on	O
the	O
use	O
of	O
deep	O
neural	B
network	I
embeddings	O
to	O
distin-	O
guish	O
speaker	B
differences	O
,	O
by	O
mapping	O
variable	O
-	O
length	B
utterances	B
to	O
ﬁxed	O
-	O
dimensional	O
embeddings	O
called	O
x	O
-	O
vectors	O
;	O
however	O
,	O
the	O
challenge	B
is	O
to	O
gather	O
enough	O
training	B
data	I
.	O
2.3.2	O
baseline	B
system	I
the	O
system	O
we	O
use	O
is	O
the	O
baseline	B
system	I
supplied	O
by	O
the	O
second	O
dihard	O
diarization	B
challenge	B
(	O
ryant	O
et	O
al	O
.	O
,	O
2019b	O
)	O
.	O
four	O
different	O
tasks	O
are	O
performed	O
,	O
that	O
is	O
to	O
say	O
speech	O
enhancement	O
,	O
beamforming	O
,	O
speech	B
activity	I
detection	I
,	O
and	O
diarization	B
.	O
firstly	O
,	O
a	O
model	B
is	O
trained	O
to	O
forecast	O
the	O
ideal	O
ratio	O
masks	O
from	O
log	B
-	O
power	O
spectra	O
features	O
using	O
a	O
densely	O
connected	O
long	O
short	O
-	O
term	O
memory	O
architecture	B
,	O
which	O
is	O
a	O
model	B
of	O
deep	O
neural	B
network	I
particularly	O
useful	O
to	O
make	O
predictions	O
.	O
10	O
102.4	O
.	O
libraries	O
and	O
tools	O
chapter	O
2	O
.	O
experimental	O
setup	B
then	O
,	O
weighted	O
delay	O
-	O
and	O
-	O
sum	O
beamforming	O
—	O
a	O
mathematical	O
technique	B
to	O
identify	O
the	O
dis-	O
tance	O
and	O
orientation	O
of	O
sound	O
waves	O
caught	O
by	O
a	O
microphone	O
—	O
is	O
carried	O
out	O
.	O
after	O
that	O
,	O
speech	B
activity	I
detection	I
for	O
tracks	B
2	O
and	O
4	O
is	O
completed	O
thanks	O
to	O
webrtc	O
’s	O
sad	O
,	O
as	O
found	O
in	O
the	O
py	O
-	O
webrtc	O
python	O
package	O
(	O
see	O
2.1.2	O
)	O
.	O
finally	O
,	O
the	O
diarization	B
is	O
achieved	O
by	O
isolating	O
each	O
recording	B
into	O
small	O
overlapping	B
segments	O
,	O
extracting	O
x	O
-	O
vectors	O
,	O
scoring	O
using	O
probabilistic	O
linear	O
discriminant	B
analysis	I
,	O
and	O
clustering	B
with	O
agglomerative	O
hierarchical	O
clustering	B
(	O
see	O
1.3	O
)	O
.	O
2.4	O
libraries	O
and	O
tools	O
this	O
section	O
presents	O
the	O
libraries	O
and	O
tools	O
used	O
in	O
the	O
development	O
of	O
this	O
project	O
.	O
we	O
use	O
audiosegment	O
from	O
the	O
pydub	O
library	O
(	O
robert	O
,	O
webbie	O
,	O
et	O
al	O
.	O
,	O
2018	O
)	O
to	O
arrange	O
the	O
ﬁles	O
for	O
the	O
acoustic	O
analysis	B
.	O
audioﬁle	O
library	O
(	O
wierstorf	O
,	O
2019	O
)	O
enables	O
us	O
to	O
read	O
audio	O
ﬁles	O
in	O
python	O
.	O
the	O
features	O
we	O
analyze	O
are	O
computed	O
with	O
the	O
libraries	O
parselmouth	O
(	O
jadoul	O
,	O
thompson	O
&	O
de	O
boer	O
,	O
2018	O
)	O
and	O
opensmile	O
(	O
eyben	O
,	O
wöllmer	O
&	O
schuller	O
,	O
2010	O
)	O
.	O
the	O
plots	O
are	O
built	O
using	O
the	O
library	O
matplotlib	O
(	O
hunter	O
,	O
2007	O
)	O
with	O
data	B
in	O
pandas	O
(	O
mckinney	O
,	O
2010	O
)	O
format	O
.	O
basic	O
statistics	B
are	O
calculated	O
by	O
the	O
numpy	O
library	O
(	O
harris	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O
sklearn	O
is	O
used	O
to	O
work	O
with	O
data	B
for	O
machine	O
learning	O
,	O
to	O
implement	O
classical	O
machine	O
learning	O
methods	O
,	O
and	O
to	O
train	O
them	O
to	O
predict	O
speech	O
overlap	O
(	O
pedregosa	O
et	O
al	O
.	O
,	O
2011	O
)	O
.	O
finally	O
,	O
pytorch	O
enables	O
us	O
to	O
implement	O
and	O
train	O
deep	B
learning	I
methods	O
(	O
paszke	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
11	O
11chapter	O
3	O
performance	O
impact	O
different	O
experiments	O
are	O
performed	O
to	O
understand	O
how	O
overlapped	B
speech	I
impacts	O
the	O
results	B
of	O
diarization	B
.	O
this	O
chapter	O
focuses	O
on	O
the	O
overlapped	B
speech	I
removal	O
experiment	O
.	O
more	O
precisely	O
,	O
the	O
segments	O
containing	O
overlap	O
are	O
removed	O
to	O
measure	O
the	O
performance	O
of	O
the	O
baseline	B
on	O
the	O
"	O
cleaned	O
"	O
dataset	O
.	O
this	O
is	O
done	O
using	O
the	O
development	O
dataset	O
from	O
dihard	O
ii	O
,	O
presented	O
in	O
2.1	O
(	O
ryant	O
et	O
al	O
.	O
,	O
2019b	O
)	O
.	O
3.1	O
finding	O
and	O
removing	O
overlapped	B
speech	I
segments	O
the	O
ﬁrst	O
step	O
of	O
the	O
experiment	O
was	O
to	O
identify	O
the	O
segments	O
containing	O
overlapped	B
speech	I
.	O
there	O
is	O
a	O
.rttm	O
ﬁle	O
for	O
each	O
audio	O
track	O
,	O
which	O
contains	O
the	O
precise	O
time	B
of	O
beginning	O
and	O
the	O
length	B
of	O
speech	O
for	O
each	O
of	O
the	O
speakers	O
.	O
these	O
.rttm	O
ﬁles	O
are	O
provided	O
as	O
a	O
part	O
of	O
the	O
corpus	B
,	O
because	O
the	O
ﬁrst	O
track	O
condition	B
is	O
a	O
reference	B
sad	O
(	O
see	O
2.1.2	O
)	O
.	O
by	O
comparing	O
these	O
ﬁles	O
,	O
the	O
overlapping	B
segments	O
can	O
be	O
computed	O
.	O
then	O
,	O
the	O
objective	O
was	O
to	O
discard	O
the	O
segments	O
containing	O
overlap	O
.	O
the	O
.uem	O
ﬁles	O
,	O
containing	O
the	O
beginning	O
and	O
end	O
of	O
each	O
audio	O
track	O
,	O
were	O
modiﬁed	O
to	O
keep	O
only	O
segments	O
without	O
any	O
overlapping	B
speech	I
.	O
after	O
that	O
,	O
.rttm	O
and	O
.sad	O
ﬁles	O
,	O
which	O
are	O
ﬁles	O
containing	O
beginning	O
and	O
end	O
of	O
speech	B
segments	I
for	O
each	O
speaker	B
,	O
were	O
adapted	O
according	O
to	O
the	O
new	O
.uem	O
ﬁles	O
.	O
if	O
a	O
.rttm	O
segment	B
did	O
not	O
belong	O
to	O
the	O
new	O
.uem	O
segments	O
,	O
even	O
partially	O
,	O
it	O
was	O
removed	O
.	O
the	O
same	O
logic	O
was	O
applied	O
to	O
.sad	O
ﬁles	O
.	O
the	O
new	O
.uem	O
segments	O
were	O
used	O
to	O
cut	O
the	O
.ﬂac	O
ﬁles	O
and	O
remove	O
any	O
speech	O
overlap	O
.	O
using	O
these	O
newly	O
created	O
.rttm	O
,	O
.uem	O
,	O
.sad	O
and	O
.ﬂac	O
ﬁles	O
,	O
we	O
were	O
ﬁnally	O
able	O
to	O
run	O
the	O
baseline	B
.	O
3.2	O
results	B
on	O
the	O
new	O
data	B
the	O
results	B
we	O
obtained	O
thanks	O
to	O
the	O
baseline	B
were	O
quite	O
surprising	O
,	O
as	O
the	O
median	O
der	O
did	O
not	O
decrease	O
in	O
most	O
cases	O
.	O
the	O
dataset	O
contains	O
12	O
audio	O
categories	O
,	O
as	O
said	O
in	O
2.1.3	O
which	O
are	O
"	O
audiobooks	O
"	O
,	O
"	O
broadcast	O
interview	O
"	O
,	O
"	O
child	O
"	O
,	O
"	O
clinical	O
"	O
,	O
"	O
court	O
"	O
,	O
"	O
maptask	O
"	O
,	O
"	O
meeting	O
"	O
,	O
"	O
restaurant	O
"	O
,	O
"	O
socio	O
ﬁeld	O
"	O
,	O
"	O
socio	O
lab	O
"	O
and	O
"	O
webvideo	O
"	O
.	O
among	O
these	O
categories	O
,	O
only	O
two	O
have	O
an	O
unchanged	O
or	O
reduced	O
error	B
rate	I
.	O
the	O
ﬁrst	O
one	O
,	O
"	O
audiobooks	O
"	O
,	O
contains	O
no	O
overlap	O
so	O
it	O
is	O
logical	O
that	O
the	O
der	O
did	O
not	O
change	B
after	O
removing	O
overlap	O
segments	O
.	O
the	O
second	O
one	O
,	O
"	O
webvideo	O
"	O
,	O
has	O
a	O
slightly	O
better	O
error	B
rate	I
when	O
compared	O
to	O
the	O
category	O
results	B
with	O
overlap	O
segments	O
.	O
the	O
performances	O
in	O
terms	B
of	O
overall	O
der	O
by	O
category	O
,	O
on	O
original	O
data	B
and	O
data	B
with	O
overlap	O
removed	O
,	O
as	O
well	O
as	O
the	O
average	B
percentage	B
of	O
overlap	O
are	O
presented	O
in	O
the	O
following	O
table	O
3.1	O
.	O
123.3	O
.	O
understanding	O
the	O
results	B
chapter	O
3	O
.	O
performance	O
impact	O
category	O
der	O
on	O
original	O
data	B
der	O
on	O
overlap	O
removed	O
percent	O
of	O
overlap	O
audiobooks	O
4	O
1.3	O
0	O
broadcast	O
interview	O
9	O
14.1	O
0.9	O
child	O
31.7	O
37.5	O
7.5	O
clinical	O
18.5	O
40.5	O
2.4	O
court	O
16.3	O
29.3	O
1.6	O
maptask	O
6.7	O
28.2	O
2	O
meeting	O
34.1	O
49	O
21.3	O
restaurant	O
50.5	O
59	O
21.4	O
socio	O
ﬁeld	O
14.7	O
35.4	O
5.7	O
socio	O
lab	O
10.4	O
29.7	O
3.7	O
webvideo	O
38.1	O
35.3	O
17.7	O
table	O
3.1	O
:	O
average	B
der	O
score	B
by	O
category	O
on	O
original	O
data	B
and	O
dataset	O
with	O
overlap	O
removed	O
(	O
dihard	O
ii	O
development	O
dataset	O
)	O
and	O
average	B
percentage	B
of	O
overlap	O
by	O
category	O
.	O
der	O
worsening	O
does	O
not	O
seem	O
to	O
depend	O
on	O
the	O
percentage	B
of	O
overlap	O
.	O
figure	O
3.1	O
:	O
median	O
der	O
for	O
each	O
audio	O
category	O
.	O
most	O
der	O
did	O
not	O
improve	O
after	O
having	O
removed	O
overlapped	O
segments	O
.	O
this	O
table	O
shows	O
no	O
correlation	O
between	O
the	O
average	B
percentage	B
of	O
overlap	O
and	O
the	O
evolution	O
of	O
average	B
der	O
for	O
a	O
category	O
.	O
for	O
example	O
,	O
the	O
category	O
"	O
maptask	O
"	O
with	O
2	O
%	O
of	O
average	B
overlap	O
obtained	O
an	O
average	B
of	O
28.2	O
der	O
after	O
removing	O
overlap	O
,	O
whereas	O
it	O
scored	O
only	O
an	O
average	B
of	O
6.7	O
der	O
with	O
the	O
original	O
data	B
.	O
another	O
example	O
,	O
with	O
a	O
high	O
percentage	B
of	O
overlap	O
such	O
as	O
the	O
category	O
"	O
meeting	O
"	O
which	O
has	O
more	O
than	O
20	O
%	O
of	O
overlap	O
,	O
the	O
average	B
der	O
worsened	O
by	O
15	O
points	O
.	O
to	O
visualize	O
how	O
each	O
average	B
error	B
rate	I
evolves	O
,	O
fig	O
.	O
3.1	O
shows	O
the	O
median	O
of	O
each	O
category	O
before	O
and	O
after	O
removing	O
overlap	O
.	O
3.3	O
understanding	O
the	O
results	B
with	O
such	O
surprising	O
results	B
,	O
the	O
codes	O
and	O
process	B
were	O
reviewed	O
to	O
look	O
for	O
any	O
mistake	O
.	O
we	O
made	O
a	O
graph	O
to	O
ﬁnd	O
any	O
correlation	O
between	O
the	O
length	B
of	O
a	O
segment	B
and	O
its	O
performance	O
(	O
see	O
fig	O
.	O
3.2	O
)	O
.	O
for	O
each	O
ﬁle	O
,	O
we	O
computed	O
the	O
length	B
of	O
the	O
audio	O
segments	O
that	O
have	O
been	O
removed	O
and	O
compared	O
it	O
to	O
the	O
difference	O
of	O
der	O
from	O
original	O
data	B
to	O
non	O
-	O
overlap	O
.	O
there	O
seems	O
to	O
be	O
no	O
real	O
correlation	O
in	O
the	O
graph	O
,	O
so	O
a	O
shorter	O
audio	O
can	O
not	O
explain	O
why	O
the	O
new	O
performance	O
measures	O
are	O
so	O
low	O
.	O
13	O
133.3	O
.	O
understanding	O
the	O
results	B
chapter	O
3	O
.	O
performance	O
impact	O
figure	O
3.2	O
:	O
mapping	O
of	O
the	O
der	O
improvement	O
and	O
the	O
length	B
difference	O
for	O
each	O
ﬁle	O
(	O
from	O
the	O
unchanged	O
dataset	O
to	O
the	O
segments	O
without	O
overlap	O
)	O
.	O
it	O
is	O
not	O
possible	O
to	O
identify	O
a	O
clear	O
correlation	O
between	O
the	O
amount	B
of	O
speech	O
removed	O
and	O
the	O
worsening	O
of	O
the	O
performance	O
.	O
figure	O
3.3	O
:	O
mapping	O
of	O
the	O
average	B
der	O
difference	O
and	O
the	O
average	B
percentage	B
of	O
overlap	O
by	O
category	O
.	O
we	O
can	O
not	O
observe	O
a	O
clear	O
correlation	O
between	O
the	O
percentage	B
of	O
overlap	O
and	O
the	O
der	O
worsening	O
.	O
14	O
143.4	O
.	O
summary	O
chapter	O
3	O
.	O
performance	O
impact	O
in	O
addition	O
to	O
this	O
,	O
we	O
created	O
fig	O
.	O
3.3	O
to	O
compare	O
the	O
average	B
percentage	B
of	O
overlap	O
on	O
the	O
original	O
data	B
to	O
the	O
average	B
der	O
difference	O
between	O
original	O
data	B
and	O
data	B
without	O
overlap	O
for	O
each	O
category	O
.	O
first	O
,	O
we	O
computed	O
the	O
average	B
der	O
per	O
category	O
,	O
then	O
we	O
subtracted	O
the	O
scores	O
from	O
non	O
-	O
overlap	O
der	O
to	O
the	O
scores	O
from	O
original	O
der	O
.	O
finally	O
,	O
this	O
difference	O
is	O
compared	O
to	O
the	O
average	B
percentage	B
of	O
overlap	O
.	O
once	O
more	O
,	O
we	O
do	O
not	O
observe	O
a	O
clear	O
correlation	O
which	O
could	O
explain	O
the	O
der	O
worsening	O
.	O
3.4	O
summary	O
this	O
performance	O
experiment	O
resulted	O
differently	O
from	O
what	O
we	O
expected	O
,	O
as	O
we	O
thought	O
removing	O
overlap	O
regions	O
should	O
reduce	O
diarization	B
errors	B
.	O
different	O
studies	O
have	O
been	O
made	O
to	O
understand	O
why	O
the	O
performance	O
was	O
so	O
low	O
,	O
but	O
no	O
correlation	O
was	O
found	O
to	O
explain	O
it	O
.	O
the	O
cause	O
for	O
poor	O
diarization	B
results	B
can	O
be	O
a	O
combination	O
of	O
different	O
elements	O
,	O
such	O
as	O
the	O
length	B
of	O
audio	O
removed	O
and	O
the	O
percentage	B
of	O
overlap	O
,	O
or	O
it	O
can	O
be	O
a	O
more	O
complex	O
one	O
.	O
as	O
said	O
in	O
our	O
previous	O
report	O
,	O
"	O
when	O
an	O
amount	B
of	O
overlap	O
is	O
big	O
,	O
it	O
makes	O
it	O
harder	O
for	O
the	O
model	B
even	O
to	O
perform	O
diarization	B
on	O
the	O
non	O
-	O
overlap	O
regions	O
,	O
even	O
though	O
those	O
regions	O
are	O
usually	O
easier	O
for	O
the	O
model	B
"	O
,	O
which	O
means	O
the	O
overlap	O
has	O
an	O
inﬂuence	O
on	O
the	O
whole	O
dataset	O
(	O
diliberto	O
,	O
pereira	O
&	O
nikiforovskaja	O
,	O
2021	O
)	O
.	O
in	O
addition	O
to	O
this	O
,	O
it	O
needs	O
to	O
be	O
recalled	O
that	O
overlap	O
regions	O
have	O
been	O
removed	O
but	O
noises	O
,	O
such	O
as	O
background	B
noise	I
,	O
are	O
still	O
present	O
and	O
can	O
make	O
the	O
task	O
more	O
difﬁcult	O
.	O
from	O
these	O
results	B
,	O
we	O
can	O
infer	O
that	O
removing	O
overlap	O
regions	O
and	O
retraining	O
the	O
model	B
on	O
the	O
dataset	O
without	O
overlap	O
is	O
not	O
a	O
viable	O
approach	O
.	O
this	O
experiment	O
differs	O
from	O
the	O
results	B
shown	O
in	O
the	O
tables	O
from	O
our	O
last	O
report	O
,	O
as	O
these	O
results	B
were	O
obtained	O
without	O
running	O
the	O
baseline	B
again	O
;	O
in	O
other	O
words	B
,	O
without	O
retraining	O
the	O
model	B
on	O
the	O
newly	O
obtained	O
data	B
without	O
overlapping	B
segments	O
(	O
diliberto	O
,	O
pereira	O
&	O
nikiforovskaja	O
,	O
2021	O
)	O
.	O
to	O
further	O
explain	O
the	O
results	B
from	O
this	O
chapter	O
,	O
the	O
acoustic	B
features	I
are	O
explored	O
in	O
the	O
next	O
part	O
.	O
we	O
identify	O
features	O
impacted	O
by	O
overlap	O
and	O
having	O
a	O
direct	O
link	O
with	O
diarization	B
errors	B
.	O
15	O
15chapter	O
4	O
acoustic	O
impact	O
acoustic	B
features	I
can	O
be	O
impacted	O
by	O
overlapping	B
segments	O
and	O
reduce	O
the	O
performance	O
of	O
diariza-	O
tion	O
(	O
diliberto	O
,	O
pereira	O
&	O
nikiforovskaja	O
,	O
2021	O
)	O
.	O
thus	O
we	O
have	O
decided	O
to	O
identify	O
which	O
acoustic	B
features	I
are	O
impacted	O
by	O
overlapping	B
speech	I
.	O
it	O
will	O
help	O
to	O
understand	O
why	O
it	O
is	O
so	O
difﬁcult	O
to	O
apply	O
a	O
speech	O
diarization	B
method	B
on	O
overlap	O
speech	O
samples	O
.	O
experiments	O
are	O
run	O
on	O
the	O
dihard	O
ii	O
development	O
dataset	O
to	O
compare	O
many	O
features	O
computed	O
on	O
the	O
overlap	O
and	O
non	O
-	O
overlap	O
samples	O
.	O
in	O
this	O
section	O
,	O
features	O
will	O
be	O
called	O
discriminative	O
when	O
they	O
are	O
impacted	O
by	O
overlap	O
.	O
4.1	O
splitting	O
audio	O
ﬁles	O
the	O
ﬁrst	O
step	O
was	O
to	O
split	O
the	O
audio	O
ﬁles	O
.	O
we	O
needed	O
to	O
have	O
separated	O
ﬁles	O
with	O
or	O
without	O
overlapping	B
speech	I
.	O
using	O
.rttm	O
ﬁles	O
,	O
we	O
found	O
the	O
overlap	O
or	O
non	O
-	O
overlap	O
segments	O
in	O
single	O
audio	O
channels	B
by	O
calculating	O
the	O
periods	O
in	O
which	O
more	O
than	O
one	O
speaker	B
was	O
active	O
.	O
then	O
,	O
we	O
joined	O
all	O
non	O
-	O
overlapped	O
segments	O
together	O
and	O
exported	O
them	O
using	O
audiosegment	O
from	O
the	O
pydub	O
library	O
,	O
and	O
we	O
did	O
the	O
same	O
thing	O
for	O
overlapped	O
segments	O
.	O
from	O
one	O
audio	O
,	O
we	O
obtained	O
three	O
ﬁles	O
:	O
the	O
complete	O
audio	O
,	O
with	O
both	O
overlap	O
and	O
non	O
-	O
overlap	O
segments	O
,	O
the	O
non	O
-	O
overlapping	B
audio	O
,	O
and	O
the	O
overlapping	B
one	O
.	O
with	O
these	O
ﬁles	O
,	O
we	O
could	O
then	O
compute	O
a	O
few	O
acoustic	B
features	I
and	O
compare	O
the	O
results	B
be-	O
tween	O
the	O
overlap	O
or	O
non	O
-	O
overlap	O
versions	O
of	O
the	O
same	O
ﬁle	O
.	O
this	O
would	O
allow	O
us	O
to	O
understand	O
if	O
,	O
with	O
the	O
same	O
parameters	O
(	O
speakers	O
,	O
environment	O
,	O
etc	O
.	O
)	O
,	O
there	O
is	O
a	O
difference	O
between	O
the	O
seg-	O
ments	O
when	O
only	O
one	O
speaker	B
is	O
talking	O
,	O
and	O
the	O
ones	O
when	O
at	O
least	O
two	O
speakers	O
are	O
talking	O
at	O
the	O
same	O
time	B
.	O
at	O
ﬁrst	O
,	O
we	O
used	O
every	O
single	B
channel	I
audio	O
ﬁle	O
from	O
the	O
development	O
part	O
of	O
the	O
dataset	O
to	O
get	O
a	O
large	O
amount	B
of	O
data	B
(	O
192	O
audio	O
ﬁles	O
in	O
total	O
)	O
.	O
however	O
,	O
we	O
observed	O
that	O
the	O
"	O
audiobook	O
"	O
ﬁles	O
were	O
composed	O
of	O
only	O
one	O
speaker	B
and	O
that	O
we	O
would	O
n’t	O
ﬁnd	O
any	O
overlap	O
segment	B
in	O
this	O
category	O
.	O
we	O
decided	O
to	O
remove	O
these	O
ﬁles	O
because	O
it	O
was	O
not	O
possible	O
to	O
compare	O
the	O
overlap	O
and	O
non	O
-	O
overlap	O
versions	O
of	O
the	O
same	O
audio	O
.	O
4.2	O
calculated	O
features	O
we	O
used	O
two	O
different	O
libraries	O
to	O
compute	O
the	O
features	O
.	O
with	O
parselmouth	O
library	O
we	O
computed	O
the	O
pitch	B
,	O
which	O
was	O
identiﬁed	O
in	O
our	O
previous	O
report	O
as	O
being	O
one	O
of	O
the	O
main	O
features	O
impacted	O
by	O
overlapping	B
speech	I
(	O
diliberto	O
,	O
pereira	O
&	O
nikiforovskaja	O
,	O
2021	O
)	O
.	O
opensmile	O
library	O
enabled	O
us	O
to	O
compute	O
89	O
different	O
features	O
on	O
our	O
audio	O
ﬁles	O
(	O
see	O
the	O
list	O
of	O
features	O
in	O
fig	O
.	O
4.1	O
)	O
.	O
164.2	O
.	O
calculated	O
features	O
chapter	O
4	O
.	O
acoustic	O
impact	O
category	O
detailed	O
feature	O
amean	O
stddev	B
norm	B
percentile	O
20.0	O
percentile	O
50.0	O
percentile	O
80.0	O
f0	O
semitone	O
from	O
27.5hz	O
pctl	O
range	O
0	O
-	O
2	O
mean	O
rising	O
slope	O
stddev	B
rising	O
slope	O
mean	O
falling	O
slope	O
stddev	B
falling	O
slope	O
amean	O
stddev	B
norm	B
percentile	O
20.0	O
percentile	O
50.0	O
percentile	O
80.0	O
loudness	O
pctl	O
range	O
0	O
-	O
2	O
mean	O
rising	O
slope	O
stddev	B
rising	O
slope	O
mean	O
falling	O
slope	O
stddev	B
falling	O
slope	O
peaks	B
per	O
sec	O
amean	O
stddev	B
norm	B
spectral	O
flux	O
v	O
amean	O
v	O
stddev	B
norm	B
uv	O
amean	O
mfcc1	O
amean	O
mfcc1	O
stddev	B
norm	B
mfcc2	O
amean	O
mfcc2	O
stddev	B
norm	B
mfcc3	O
amean	O
mfcc3	O
stddev	B
norm	B
mfcc4	O
amean	O
mfcc4	O
stddev	B
norm	B
mfcc	O
mfcc1v	O
amean	O
mfcc1v	O
stddev	B
norm	B
mfcc2v	O
amean	O
mfcc2v	O
stddev	B
norm	B
mfcc3v	O
amean	O
mfcc3v	O
stddev	B
norm	B
mfcc4v	O
amean	O
mfcc4v	O
stddev	B
norm	B
amean	O
jitter	O
local	O
stddev	B
norm	B
amean	O
shimmer	O
local	O
stddev	B
norm	B
amean	O
hnrdbacf	O
stddev	B
norm	B
h2	O
amean	O
h2	O
stddev	B
norm	B
logrel	O
-	O
f0-h1	O
a3	O
amean	O
a3	O
stddev	B
norm	B
17	O
174.3	O
.	O
visual	O
results	B
chapter	O
4	O
.	O
acoustic	O
impact	O
frequency	B
amean	O
frequency	B
stddev	B
norm	B
bandwidth	O
amean	O
f1	O
bandwidth	O
stddev	B
norm	B
amplitude	O
logrelf0	O
amean	O
amplitude	O
logrelf0	O
stddev	B
norm	B
frequency	B
amean	O
frequency	B
stddev	B
norm	B
bandwidth	O
amean	O
f2	O
bandwidth	O
stddev	B
norm	B
amplitude	O
logrelf0	O
amean	O
amplitude	O
logrelf0	O
stddev	B
norm	B
frequency	B
amean	O
frequency	B
stddev	B
norm	B
bandwidth	O
amean	O
f3	O
bandwidth	O
stddev	B
norm	B
amplitude	O
logrelf0	O
amean	O
amplitude	O
logrelf0	O
stddev	B
norm	B
v	O
amean	O
alpha	O
ratio	O
v	O
stddev	B
norm	B
uv	O
amean	O
v	O
amean	O
hammarberg	O
index	O
v	O
stddev	B
norm	B
uv	O
amean	O
v0	O
-	O
500	O
amean	O
v0	O
-	O
500	O
stddev	B
norm	B
slope	O
v500	O
-	O
1500	O
amean	O
v500	O
-	O
1500	O
stddev	B
norm	B
uv0	O
-	O
500	O
amean	O
uv500	O
-	O
1500	O
amean	O
voiced	O
segments	O
per	O
sec	O
mean	O
voiced	O
segment	B
length	B
per	O
sec	O
voicing	O
stddev	B
voiced	O
segment	B
length	B
per	O
sec	O
mean	O
unvoiced	O
segment	B
length	B
per	O
sec	O
stddev	B
unvoiced	O
segment	B
lenght	O
per	O
sec	O
equivalent	O
sound	O
level	B
pitch	B
table	O
4.1	O
:	O
acoustic	B
features	I
computed	O
.	O
4.3	O
visual	O
results	B
these	O
90	O
features	O
were	O
computed	O
on	O
each	O
audio	O
(	O
complete	O
,	O
overlap	O
,	O
and	O
non	O
-	O
overlap	O
)	O
of	O
each	O
category	O
,	O
and	O
visualized	O
with	O
histograms	O
to	O
get	O
a	O
ﬁrst	O
opinion	O
on	O
what	O
are	O
the	O
most	O
discriminative	O
features	O
.	O
for	O
this	O
analysis	B
,	O
we	O
also	O
removed	O
the	O
"	O
broadcast	O
interview	O
"	O
audio	O
ﬁles	O
,	O
because	O
the	O
mean	O
of	O
overlapped	O
percentage	B
in	O
this	O
category	O
is	O
0.86	O
%	O
.	O
as	O
can	O
be	O
seen	O
in	O
fig	O
.	O
4.1	O
,	O
the	O
values	B
of	O
pitch	B
look	O
very	O
different	O
when	O
dealing	O
with	O
overlapped	B
speech	I
and	O
with	O
non	O
-	O
overlapped	O
.	O
pitch	B
results	B
from	O
the	O
tension	O
of	O
the	O
vibration	O
of	O
the	O
vocal	O
folds	O
and	O
is	O
closely	O
related	O
to	O
the	O
fundamental	O
frequency	B
f0	O
(	O
aung	O
&	O
puts	O
,	O
2020	O
)	O
.	O
for	O
each	O
ﬁle	O
,	O
the	O
pitch	B
value	O
of	O
overlapped	O
segments	O
is	O
at	O
least	O
100	O
hz	O
higher	O
than	O
the	O
one	O
for	O
non	O
-	O
overlapped	O
segments	O
.	O
we	O
can	O
assume	O
this	O
disparity	O
is	O
one	O
of	O
the	O
reasons	O
why	O
it	O
is	O
so	O
difﬁcult	O
to	O
apply	O
diarization	B
on	O
overlapped	B
speech	I
.	O
18	O
184.4	O
.	O
statistical	O
results	B
chapter	O
4	O
.	O
acoustic	O
impact	O
as	O
for	O
the	O
pitch	B
,	O
we	O
can	O
see	O
in	O
fig	O
.	O
4.2	O
a	O
large	O
variation	O
in	O
loudness	O
peaks	B
per	O
second	O
for	O
overlapped	O
and	O
non	O
-	O
overlapped	O
.	O
when	O
multiple	O
speakers	O
are	O
talking	O
at	O
the	O
same	O
time	B
,	O
it	O
seems	O
there	O
are	O
more	O
loudness	O
peaks	B
in	O
the	O
speech	O
.	O
similarly	O
,	O
fig	O
.	O
4.3	O
represents	O
the	O
comparison	O
between	O
the	O
voiced	O
segments	O
per	O
second	O
in	O
over-	O
lapped	O
and	O
non	O
-	O
overlapped	B
speech	I
samples	O
.	O
the	O
number	O
of	O
voiced	O
segments	O
looks	O
higher	O
for	O
each	O
overlapped	O
audio	O
ﬁle	O
than	O
the	O
number	O
for	O
the	O
corresponding	O
non	O
-	O
overlapped	O
ﬁle	O
.	O
figure	O
4.1	O
:	O
pitch	B
values	B
for	O
overlapped	O
and	O
non	O
-	O
overlapped	B
speech	I
samples	O
in	O
the	O
category	O
"	O
restaurant	O
"	O
.	O
4.4	O
statistical	O
results	B
for	O
the	O
statistical	O
analysis	B
of	O
features	O
,	O
we	O
decided	O
to	O
keep	O
only	O
the	O
ﬁles	O
with	O
a	O
percentage	B
of	O
overlap	O
higher	O
than	O
20	O
%	O
to	O
be	O
sure	O
our	O
results	B
were	O
consistent	O
.	O
according	O
to	O
this	O
condition	B
,	O
the	O
analysis	B
was	O
performed	O
on	O
26	O
ﬁles	O
from	O
the	O
following	O
categories	O
:	O
3	O
from	O
"	O
child	O
"	O
,	O
6	O
from	O
"	O
meeting	O
"	O
,	O
7	O
from	O
"	O
restaurant	O
"	O
,	O
10	O
from	O
"	O
webvideo	O
"	O
.	O
table	O
4.2	O
shows	O
the	O
statistical	O
values	B
of	O
some	O
features	O
we	O
selected	O
using	O
these	O
26	O
ﬁles	O
.	O
in	O
our	O
table	O
,	O
the	O
ratio	O
corresponds	O
to	O
the	O
quotient	O
of	O
the	O
non	O
-	O
overlap	O
mean	O
(	O
or	O
median	O
)	O
over	O
the	O
overlap	O
mean	O
(	O
or	O
median	O
)	O
.	O
when	O
this	O
ratio	O
is	O
higher	O
than	O
1	O
,	O
it	O
means	O
that	O
the	O
values	B
increase	O
when	O
there	O
is	O
overlap	O
,	O
in	O
comparison	O
to	O
non	O
-	O
overlap	O
.	O
the	O
higher	O
the	O
ratio	O
is	O
,	O
the	O
more	O
discriminative	O
the	O
feature	O
is	O
(	O
i.e.	O
values	B
differ	O
a	O
lot	O
from	O
"	O
normal	O
values	B
"	O
when	O
there	O
is	O
overlapping	B
speech	I
)	O
.	O
oppositely	O
,	O
if	O
it	O
is	O
lower	O
than	O
1	O
,	O
it	O
means	O
that	O
the	O
values	B
decrease	O
,	O
and	O
the	O
lower	O
the	O
ratio	O
is	O
,	O
the	O
more	O
discriminative	O
the	O
feature	O
is	O
.	O
nov	O
refers	O
to	O
non	O
-	O
overlapped	B
speech	I
while	O
ov	O
refers	O
to	O
overlapped	B
speech	I
.	O
we	O
listed	O
here	O
the	O
most	O
discriminative	O
features	O
.	O
4.5	O
discriminative	O
features	O
one	O
can	O
see	O
in	O
table	O
4.2	O
that	O
the	O
pitch	B
value	O
differs	O
a	O
lot	O
between	O
overlap	O
and	O
non	O
-	O
overlap	O
seg-	O
ments	O
.	O
there	O
is	O
an	O
increase	O
of	O
46	O
%	O
in	O
the	O
mean	O
of	O
overlap	O
in	O
comparison	O
to	O
the	O
non	O
-	O
overlap	O
one	O
19	O
194.6	O
.	O
summary	O
chapter	O
4	O
.	O
acoustic	O
impact	O
figure	O
4.2	O
:	O
loudness	O
peaks	B
per	O
second	O
for	O
overlapped	O
and	O
non	O
-	O
overlapped	B
speech	I
samples	O
in	O
the	O
category	O
"	O
webvideo	O
"	O
.	O
and	O
71	O
%	O
for	O
the	O
median	O
.	O
however	O
,	O
the	O
standard	O
deviation	O
remains	O
similar	O
which	O
means	O
that	O
the	O
variation	O
of	O
the	O
values	B
does	O
n’t	O
increase	O
.	O
the	O
spectral	O
flux	O
measures	O
the	O
degree	O
of	O
variation	O
in	O
the	O
spectrum	B
across	O
time	B
(	O
sadjadi	O
&	O
hansen	O
,	O
2013	O
)	O
.	O
it	O
is	O
very	O
discriminative	O
for	O
overlap	O
as	O
we	O
can	O
see	O
:	O
the	O
mean	O
increases	O
by	O
47	O
%	O
and	O
the	O
median	O
by	O
60	O
%	O
.	O
similarly	O
,	O
the	O
overlap	O
values	B
of	O
the	O
spectral	O
slope	O
—	O
the	O
logarithmic	O
power	O
of	O
the	O
mel	O
band	O
—	O
are	O
really	O
distinct	O
from	O
the	O
non	O
-	O
overlap	O
ones	O
(	O
increase	O
of	O
39	O
%	O
for	O
mean	O
and	O
65	O
%	O
for	O
median	O
)	O
,	O
as	O
well	O
as	O
for	O
the	O
fundamental	O
frequency	B
f0	O
(	O
increase	O
of	O
35	O
%	O
for	O
mean	O
and	O
44	O
%	O
for	O
median	O
)	O
(	O
zheng	O
,	O
wang	O
&	O
jia	O
,	O
2020	O
)	O
.	O
as	O
could	O
be	O
supposed	O
,	O
the	O
loudness	O
,	O
the	O
length	B
of	O
unvoiced	O
segments	O
,	O
and	O
the	O
rate	O
of	O
voiced	O
segments	O
are	O
also	O
impacted	O
by	O
overlap	O
.	O
when	O
many	O
people	O
talk	O
at	O
the	O
same	O
time	B
,	O
the	O
ambient	O
is	O
noisier	O
.	O
the	O
voicing	O
(	O
voiced	O
and	O
unvoiced	O
segments	O
)	O
corresponds	O
to	O
the	O
vibration	O
(	O
or	O
not	O
)	O
of	O
the	O
vocal	O
folds	O
.	O
the	O
more	O
people	O
are	O
talking	O
,	O
the	O
more	O
voiced	O
speech	O
is	O
detected	O
,	O
which	O
explains	O
why	O
the	O
mean	O
length	B
of	O
unvoiced	O
segments	O
decreases	O
with	O
overlap	O
while	O
the	O
number	O
of	O
voiced	O
segments	O
per	O
second	O
increases	O
.	O
4.6	O
summary	O
at	O
this	O
stage	B
,	O
we	O
identiﬁed	O
six	O
features	O
that	O
are	O
impacted	O
a	O
lot	O
by	O
overlap	O
:	O
pitch	B
,	O
spectral	O
ﬂux	O
,	O
fundamental	O
frequency	B
,	O
loudness	O
,	O
spectral	O
slope	O
,	O
and	O
unvoiced	O
or	O
voiced	O
segments	O
.	O
these	O
features	O
compute	O
values	B
that	O
are	O
dissimilar	O
to	O
non	O
-	O
overlap	O
ones	O
,	O
as	O
they	O
are	O
greatly	O
higher	O
or	O
lower	O
.	O
from	O
this	O
analysis	B
,	O
we	O
can	O
conclude	O
they	O
certainly	O
impact	O
the	O
performance	O
of	O
speaker	B
diarization	I
methods	O
applied	O
on	O
overlapped	B
speech	I
.	O
to	O
improve	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
,	O
a	O
new	O
perspective	O
could	O
be	O
to	O
base	O
a	O
model	B
on	O
non	O
discriminative	O
features	O
.	O
20	O
204.6	O
.	O
summary	O
chapter	O
4	O
.	O
acoustic	O
impact	O
figure	O
4.3	O
:	O
voiced	O
segments	O
per	O
second	O
for	O
overlapped	O
and	O
non	O
-	O
overlapped	B
speech	I
samples	O
in	O
the	O
category	O
"	O
webvideo	O
"	O
.	O
mean	O
median	O
std	O
dev	O
feature	O
nov	O
ov	O
ratio	O
nov	O
ov	O
ratio	O
nov	O
ov	O
pitch	B
439	O
641	O
1.46	O
367	O
628	O
1.71	O
218	O
233	O
spectralflux	O
:	O
amean	O
0.32	O
0.47	O
1.46	O
0.23	O
0.36	O
1.60	O
0.22	O
0.30	O
f0	O
:	O
meanfallingslope	O
98	O
132	O
1.35	O
88	O
127	O
1.44	O
43	O
56	O
loudness	O
:	O
amean	O
0.73	O
0.99	O
1.34	O
0.59	O
0.82	O
1.39	O
0.46	O
0.56	O
slopev0	O
-	O
500	O
:	O
amean	O
0.015	O
0.02	O
1.39	O
0.008	O
0.01	O
1.65	O
0.03	O
0.03	O
unvoiced	O
seg	O
len	O
:	O
mean	O
0.41	O
0.24	O
0.59	O
0.31	O
0.19	O
0.61	O
0.25	O
0.13	O
voiced	O
seg	O
/	O
sec	O
1.93	O
2.78	O
1.44	O
2.01	O
2.62	O
1.32	O
0.56	O
0.76	O
table	O
4.2	O
:	O
statistical	O
results	B
of	O
some	O
features	O
based	O
on	O
the	O
study	O
of	O
26	O
ﬁles	O
.	O
21	O
21chapter	O
5	O
overlap	O
detectors	O
5.1	O
introduction	O
overlapping	B
segments	O
can	O
drastically	O
reduce	O
the	O
quality	B
of	O
performance	O
(	O
diliberto	O
,	O
pereira	O
&	O
niki-	O
forovskaja	O
,	O
2021	O
)	O
.	O
thus	O
we	O
have	O
decided	O
to	O
experiment	O
on	O
overlap	B
detection	I
to	O
improve	O
the	O
performance	O
.	O
the	O
main	O
idea	O
is	O
to	O
develop	O
a	O
classiﬁer	O
which	O
would	O
detect	O
if	O
a	O
segment	B
of	O
the	O
recording	B
contains	O
overlap	O
or	O
not	O
.	O
overlap	B
detection	I
is	O
usually	O
performed	O
in	O
one	O
of	O
these	O
three	O
ways	O
:	O
with	O
signal	B
processing	I
,	O
sta-	O
tistical	O
methods	O
or	O
deep	B
learning	I
.	O
the	O
most	O
popular	O
and	O
effective	O
classiﬁers	O
currently	O
are	O
deep	B
learning	I
based	O
(	O
diliberto	O
,	O
pereira	O
&	O
nikiforovskaja	O
,	O
2021	O
)	O
.	O
the	O
lstm	O
-	O
based	O
(	O
bullock	O
,	O
bredin	O
&	O
garcia	O
-	O
perera	O
,	O
2020	O
;	O
yoshioka	O
et	O
al	O
.	O
,	O
2018	O
)	O
and	O
cnn	O
-	O
based	O
methods	O
(	O
kunešová	O
et	O
al	O
.	O
,	O
2019	O
;	O
an-	O
drei	O
,	O
cucu	O
&	O
burileanu	O
,	O
2019	O
;	O
málek	O
&	O
žd’ánsky	O
,	O
2020	O
)	O
are	O
especially	O
popular	O
.	O
x	O
-	O
vectors	O
are	O
embeddings	O
for	O
recording	B
segments	O
which	O
were	O
trained	O
by	O
cnn	O
.	O
it	O
was	O
shown	O
that	O
usage	O
of	O
x	O
-	O
vectors	O
can	O
improve	O
the	O
performance	O
,	O
as	O
they	O
might	O
contain	O
more	O
information	B
than	O
only	O
about	O
single	O
speakers	O
(	O
málek	O
&	O
žd’ánsky	O
,	O
2020	O
)	O
.	O
we	O
want	O
to	O
further	O
explore	O
their	O
usage	O
for	O
overlap	B
detection	I
with	O
different	O
models	B
.	O
in	O
this	O
chapter	O
we	O
describe	O
the	O
prepared	O
data	B
,	O
the	O
models	B
used	O
around	O
x	O
-	O
vectors	O
,	O
the	O
testing	O
system	O
architecture	B
,	O
and	O
ﬁnally	O
the	O
evaluation	B
of	O
the	O
chosen	O
methods	O
.	O
5.2	O
classiﬁcation	O
methods	O
idea	O
the	O
main	O
idea	O
was	O
to	O
use	O
x	O
-	O
vectors	O
as	O
the	O
embedding	O
vectors	O
of	O
the	O
audio	O
segments	O
to	O
classify	O
those	O
segments	O
into	O
overlap	O
and	O
non	O
overlap	O
.	O
however	O
,	O
as	O
shown	O
in	O
fig	O
.	O
5.1	O
the	O
percentage	B
of	O
overlap	O
in	O
the	O
segment	B
is	O
quite	O
often	O
not	O
100	O
%	O
.	O
that	O
is	O
why	O
we	O
have	O
decided	O
to	O
divide	O
the	O
segments	O
not	O
into	O
two	O
groups	O
for	O
classiﬁcation	O
,	O
but	O
into	O
several	O
,	O
so	O
that	O
we	O
could	O
have	O
more	O
information	B
about	O
the	O
segments	O
automatically	O
.	O
5.3	O
experimental	O
setup	B
5.3.1	O
data	B
organization	O
we	O
exploited	O
already	O
computed	O
x	O
-	O
vectors	O
on	O
development	B
data	I
as	O
a	O
source	B
material	O
.	O
we	O
used	O
the	O
following	O
categories	O
of	O
recordings	O
from	O
the	O
dataset	O
to	O
train	O
and	O
evaluate	O
our	O
methods	O
:	O
"	O
webvideo	O
"	O
,	O
"	O
meeting	O
"	O
,	O
and	O
"	O
restaurant	O
"	O
.	O
these	O
categories	O
contain	O
quite	O
a	O
lot	O
of	O
overlap	O
segments	O
which	O
are	O
of	O
a	O
decent	O
quality	B
,	O
this	O
explains	O
why	O
we	O
used	O
them	O
.	O
for	O
each	O
segment	B
for	O
which	O
we	O
had	O
an	O
x	O
-	O
vector	O
,	O
we	O
calculated	O
the	O
ratio	O
of	O
the	O
overlap	O
part	O
on	O
225.3	O
.	O
experimental	O
setup	B
chapter	O
5	O
.	O
overlap	O
detectors	O
figure	O
5.1	O
:	O
distribution	O
of	O
ratio	O
of	O
overlap	O
.	O
colors	O
show	O
the	O
way	O
we	O
have	O
divided	O
the	O
ratios	O
into	O
classes	O
.	O
this	O
segment	B
.	O
and	O
therefore	O
we	O
produced	O
the	O
ratio	O
which	O
can	O
be	O
predicted	O
.	O
also	O
,	O
for	O
each	O
ratio	O
we	O
decided	O
to	O
which	O
class	O
it	O
belongs	O
,	O
so	O
that	O
we	O
had	O
a	O
classiﬁcation	O
problem	O
,	O
as	O
our	O
ﬁnal	O
goal	O
is	O
to	O
predict	O
if	O
there	O
is	O
or	O
is	O
not	O
an	O
overlap	O
.	O
afterwards	O
,	O
we	O
built	O
a	O
dataset	O
with	O
the	O
following	O
parameters	O
:	O
number	O
of	O
segments	O
information	B
to	O
take	O
before	O
the	O
goal	O
segment	B
,	O
number	O
of	O
segments	O
information	B
to	O
take	O
after	O
the	O
goal	O
segment	B
,	O
and	O
the	O
identiﬁcation	O
numbers	O
of	O
the	O
ﬁle	O
where	O
the	O
segments	O
are	O
taken	O
from	O
.	O
then	O
we	O
had	O
two	O
variants	O
:	O
either	O
to	O
have	O
classes	O
to	O
predict	O
or	O
the	O
ratio	O
itself	O
.	O
the	O
ratio	O
intervals	O
of	O
the	O
classes	O
are	O
calculated	O
using	O
the	O
following	O
formula	O
.	O
if	O
the	O
ratio	O
is	O
smaller	O
than	O
0.1	O
then	O
the	O
class	O
is	O
0	O
.	O
otherwise	O
the	O
classes	O
are	O
equally	O
distributed	O
on	O
the	O
segment	B
[	O
0.1	O
,	O
1	O
]	O
and	O
are	O
calculated	O
with	O
the	O
formula	O
1	O
+	O
min(3	O
,	O
(	O
cid:98)(r	O
−	O
0.1	O
)	O
·	O
4(cid:99	O
)	O
)	O
,	O
where	O
r	O
is	O
the	O
overlap	O
ratio	O
.	O
therefore	O
we	O
have	O
5	O
classes	O
of	O
overlap	O
.	O
the	O
development	B
data	I
is	O
divided	O
into	O
train	O
and	O
test	B
parts	O
in	O
the	O
proportion	O
of	O
7:3	O
.	O
we	O
divided	O
the	O
segments	O
into	O
these	O
two	O
groups	O
such	O
that	O
all	O
the	O
segments	O
of	O
one	O
ﬁle	O
belong	O
to	O
the	O
same	O
group	O
.	O
5.3.2	O
architecture	B
we	O
used	O
object	O
oriented	O
programming	O
to	O
organize	O
our	O
code	O
so	O
that	O
it	O
was	O
easy	O
to	O
modify	O
.	O
there	O
are	O
base	O
classes	O
for	O
regression	B
and	O
classiﬁcation	O
methods	O
,	O
which	O
contain	O
several	O
evaluation	B
methods	O
inside	O
.	O
from	O
each	O
base	O
class	O
,	O
classes	O
from	O
sklearn	O
(	O
pedregosa	O
et	O
al	O
.	O
,	O
2011	O
)	O
and	O
pytorch	O
(	O
paszke	O
et	O
al	O
.	O
,	O
2019	O
)	O
algorithms	O
are	O
inherited	O
.	O
the	O
class	O
for	O
sklearn	O
algorithm	O
allows	O
to	O
run	O
all	O
the	O
needed	O
functionalities	O
,	O
by	O
passing	O
the	O
name	O
of	O
the	O
sklearn	O
method	B
and	O
its	O
parameters	O
.	O
the	O
class	O
for	O
pytorch	O
algorithms	O
allows	O
to	O
run	O
pytorch	O
models	B
by	O
passing	O
the	O
base	O
model	B
itself	O
,	O
optimizer	O
,	O
epochs	O
and	O
the	O
device	O
to	O
run	O
on	O
.	O
the	O
described	O
above	O
scheme	O
of	O
the	O
classes	O
can	O
be	O
seen	O
on	O
fig	O
.	O
5.2	O
.	O
all	O
the	O
introduced	O
algorithms	O
take	O
x	O
-	O
vectors	O
as	O
an	O
input	B
as	O
can	O
be	O
seen	O
in	O
fig	O
.	O
5.3	O
.	O
however	O
,	O
classiﬁcation	O
algorithms	O
return	O
the	O
class	O
of	O
overlap	O
,	O
while	O
regression	B
ones	O
return	O
the	O
ratio	O
of	O
over-	O
lap	O
.	O
5.3.3	O
evaluation	B
methods	O
as	O
we	O
had	O
quite	O
imbalanced	O
classes	O
,	O
we	O
have	O
decided	O
to	O
use	O
uar	O
for	O
evaluation	B
of	O
classiﬁcation	O
results	B
.	O
uar	O
stands	O
for	O
unweighted	O
average	B
recall	O
and	O
is	O
an	O
unweighted	O
mean	O
value	O
of	O
recall	O
for	O
23	O
235.4	O
.	O
models	B
tested	O
chapter	O
5	O
.	O
overlap	O
detectors	O
figure	O
5.2	O
:	O
classes	O
structure	O
diagram	O
of	O
the	O
project	O
.	O
figure	O
5.3	O
:	O
block	O
scheme	O
of	O
usage	O
of	O
the	O
x	O
-	O
vectors	O
.	O
each	O
class	O
.	O
this	O
evaluation	B
methods	O
helps	O
to	O
check	O
that	O
each	O
class	O
is	O
predicted	O
well	O
enough	O
,	O
not	O
only	O
the	O
majoring	O
one	O
.	O
for	O
evaluation	B
of	O
regression	B
results	B
we	O
used	O
r2	O
score	B
,	O
which	O
is	O
commonly	O
used	O
for	O
regression	B
tasks	O
and	O
is	O
a	O
coefﬁcient	O
of	O
determination	O
.	O
r2	O
score	B
is	O
a	O
score	B
based	O
on	O
the	O
proportion	O
of	O
the	O
variance	O
.	O
5.4	O
models	B
tested	O
first	O
we	O
used	O
some	O
simple	O
methods	O
as	O
a	O
baseline	B
for	O
classiﬁcation	O
on	O
x	O
-	O
vectors	O
.	O
they	O
are	O
machine	O
learning	O
methods	O
from	O
sklearn	O
library	O
such	O
as	O
ridgeclassiﬁer	O
,	O
svc	O
,	O
sgdclassiﬁer	O
and	O
decision-	O
treeclassiﬁer	O
.	O
as	O
for	O
pytorch	O
based	O
models	B
,	O
we	O
created	O
a	O
simple	O
linear	O
network	B
for	O
another	O
baseline	B
solution	O
.	O
besides	O
we	O
used	O
the	O
tdnn	O
model	B
introduced	O
in	O
a	O
previous	O
research	B
as	O
it	O
was	O
already	O
designed	O
for	O
x	O
-	O
vectors	O
(	O
málek	O
&	O
žd’ánsky	O
,	O
2020	O
)	O
.	O
we	O
call	O
this	O
model	B
tdnnbasedmodel	O
,	O
as	O
it	O
mainly	O
consists	O
of	O
tdnn	O
layers	O
which	O
are	O
cnn	O
-	O
based	O
layers	O
applied	O
to	O
plain	O
vectors	O
(	O
krizhevsky	O
,	O
sutskever	O
&	O
hinton	O
,	O
2012	O
)	O
.	O
the	O
main	O
idea	O
is	O
to	O
gather	O
a	O
context	O
of	O
the	O
value	O
in	O
the	O
vector	O
with	O
some	O
weights	O
for	O
each	O
value	O
and	O
create	O
the	O
next	O
vector	O
this	O
way	O
.	O
if	O
the	O
context	O
is	O
symmetrical	O
it	O
can	O
be	O
done	O
with	O
a	O
one	O
-	O
dimensional	O
convolution	O
layer	B
.	O
24	O
245.5	O
.	O
evaluation	B
results	B
chapter	O
5	O
.	O
overlap	O
detectors	O
as	O
we	O
have	O
also	O
seen	O
,	O
blstm	O
usually	O
work	O
well	O
;	O
however	O
,	O
they	O
have	O
never	O
been	O
applied	O
to	O
x	O
-	O
vectors	O
.	O
so	O
we	O
tried	O
to	O
apply	O
the	O
model	B
from	O
a	O
previous	O
research	B
,	O
which	O
consists	O
of	O
blstm	O
layers	O
(	O
bullock	O
,	O
bredin	O
&	O
garcia	O
-	O
perera	O
,	O
2020	O
)	O
.	O
lstm	O
layers	O
are	O
recurrent	O
neural	B
network	I
layers	O
which	O
iterate	O
through	O
the	O
sequence	B
and	O
on	O
each	O
iteration	O
take	O
the	O
previous	O
output	B
and	O
use	O
it	O
as	O
a	O
new	O
input	B
.	O
bidirectional	O
lstm	O
or	O
blstm	O
repeats	O
this	O
process	B
in	O
the	O
other	O
direction	O
.	O
we	O
also	O
tried	O
a	O
similar	O
model	B
with	O
gru	O
units	O
instead	O
of	O
blstm	O
units	O
.	O
gru	O
stands	O
for	O
gated	O
recurrent	O
unit	O
,	O
and	O
is	O
a	O
simpler	O
version	O
of	O
lstms	O
.	O
we	O
call	O
these	O
models	B
blstmbasedmodel	O
and	O
grubasedmodel	O
respectively	O
.	O
figure	O
5.4	O
:	O
used	O
models	B
parameters	O
and	O
layer	B
structure	O
.	O
the	O
pytorch	O
models	B
used	O
are	O
described	O
by	O
the	O
layer	B
structure	O
in	O
fig	O
.	O
5.4	O
.	O
the	O
last	O
layer	B
in	O
each	O
model	B
outputs	O
a	O
tensor	O
,	O
which	O
length	B
is	O
either	O
the	O
number	O
of	O
classes	O
if	O
we	O
perform	O
classiﬁcation	O
,	O
or	O
1	O
if	O
we	O
perform	O
regression	B
.	O
blstm	O
and	O
gru	O
based	O
models	B
iterate	O
over	O
different	O
x	O
-	O
vectors	O
,	O
which	O
are	O
taken	O
as	O
a	O
context	O
.	O
when	O
used	O
for	O
classiﬁcation	O
,	O
pytorch	O
models	B
are	O
trained	O
with	O
cross	O
-	O
entropy	O
loss	O
,	O
while	O
when	O
used	O
for	O
regression	B
they	O
are	O
trained	O
with	O
mean	O
squared	O
error	O
loss	O
.	O
the	O
parameters	O
of	O
optimizers	O
were	O
tuned	O
for	O
each	O
model	B
separately	O
.	O
as	O
classes	O
were	O
not	O
balanced	O
well	O
(	O
60	O
%	O
of	O
the	O
data	B
corresponds	O
to	O
class	O
0	O
,	O
when	O
there	O
are	O
5	O
classes	O
)	O
,	O
during	O
training	O
we	O
extracted	O
segments	O
from	O
the	O
classes	O
,	O
so	O
that	O
the	O
probability	B
to	O
take	O
a	O
segment	B
from	O
one	O
class	O
was	O
equal	O
to	O
the	O
probability	B
to	O
take	O
a	O
segment	B
from	O
another	O
class	O
.	O
this	O
way	O
we	O
improved	O
the	O
performance	O
for	O
classiﬁcation	O
methods	O
.	O
5.5	O
evaluation	B
results	B
current	O
results	B
for	O
classiﬁcation	O
experiments	O
are	O
shown	O
in	O
the	O
table	O
5.1	O
.	O
table	O
5.2	O
shows	O
the	O
results	B
for	O
regression	B
experiments	O
.	O
we	O
ran	O
those	O
algorithms	O
on	O
bigger	O
contexts	O
consisting	O
of	O
3	O
vectors	O
of	O
information	B
for	O
previous	O
segments	O
,	O
1	O
vector	O
of	O
information	B
for	O
the	O
following	O
segment	B
,	O
and	O
smaller	O
contexts	O
which	O
consist	O
of	O
2	O
vectors	O
of	O
information	B
for	O
previous	O
segments	O
of	O
a	O
current	O
one	O
.	O
classiﬁcation	O
results	B
show	O
that	O
the	O
deep	B
learning	I
based	O
model	B
performs	O
much	O
better	O
with	O
the	O
increase	O
of	O
the	O
context	O
,	O
while	O
there	O
might	O
not	O
be	O
such	O
a	O
big	O
difference	O
for	O
the	O
simple	O
machine	O
learning	O
methods	O
.	O
the	O
top	O
performers	O
are	O
ridgeclassiﬁer	O
and	O
tdnnbasedmodel	O
;	O
they	O
do	O
not	O
have	O
a	O
big	O
difference	O
.	O
regression	B
results	B
show	O
that	O
tdnnbasedmodel	O
improves	O
with	O
the	O
increase	O
of	O
the	O
context	O
;	O
how-	O
ever	O
,	O
the	O
overall	O
performance	O
for	O
all	O
methods	O
is	O
low	O
.	O
the	O
leaders	O
here	O
are	O
lasso	O
and	O
svr	O
.	O
we	O
believe	O
the	O
results	B
here	O
might	O
be	O
that	O
low	O
because	O
of	O
the	O
imbalance	O
of	O
data	B
,	O
which	O
was	O
ﬁxed	O
for	O
classiﬁcation	O
part	O
but	O
was	O
not	O
ﬁxed	O
for	O
regression	B
.	O
25	O
255.6	O
.	O
summary	O
chapter	O
5	O
.	O
overlap	O
detectors	O
method	B
uar	O
score	B
on	O
bigger	O
context	O
uar	O
score	B
on	O
smaller	O
context	O
ridgeclassiﬁer	O
0.26	O
0.23	O
svc	O
0.20	O
0.20	O
sgdclassiﬁer	O
0.24	O
0.23	O
decisiontreeclassiﬁer	O
0.22	O
0.22	O
linearnet	O
0.24	O
0.24	O
tdnnbasedmodel	O
0.25	O
0.23	O
blstmbasedmodel	O
0.23	O
0.20	O
grubasedmodel	O
0.22	O
0.19	O
table	O
5.1	O
:	O
evaluation	B
results	B
for	O
classiﬁcation	O
methods	O
.	O
method	B
r2	O
score	B
on	O
bigger	O
context	O
r2	O
score	B
on	O
smaller	O
context	O
lasso	O
0.006	O
-0.051	O
svr	O
0.070	O
0.052	O
sgdregressor	O
-2e27	O
-1.5e27	O
decisiontreeregressor	O
-0.79	O
-0.808	O
linearnet	O
-0.34	O
-0.333	O
tdnnbasedmodel	O
-0.065	O
-0.124	O
blstmbasedmodel	O
-0.498	O
-0.252	O
grubasedmodel	O
-1.207	O
-0.551	O
table	O
5.2	O
:	O
evaluation	B
results	B
for	O
regression	B
methods	O
.	O
5.6	O
summary	O
we	O
built	O
a	O
convenient	O
system	O
for	O
training	O
and	O
testing	O
models	B
for	O
overlap	B
detection	I
based	O
on	O
x-	O
vectors	O
.	O
to	O
that	O
end	O
,	O
we	O
implemented	O
several	O
methods	O
;	O
both	O
classical	O
machine	O
learning	O
methods	O
and	O
deep	B
learning	I
methods	O
.	O
the	O
results	B
of	O
the	O
evaluation	B
show	O
us	O
that	O
classiﬁcation	O
-	O
based	O
methods	O
work	O
better	O
for	O
overlap	O
prediction	O
.	O
we	O
can	O
also	O
see	O
that	O
among	O
deep	B
learning	I
methods	O
,	O
the	O
tdnn	O
-	O
based	O
is	O
the	O
best	O
one	O
and	O
shows	O
an	O
improvement	O
with	O
the	O
increase	O
of	O
the	O
context	O
.	O
we	O
acknowledge	O
that	O
x	O
-	O
vectors	O
contain	O
some	O
information	B
which	O
can	O
be	O
used	O
for	O
overlap	B
detection	I
.	O
we	O
have	O
some	O
more	O
ideas	O
on	O
how	O
to	O
increase	O
the	O
performance	O
of	O
the	O
introduced	O
methods	O
.	O
the	O
deep	B
learning	I
models	B
can	O
be	O
increased	O
in	O
size	B
.	O
it	O
also	O
makes	O
sense	O
to	O
take	O
more	O
data	B
for	O
training	O
and	O
to	O
possibly	O
perform	O
some	O
kind	O
of	O
data	B
augmentation	I
before	O
.	O
it	O
would	O
also	O
be	O
good	O
to	O
balance	O
data	B
via	O
adding	O
new	O
overlapped	O
segments	O
,	O
which	O
could	O
be	O
achieved	O
by	O
data	B
augmentation	I
or	O
an	O
artiﬁcial	O
audio	O
recordings	O
combination	O
.	O
26	O
26chapter	O
6	O
conclusion	O
6.1	O
summary	O
the	O
intent	O
of	O
this	O
project	O
was	O
to	O
come	O
up	O
with	O
and	O
test	B
suggestions	O
to	O
improve	O
speaker	B
diarization	I
with	O
overlapped	B
speech	I
.	O
the	O
ﬁrst	O
stage	B
of	O
this	O
project	O
was	O
a	O
bibliographic	O
research	B
,	O
as	O
described	O
in	O
our	O
previous	O
ar-	O
ticle	O
(	O
diliberto	O
,	O
pereira	O
&	O
nikiforovskaja	O
,	O
2021	O
)	O
.	O
this	O
study	O
of	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
of	O
diarization	B
methods	O
enabled	O
us	O
to	O
comprehend	O
the	O
three	O
main	O
kinds	O
of	O
approaches	O
:	O
using	O
signal	B
processing	I
,	O
statistics	B
,	O
or	O
more	O
recently	O
deep	O
neural	B
networks	I
.	O
even	O
if	O
the	O
new	O
methods	O
have	O
good	O
efﬁciency	O
,	O
the	O
performance	O
is	O
reduced	O
with	O
overlapped	B
speech	I
,	O
and	O
there	O
is	O
still	O
space	O
for	O
improvement	O
.	O
this	O
part	O
of	O
the	O
project	O
aimed	O
at	O
running	O
experiments	O
to	O
further	O
analyze	O
and	O
understand	O
how	O
speaker	B
diarization	I
is	O
impacted	O
by	O
overlap	O
,	O
and	O
ﬁnding	O
suitable	O
approaches	O
to	O
deal	O
with	O
overlapped	B
speech	I
.	O
to	O
determine	O
the	O
impact	O
on	O
performance	O
of	O
an	O
overlapped	B
speech	I
,	O
we	O
tried	O
to	O
remove	O
over-	O
lapping	O
segments	O
and	O
to	O
run	O
the	O
system	O
baseline	B
.	O
unfortunately	O
,	O
the	O
experiment	O
did	O
not	O
perform	O
as	O
well	O
as	O
we	O
expected	O
.	O
this	O
can	O
be	O
explained	O
by	O
the	O
fact	O
that	O
overlap	O
has	O
an	O
inﬂuence	O
even	O
on	O
non	O
-	O
overlap	O
regions	O
.	O
other	O
causes	O
for	O
diarization	B
errors	B
can	O
be	O
found	O
such	O
as	O
the	O
presence	B
of	O
background	B
noise	I
.	O
we	O
investigated	O
the	O
impact	O
of	O
overlapped	B
speech	I
on	O
90	O
acoustic	B
features	I
to	O
determine	O
if	O
they	O
can	O
be	O
a	O
cause	O
for	O
the	O
loss	O
of	O
performance	O
in	O
speaker	B
diarization	I
.	O
we	O
identiﬁed	O
six	O
features	O
that	O
have	O
unexpected	O
values	B
when	O
computed	O
on	O
overlap	O
segments	O
.	O
this	O
can	O
explain	O
the	O
low	O
efﬁciency	O
results	B
for	O
speaker	B
diarization	I
.	O
as	O
they	O
are	O
trained	O
with	O
non	O
-	O
overlap	O
values	B
,	O
models	B
wo	O
n’t	O
perform	O
well	O
on	O
speech	O
with	O
features	O
having	O
these	O
disparate	O
values	B
.	O
we	O
introduced	O
the	O
possibility	O
of	O
using	O
x	O
-	O
vectors	O
to	O
train	O
overlap	O
detectors	O
and	O
implemented	O
several	O
models	B
to	O
do	O
that	O
.	O
we	O
found	O
out	O
that	O
classiﬁcation	O
interpretation	O
of	O
the	O
problem	O
of	O
speech	O
overlap	B
detection	I
allows	O
to	O
have	O
better	O
results	B
than	O
regression	B
interpretation	O
.	O
we	O
also	O
showed	O
that	O
with	O
the	O
increase	O
of	O
segments	O
in	O
context	O
we	O
obtain	O
higher	O
results	B
with	O
deep	B
learning	I
methods	O
.	O
finally	O
,	O
we	O
introduced	O
several	O
possible	O
improvements	B
,	O
as	O
we	O
consider	O
the	O
usage	O
of	O
x	O
-	O
vectors	O
as	O
promising	O
.	O
in	O
this	O
report	O
,	O
we	O
provided	O
some	O
suggestions	O
about	O
the	O
improvement	O
of	O
speaker	B
diarization	I
with	O
overlapped	B
speech	I
.	O
we	O
identiﬁed	O
the	O
reasons	O
of	O
the	O
low	O
performance	O
of	O
actual	O
systems	O
by	O
exploring	O
the	O
results	B
of	O
overlap	O
removal	O
,	O
and	O
by	O
computing	O
and	O
examining	O
acoustic	B
features	I
.	O
we	O
ﬁnally	O
built	O
a	O
convenient	O
system	O
of	O
overlap	B
detection	I
by	O
comparing	O
different	O
deep	O
neural	B
network	I
models	B
.	O
276.2	O
.	O
limitations	O
chapter	O
6	O
.	O
conclusion	O
6.2	O
limitations	O
the	O
experiments	O
were	O
conducted	O
on	O
the	O
dihard	O
ii	O
dataset	O
,	O
which	O
was	O
designed	O
for	O
the	O
purposes	O
of	O
the	O
challenge	B
on	O
speaker	B
diarization	I
.	O
thus	O
,	O
the	O
corpus	B
is	O
not	O
representative	O
of	O
a	O
real	O
world	O
situation	O
,	O
as	O
the	O
overlap	O
amount	B
has	O
been	O
chosen	O
and	O
the	O
speaker	B
number	O
has	O
been	O
controlled	O
.	O
the	O
results	B
of	O
our	O
experiments	O
are	O
impacted	O
by	O
background	B
noise	I
.	O
the	O
outcome	O
could	O
be	O
better	O
without	O
any	O
background	B
noise	I
;	O
however	O
,	O
it	O
is	O
a	O
normal	O
phenomenon	O
,	O
which	O
happens	O
regularly	O
in	O
real	O
world	O
situations	O
.	O
the	O
performance	O
of	O
our	O
overlap	O
detector	O
is	O
reduced	O
by	O
the	O
small	O
size	B
of	O
our	O
dataset	O
.	O
moreover	O
,	O
this	O
dataset	O
contains	O
a	O
relatively	O
low	O
percentage	B
of	O
overlap	O
(	O
see	O
table	O
3.1	O
)	O
,	O
which	O
can	O
prejudice	O
the	O
training	O
of	O
the	O
model	B
.	O
6.3	O
future	O
work	O
the	O
same	O
experiments	O
using	O
a	O
real	O
world	O
corpus	B
need	O
to	O
be	O
explored	O
as	O
an	O
extension	O
of	O
this	O
work	O
.	O
in	O
addition	O
,	O
using	O
tools	O
to	O
remove	O
background	B
noise	I
as	O
a	O
preprocessing	O
task	O
might	O
be	O
useful	O
.	O
for	O
further	O
development	O
of	O
overlap	O
detectors	O
,	O
it	O
is	O
desirable	O
to	O
test	B
our	O
experiments	O
on	O
larger	O
corpora	B
with	O
a	O
higher	O
percentage	B
of	O
overlap	O
.	O
finally	O
,	O
the	O
ﬁndings	O
from	O
our	O
acoustic	O
experiments	O
can	O
guide	O
future	O
works	O
on	O
speaker	B
diariza-	O
tion	O
with	O
overlapped	B
speech	I
.	O
28	O
28bibliography	O
andrei	O
,	O
v.	O
,	O
cucu	O
,	O
h.	O
&	O
burileanu	O
,	O
c.	O
(	O
2019	O
)	O
overlapped	B
speech	I
detection	B
and	O
competing	O
speaker	B
counting	O
–	O
humans	O
versus	O
deep	B
learning	I
.	O
ieee	O
journal	O
of	O
selected	O
topics	O
in	O
signal	B
processing	I
.	O
13	O
,	O
850–862	O
.	O
anguera	O
,	O
x.	O
,	O
bozonnet	O
,	O
s.	O
,	O
evans	O
,	O
n.	O
,	O
fredouille	O
,	O
c.	O
,	O
friedland	O
,	O
g.	O
&	O
vinyals	O
,	O
o.	O
(	O
2012	O
)	O
speaker	B
diarization	I
:	O
a	O
review	O
of	O
recent	O
research	B
.	O
ieee	O
transactions	O
on	O
audio	O
,	O
speech	O
,	O
and	O
language	O
pro-	O
cessing	O
.	O
20	O
(	O
2	O
)	O
,	O
356–370	O
.	O
aung	O
,	O
t.	O
&	O
puts	O
,	O
d.	O
(	O
2020	O
)	O
voice	O
pitch	B
:	O
a	O
window	O
into	O
the	O
communication	B
of	O
social	O
power	O
.	O
current	O
opinion	O
in	O
psychology	O
.	O
33	O
,	O
154–161	O
.	O
bullock	O
,	O
l.	O
,	O
bredin	O
,	O
h.	O
&	O
garcia	O
-	O
perera	O
,	O
l.	O
p.	O
(	O
2020	O
)	O
overlap	O
-	O
aware	O
diarization	B
:	O
resegmentation	B
using	O
neural	O
end	O
-	O
to	O
-	O
end	O
overlapped	B
speech	I
detection	B
.	O
2020	O
ieee	O
international	O
conference	O
on	O
acous-	O
tics	O
,	O
speech	O
and	O
signal	B
processing	I
.	O
barcelona	O
,	O
spain	O
,	O
7114–7118	O
.	O
diliberto	O
,	O
j.	O
,	O
pereira	O
,	O
c.	O
&	O
nikiforovskaja	O
,	O
a.	O
(	O
2021	O
)	O
speaker	B
diarization	I
with	O
overlapped	B
speech	I
;	O
bibliographical	O
report	O
.	O
eyben	O
,	O
f.	O
,	O
wöllmer	O
,	O
m.	O
&	O
schuller	O
,	O
b.	O
(	O
2010	O
)	O
opensmile	O
:	O
the	O
munich	O
versatile	O
and	O
fast	O
open-	O
source	B
audio	O
feature	O
extractor	B
.	O
proceedings	O
of	O
the	O
18th	O
acm	O
international	O
conference	O
on	O
multime-	O
dia	O
,	O
1459–1462	O
.	O
harris	O
,	O
c.	O
r.	O
,	O
millman	O
,	O
k.	O
j.	O
,	O
walt	O
,	O
s.	O
j.	O
van	O
der	O
,	O
gommers	O
,	O
r.	O
,	O
virtanen	O
,	O
p.	O
,	O
cournapeau	O
,	O
d.	O
,	O
wieser	O
,	O
e.	O
,	O
taylor	O
,	O
j.	O
,	O
berg	O
,	O
s.	O
,	O
smith	O
,	O
n.	O
j.	O
,	O
kern	O
,	O
r.	O
,	O
picus	O
,	O
m.	O
,	O
hoyer	O
,	O
s.	O
,	O
kerkwijk	O
,	O
m.	O
h.	O
van	O
,	O
brett	O
,	O
m.	O
,	O
haldane	O
,	O
a.	O
,	O
río	O
,	O
j.	O
f.	O
del	O
,	O
wiebe	O
,	O
m.	O
,	O
peterson	O
,	O
p.	O
,	O
gérard	O
-	O
marchant	O
,	O
p.	O
,	O
sheppard	O
,	O
k.	O
,	O
reddy	O
,	O
t.	O
,	O
weckesser	O
,	O
w.	O
,	O
abbasi	O
,	O
h.	O
,	O
gohlke	O
,	O
c.	O
&	O
oliphant	O
,	O
t.	O
e.	O
(	O
2020	O
)	O
array	O
programming	O
with	O
numpy	O
.	O
nature	O
.	O
585	O
(	O
7825	O
)	O
,	O
357–362	O
.	O
hunter	O
,	O
j.	O
d.	O
(	O
2007	O
)	O
matplotlib	O
:	O
a	O
2d	O
graphics	O
environment	O
.	O
computing	O
in	O
science	O
&	O
engineering	O
.	O
9	O
(	O
3	O
)	O
,	O
90–95	O
.	O
jadoul	O
,	O
y.	O
,	O
thompson	O
,	O
b.	O
&	O
de	O
boer	O
,	O
b.	O
(	O
2018	O
)	O
introducing	O
parselmouth	O
:	O
a	O
python	O
interface	O
to	O
praat	O
.	O
journal	O
of	O
phonetics	O
.	O
71	O
,	O
1–15	O
.	O
krizhevsky	O
,	O
a.	O
,	O
sutskever	O
,	O
i.	O
&	O
hinton	O
,	O
g.	O
e.	O
(	O
2012	O
)	O
imagenet	O
classiﬁcation	O
with	O
deep	O
convolutional	O
neural	B
networks	I
.	O
advances	O
in	O
neural	O
information	B
processing	B
systems	O
.	O
25	O
,	O
1097–1105	O
.	O
kunešová	O
,	O
m.	O
,	O
hrúz	O
,	O
m.	O
,	O
zajíc	O
,	O
z.	O
&	O
radová	O
,	O
v.	O
(	O
2019	O
)	O
detection	B
of	O
overlapping	B
speech	I
for	O
the	O
purposes	O
of	O
speaker	B
diarization	I
.	O
international	O
conference	O
on	O
speech	O
and	O
computer	B
,	O
247–257	O
.	O
málek	O
,	O
j.	O
&	O
žd’ánsky	O
,	O
j.	O
(	O
2020	O
)	O
voice	O
-	O
activity	O
and	O
overlapped	B
speech	I
detection	B
using	O
x	O
-	O
vectors	O
.	O
international	O
conference	O
on	O
text	O
,	O
speech	O
,	O
and	O
dialogue	O
,	O
366–376	O
.	O
mckinney	O
,	O
w.	O
(	O
2010	O
)	O
data	B
structures	O
for	O
statistical	O
computing	O
in	O
python	O
.	O
proceedings	O
of	O
the	O
9th	O
python	O
in	O
science	O
conference	O
.	O
ed	O
.	O
by	O
s.	O
van	O
der	O
walt	O
&	O
j.	O
millman	O
,	O
56–61	O
.	O
paszke	O
,	O
a.	O
,	O
gross	O
,	O
s.	O
,	O
massa	O
,	O
f.	O
,	O
lerer	O
,	O
a.	O
,	O
bradbury	O
,	O
j.	O
,	O
chanan	O
,	O
g.	O
,	O
killeen	O
,	O
t.	O
,	O
lin	O
,	O
z.	O
,	O
gimelshein	O
,	O
n.	O
,	O
antiga	O
,	O
l.	O
,	O
desmaison	O
,	O
a.	O
,	O
kopf	O
,	O
a.	O
,	O
yang	O
,	O
e.	O
,	O
devito	O
,	O
z.	O
,	O
raison	O
,	O
m.	O
,	O
tejani	O
,	O
a.	O
,	O
chilamkurthy	O
,	O
s.	O
,	O
steiner	O
,	O
b.	O
,	O
fang	O
,	O
l.	O
,	O
bai	O
,	O
j.	O
&	O
chintala	O
,	O
s.	O
(	O
2019	O
)	O
pytorch	O
:	O
an	O
imperative	O
style	O
,	O
high	O
-	O
performance	O
deep	B
learning	I
library	O
.	O
advances	O
in	O
neural	O
information	B
processing	B
systems	O
32	O
.	O
ed	O
.	O
by	O
h.	O
wallach	O
,	O
h.	O
larochelle	O
,	O
a.	O
beygelzimer	O
,	O
f.	O
d’alché	O
-	O
buc	O
,	O
e.	O
fox	O
&	O
r.	O
garnett	O
.	O
curran	O
associates	O
,	O
inc	O
.	O
,	O
8024	O
–	O
8035	O
.	O
29bibliography	O
bibliography	O
pedregosa	O
,	O
f.	O
,	O
varoquaux	O
,	O
g.	O
,	O
gramfort	O
,	O
a.	O
,	O
michel	O
,	O
v.	O
,	O
thirion	O
,	O
b.	O
,	O
grisel	O
,	O
o.	O
,	O
blondel	O
,	O
m.	O
,	O
pretten-	O
hofer	O
,	O
p.	O
,	O
weiss	O
,	O
r.	O
,	O
dubourg	O
,	O
v.	O
,	O
vanderplas	O
,	O
j.	O
,	O
passos	O
,	O
a.	O
,	O
cournapeau	O
,	O
d.	O
,	O
brucher	O
,	O
m.	O
,	O
perrot	O
,	O
m.	O
&	O
duchesnay	O
,	O
e.	O
(	O
2011	O
)	O
scikit	O
-	O
learn	O
:	O
machine	O
learning	O
in	O
python	O
.	O
journal	O
of	O
machine	O
learning	O
research	B
.	O
12	O
,	O
2825–2830	O
.	O
robert	O
,	O
j.	O
,	O
webbie	O
,	O
m.	O
,	O
et	O
al	O
.	O
(	O
2018	O
)	O
pydub	O
.	O
rudnicky	O
,	O
a.	O
i.	O
,	O
hauptmann	O
,	O
a.	O
g.	O
&	O
lee	O
,	O
k.-f	O
.	O
(	O
1994	O
)	O
survey	O
of	O
current	O
speech	O
technology	O
.	O
com-	O
munications	O
of	O
the	O
acm	O
.	O
37	O
(	O
3	O
)	O
,	O
52–57	O
.	O
ryant	O
,	O
n.	O
,	O
church	O
,	O
k.	O
,	O
cieri	O
,	O
c.	O
,	O
cristia	O
,	O
a.	O
,	O
du	O
,	O
j.	O
,	O
ganapathy	O
,	O
s.	O
&	O
liberman	O
,	O
m.	O
(	O
2019a	O
)	O
second	O
dihard	B
challenge	I
evaluation	B
plan	I
.	O
linguistic	O
data	B
consortium	O
,	O
tech	O
.	O
rep	O
.	O
—	O
(	O
2019b	O
)	O
the	O
second	O
dihard	O
diarization	B
challenge	B
:	O
dataset	O
,	O
task	O
,	O
and	O
baselines	O
.	O
20th	O
annual	B
conference	I
of	O
the	O
international	O
speech	B
communication	I
association	O
,	O
978–982	O
.	O
sadjadi	O
,	O
s.	O
o.	O
&	O
hansen	O
,	O
j.	O
h.	O
l.	O
(	O
2013	O
)	O
unsupervised	O
speech	B
activity	I
detection	I
using	O
voicing	O
measures	O
and	O
perceptual	O
spectral	O
flux	O
.	O
ieee	O
signal	B
processing	I
letters	O
.	O
20	O
(	O
3	O
)	O
,	O
197–200	O
.	O
sadjadi	O
,	O
s.	O
o.	O
,	O
kheyrkhah	O
,	O
t.	O
,	O
tong	O
,	O
a.	O
,	O
greenberg	O
,	O
c.	O
s.	O
,	O
reynolds	O
,	O
d.	O
a.	O
,	O
singer	O
,	O
e.	O
,	O
mason	O
,	O
l.	O
p.	O
&	O
hernandez	O
-	O
cordero	O
,	O
j.	O
(	O
2017	O
)	O
the	O
2016	O
nist	O
speaker	B
recognition	O
evaluation	B
.	O
18th	O
annual	B
conference	I
of	O
the	O
international	O
speech	B
communication	I
association	O
,	O
1353–1357	O
.	O
sahidullah	O
,	O
m.	O
et	O
al	O
.	O
(	O
2019	O
)	O
the	O
speed	O
submission	O
to	O
dihard	O
ii	O
:	O
contributions	O
&	O
lessons	O
learned	O
.	O
arxiv	O
preprint	O
arxiv:1911.02388	O
.	O
snyder	O
,	O
d.	O
,	O
garcia	O
-	O
romero	O
,	O
d.	O
,	O
povey	O
,	O
d.	O
&	O
khudanpur	O
,	O
s.	O
(	O
2017	O
)	O
deep	O
neural	B
network	I
embed-	O
dings	O
for	O
text	O
-	O
independent	O
speaker	B
veriﬁcation	O
.	O
18th	O
annual	B
conference	I
of	O
the	O
international	O
speech	B
communication	I
association	O
,	O
999–1003	O
.	O
snyder	O
,	O
d.	O
,	O
garcia	O
-	O
romero	O
,	O
d.	O
,	O
sell	O
,	O
g.	O
,	O
povey	O
,	O
d.	O
&	O
khudanpur	O
,	O
s.	O
(	O
2018	O
)	O
x	O
-	O
vectors	O
:	O
robust	O
dnn	O
embeddings	O
for	O
speaker	B
recognition	O
.	O
2018	O
ieee	O
international	O
conference	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
,	O
5329–5333	O
.	O
tranter	O
,	O
s.	O
e.	O
&	O
reynolds	O
,	O
d.	O
a.	O
(	O
2006	O
)	O
an	O
overview	O
of	O
automatic	O
speaker	B
diarization	I
systems	I
.	O
ieee	O
transactions	O
on	O
audio	O
,	O
speech	O
,	O
and	O
language	B
processing	I
.	O
14	O
(	O
5	O
)	O
,	O
1557–1565	O
.	O
wierstorf	O
,	O
h.	O
(	O
2019	O
)	O
audioﬁle	O
.	O
yoshioka	O
,	O
t.	O
,	O
erdogan	O
,	O
h.	O
,	O
chen	O
,	O
z.	O
,	O
xiao	O
,	O
x.	O
&	O
alleva	O
,	O
f.	O
(	O
2018	O
)	O
recognizing	O
overlapped	B
speech	I
in	O
meetings	O
:	O
a	O
multichannel	B
separation	O
approach	O
using	O
neural	B
networks	I
.	O
19th	O
annual	B
conference	I
of	O
the	O
international	O
speech	B
communication	I
association	O
,	O
3038–3042	O
.	O
zheng	O
,	O
c.	O
,	O
wang	O
,	O
c.	O
&	O
jia	O
,	O
n.	O
(	O
2020	O
)	O
an	O
ensemble	O
model	B
for	O
multi	O
-	O
level	B
speech	O
emotion	O
recog-	O
nition	O
.	O
applied	O
sciences	O
.	O
10	O
(	O
1	O
)	O
.	O

chapter	O
7	O
 	O
speaker	B
 	O
recognition	O
 	O
and	O
diarization	B
    	O
gerald	O
  	O
friedland	O
  	O
and	O
  	O
david	O
  	O
van	O
  	O
leeuwen	O
          	O
7.1	O
   	O
introduction	O
  	O
the	O
meaning	O
that	O
can	O
be	O
extracted	O
from	O
captured	O
speech	O
is	O
not	O
restricted	O
to	O
 	O
only	O
the	O
analysis	B
of	O
the	O
uttered	O
words	B
.	O
for	O
example	O
,	O
speech	O
contains	O
informa-	O
tion	O
about	O
the	O
emotional	O
and	O
social	O
level	B
of	O
a	O
conversation	O
and	O
different	O
cues	O
 	O
about	O
 	O
the	O
 	O
gender	O
,	O
 	O
age	O
,	O
 	O
and	O
 	O
health	O
 	O
status	O
 	O
of	O
 	O
the	O
 	O
speakers	O
,	O
 	O
and	O
 	O
ultimately	O
,	O
 	O
of	O
 	O
course	O
,	O
it	O
usually	O
reveals	O
a	O
speaker	B
’	O
s	O
identity	O
.	O
this	O
chapter	O
presents	O
a	O
continu-	O
ously	O
growing	O
ﬁ	O
eld	O
that	O
promises	O
a	O
wealth	O
of	O
applications	O
far	O
beyond	O
the	O
ﬁ	O
eld	O
 	O
of	O
speech	O
processing	B
:	O
the	O
automatic	O
identiﬁ	O
cation	O
of	O
persons	O
from	O
their	O
uttered	O
 	O
speech	O
.	O
  	O
research	B
 	O
is	O
 	O
currently	O
 	O
focusing	O
 	O
mainly	O
 	O
on	O
 	O
two	O
 	O
tasks	O
:	O
the	O
 	O
task	O
 	O
of	O
 	O
speaker	B
 	O
detection	B
(	O
generally	O
referred	O
to	O
as	O
speaker	B
recognition	O
,	O
the	O
subtle	O
difference	O
 	O
is	O
explained	O
in	O
section	O
 	O
7.4	O
)	O
is	O
to	O
verify	O
the	O
identity	O
of	O
a	O
new	O
speaker	B
against	O
a	O
 	O
set	B
 	O
of	O
 	O
pretrained	O
 	O
speaker	B
 	O
models	B
.	O
applications	O
 	O
in	O
 	O
this	O
 	O
domain	B
 	O
target	O
 	O
mainly	O
 	O
biometric	O
authentication	O
and	O
fraud	O
detection	B
.	O
the	O
task	O
of	O
speaker	B
diarization	I
 	O
is	O
to	O
ﬁ	O
nd	O
speech	B
segments	I
of	O
the	O
same	B
speaker	I
without	O
any	O
a	O
priori	O
knowledge	B
.	O
 	O
it	O
 	O
is	O
 	O
a	O
 	O
completely	O
 	O
unsupervised	O
 	O
approach	O
 	O
that	O
 	O
aims	O
 	O
to	O
 	O
answer	O
 	O
the	O
 	O
question	O
  	O
“	O
who	O
 	O
spoke	O
 	O
when	O
”	O
  	O
in	O
 	O
a	O
 	O
meeting	O
,	O
 	O
news	O
 	O
video	O
,	O
 	O
or	O
 	O
any	O
 	O
other	O
 	O
audio	O
 	O
recording	B
 	O
that	O
contains	O
multiple	O
speakers	O
.	O
it	O
is	O
mostly	O
used	O
as	O
a	O
preprocessing	O
step	O
for	O
 	O
a	O
large	O
variety	O
of	O
automatic	O
speech	B
recognition	I
(	O
asr	B
)	O
tasks	O
,	O
including	O
the	O
use	O
 	O
of	O
 	O
speaker	B
-	O
adapted	O
asr	B
 	O
models	B
 	O
in	O
 	O
a	O
 	O
multispeaker	O
 	O
recording	B
,	O
 	O
or	O
 	O
as	O
 	O
a	O
 	O
helper	O
 	O
for	O
sentence	O
boundary	O
detection	B
.	O
speaker	B
diarization	I
is	O
also	O
used	O
in	O
informa-	O
tion	O
retrieval	O
tasks	O
.	O
  	O
the	O
chapter	O
is	O
organized	O
as	O
follows	O
:	O
section	O
 	O
7.2	O
 	O
introduces	O
the	O
general	O
ideas	O
 	O
in	O
 	O
the	O
 	O
two	O
 	O
ﬁ	O
elds	O
.	O
 	O
section	O
  	O
7.3	O
  	O
then	O
 	O
continues	O
 	O
to	O
 	O
explain	O
 	O
the	O
 	O
task	O
 	O
of	O
 	O
speaker	B
 	O
diarization	B
by	O
providing	O
an	O
overview	O
of	O
current	O
work	O
before	O
providing	O
a	O
more	O
 	O
detailed	O
description	O
of	O
a	O
concrete	O
example	O
of	O
a	O
diarization	B
system	O
.	O
then	O
,	O
vari-	O
ants	O
 	O
and	O
 	O
current	O
 	O
research	B
 	O
topics	O
 	O
are	O
 	O
discussed	O
.	O
 	O
section	O
  	O
7.4	O
  	O
presents	O
 	O
speaker	B
 	O
semantic	O
computing	O
,	O
 	O
edited	O
by	O
sheu	O
,	O
yu	O
,	O
ramamoorthy	O
,	O
joshi	O
,	O
and	O
zadeh	O
copyright	O
©	O
2010	O
the	O
institute	O
of	O
electrical	O
and	O
electronics	O
engineers	O
,	O
inc	O
.	O
115116	O
   	O
speaker	B
recognition	O
and	O
diarization	B
recognition	O
in	O
a	O
similar	O
way	O
.	O
finally	O
,	O
section	O
 	O
7.5	O
 	O
concludes	O
the	O
chapter	O
point-	O
ing	O
to	O
open	O
problems	O
.	O
    	O
7.2	O
   	O
common	O
approaches	O
to	O
speaker	B
diarization	I
 	O
and	O
recognition	O
  	O
speech	O
is	O
usually	O
modeled	O
using	O
statistical	O
models	B
,	O
such	O
as	O
gaussian	O
mixture	O
 	O
models	B
(	O
gmms	O
)	O
,	O
neural	B
networks	I
,	O
or	O
support	O
vector	O
machines	O
(	O
svms	O
)	O
,	O
using	O
 	O
a	O
small	O
set	B
of	O
standard	O
features	O
.	O
this	O
section	O
is	O
meant	O
as	O
a	O
nutshell	O
introduction	O
 	O
to	O
the	O
most	O
important	O
aspects	O
of	O
the	O
underlying	O
speech	O
processing	B
methods	O
.	O
   	O
7.2.1	O
   	O
speech	O
features	O
  	O
the	O
speech	B
signal	I
is	O
parameterized	O
in	O
frames	O
of	O
10	O
–	O
20	O
  	O
ms	O
,	O
with	O
typically	O
13	O
–	O
19	O
 	O
parameters	O
.	O
 	O
popular	O
 	O
features	O
 	O
are	O
 	O
scaled	O
 	O
mel	O
 	O
frequency	B
 	O
cepstral	O
 	O
coefﬁ	O
cients	O
 	O
(	O
mfccs	O
)	O
and	O
perceptual	O
linear	O
prediction	O
(	O
plp	O
)	O
,	O
sometimes	O
augmented	O
with	O
 	O
log	B
 	O
energy	O
.	O
 	O
note	O
 	O
that	O
 	O
these	O
 	O
are	O
 	O
the	O
 	O
same	O
 	O
features	O
 	O
used	O
 	O
in	O
 	O
automatic	O
 	O
s	O
 	O
peech	O
  	O
recognition	O
and	O
other	O
speech	O
processing	B
technologies	O
.	O
additional	O
features	O
are	O
 	O
found	O
by	O
computing	O
ﬁ	O
rst	O
-	O
 	O
and	O
second	O
order	B
derivatives	O
,	O
often	O
found	O
by	O
apply-	O
ing	O
linear	O
regression	B
over	O
typically	O
three	O
to	O
seven	O
consecutive	O
frames	O
.	O
thus	O
,	O
a	O
 	O
common	O
dimensionality	O
of	O
the	O
feature	O
space	O
is	O
26	O
or	O
39	O
.	O
    	O
7.2.2	O
   	O
gaussian	O
mixture	O
model	B
  	O
a	O
gmm	O
is	O
a	O
phenomenological	O
model	B
for	O
representing	O
the	O
probability	B
density	O
 	O
function	O
(	O
pdf	O
)	O
of	O
the	O
feature	O
space	O
.	O
it	O
consists	O
of	O
a	O
weighted	O
combination	O
of	O
 	O
multivariate	O
gaussian	O
pdfs	O
.	O
the	O
idea	O
is	O
that	O
for	O
each	O
sound	O
,	O
or	O
 	O
“	O
phone	O
”	O
,	O
that	O
 	O
is	O
different	O
enough	O
from	O
another	O
sound	O
,	O
or	O
uttered	O
by	O
another	O
speaker	B
,	O
a	O
dif-	O
ferent	O
 	O
gaussian	O
 	O
can	O
 	O
be	O
 	O
used	O
 	O
to	O
 	O
represent	O
 	O
the	O
 	O
features	O
 	O
observed	O
 	O
under	O
 	O
that	O
 	O
condition	B
.	O
although	O
in	O
principle	O
capable	O
of	O
modeling	O
any	O
feature	O
space	O
,	O
fea-	O
tures	O
 	O
that	O
 	O
are	O
 	O
decorrelated	O
 	O
are	O
 	O
preferred	O
 	O
because	O
 	O
their	O
 	O
gaussian	O
 	O
pdfs	O
 	O
can	O
 	O
then	O
be	O
modeled	O
with	O
diagonal	O
covariances	O
.	O
this	O
allows	O
using	O
a	O
small	O
number	O
 	O
of	O
 	O
parameters	O
,	O
 	O
which	O
 	O
in	O
 	O
turn	O
 	O
reduces	O
 	O
computational	O
 	O
effort	O
 	O
to	O
 	O
estimate	O
 	O
the	O
 	O
parameters	O
 	O
and	O
 	O
to	O
 	O
calculate	O
 	O
likelihoods	O
.	O
 	O
a	O
 	O
gmm	O
 	O
is	O
 	O
characterized	O
 	O
by	O
 	O
the	O
 	O
number	O
of	O
components	B
,	O
or	O
gaussians	O
,	O
that	O
are	O
used	O
to	O
model	B
the	O
pdf	O
.	O
more	O
 	O
gaussians	O
mean	O
that	O
the	O
pdf	O
is	O
estimated	O
more	O
accurately	O
—	O
but	O
depending	O
 	O
on	O
the	O
setup	B
this	O
may	O
mean	O
that	O
a	O
model	B
can	O
be	O
overtrained	O
.	O
a	O
rule	O
of	O
thumb	O
 	O
is	O
we	O
need	O
at	O
least	O
5	O
  	O
s	O
of	O
speech	O
(	O
approximately	O
500	O
observations	O
)	O
per	O
gaussian	O
 	O
for	O
training	O
a	O
gmm	O
.	O
  	O
a	O
gmm	O
can	O
be	O
conditioned	O
to	O
model	B
(	O
part	O
of	O
)	O
a	O
single	O
phone	O
,	O
as	O
in	O
speech	O
 	O
recognition	O
,	O
 	O
or	O
 	O
all	O
 	O
speech	O
 	O
of	O
 	O
a	O
 	O
single	O
 	O
speaker	B
,	O
 	O
as	O
 	O
in	O
 	O
speaker	B
 	O
identiﬁ	O
cation	O
 	O
or	O
 	O
diarization	B
,	O
 	O
or	O
 	O
all	O
 	O
speech	O
 	O
of	O
 	O
all	O
 	O
possible	O
 	O
speakers	O
,	O
 	O
as	O
 	O
is	O
 	O
done	O
 	O
in	O
 	O
the	O
 	O
ubm	O
 	O
approach	O
(	O
see	O
below	O
)	O
.	O
hence	O
,	O
a	O
gmm	O
is	O
a	O
very	O
ﬂ	O
exible	O
modeling	O
tool	O
that	O
has	O
 	O
found	O
its	O
way	O
in	O
many	O
parts	O
in	O
speech	O
technology	O
.	O
 	O
speaker	B
diarization	I
   	O
117	O
  	O
7.2.3	O
   	O
universal	O
background	O
model	B
    	O
for	O
the	O
ﬁ	O
rst	O
time	B
applied	O
to	O
speaker	B
recognition	O
 	O
[	O
1	O
]	O
,	O
a	O
universal	O
background	O
 	O
model	B
(	O
ubm	O
)	O
represents	O
the	O
speech	O
of	O
 	O
“	O
all	O
possible	O
speakers	O
.	O
”	O
 	O
it	O
is	O
basically	O
 	O
a	O
gmm	O
consisting	O
of	O
many	O
gaussians	O
,	O
typical	O
ﬁ	O
gures	O
are	O
512	O
–	O
2048	O
(	O
tradition-	O
ally	O
,	O
 	O
the	O
 	O
number	O
 	O
of	O
 	O
gaussians	O
 	O
is	O
 	O
chosen	O
 	O
as	O
 	O
powers	O
 	O
of	O
 	O
2	O
)	O
.	O
a	O
 	O
ubm	O
 	O
is	O
 	O
used	O
 	O
as	O
 	O
denominator	O
in	O
determining	O
a	O
likelihood	B
ratio	I
,	O
representing	O
the	O
likelihood	B
of	O
 	O
the	O
  	O
“	O
alternative	O
 	O
speaker	B
”	O
  	O
in	O
 	O
speaker	B
 	O
detection	B
,	O
 	O
but	O
 	O
also	O
 	O
has	O
 	O
applications	O
 	O
in	O
calculating	O
cross-	O
 	O
likelihood	B
ratios	O
during	O
clustering	B
in	O
speaker	B
diarization	I
.	O
 	O
for	O
 	O
speaker	B
 	O
recognition	O
,	O
 	O
thousands	O
 	O
of	O
 	O
speakers	O
 	O
can	O
 	O
be	O
 	O
used	O
 	O
to	O
 	O
train	O
 	O
the	O
 	O
ubm	O
;	O
 	O
for	O
 	O
speaker	B
 	O
diarization	B
,	O
 	O
the	O
 	O
ubm	O
 	O
is	O
 	O
trained	O
 	O
on	O
 	O
all	O
 	O
speech	O
,	O
 	O
that	O
 	O
is	O
,	O
 	O
all	O
 	O
available	O
speakers	O
of	O
the	O
task	O
.	O
  	O
the	O
 	O
importance	O
 	O
of	O
 	O
the	O
 	O
ubm	O
 	O
extends	O
 	O
that	O
 	O
of	O
 	O
generating	O
 	O
likelihoods	O
 	O
of	O
 	O
speech	O
utterances	B
.	O
in	O
speaker	B
recognition	O
,	O
it	O
is	O
often	O
used	O
as	O
the	O
starting	O
point	O
 	O
for	O
 	O
modeling	O
 	O
a	O
 	O
speciﬁ	O
c	O
 	O
speaker	B
,	O
 	O
which	O
 	O
can	O
 	O
be	O
 	O
found	O
 	O
by	O
 	O
adapting	O
 	O
the	O
 	O
ubm	O
 	O
using	O
 	O
limited	O
 	O
amounts	O
 	O
of	O
 	O
speech	O
 	O
from	O
 	O
a	O
 	O
speciﬁ	O
c	O
 	O
speaker	B
.	O
 	O
it	O
 	O
is	O
 	O
often	O
 	O
the	O
 	O
dis-	O
placements	O
of	O
the	O
centers	O
of	O
the	O
gaussians	O
that	O
are	O
used	O
to	O
completely	O
char-	O
acterize	O
a	O
speaker	B
.	O
    	O
7.2.4	O
   	O
speech	B
activity	I
detection	I
  	O
a	O
very	O
important	O
preprocessing	O
step	O
for	O
almost	O
every	O
speech	O
processing	B
algo-	O
rithm	O
is	O
the	O
so	O
-	O
called	O
speech	B
activity	I
detection	I
(	O
sad	O
)	O
,	O
also	O
known	O
as	O
speech/	O
non	O
-	O
speech	B
detection	I
,	O
or	O
frame	B
selection	O
.	O
it	O
is	O
a	O
very	O
hard	O
problem	O
to	O
select	O
 	O
useful	O
speech	O
frames	O
from	O
a	O
background	O
of	O
sounds	O
(	O
silence	B
,	O
noise	O
,	O
music	O
,	O
other	O
 	O
speakers	O
)	O
 	O
and	O
 	O
may	O
 	O
even	O
 	O
be	O
 	O
interpreted	O
 	O
as	O
 	O
a	O
  	O
“	O
speech	O
 	O
diarization	B
”	O
  	O
problem	O
.	O
 	O
simple	O
 	O
approaches	O
 	O
to	O
 	O
sad	O
 	O
are	O
 	O
energy	O
 	O
based	O
,	O
 	O
where	O
 	O
the	O
 	O
regions	O
 	O
of	O
 	O
speech	O
 	O
with	O
an	O
energy	O
above	O
a	O
minimum	O
threshold	B
(	O
e.g.	O
,	O
30	O
  	O
db	O
below	O
the	O
maximum	O
 	O
energy	O
of	O
the	O
utterance	O
,	O
but	O
more	O
advanced	O
approaches	O
have	O
been	O
made	O
 	O
[	O
2	O
]	O
)	O
 	O
are	O
 	O
considered	O
 	O
speech	O
 	O
and	O
 	O
the	O
 	O
rest	O
 	O
silence	B
.	O
 	O
this	O
 	O
works	O
 	O
for	O
 	O
relatively	O
 	O
clean	O
 	O
domains	O
,	O
such	O
as	O
telephone	B
speech	I
,	O
but	O
will	O
fail	O
in	O
situations	O
with	O
background	O
 	O
noise	O
.	O
therefore	O
,	O
 	O
a	O
 	O
more	O
 	O
advanced	O
 	O
approach	O
 	O
is	O
 	O
to	O
 	O
have	O
 	O
separate	O
 	O
models	B
 	O
for	O
 	O
speech	O
,	O
silence	B
,	O
and	O
nonspeech	O
sounds	O
and	O
use	O
a	O
decoding	O
strategy	O
to	O
ﬁ	O
nd	O
the	O
 	O
maximum	O
-	O
likelihood	B
solution	O
to	O
what	O
parts	O
in	O
the	O
signal	B
are	O
actually	O
speech	O
 	O
segments	O
.	O
recently	O
,	O
a	O
hybrid	O
approach	O
has	O
been	O
proposed	O
 	O
[	O
3	O
]	O
 	O
that	O
forms	O
the	O
 	O
models	B
 	O
for	O
 	O
speech	O
 	O
and	O
 	O
nonspeech	O
 	O
sound	O
 	O
from	O
 	O
the	O
 	O
speech	O
 	O
data	B
 	O
itself	O
,	O
 	O
found	O
 	O
iteratively	O
after	O
an	O
energy-	O
  	O
and	O
model	B
-	O
based	O
initialization	O
.	O
     	O
7.3	O
   	O
speaker	B
diarization	I
  	O
the	O
goal	O
of	O
speaker	B
diarization	I
is	O
to	O
segment	B
an	O
audio	O
recording	B
into	O
speaker	B
-	O
 	O
homogeneous	O
regions	O
and	O
cluster	O
these	O
,	O
with	O
the	O
goal	O
of	O
answering	O
the	O
ques-	O
tion	O
 	O
“	O
who	O
spoke	O
when	O
?	O
”	O
  	O
[	O
4	O
]	O
.	O
figure	O
 	O
7.1	O
 	O
illustrates	O
the	O
idea	O
.	O
speaker	B
diarization	I
 	O
has	O
 	O
a	O
 	O
large	O
 	O
set	B
 	O
of	O
 	O
possible	O
 	O
and	O
 	O
actual	O
 	O
applications	O
.	O
 	O
usually	O
,	O
 	O
it	O
 	O
is	O
 	O
used	O
 	O
as	O
 	O
a	O
118	O
   	O
speaker	B
recognition	O
and	O
diarization	B
     	O
figure	O
7.1	O
     	O
speaker	B
diarization	I
.	O
  	O
front	O
-	O
end	O
 	O
(	O
also	O
 	O
called	O
 	O
upstream	O
)	O
 	O
application	B
 	O
for	O
 	O
different	O
 	O
higher	O
 	O
level	B
 	O
tasks	O
,	O
 	O
such	O
 	O
as	O
 	O
speech	O
 	O
recognition	O
;	O
 	O
meeting	O
,	O
 	O
seminar	O
,	O
 	O
or	O
 	O
broadcast	O
 	O
news	O
 	O
navigation	O
;	O
 	O
or	O
even	O
dominance	O
modeling	O
 	O
[	O
5	O
]	O
.	O
    	O
in	O
 	O
contrast	O
 	O
to	O
 	O
speaker	B
 	O
recognition	O
 	O
or	O
 	O
identiﬁ	O
cation	O
,	O
 	O
speaker	B
 	O
diarization	B
 	O
attempts	O
to	O
use	O
no	O
prior	O
knowledge	B
of	O
any	O
kind	O
.	O
this	O
usually	O
means	O
that	O
no	O
 	O
speciﬁ	O
c	O
speaker	B
models	B
are	O
trained	O
for	O
the	O
speakers	O
that	O
are	O
to	O
be	O
identiﬁ	O
ed	O
 	O
in	O
 	O
the	O
 	O
recording	B
.	O
 	O
in	O
 	O
practice	O
,	O
 	O
this	O
 	O
means	O
 	O
a	O
 	O
speaker	B
 	O
diarization	B
 	O
system	O
 	O
has	O
 	O
to	O
 	O
answer	O
the	O
following	O
questions	O
:	O
    	O
(	O
cid:129	O
)	O
      	O
what	O
are	O
the	O
speech	O
regions	O
?	O
     	O
(	O
cid:129	O
)	O
      	O
how	O
many	O
speakers	O
occur	O
in	O
the	O
recording	B
?	O
     	O
(	O
cid:129	O
)	O
      	O
which	O
speech	O
regions	O
belong	O
to	O
the	O
same	B
speaker	I
?	O
     	O
therefore	O
,	O
a	O
speaker	B
diarization	I
system	I
conceptually	O
performs	O
three	O
tasks	O
:	O
 	O
(	O
1	O
)	O
discriminates	O
between	O
speech	O
and	O
nonspeech	O
regions	O
,	O
(	O
2	O
)	O
detects	O
speaker	B
 	O
changes	O
 	O
to	O
 	O
segment	B
 	O
the	O
 	O
audio	O
 	O
data	B
,	O
 	O
and	O
 	O
(	O
3	O
)	O
 	O
groups	O
 	O
the	O
 	O
segmented	O
 	O
regions	O
 	O
together	O
into	O
speaker	B
-	O
homogeneous	O
clusters	O
.	O
some	O
systems	O
unify	O
the	O
two	O
last	O
 	O
steps	B
into	O
a	O
single	O
one	O
;	O
that	O
is	O
,	O
segmentation	B
and	O
clustering	B
are	O
performed	O
in	O
one	O
 	O
step	O
.	O
 	O
over	O
 	O
the	O
 	O
years	O
,	O
 	O
many	O
 	O
different	O
 	O
algorithms	O
 	O
have	O
 	O
been	O
 	O
developed	O
 	O
in	O
 	O
the	O
 	O
speech	O
community	O
.	O
a	O
summary	O
can	O
be	O
found	O
in	O
the	O
next	O
section	O
and	O
also	O
in	O
 	O
[	O
6	O
]	O
.	O
   	O
7.3.1	O
   	O
overview	O
of	O
field	O
  	O
the	O
different	O
speaker	B
diarization	I
approaches	O
that	O
have	O
been	O
developed	O
over	O
 	O
the	O
 	O
years	O
 	O
can	O
 	O
be	O
 	O
mainly	O
 	O
organized	O
 	O
into	O
 	O
two	O
 	O
categories	O
:	O
 	O
one	O
-	O
  	O
and	O
 	O
two	O
-	O
stage	B
speaker	B
diarization	I
   	O
119	O
algorithms	O
.	O
the	O
 	O
underlying	O
 	O
speaker	B
 	O
change	B
 	O
detection	B
 	O
methods	O
 	O
can	O
 	O
be	O
 	O
orga-	O
nized	O
into	O
metric-	O
 	O
based	O
and	O
probabilistic	O
systems	O
and	O
model	B
-	O
based	O
and	O
non	O
-	O
 	O
model	B
-	O
based	O
systems	O
.	O
  	O
many	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
speaker	B
diarization	I
systems	I
,	O
including	O
the	O
international	O
 	O
computer	B
science	O
institute	O
(	O
icsi	O
)	O
speaker	B
diarization	I
engine	O
(	O
see	O
below	O
)	O
,	O
use	O
 	O
a	O
one	O
-	O
stage	B
approach	O
,	O
that	O
is	O
the	O
combination	O
of	O
agglomerative	O
clustering	B
with	O
 	O
bayesian	O
 	O
information	B
 	O
criterion	B
 	O
(	O
bic	B
)	O
  	O
[	O
7	O
]	O
  	O
and	O
 	O
gmms	O
 	O
(	O
see	O
 	O
section	O
  	O
7.2.2	O
)	O
 	O
of	O
 	O
frame	B
-	O
based	O
cepstral	O
features	O
(	O
mfccs	O
;	O
see	O
section	O
 	O
2.1	O
)	O
 	O
[	O
4	O
]	O
.	O
recently	O
,	O
a	O
new	O
 	O
speaker	B
clustering	B
approach	O
which	O
applies	O
the	O
ng	O
–	O
jorden	O
–	O
weiss	O
(	O
njw	O
)	O
spec-	O
tral	O
clustering	B
algorithm	O
to	O
speaker	B
diarization	I
has	O
been	O
reported	O
 	O
[	O
8	O
]	O
.	O
  	O
in	O
two	O
-	O
stage	B
speaker	B
diarization	I
approaches	O
,	O
the	O
ﬁ	O
rst	O
step	O
(	O
speaker	B
segmen-	O
tation	O
)	O
aims	O
at	O
detecting	O
speaker	B
change	I
points	O
and	O
is	O
essentially	O
a	O
two	O
-	O
way	O
 	O
classiﬁ	O
cation	O
/	O
decision	O
problem	O
;	O
that	O
is	O
,	O
for	O
each	O
frame	B
,	O
a	O
decision	O
needs	O
to	O
be	O
 	O
made	O
 	O
on	O
 	O
whether	O
 	O
this	O
 	O
is	O
 	O
a	O
 	O
speaker	B
 	O
change	B
 	O
point	O
 	O
or	O
 	O
not	O
.	O
 	O
after	O
 	O
the	O
 	O
speaker	B
 	O
change	B
 	O
detection	B
,	O
 	O
the	O
 	O
speech	O
 	O
segments	O
,	O
 	O
each	O
 	O
of	O
 	O
which	O
 	O
contains	O
 	O
only	O
 	O
one	O
 	O
speaker	B
,	O
are	O
then	O
clustered	O
using	O
either	O
top	O
-	O
down	O
or	O
bottom	O
-	O
up	O
clustering	B
.	O
in	O
 	O
model	B
-	O
based	O
approaches	O
,	O
pretrained	O
speech	O
and	O
silence	B
models	B
are	O
used	O
for	O
 	O
segmentation	B
.	O
 	O
the	O
 	O
decision	O
 	O
about	O
 	O
speaker	B
 	O
change	B
 	O
is	O
 	O
made	O
 	O
based	O
 	O
on	O
 	O
frame	B
 	O
assignment	O
;	O
that	O
is	O
,	O
the	O
detected	O
silence	B
gaps	O
are	O
considered	O
to	O
be	O
the	O
speaker	B
 	O
change	B
 	O
points	O
.	O
 	O
metric	B
-	O
based	O
 	O
approaches	O
 	O
are	O
 	O
more	O
 	O
often	O
 	O
used	O
 	O
for	O
 	O
speaker	B
 	O
segmentation	B
.	O
usually	O
,	O
a	O
metric	B
between	O
probabilistic	O
models	B
of	O
two	O
contigu-	O
ous	O
speech	B
segments	I
,	O
such	O
as	O
gmms	O
,	O
is	O
deﬁ	O
ned	O
and	O
the	O
decision	O
is	O
made	O
via	O
 	O
a	O
simple	O
thresholding	O
procedure	O
.	O
  	O
during	O
the	O
last	O
years	O
,	O
research	B
has	O
mainly	O
concentrated	O
on	O
ﬁ	O
nding	O
metrics	O
 	O
for	O
 	O
speaker	B
 	O
change	B
 	O
detection	B
.	O
 	O
examples	O
 	O
are	O
 	O
the	O
 	O
bic	B
  	O
[	O
7	O
]	O
,	O
 	O
cross	O
 	O
bic	B
 	O
(	O
xbic	O
)	O
  	O
[	O
9	O
,	O
10	O
]	O
,	O
generalized	O
likelihood	B
ratio	I
(	O
glr	O
)	O
 	O
[	O
11	O
]	O
,	O
gish	O
distance	B
 	O
[	O
12	O
]	O
,	O
kullback	O
–	O
 	O
leibler	O
(	O
kl	O
)	O
divergence	O
 	O
[	O
13	O
]	O
,	O
and	O
divergence	O
shape	O
distance	B
(	O
dsd	O
)	O
 	O
[	O
14	O
]	O
.	O
    	O
7.3.2	O
   	O
example	O
diarization	B
system	O
  	O
the	O
authors	O
of	O
this	O
chapter	O
are	O
actively	O
involved	O
in	O
the	O
development	O
of	O
speaker	B
 	O
diarization	B
and	O
identiﬁ	O
cation	O
systems	O
.	O
to	O
provide	O
more	O
technical	O
details	O
about	O
 	O
how	O
a	O
diarization	B
system	O
actually	O
works	O
,	O
we	O
take	O
the	O
icsi	O
diarization	B
engine	O
 	O
as	O
an	O
example	O
.	O
the	O
speaker	B
diarization	I
engine	O
developed	O
at	O
icsi	O
(	O
berkeley	O
,	O
 	O
ca	O
)	O
,	O
which	O
in	O
the	O
remainder	O
of	O
this	O
text	O
is	O
called	O
the	O
icsi	O
speaker	B
diarization	I
 	O
engine	O
,	O
uses	O
an	O
agglomerative	O
clustering	B
approach	O
to	O
perform	O
both	O
segmenta-	O
tion	O
 	O
of	O
 	O
the	O
 	O
audio	O
 	O
track	O
 	O
into	O
 	O
speaker	B
-	O
homogeneous	O
 	O
time	B
 	O
segments	O
 	O
and	O
 	O
the	O
 	O
grouping	O
of	O
these	O
segments	O
into	O
speaker	B
-	O
homogeneous	O
clusters	O
in	O
one	O
step	O
.	O
  	O
the	O
audio	O
track	O
is	O
usually	O
processed	O
as	O
19th	O
-	O
order	B
mfcc	O
features	O
using	O
a	O
 	O
frame	B
 	O
size	B
 	O
of	O
 	O
10	O
  	O
ms	O
.	O
a	O
 	O
speech	O
 	O
activity	O
 	O
detector	O
 	O
(	O
see	O
 	O
section	O
  	O
7.2.4	O
)	O
 	O
is	O
 	O
used	O
 	O
to	O
 	O
ﬁ	O
lter	O
 	O
out	O
 	O
regions	O
 	O
that	O
 	O
do	O
 	O
not	O
 	O
contain	O
 	O
speech	O
.	O
 	O
the	O
 	O
nonspeech	O
 	O
regions	O
 	O
are	O
 	O
excluded	O
from	O
the	O
agglomerative	O
clustering	B
.	O
the	O
algorithm	O
is	O
initialized	O
using	O
 	O
a	O
much	O
higher	O
number	O
of	O
clusters	O
than	O
speakers	O
expected	O
in	O
the	O
audio	O
track	O
.	O
 	O
let	O
this	O
number	O
be	O
 	O
k	O
.	O
an	O
initial	O
segmentation	B
is	O
generated	O
by	O
randomly	O
par-	O
titioning	O
the	O
audio	O
track	O
into	O
k	O
   	O
segments	O
of	O
the	O
same	O
length	B
.	O
using	O
the	O
initial	O
120	O
   	O
speaker	B
recognition	O
and	O
diarization	B
audio	O
signal	B
segmentaiton	O
feature	O
extraction	B
mfcc	O
diarization	B
merge	O
two	O
mfcc	O
(	O
only	O
engine	O
metadata	O
initialization	O
clusters	O
?	O
speech	O
)	O
no	O
speech/	O
nonspeech	O
clustering	B
retraining	O
&	O
end	O
yes	O
detector	O
realignment	O
     	O
figure	O
7.2	O
     	O
steps	B
of	O
icsi	O
speaker	B
diarization	I
system	I
as	O
explained	O
in	O
section	O
 	O
7.3.2	O
.	O
 	O
left	O
:	O
  	O
overview	O
;	O
 	O
right	O
:	O
 	O
agglomerative	O
clustering	B
.	O
  	O
segmentation	B
,	O
k	O
   	O
gmms	O
are	O
trained	O
.	O
as	O
classiﬁ	O
cations	O
based	O
on	O
10	O
-	O
ms	O
frames	O
 	O
are	O
very	O
noisy	O
,	O
a	O
minimum	O
duration	O
of	O
2.5	O
  	O
s	O
is	O
assumed	O
for	O
each	O
speech	B
segment	I
.	O
 	O
a	O
 	O
majority	O
 	O
vote	O
 	O
is	O
 	O
then	O
 	O
used	O
 	O
to	O
 	O
combine	O
 	O
the	O
 	O
individual	O
 	O
decisions	O
.	O
the	O
 	O
algo-	O
rithm	O
then	O
performs	O
the	O
following	O
loop	O
:	O
    	O
(	O
cid:129	O
)	O
      	O
resegmentation	B
     	O
compute	O
 	O
the	O
 	O
likelihoods	O
 	O
with	O
 	O
respect	O
 	O
to	O
 	O
each	O
 	O
gmm	O
 	O
and	O
vote	O
to	O
determine	O
the	O
assignment	O
of	O
each	O
minimum	O
-	O
duration	O
segment	B
 	O
to	O
a	O
particular	O
model	B
.	O
     	O
(	O
cid:129	O
)	O
      	O
retraining	O
     	O
given	O
 	O
the	O
 	O
new	O
 	O
segmentation	B
 	O
of	O
 	O
the	O
 	O
audio	O
 	O
track	O
,	O
 	O
train	O
 	O
new	O
 	O
gmms	O
for	O
each	O
of	O
them	O
.	O
     	O
(	O
cid:129	O
)	O
      	O
cluster	O
merging	O
     	O
given	O
the	O
new	O
gmms	O
,	O
try	O
to	O
ﬁ	O
nd	O
the	O
two	O
models	B
that	O
 	O
most	O
 	O
likely	O
 	O
represent	O
 	O
the	O
 	O
same	O
 	O
speaker	B
.	O
this	O
 	O
is	O
 	O
done	O
 	O
by	O
 	O
computing	O
 	O
the	O
 	O
bic	B
score	B
of	O
each	O
of	O
the	O
models	B
and	O
the	O
bic	B
score	B
of	O
a	O
new	O
gmm	O
trained	O
 	O
on	O
the	O
merged	O
segments	O
for	O
two	O
clusters	O
.	O
if	O
the	O
bic	B
score	B
of	O
the	O
merged	O
 	O
gmm	O
is	O
smaller	O
than	O
or	O
equal	O
to	O
the	O
sum	O
of	O
the	O
individual	O
bic	B
scores	O
,	O
 	O
the	O
two	O
models	B
are	O
merged	O
and	O
the	O
algorithm	O
loops	O
at	O
the	O
resegmentation	B
 	O
step	O
using	O
the	O
merged	O
gmm	O
.	O
if	O
no	O
pair	O
is	O
found	O
,	O
the	O
algorithm	O
stops	O
.	O
     	O
figure	O
  	O
7.2	O
  	O
illustrates	O
 	O
the	O
 	O
steps	B
 	O
of	O
 	O
the	O
 	O
algorithm	O
,	O
 	O
a	O
 	O
more	O
 	O
detailed	O
 	O
description	O
 	O
can	O
be	O
found	O
in	O
 	O
[	O
9	O
,	O
15	O
]	O
.	O
      	O
7.3.3	O
   	O
evaluation	B
measures	O
  	O
the	O
 	O
output	B
 	O
of	O
 	O
a	O
 	O
speaker	B
 	O
diarization	B
 	O
system	O
 	O
consists	O
 	O
of	O
 	O
metadata	O
 	O
describing	O
 	O
speech	O
 	O
segments	O
 	O
in	O
 	O
terms	B
 	O
of	O
 	O
starting	O
 	O
time	B
,	O
 	O
ending	O
 	O
time	B
,	O
 	O
and	O
 	O
speaker	B
 	O
cluster	O
 	O
name	O
.	O
 	O
this	O
 	O
output	B
 	O
is	O
 	O
usually	O
 	O
evaluated	O
 	O
against	O
 	O
manually	O
 	O
annotated	O
 	O
ground	B
 	O
truth	O
segments	O
.	O
a	O
dynamic	O
programming	O
procedure	O
is	O
used	O
to	O
ﬁ	O
nd	O
the	O
optimal	O
 	O
one	O
-	O
to	O
-	O
one	O
mapping	O
between	O
the	O
hypothesis	B
and	O
the	O
ground	B
truth	I
segments	O
 	O
so	O
that	O
the	O
total	O
overlap	O
between	O
the	O
reference	B
speaker	I
and	O
the	O
corresponding	O
 	O
mapped	O
hypothesized	O
speaker	B
cluster	O
is	O
maximized	O
.	O
the	O
difference	O
is	O
expressed	O
 	O
as	O
 	O
the	O
 	O
diarization	B
 	O
error	O
 	O
rate	O
 	O
(	O
der	O
)	O
,	O
 	O
which	O
 	O
is	O
 	O
deﬁ	O
ned	O
 	O
by	O
 	O
the	O
 	O
u.s	O
.	O
 	O
national	O
 	O
institute	O
of	O
standards	O
and	O
technology	O
(	O
nist	O
)	O
.	O
the	O
der	O
can	O
be	O
decomposed	O
speaker	B
diarization	I
   	O
121	O
into	O
 	O
three	O
 	O
components	B
:	O
 	O
misses	O
 	O
(	O
speaker	B
 	O
in	O
 	O
reference	B
,	O
 	O
but	O
 	O
not	O
 	O
in	O
 	O
hypothesis	B
)	O
,	O
 	O
false	O
alarms	O
(	O
speaker	B
in	O
hypothesis	B
,	O
but	O
not	O
in	O
reference	B
)	O
,	O
and	O
speaker	B
errors	B
 	O
(	O
mapped	O
reference	B
is	O
not	O
the	O
same	O
as	O
hypothesized	O
speaker).the	O
icsi	O
speaker	B
 	O
diarization	B
system	O
has	O
competed	O
in	O
the	O
nist	O
evaluations	O
of	O
the	O
past	O
several	O
 	O
years	O
 	O
and	O
 	O
established	O
 	O
itself	O
 	O
well	O
 	O
among	O
 	O
state-	O
 	O
of	O
-	O
the	O
-	O
art	O
 	O
systems	O
.	O
the	O
 	O
current	O
 	O
ofﬁ	O
cial	O
score	B
is	O
21.74	O
%	O
der	O
for	O
the	O
single	O
-	O
microphone	O
case	O
(	O
rt07	O
evaluation	B
 	O
set	B
)	O
.	O
 	O
this	O
 	O
error	O
 	O
can	O
 	O
be	O
 	O
decomposed	O
 	O
in	O
 	O
6.8	O
%	O
 	O
speech	O
/	O
nonspeech	O
 	O
error	O
 	O
and	O
 	O
14.9	O
%	O
speaker	B
clustering	B
error	O
.	O
the	O
speaker	B
error	O
includes	O
all	O
wrongly	O
classi-	O
ﬁ	O
ed	O
segments	O
,	O
including	O
overlapped	B
speech	I
and	O
very	O
short	O
segments	O
.	O
    	O
7.3.4	O
   	O
incorporation	O
of	O
spatial	O
information	B
  	O
in	O
 	O
speech	O
 	O
recognition	O
,	O
 	O
microphone	O
 	O
arrays	O
 	O
are	O
 	O
often	O
 	O
used	O
 	O
as	O
 	O
a	O
 	O
method	B
 	O
to	O
 	O
enhance	O
 	O
the	O
 	O
recorded	O
 	O
audio	O
 	O
signal	B
 	O
captured	O
 	O
by	O
 	O
far	O
-	O
ﬁ	O
eld	O
 	O
microphones	O
.	O
 	O
the	O
 	O
redundant	O
signals	B
enhance	O
the	O
signal	B
,	O
even	O
if	O
some	O
of	O
the	O
channels	B
have	O
a	O
very	O
 	O
poor	O
signal	B
-	O
to	O
-	O
noise	O
ratio	O
(	O
snr	O
)	O
.	O
with	O
speaker	B
diarization	I
being	O
a	O
front	O
-	O
end	O
 	O
processing	B
 	O
step	O
 	O
for	O
 	O
speech	O
 	O
recognition	O
,	O
 	O
it	O
 	O
seems	O
 	O
natural	O
 	O
to	O
 	O
exploit	O
 	O
the	O
 	O
avail-	O
ability	O
 	O
of	O
 	O
spatial	O
 	O
information	B
 	O
for	O
 	O
speaker	B
 	O
segmentation	B
 	O
and	O
 	O
clustering	B
.	O
 	O
by	O
 	O
correlating	O
the	O
individual	O
microphone	O
signals	B
,	O
one	O
can	O
obtain	O
information	B
on	O
 	O
the	O
 	O
location	O
 	O
of	O
 	O
the	O
 	O
audio	O
 	O
source	B
 	O
(	O
speaker	B
)	O
 	O
by	O
 	O
calculating	O
 	O
the	O
 	O
so	O
-	O
called	O
 	O
time	B
 	O
delay	O
 	O
of	O
 	O
arrival	O
 	O
(	O
tdoa	O
)	O
.	O
this	O
 	O
is	O
 	O
the	O
 	O
phase	O
 	O
shift	O
 	O
caused	O
 	O
by	O
 	O
the	O
 	O
varying	O
 	O
dis-	O
tances	O
 	O
of	O
 	O
the	O
 	O
speakers	O
 	O
to	O
 	O
the	O
 	O
microphones	O
.	O
 	O
nist	O
 	O
also	O
 	O
evaluated	O
 	O
diarization	B
 	O
on	O
microphone	O
arrays	O
as	O
the	O
so-	O
 	O
called	O
mdm	O
(	O
multidistant	O
microphone	O
)	O
condi-	O
tion	O
.	O
combining	O
the	O
tdoa	O
features	O
with	O
mfccs	O
resulted	O
in	O
a	O
relative	O
reduc-	O
tion	O
of	O
55	O
%	O
der	O
with	O
respect	O
to	O
the	O
sdm	O
(	O
single	O
-	O
distant	O
microphone	O
)	O
error	O
 	O
(	O
8.51	O
%	O
 	O
absolute	O
;	O
 	O
see	O
  	O
[	O
16	O
]	O
)	O
.	O
there	O
 	O
are	O
 	O
several	O
 	O
downsides	O
 	O
to	O
 	O
obtaining	O
 	O
spatial	O
 	O
information	B
purely	O
from	O
the	O
audio	O
signal	B
.	O
first	O
,	O
it	O
is	O
very	O
hard	O
to	O
detect	O
when	O
 	O
a	O
person	O
moves	O
or	O
walks	O
around	O
;	O
therefore	O
the	O
method	B
fails	O
by	O
reporting	O
dif-	O
ferent	O
 	O
speakers	O
.	O
 	O
second	O
,	O
 	O
this	O
 	O
method	B
 	O
requires	O
 	O
signiﬁ	O
cantly	O
 	O
more	O
 	O
computa-	O
tional	O
 	O
effort	O
 	O
as	O
 	O
eight	O
 	O
or	O
 	O
more	O
 	O
data	B
 	O
streams	O
 	O
have	O
 	O
to	O
 	O
be	O
 	O
processed	O
 	O
in	O
 	O
parallel	O
.	O
 	O
third	O
,	O
and	O
most	O
importantly	O
,	O
a	O
microphone	O
array	O
is	O
required	O
,	O
which	O
limits	O
the	O
 	O
usefulness	O
 	O
of	O
 	O
this	O
 	O
approach	O
 	O
to	O
 	O
laboratory	O
 	O
conditions	O
.	O
 	O
however	O
,	O
 	O
this	O
 	O
experi-	O
ment	O
shows	O
that	O
spatial	O
information	B
is	O
of	O
tremendous	O
help	O
for	O
the	O
solution	O
of	O
 	O
the	O
task	O
.	O
    	O
7.3.5	O
   	O
current	O
research	B
focus	O
  	O
one	O
of	O
the	O
major	O
changes	O
that	O
speaker	B
diarization	I
research	B
is	O
currently	O
under-	O
going	O
 	O
is	O
 	O
a	O
 	O
trend	O
 	O
toward	O
 	O
multimodality	O
.	O
as	O
 	O
explained	O
 	O
in	O
 	O
section	O
  	O
7.3.4	O
,	O
 	O
spatial	O
 	O
information	B
 	O
in	O
 	O
combination	O
 	O
with	O
 	O
mfccs	O
 	O
had	O
 	O
been	O
 	O
used	O
 	O
very	O
 	O
successfully	O
.	O
 	O
also	O
,	O
 	O
in	O
 	O
different	O
 	O
studies	O
 	O
on	O
 	O
audiovisual	O
 	O
synchrony	O
 	O
(	O
e.g.	O
,	O
  	O
[	O
17	O
]	O
  	O
or	O
  	O
[	O
18	O
]	O
)	O
,	O
 	O
the	O
 	O
application	B
of	O
audiovisual	O
combination	O
techniques	B
has	O
been	O
shown	O
to	O
be	O
suc-	O
cessful	O
,	O
at	O
least	O
for	O
laboratory	O
conditions	O
.	O
this	O
and	O
other	O
evidence	O
motivates	O
 	O
researchers	O
to	O
incorporate	O
other	O
media	O
in	O
the	O
task	O
,	O
such	O
as	O
video	O
.	O
for	O
example	O
,	O
 	O
in	O
 	O
their	O
 	O
article	O
  	O
“	O
audio	O
 	O
segmentation	B
 	O
and	O
 	O
speaker	B
 	O
localization	O
 	O
in	O
 	O
meeting	O
122	O
   	O
speaker	B
recognition	O
and	O
diarization	B
videos	B
”	O
  	O
[	O
19	O
]	O
,	O
the	O
authors	O
present	O
a	O
system	O
that	O
combines	O
audio	O
and	O
video	O
on	O
 	O
a	O
 	O
feature	O
 	O
level	B
.	O
 	O
another	O
 	O
recent	O
 	O
article	O
  	O
[	O
20	O
]	O
  	O
presents	O
 	O
a	O
 	O
multimodal	O
 	O
speaker	B
 	O
localization	O
 	O
effort	O
 	O
using	O
 	O
a	O
 	O
specialized	O
 	O
microphone	O
 	O
and	O
 	O
an	O
 	O
omnidirectional	O
 	O
camera	O
.	O
  	O
another	O
 	O
trend	O
 	O
in	O
 	O
speaker	B
 	O
diarization	B
 	O
is	O
 	O
the	O
 	O
research	B
 	O
on	O
 	O
online	O
 	O
(	O
i.e.	O
,	O
 	O
non	O
–	O
 	O
batch	O
processing	B
)	O
approaches	O
.	O
for	O
example	O
,	O
in	O
 	O
[	O
21	O
]	O
,	O
the	O
authors	O
present	O
exper-	O
iments	O
 	O
on	O
 	O
a	O
 	O
framework	O
 	O
for	O
 	O
a	O
 	O
multimodal	O
 	O
online	O
 	O
diarization	B
 	O
system	O
 	O
focusing	O
 	O
on	O
bootstrapping	O
models	B
for	O
a	O
two	O
-	O
person	O
scenario	O
.	O
     	O
7.4	O
   	O
speaker	B
recognition	O
  	O
speaker	B
 	O
recognition	O
 	O
is	O
 	O
the	O
 	O
general	O
 	O
term	O
 	O
used	O
 	O
for	O
 	O
speech	O
 	O
technology	O
 	O
tasks	O
 	O
where	O
the	O
identity	O
of	O
the	O
speaker	B
is	O
the	O
key	O
unknown	O
to	O
be	O
found	O
automati-	O
cally	O
by	O
the	O
system	O
.	O
the	O
most	O
salient	O
differences	O
with	O
speaker	B
diarization	I
are	O
 	O
that	O
    	O
(	O
cid:129	O
)	O
      	O
there	O
 	O
is	O
 	O
enrollment	O
,	O
 	O
that	O
 	O
is	O
,	O
 	O
training	O
 	O
speech	O
 	O
material	O
 	O
is	O
 	O
available	O
 	O
for	O
 	O
the	O
 	O
known	O
speaker(s	O
)	O
,	O
and	O
     	O
(	O
cid:129	O
)	O
      	O
the	O
 	O
unknown	O
 	O
speech	O
 	O
segment	B
,	O
 	O
or	O
 	O
test	B
 	O
segment	B
,	O
 	O
is	O
 	O
assumed	O
 	O
to	O
 	O
contain	O
 	O
speech	O
from	O
only	O
one	O
speaker	B
.	O
     	O
there	O
are	O
speaker	B
recognition	O
applications	O
for	O
which	O
the	O
latter	O
does	O
not	O
hold	O
,	O
 	O
but	O
for	O
the	O
sake	O
of	O
simplicity	O
we	O
treat	O
this	O
as	O
a	O
task	O
where	O
ﬁ	O
rst	O
speaker	B
diariza-	O
tion	O
on	O
the	O
test	B
segment	B
needs	O
to	O
be	O
performed	O
,	O
after	O
which	O
speaker	B
recogni-	O
tion	O
can	O
be	O
applied	O
to	O
the	O
segmented	O
speech	O
.	O
  	O
there	O
are	O
various	O
 	O
“	O
guises	O
”	O
 	O
of	O
speaker	B
recognition	O
.	O
perhaps	O
the	O
most	O
natural	O
 	O
form	O
,	O
 	O
from	O
 	O
a	O
 	O
human	O
 	O
point	O
 	O
of	O
 	O
view	O
,	O
 	O
is	O
 	O
that	O
 	O
of	O
 	O
speaker	B
 	O
identiﬁ	O
cation	O
,	O
 	O
which	O
 	O
is	O
 	O
to	O
identify	O
the	O
identity	O
of	O
the	O
speaker	B
from	O
a	O
spoken	O
utterance	O
given	O
the	O
set	B
 	O
of	O
 	O
possible	O
 	O
speakers	O
 	O
of	O
 	O
that	O
 	O
utterance	O
.	O
 	O
however	O
,	O
 	O
in	O
 	O
practical	O
 	O
situations	O
 	O
it	O
 	O
hardly	O
ever	O
occurs	O
that	O
the	O
set	B
of	O
possible	O
speakers	O
is	O
limited	O
;	O
rather	O
,	O
usually	O
 	O
there	O
needs	O
to	O
be	O
some	O
veriﬁ	O
cation	O
that	O
the	O
speaker	B
is	O
actually	O
one	O
of	O
the	O
set	B
,	O
 	O
or	O
even	O
worse	O
,	O
that	O
the	O
recorded	O
sound	O
actually	O
contains	O
speech	O
.	O
allowing	O
for	O
 	O
the	O
possibility	O
of	O
out	O
-	O
of	O
-	O
set	B
speakers	O
is	O
termed	O
open	O
-	O
set	B
speaker	B
identiﬁ	O
cation	O
 	O
and	O
 	O
requires	O
 	O
that	O
 	O
internal	O
 	O
similarity	B
 	O
scores	O
 	O
have	O
 	O
some	O
 	O
form	O
 	O
of	O
  	O
“	O
absolute	O
”	O
  	O
meaning	O
so	O
that	O
a	O
score	B
can	O
be	O
thresholded	O
and	O
a	O
hypothesized	O
speaker	B
can	O
 	O
be	O
 	O
rejected	O
 	O
if	O
 	O
the	O
 	O
score	B
 	O
is	O
 	O
too	O
 	O
low	O
.	O
this	O
 	O
capability	O
 	O
of	O
 	O
rejecting	O
 	O
an	O
 	O
unknown	O
 	O
speaker	B
is	O
so	O
important	O
that	O
it	O
has	O
been	O
the	O
main	O
focus	O
in	O
speaker	B
recognition	O
 	O
technology	O
and	O
its	O
performance	O
evaluation	B
.	O
for	O
non	O
-	O
discriminative	O
modeling	O
,	O
 	O
the	O
open	O
-	O
set	B
speaker	B
recognition	O
problem	O
can	O
be	O
generalized	O
to	O
the	O
speaker	B
 	O
detection	B
 	O
task	O
,	O
 	O
where	O
 	O
the	O
 	O
task	O
 	O
is	O
 	O
to	O
 	O
decide	O
 	O
whether	O
 	O
or	O
 	O
not	O
 	O
a	O
 	O
given	O
 	O
speech	O
 	O
segment	B
is	O
spoken	O
by	O
a	O
target	O
speaker	B
.	O
as	O
this	O
general	O
task	O
is	O
at	O
the	O
basis	O
of	O
 	O
many	O
 	O
different	O
 	O
application	B
 	O
scenarios	O
,	O
 	O
we	O
 	O
will	O
 	O
use	O
 	O
the	O
 	O
speaker	B
 	O
detection	B
 	O
task	O
 	O
(	O
equivalent	O
 	O
to	O
 	O
one	O
 	O
speaker	B
 	O
open	O
-	O
set	B
 	O
identiﬁ	O
cation	O
)	O
 	O
as	O
 	O
the	O
 	O
prototype	O
 	O
task	O
 	O
in	O
 	O
the	O
remainder	O
of	O
this	O
chapter	O
.	O
speaker	B
recognition	O
   	O
123	O
  	O
7.4.1	O
   	O
evaluation	B
measures	O
  	O
applications	O
 	O
in	O
 	O
speaker	B
 	O
detection	B
 	O
range	O
 	O
from	O
 	O
target	O
-	O
sparse	O
 	O
applications	O
 	O
in	O
 	O
intelligence	O
(	O
ﬁ	O
nding	O
the	O
few	O
utterances	B
from	O
a	O
target	O
speaker	B
in	O
a	O
very	O
large	O
 	O
database	O
 	O
of	O
 	O
recordings	O
)	O
 	O
to	O
 	O
target-	O
 	O
rich	O
 	O
applications	O
 	O
such	O
 	O
as	O
 	O
access	O
 	O
control	O
 	O
(	O
ﬁ	O
nding	O
the	O
presumably	O
very	O
few	O
break	O
-	O
in	O
attempts	O
in	O
long	O
sequences	O
of	O
genu-	O
inely	O
authorized	O
speakers	O
)	O
.	O
in	O
a	O
detection	B
trial	O
,	O
the	O
prior	O
probability	B
of	O
a	O
target	O
 	O
speaker	B
plays	O
a	O
crucial	O
role	O
.	O
however	O
,	O
these	O
priors	O
can	O
not	O
be	O
determined	O
by	O
 	O
the	O
 	O
speaker	B
 	O
recognition	O
 	O
technology	O
 	O
itself	O
 	O
and	O
 	O
are	O
 	O
given	O
 	O
by	O
 	O
the	O
 	O
application	B
.	O
 	O
therefore	O
,	O
the	O
framework	O
in	O
which	O
a	O
speaker	B
recognition	O
system	O
is	O
evaluated	O
 	O
is	O
by	O
deﬁ	O
ning	O
a	O
cost	B
function	O
:	O
     	O
c	O
=	O
c	O
p	O
p	O
+	O
c	O
(	O
1	O
−	O
p	O
)	O
p	O
     	O
(	O
7.1	O
)	O
   	O
det	O
miss	B
tar	O
miss	B
fa	O
tar	O
fa	O
 	O
here	O
,	O
 	O
the	O
 	O
application	B
-	O
speciﬁ	O
c	O
 	O
cost	B
 	O
parameters	O
  	O
c	O
     	O
and	O
  	O
c	O
     	O
determine	O
 	O
the	O
 	O
miss	B
fa	O
expected	O
costs	O
made	O
in	O
decision	O
errors	B
.	O
the	O
error	B
rates	I
 	O
p	O
    	O
and	O
 	O
p	O
    	O
indicate	O
 	O
fa	O
miss	B
the	O
probability	B
of	O
a	O
miss	B
(	O
a	O
not	O
-	O
detected	O
target	O
trial	O
)	O
and	O
false	B
alarm	I
(	O
a	O
falsely	O
 	O
detected	O
 	O
nontarget	O
 	O
trial	O
)	O
 	O
and	O
 	O
must	O
 	O
be	O
 	O
determined	O
 	O
in	O
 	O
an	O
 	O
evaluation	B
 	O
of	O
 	O
the	O
 	O
system	O
.	O
 	O
from	O
 	O
(	O
7.1	O
)	O
,	O
 	O
it	O
 	O
can	O
 	O
be	O
 	O
seen	O
 	O
that	O
 	O
the	O
 	O
target	O
 	O
prior	O
  	O
p	O
     	O
governs	O
 	O
the	O
 	O
cost	B
 	O
tar	O
function	O
.	O
  	O
even	O
though	O
in	O
nist	O
evaluations	O
of	O
text	O
-	O
independent	O
speaker	B
recognition	O
 	O
systems	O
c	O
      	O
is	O
the	O
primary	O
evaluation	B
measure	O
system	O
,	O
developers	O
use	O
many	O
 	O
det	O
more	O
 	O
performance	O
 	O
metrics	O
 	O
to	O
 	O
optimize	O
 	O
their	O
 	O
system	O
.	O
 	O
these	O
 	O
metrics	O
 	O
are	O
 	O
dis-	O
cussed	O
at	O
length	B
in	O
 	O
[	O
22	O
]	O
 	O
but	O
we	O
will	O
give	O
a	O
brief	O
summary	O
here	O
:	O
    	O
(	O
cid:129	O
)	O
      	O
det	O
 	O
curve	O
     	O
the	O
 	O
detection	B
 	O
error	O
 	O
trade	O
-	O
off	O
 	O
curve	O
 	O
is	O
 	O
a	O
 	O
parametric	O
 	O
plot	O
 	O
showing	O
 	O
the	O
 	O
trade	O
-	O
off	O
 	O
between	O
 	O
p	O
       	O
and	O
  	O
p	O
     	O
when	O
 	O
the	O
 	O
internal	O
 	O
system	O
 	O
fa	O
miss	B
rejection	O
threshold	B
is	O
varied	O
.	O
although	O
essentially	O
being	O
a	O
receiver	O
oper-	O
ating	O
characteristic	O
(	O
roc	O
)	O
,	O
by	O
using	O
axes	O
that	O
are	O
warped	O
by	O
the	O
probit	O
 	O
function	O
,	O
the	O
trade	O
-	O
off	O
often	O
appears	O
as	O
a	O
straight	O
line	O
(	O
indicating	O
 	O
“	O
normal	O
”	O
  	O
behavior	O
of	O
the	O
target	O
and	O
nontarget	O
score	B
distributions	O
)	O
and	O
allows	O
com-	O
parison	O
between	O
systems	O
in	O
a	O
wide	O
range	O
of	O
system	O
performance	O
.	O
indeed	O
,	O
 	O
the	O
 	O
det	O
 	O
plot	O
 	O
has	O
 	O
been	O
 	O
embraced	O
 	O
almost	O
 	O
emotionally	O
 	O
by	O
 	O
the	O
 	O
speaker	B
 	O
recognition	O
community	O
since	O
its	O
introduction	O
in	O
1997	O
 	O
[	O
23	O
]	O
.	O
     	O
(	O
cid:129	O
)	O
      	O
equal	O
error	B
rate	I
     	O
the	O
equal	O
error	B
rate	I
(	O
eer	B
)	O
is	O
the	O
point	O
in	O
the	O
det	O
 	O
curve	O
where	O
 	O
p	O
    	O
and	O
 	O
p	O
    	O
are	O
equal	O
.	O
it	O
is	O
a	O
single	O
performance	O
measure	O
 	O
miss	B
fa	O
describing	O
the	O
discriminative	O
abilities	O
of	O
a	O
speaker	B
recognition	O
system	O
.	O
it	O
 	O
does	O
not	O
,	O
however	O
,	O
measure	O
the	O
capability	O
of	O
setting	O
a	O
proper	O
threshold	B
,	O
 	O
as	O
 	O
it	O
 	O
is	O
 	O
an	O
 	O
after	O
-	O
the	O
-	O
fact	O
 	O
evaluation	B
 	O
measure	O
.	O
 	O
this	O
 	O
is	O
 	O
perhaps	O
 	O
the	O
 	O
most	O
 	O
widely	O
reported	O
performance	O
measure	O
in	O
speaker	B
recognition	O
.	O
     	O
(	O
cid:129	O
)	O
      	O
minimum	O
 	O
cd	O
et	O
      	O
the	O
  	O
“	O
minimum	O
  	O
c	O
 	O
det	O
 	O
”	O
  	O
is	O
 	O
the	O
 	O
value	O
 	O
of	O
 	O
the	O
 	O
cost	B
 	O
function	O
 	O
obtained	O
if	O
the	O
threshold	B
had	O
been	O
set	B
optimally	O
.	O
it	O
also	O
is	O
an	O
after	O
-	O
the	O
-	O
fact	O
 	O
measure	O
but	O
is	O
targeted	O
more	O
toward	O
the	O
application	B
deﬁ	O
ned	O
by	O
the	O
cost	B
 	O
function	O
(	O
compared	O
to	O
eer	B
)	O
.	O
 	O
124	O
   	O
speaker	B
recognition	O
and	O
diarization	B
   	O
(	O
cid:129	O
)	O
      	O
c	O
llr	O
      	O
a	O
 	O
cost	B
 	O
function	O
 	O
alternative	O
 	O
to	O
 	O
c	O
   	O
det	O
  	O
has	O
 	O
been	O
 	O
proposed	O
 	O
by	O
 	O
niko	O
 	O
br	O
ü	O
mmer	O
in	O
2004	O
and	O
used	O
as	O
an	O
alternative	O
measure	O
in	O
nist	O
evaluations	O
 	O
since	O
 	O
2006	O
.	O
 	O
the	O
 	O
log	B
-	O
likelihood	B
-	O
ratio	O
 	O
cost	B
 	O
function	O
 	O
c	O
       	O
can	O
 	O
be	O
 	O
seen	O
 	O
as	O
 	O
a	O
 	O
llr	O
version	O
of	O
c	O
      	O
generalized	O
to	O
all	O
application	B
scenarios	O
by	O
integrating	O
over	O
 	O
det	O
the	O
(	O
effective	O
)	O
prior	O
.	O
the	O
measure	O
evaluates	O
the	O
capability	O
of	O
a	O
system	O
to	O
 	O
produce	O
scores	O
that	O
can	O
be	O
interpreted	O
as	O
a	O
log	B
-	O
likelihood	B
ratio	I
,	O
which	O
has	O
 	O
the	O
advantage	O
that	O
the	O
ideal	O
threshold	B
for	O
any	O
application	B
type	O
is	O
deter-	O
mined	O
solely	O
by	O
the	O
cost	B
parameters	O
and	O
prior	O
.	O
therefore	O
,	O
the	O
system	O
does	O
 	O
not	O
need	O
to	O
be	O
recalibrated	O
if	O
the	O
application	B
parameters	O
change	B
.	O
     	O
(	O
cid:129	O
)	O
      	O
minimum	O
cl	O
lr	O
      	O
by	O
optimizing	O
the	O
score	B
-	O
to	O
-	O
log	B
-	O
likelihood	B
-	O
ratio	O
function	O
,	O
 	O
one	O
can	O
determine	O
the	O
value	O
of	O
 	O
c	O
    	O
if	O
the	O
calibration	O
stage	B
(	O
“	O
setting	O
the	O
 	O
llr	O
threshold	B
”	O
 	O
—	O
but	O
 	O
generalized	O
 	O
to	O
 	O
all	O
 	O
cost	B
 	O
functions	O
)	O
 	O
would	O
 	O
be	O
 	O
ideal	O
.	O
 	O
this	O
 	O
metric	B
 	O
concentrates	O
 	O
on	O
 	O
the	O
 	O
discrimination	O
 	O
abilities	O
 	O
of	O
 	O
a	O
 	O
system	O
 	O
but	O
 	O
one	O
 	O
generalized	O
to	O
all	O
application	B
scenarios	O
.	O
       	O
7.4.2	O
   	O
system	O
architecture	B
  	O
the	O
general	O
system	O
architecture	B
for	O
a	O
speaker	B
recognition	O
system	O
is	O
shown	O
in	O
 	O
figure	O
 	O
7.3	O
  	O
.	O
as	O
discussed	O
earlier	O
,	O
it	O
has	O
certain	O
steps	B
in	O
common	O
with	O
speaker	B
 	O
diarization	B
.	O
 	O
because	O
 	O
there	O
 	O
is	O
 	O
a	O
 	O
speciﬁ	O
c	O
 	O
training	O
,	O
 	O
or	O
 	O
enrollment	O
,	O
 	O
phase	O
 	O
of	O
 	O
a	O
 	O
speaker	B
and	O
a	O
testing	O
phase	O
,	O
we	O
can	O
differentiate	O
between	O
the	O
common	O
parts	O
 	O
speech	O
supervector	O
supervector	O
model	B
speech	B
activity	I
model	B
generation	O
scoring	O
detection	B
t	O
-	O
norm	B
model	B
feature	O
extraction	B
z	O
-	O
norm	B
t	O
-	O
normalization	O
speakers	O
speakers	O
z	O
-	O
normalization	O
test	B
ubm	O
database	O
ubm	O
index	O
calibration	O
model	B
,	O
z	O
-	O
stats	O
map	O
ubm	O
log	B
-	O
likelihood	B
ratio	I
adaptation	O
other	O
llr	O
’s	O
fusion	O
supervector	O
calibrated	O
log	B
-	O
likelihood	B
ratio	I
common	O
training	O
testing	O
     	O
figure	O
 	O
7.3	O
     	O
typical	O
 	O
architecture	B
 	O
of	O
 	O
speaker	B
 	O
recognition	O
 	O
system	O
 	O
as	O
 	O
described	O
 	O
in	O
 	O
section	O
 	O
7.4	O
.	O
 	O
speaker	B
recognition	O
   	O
125	O
and	O
 	O
the	O
 	O
training	O
/	O
testing	O
 	O
speciﬁ	O
c	O
 	O
parts	O
 	O
of	O
 	O
the	O
 	O
architecture	B
.	O
the	O
 	O
common	O
 	O
pro-	O
cessing	O
steps	B
for	O
a	O
given	O
speech	B
segment	I
are	O
:	O
    	O
(	O
cid:129	O
)	O
      	O
speech	B
activity	I
detection	I
    	O
s	O
 	O
imilar	O
to	O
speaker	B
diarization	I
,	O
for	O
telephone	O
 	O
speech	O
often	O
energy	O
-	O
based	O
methods	O
sufﬁ	O
ce	O
.	O
     	O
(	O
cid:129	O
)	O
      	O
feature	O
extraction	B
    	O
d	O
 	O
iscussed	O
in	O
section	O
 	O
7.2.1	O
.	O
     	O
(	O
cid:129	O
)	O
      	O
ubm	O
 	O
index	O
 	O
generation	O
    	O
t	O
 	O
his	O
 	O
step	O
 	O
computes	O
 	O
the	O
 	O
contribution	O
 	O
to	O
 	O
the	O
 	O
ubm	O
 	O
likelihood	B
 	O
of	O
 	O
every	O
 	O
gaussian	O
 	O
component	O
 	O
for	O
 	O
every	O
 	O
frame	B
 	O
of	O
 	O
the	O
 	O
speech	O
 	O
segment	B
.	O
 	O
then	O
 	O
the	O
 	O
indices	O
 	O
of	O
 	O
the	O
 	O
n	O
    	O
topmost	O
 	O
contributors	O
 	O
are	O
 	O
extracted	O
;	O
typically	O
n	O
     	O
=	O
  	O
5	O
gaussians	O
are	O
used	O
.	O
the	O
idea	O
is	O
that	O
these	O
ﬁ	O
ve	O
 	O
are	O
enough	O
to	O
accurately	O
compute	O
the	O
likelihood	B
of	O
the	O
frame	B
.	O
     	O
(	O
cid:129	O
)	O
      	O
supervector	O
 	O
generation	O
    	O
u	O
 	O
sing	O
 	O
the	O
 	O
top	O
-	O
 	O
n	O
  	O
gaussians	O
 	O
per	O
 	O
frame	B
 	O
in	O
 	O
the	O
 	O
calculation	O
,	O
 	O
the	O
 	O
means	O
 	O
of	O
 	O
the	O
 	O
ubm	O
 	O
can	O
 	O
be	O
 	O
adapted	O
 	O
to	O
 	O
the	O
 	O
maximum	O
 	O
a	O
 	O
posteriori	O
 	O
(	O
map	O
)	O
 	O
likelihood	B
 	O
of	O
 	O
the	O
 	O
speech	O
 	O
segment	B
  	O
[	O
24	O
]	O
)	O
.	O
 	O
the	O
 	O
shift	O
 	O
in	O
 	O
means	O
can	O
be	O
said	O
to	O
represent	O
the	O
speaker	B
of	O
the	O
speech	B
segment	I
.	O
(	O
note	O
 	O
that	O
 	O
also	O
 	O
the	O
 	O
gaussian	O
 	O
component	O
’	O
s	O
 	O
prior	O
 	O
and	O
 	O
covariance	O
 	O
can	O
 	O
be	O
 	O
map	O
 	O
adapted	O
,	O
 	O
but	O
 	O
this	O
 	O
is	O
 	O
generally	O
 	O
considered	O
 	O
not	O
 	O
to	O
 	O
encode	O
 	O
much	O
 	O
speaker	B
-	O
 	O
dependent	O
information	B
.	O
)	O
a	O
per	O
-	O
dimension	O
scaling	O
of	O
this	O
displacement	O
 	O
[	O
25	O
]	O
  	O
(	O
using	O
the	O
prior	O
and	O
variance	O
parameters	O
of	O
the	O
ubm	O
)	O
and	O
concatenation	O
 	O
of	O
the	O
scaled	O
displacement	O
vectors	O
into	O
a	O
so	O
-	O
called	O
supervector	O
s	O
   	O
allows	O
a	O
 	O
geometric	O
interpretation	O
of	O
this	O
space	O
.	O
a	O
speech	O
utterance	O
is	O
represented	O
 	O
as	O
a	O
point	O
in	O
this	O
space	O
,	O
and	O
when	O
points	O
lie	O
close	O
together	O
,	O
we	O
consider	O
it	O
 	O
more	O
likely	O
that	O
the	O
speech	O
was	O
uttered	O
by	O
the	O
same	B
speaker	I
.	O
       	O
the	O
steps	B
speciﬁ	O
c	O
to	O
training	O
are	O
as	O
follows	O
:	O
    	O
(	O
cid:129	O
)	O
      	O
model	B
 	O
generation	O
    	O
t	O
 	O
here	O
 	O
are	O
 	O
two	O
 	O
distinct	O
 	O
classes	O
 	O
of	O
 	O
modeling	O
 	O
used	O
 	O
in	O
 	O
speaker	B
 	O
recognition	O
:	O
 	O
generative	O
 	O
and	O
 	O
discriminative	O
.	O
 	O
for	O
 	O
a	O
 	O
generative	O
 	O
model	B
,	O
the	O
map	O
-	O
adapted	O
gmm	O
is	O
the	O
model	B
—	O
the	O
important	O
parameters	O
 	O
are	O
the	O
(	O
unscaled	O
)	O
means	O
of	O
the	O
gaussians	O
.	O
alternatively	O
,	O
a	O
discriminative	O
 	O
model	B
can	O
be	O
formed	O
by	O
using	O
a	O
svm	O
.	O
additional	O
to	O
the	O
target	O
speaker	B
,	O
 	O
for	O
which	O
the	O
model	B
is	O
to	O
be	O
trained	O
,	O
many	O
nontarget	O
(	O
i.e.	O
,	O
 	O
“	O
background	O
”	O
)	O
 	O
speakers	O
 	O
are	O
 	O
used	O
 	O
to	O
 	O
compare	O
 	O
the	O
 	O
target	O
 	O
speaker	B
 	O
to	O
.	O
 	O
an	O
 	O
svm	O
 	O
tries	O
 	O
to	O
 	O
maximize	O
 	O
the	O
 	O
margin	O
 	O
between	O
 	O
the	O
 	O
target	O
 	O
speaker	B
 	O
and	O
 	O
the	O
 	O
background	O
 	O
speakers	O
.	O
that	O
 	O
is	O
,	O
 	O
it	O
 	O
tries	O
 	O
to	O
 	O
position	O
 	O
a	O
 	O
hyperplane	O
 	O
in	O
 	O
supervector	O
 	O
space	O
 	O
which	O
 	O
has	O
 	O
a	O
 	O
maximum	O
 	O
distance	B
 	O
from	O
 	O
the	O
 	O
target	O
 	O
speaker	B
.	O
 	O
the	O
 	O
svm	O
 	O
model	B
now	O
is	O
characterized	O
by	O
the	O
normal	O
n	O
   	O
of	O
this	O
separating	O
hyperplane	O
 	O
and	O
 	O
an	O
 	O
offset	O
  	O
b	O
.	O
 	O
five	O
 	O
hundred	O
 	O
to	O
 	O
2000	O
 	O
background	O
 	O
speakers	O
 	O
are	O
 	O
used	O
 	O
typically	O
.	O
     	O
(	O
cid:129	O
)	O
      	O
z	O
-	O
norm	B
 	O
statistics	B
 	O
collection	O
    	O
f	O
 	O
or	O
 	O
generative	O
 	O
modeling	O
,	O
 	O
a	O
 	O
set	B
 	O
of	O
 	O
back-	O
ground	B
speakers	O
can	O
be	O
used	O
in	O
a	O
different	O
way	O
.	O
the	O
likelihoods	O
of	O
back-	O
ground	B
speakers	O
given	O
the	O
target	O
speaker	B
gmm	O
can	O
be	O
calculated	O
for	O
a	O
 	O
set	B
 	O
of	O
 	O
nontarget	O
 	O
speakers	O
.	O
 	O
the	O
 	O
mean	O
 	O
and	O
 	O
variance	O
 	O
of	O
 	O
these	O
 	O
likelihoods	O
 	O
can	O
be	O
stored	O
with	O
the	O
speaker	B
model	B
and	O
used	O
for	O
score	B
normalization	O
126	O
   	O
speaker	B
recognition	O
and	O
diarization	B
in	O
the	O
test	B
phase	O
(	O
known	O
as	O
 	O
z	O
 	O
-	O
norming	O
)	O
.	O
typically	O
,	O
hundreds	O
of	O
speakers	O
 	O
are	O
used	O
for	O
 	O
z	O
 	O
-	O
norming	O
.	O
interestingly	O
,	O
 	O
z	O
 	O
-	O
norming	O
does	O
not	O
seem	O
to	O
help	O
 	O
with	O
discriminative	O
svms	O
(	O
presumably	O
because	O
background	O
speakers	O
are	O
 	O
already	O
 	O
accounted	O
 	O
for	O
 	O
in	O
 	O
the	O
 	O
model	B
)	O
 	O
but	O
 	O
is	O
 	O
essential	O
 	O
for	O
 	O
certain	O
 	O
more	O
 	O
advanced	O
factor	B
analysis	I
models	B
 	O
[	O
26	O
,	O
27	O
]	O
.	O
     	O
finally	O
,	O
the	O
steps	B
unique	O
to	O
producing	O
scores	O
at	O
test	B
time	B
are	O
as	O
follows	O
:	O
    	O
(	O
cid:129	O
)	O
      	O
score	B
generation	O
    	O
g	O
 	O
iven	O
a	O
test	B
speech	O
utterance	O
,	O
a	O
score	B
s	O
   	O
can	O
be	O
calcu-	O
lated	O
that	O
indicates	O
how	O
well	O
the	O
speech	O
 	O
“	O
matches	O
”	O
 	O
the	O
target	O
speaker	B
'	O
s	O
 	O
model	B
.	O
for	O
the	O
generative	O
gmm	O
,	O
the	O
overall	O
likelihood	B
 	O
l	O
 	O
of	O
the	O
speech	O
  	O
x	O
,	O
given	O
the	O
target	O
speaker	B
model	B
t	O
  	O
,	O
is	O
used	O
.	O
it	O
is	O
normalized	O
by	O
the	O
likeli-	O
hood	O
 	O
of	O
 	O
the	O
 	O
speech	O
 	O
given	O
 	O
the	O
 	O
ubm	O
  	O
u	O
.	O
 	O
in	O
 	O
these	O
 	O
likelihood	B
 	O
calculations	O
,	O
 	O
only	O
the	O
top	O
-	O
 	O
n	O
 	O
gaussians	O
per	O
frame	B
are	O
used	O
:	O
     	O
s	O
=	O
log	B
l(x	O
t	O
)	O
   	O
l(x	O
u	O
)	O
 	O
for	O
the	O
discriminative	O
svm	O
model	B
,	O
the	O
score	B
is	O
given	O
by	O
the	O
inner	O
product	O
 	O
of	O
the	O
normal	O
vector	O
and	O
the	O
supervector	O
,	O
s	O
     	O
=	O
   	O
n	O
    	O
·	O
    	O
s	O
   	O
+	O
   	O
b	O
.	O
     	O
(	O
cid:129	O
)	O
      	O
t	O
-	O
normalization	O
     	O
after	O
an	O
optional	O
z	O
   	O
-	O
scaling	O
of	O
the	O
scores	O
using	O
the	O
z	O
   	O
-	O
 	O
norm	B
statistics	B
,	O
the	O
score	B
 	O
s	O
 	O
can	O
further	O
be	O
normalized	O
.	O
by	O
calculating	O
the	O
 	O
scores	O
 	O
of	O
 	O
the	O
 	O
test	B
 	O
segment	B
 	O
for	O
 	O
many	O
 	O
nontarget	O
 	O
models	B
 	O
from	O
 	O
a	O
 	O
so	O
-	O
called	O
  	O
t	O
 	O
-	O
norm	B
 	O
cohort	O
,	O
 	O
a	O
 	O
further	O
 	O
z	O
   	O
-	O
scaling	O
 	O
helps	O
 	O
to	O
 	O
remove	O
 	O
unwanted	O
 	O
variation	O
 	O
in	O
the	O
score	B
due	O
to	O
the	O
variability	O
of	O
the	O
test	B
segment	B
(	O
e.g.	O
,	O
the	O
content	O
or	O
 	O
the	O
quality	B
)	O
.	O
     	O
(	O
cid:129	O
)	O
      	O
calibration	O
    	O
a	O
 	O
t	O
 	O
this	O
 	O
stage	B
,	O
 	O
the	O
 	O
interpretation	O
 	O
of	O
 	O
a	O
 	O
score	B
 	O
still	O
 	O
is	O
 	O
quite	O
 	O
limited	O
.	O
 	O
a	O
 	O
higher	O
 	O
score	B
 	O
means	O
 	O
more	O
 	O
similarity	B
 	O
between	O
 	O
train	O
 	O
and	O
 	O
test	B
 	O
segments	O
,	O
 	O
and	O
 	O
this	O
 	O
reﬂ	O
ects	O
 	O
the	O
 	O
discriminative	O
 	O
capabilities	O
 	O
of	O
 	O
the	O
 	O
system	O
.	O
 	O
if	O
the	O
system	O
is	O
to	O
make	O
decisions	O
about	O
whether	O
or	O
not	O
a	O
test	B
segment	B
is	O
 	O
uttered	O
 	O
by	O
 	O
the	O
 	O
target	O
 	O
speaker	B
,	O
 	O
a	O
 	O
threshold	B
 	O
needs	O
 	O
to	O
 	O
be	O
 	O
set	B
.	O
this	O
 	O
can	O
 	O
be	O
 	O
done	O
by	O
evaluating	O
the	O
system	O
on	O
a	O
large	O
collection	O
of	O
target	O
and	O
nontar-	O
get	O
trials	O
and	O
computing	O
the	O
threshold	B
at	O
which	O
the	O
cost	B
is	O
minimal	O
.	O
this	O
 	O
threshold	B
 	O
depends	O
 	O
on	O
 	O
the	O
 	O
application	B
-	O
speciﬁ	O
c	O
 	O
parameters	O
 	O
of	O
 	O
cost	B
 	O
and	O
 	O
prior	O
.	O
 	O
rather	O
 	O
than	O
 	O
ﬁ	O
xing	O
 	O
the	O
 	O
scores	O
 	O
and	O
 	O
choosing	O
 	O
the	O
 	O
threshold	B
,	O
 	O
we	O
 	O
can	O
 	O
ﬁ	O
x	O
 	O
the	O
 	O
threshold	B
 	O
and	O
 	O
shift	O
 	O
the	O
 	O
scores	O
.	O
 	O
it	O
 	O
is	O
 	O
possible	O
 	O
to	O
 	O
choose	O
 	O
a	O
 	O
simple	O
 	O
threshold	B
function	O
⎛	O
c	O
1	O
−	O
p	O
⎞	O
θ	O
=	O
log	B
⎜	O
fa	O
tar	O
⎟	O
⎝	O
⎠	O
c	O
p	O
     	O
miss	B
tar	O
  	O
and	O
transform	O
the	O
scores	O
accordingly	O
to	O
obtain	O
a	O
minimal	O
cost	B
for	O
all	O
pos-	O
sible	O
 	O
application	B
-	O
speciﬁ	O
c	O
 	O
parameters	O
.	O
 	O
this	O
 	O
transformation	O
 	O
of	O
 	O
scores	O
 	O
is	O
 	O
called	O
c	O
 	O
alibration	O
 	O
and	O
gives	O
the	O
transformed	O
scores	O
the	O
interpretation	O
of	O
conclusion	O
   	O
127	O
a	O
log	B
-	O
likelihood	B
ratio	I
(	O
not	O
to	O
be	O
confused	O
with	O
the	O
gmm	O
/	O
ubm	O
log	B
likeli-	O
hood	O
ratio	O
)	O
.	O
     	O
(	O
cid:129	O
)	O
      	O
fusion	O
    	O
m	O
 	O
ultiple	O
systems	O
can	O
be	O
fused	O
together	O
to	O
obtain	O
a	O
better	O
detec-	O
tor	O
.	O
this	O
works	O
best	O
with	O
calibrated	O
systems	O
,	O
but	O
calibration	O
is	O
not	O
strictly	O
 	O
necessary	O
.	O
a	O
simple	O
fusing	O
scheme	O
is	O
a	O
weighed	O
average	B
of	O
the	O
subsystem	O
 	O
scores	O
.	O
finding	O
the	O
optimal	O
weighting	O
scheme	O
needs	O
another	O
set	B
of	O
super-	O
vised	O
 	O
trials	O
.	O
 	O
luckily	O
,	O
 	O
the	O
 	O
same	O
 	O
trials	O
 	O
can	O
 	O
be	O
 	O
used	O
 	O
as	O
 	O
for	O
 	O
calibration	O
,	O
 	O
and	O
 	O
often	O
these	O
steps	B
are	O
carried	O
out	O
simultaneously	O
.	O
       	O
7.4.3	O
   	O
training	B
data	I
  	O
as	O
 	O
indicated	O
 	O
above	O
,	O
 	O
there	O
 	O
are	O
 	O
many	O
 	O
places	O
 	O
in	O
 	O
which	O
 	O
a	O
 	O
speaker	B
 	O
recognition	O
 	O
system	O
needs	O
training	B
data	I
to	O
model	B
the	O
variability	O
in	O
speakers	O
.	O
these	O
are	O
the	O
 	O
ubm	O
,	O
 	O
the	O
 	O
svm	O
 	O
background	O
 	O
supervectors	O
,	O
 	O
z	O
-	O
norm	B
 	O
and	O
t	O
-	O
norm	B
 	O
cohorts	O
,	O
 	O
and	O
 	O
the	O
 	O
supervised	O
 	O
trials	O
 	O
for	O
 	O
calibration	O
 	O
and	O
 	O
fusion	O
.	O
the	O
 	O
speakers	O
 	O
for	O
 	O
this	O
 	O
back-	O
ground	B
data	B
need	O
to	O
be	O
carefully	O
chosen	O
,	O
as	O
the	O
performance	O
heavily	O
depends	O
 	O
on	O
 	O
it	O
.	O
 	O
in	O
 	O
the	O
 	O
past	O
 	O
decade	O
,	O
 	O
the	O
 	O
ldc	O
 	O
has	O
 	O
collected	O
 	O
large	O
 	O
data	B
 	O
collections	O
 	O
with	O
 	O
thousands	O
of	O
speakers	O
.	O
    	O
7.4.4	O
   	O
current	O
research	B
focus	O
  	O
in	O
 	O
recent	O
 	O
years	O
,	O
 	O
the	O
 	O
research	B
 	O
focus	O
 	O
in	O
 	O
text	O
-	O
independent	O
 	O
speaker	B
 	O
recognition	O
 	O
has	O
 	O
been	O
 	O
on	O
 	O
the	O
 	O
problem	O
 	O
of	O
 	O
channel	O
 	O
and	O
 	O
session	O
 	O
variability	O
.	O
when	O
 	O
the	O
 	O
same	O
 	O
speaker	B
is	O
trained	O
and	O
tested	O
with	O
recordings	O
made	O
over	O
difference	O
channels	B
 	O
(	O
e.g.	O
,	O
cellular	O
vs.	O
land	O
line	O
phone	O
,	O
or	O
different	O
microphones	O
or	O
acoustics	B
)	O
,	O
it	O
is	O
 	O
harder	O
to	O
detect	O
they	O
are	O
of	O
the	O
same	B
speaker	I
.	O
new	O
techniques	B
such	O
as	O
factor	B
 	O
analysis	B
  	O
[	O
27	O
]	O
  	O
and	O
 	O
nuisance	O
 	O
attribute	O
 	O
projection	O
  	O
[	O
28	O
]	O
  	O
have	O
 	O
proved	O
 	O
to	O
 	O
be	O
 	O
very	O
 	O
successful	O
at	O
attempts	O
to	O
remove	O
this	O
unwanted	O
variability	O
in	O
scores	O
.	O
however	O
,	O
 	O
the	O
complexity	O
of	O
the	O
factor	B
analysis	I
model	B
does	O
still	O
leave	O
discussion	O
about	O
 	O
what	O
technical	O
implementation	O
details	O
work	O
best	O
.	O
     	O
7.5	O
   	O
conclusion	O
  	O
when	O
listening	O
to	O
speech	O
,	O
human	O
beings	O
are	O
easily	O
able	O
to	O
discriminate	O
between	O
 	O
different	O
speakers	O
and	O
are	O
in	O
most	O
cases	O
easily	O
able	O
to	O
memorize	O
a	O
given	O
voice	O
.	O
 	O
this	O
implicit	O
meaning	O
sticks	O
with	O
every	O
word	B
uttered	O
and	O
extracting	O
it	O
brings	O
 	O
us	O
 	O
one	O
 	O
step	O
 	O
closer	O
 	O
to	O
 	O
a	O
 	O
more	O
 	O
natural	O
 	O
interaction	O
 	O
between	O
 	O
computers	O
 	O
and	O
 	O
human	O
 	O
beings	O
.	O
 	O
this	O
 	O
chapter	O
 	O
provided	O
 	O
a	O
 	O
very	O
 	O
brief	O
 	O
overview	O
 	O
of	O
 	O
the	O
 	O
current	O
 	O
concepts	O
and	O
technologies	O
.	O
there	O
is	O
a	O
long	O
way	O
to	O
go	O
and	O
speaker	B
diarization	I
 	O
and	O
 	O
recognition	O
 	O
will	O
 	O
provide	O
 	O
research	B
 	O
topics	O
 	O
for	O
 	O
generations	O
 	O
to	O
 	O
come	O
.	O
 	O
as	O
 	O
pointed	O
 	O
out	O
 	O
earlier	O
,	O
 	O
channel	O
 	O
invariability	O
 	O
is	O
 	O
one	O
 	O
of	O
 	O
the	O
 	O
major	O
 	O
issues	O
 	O
in	O
 	O
both	O
 	O
speaker	B
recognition	O
and	O
diarization	B
(	O
when	O
ubms	O
are	O
used	O
)	O
.	O
current	O
speaker	B
 	O
recognition	O
 	O
and	O
 	O
diarization	B
 	O
systems	O
 	O
are	O
 	O
not	O
 	O
able	O
 	O
to	O
 	O
cope	O
 	O
with	O
 	O
overlapping	B
 	O
speech	O
 	O
(	O
i.e.	O
,	O
 	O
two	O
 	O
or	O
 	O
more	O
 	O
speakers	O
 	O
speaking	O
 	O
at	O
 	O
the	O
 	O
same	O
 	O
time	B
)	O
 	O
or	O
 	O
with	O
128	O
   	O
speaker	B
recognition	O
and	O
diarization	B
emotional	O
 	O
variation	O
.	O
 	O
laughter	O
,	O
 	O
coughs	O
,	O
 	O
external	O
 	O
noise	O
,	O
 	O
and	O
 	O
other	O
 	O
conditions	O
 	O
that	O
 	O
the	O
 	O
human	O
 	O
brain	O
 	O
is	O
 	O
able	O
 	O
to	O
 	O
cope	O
 	O
with	O
 	O
easily	O
 	O
still	O
 	O
pose	O
 	O
major	O
 	O
issues	O
 	O
to	O
 	O
current	O
computer	B
-	O
based	O
approaches	O
.	O
    	O
references	B
   	O
1	O
.	O
       	O
d.	O
  	O
reynolds	O
 	O
,	O
  	O
t.	O
  	O
quatieri	O
 	O
,	O
and	O
  	O
r.	O
  	O
dunn	O
 	O
,	O
 	O
speaker	B
veriﬁ	O
cation	O
using	O
adapted	O
gaussian	O
 	O
mixture	O
models	B
,	O
 	O
digital	O
signal	B
process	B
.	O
,	O
 	O
10	O
:	O
19	O
 	O
–	O
 	O
41	O
,	O
 	O
2000	O
.	O
    	O
2	O
.	O
       	O
l.	O
 	O
f.	O
   	O
lamel	O
 	O
,	O
   	O
l.	O
 	O
r.	O
   	O
rabiner	O
 	O
,	O
   	O
a.	O
 	O
e.	O
   	O
rosenberg	O
 	O
,	O
 	O
and	O
   	O
j.	O
 	O
g.	O
   	O
wilpon	O
 	O
,	O
  	O
an	O
 	O
improved	O
 	O
endpoint	O
 	O
detector	O
 	O
for	O
 	O
isolated	O
 	O
word	B
 	O
recognition	O
,	O
 	O
i	O
 	O
eee	O
 	O
trans	O
.	O
 	O
acoust	O
.	O
 	O
speech	O
 	O
signal	B
process	B
.	O
,	O
 	O
assp	O
-	O
29	O
(	O
4	O
):	O
777	O
 	O
–	O
 	O
785	O
,	O
 	O
1981	O
.	O
    	O
3	O
.	O
       	O
m.	O
  	O
huijbregts	O
 	O
,	O
  	O
c.	O
  	O
wooters	O
 	O
,	O
and	O
  	O
r.	O
  	O
ordelman	O
 	O
,	O
 	O
filtering	O
the	O
unknown	O
:	O
speech	O
activ-	O
ity	O
 	O
detection	B
 	O
in	O
 	O
heterogeneous	O
 	O
video	O
 	O
collections	O
,	O
 	O
in	O
  	O
proceedings	O
 	O
of	O
 	O
interpeech	O
,	O
 	O
antwerpen	O
,	O
 	O
2007	O
,	O
pp	O
.	O
 	O
2925	O
 	O
–	O
 	O
2928	O
  	O
.	O
    	O
4	O
.	O
       	O
d.	O
   	O
reynolds	O
   	O
and	O
   	O
p.	O
   	O
torres	O
-	O
carrasquillo	O
 	O
,	O
  	O
approaches	O
 	O
and	O
 	O
applications	O
 	O
of	O
 	O
audio	O
 	O
diarization	B
,	O
 	O
proc	O
.	O
ieee	O
int	O
.	O
conf	O
.	O
acoust	O
.	O
speech	B
signal	I
process	B
.	O
,	O
 	O
5	O
:	O
953	O
 	O
–	O
 	O
956	O
,	O
 	O
2005	O
.	O
    	O
5	O
.	O
       	O
h.	O
  	O
hung	O
 	O
,	O
  	O
d.	O
  	O
jayagopi	O
 	O
,	O
  	O
c.	O
  	O
yeo	O
 	O
,	O
  	O
g.	O
  	O
friedland	O
 	O
,	O
  	O
s.	O
  	O
ba	O
 	O
,	O
  	O
j.	O
-	O
m.	O
  	O
odobez	O
 	O
,	O
  	O
k.	O
  	O
ramchandran	O
 	O
,	O
   	O
n.	O
  	O
mirghafori	O
 	O
,	O
and	O
  	O
d.	O
  	O
gatica	O
-	O
perez	O
 	O
,	O
 	O
using	O
audio	O
and	O
video	O
features	O
to	O
classify	O
the	O
 	O
most	O
 	O
dominant	O
 	O
person	O
 	O
in	O
 	O
a	O
 	O
group	O
 	O
meeting	O
,	O
 	O
in	O
  	O
multimedia	O
’	O
07	O
:	O
 	O
proceedings	O
 	O
of	O
 	O
the	O
 	O
15th	O
 	O
international	O
 	O
conference	O
 	O
on	O
 	O
multimedia	O
,	O
 	O
acm	O
,	O
 	O
new	O
 	O
york	O
,	O
  	O
2007	O
,	O
 	O
pp	O
.	O
 	O
835	O
 	O
–	O
 	O
838	O
  	O
.	O
    	O
6	O
.	O
       	O
x.	O
   	O
anguera	O
 	O
,	O
 	O
robust	O
 	O
speaker	B
 	O
diarization	B
 	O
for	O
 	O
meetings	O
,	O
 	O
ph.d	O
.	O
 	O
thesis	O
,	O
 	O
technical	O
 	O
university	O
of	O
catalonia	O
,	O
barcelona	O
,	O
spain	O
,	O
december	O
 	O
2006	O
.	O
    	O
7	O
.	O
       	O
s.	O
  	O
chen	O
  	O
and	O
  	O
p.	O
  	O
gopalakrishnan	O
 	O
,	O
 	O
speaker	B
,	O
environment	O
and	O
channel	O
change	B
detec-	O
tion	O
 	O
and	O
 	O
clustering	B
 	O
via	O
 	O
the	O
 	O
bayesian	O
 	O
information	B
 	O
criterion	B
,	O
 	O
in	O
  	O
proceedings	O
 	O
of	O
 	O
darpa	O
speech	B
recognition	I
workshop	O
,	O
 	O
1998	O
  	O
.	O
    	O
8	O
.	O
       	O
h.	O
  	O
ning	O
 	O
,	O
  	O
m.	O
  	O
liu	O
 	O
,	O
  	O
h.	O
  	O
tang	O
 	O
,	O
and	O
  	O
t.	O
  	O
huang	O
 	O
,	O
 	O
a	O
spectral	O
clustering	B
approach	O
to	O
speaker	B
 	O
diarization	B
,	O
in	O
 	O
proceedings	O
of	O
interspeech	O
,	O
isca	O
,	O
 	O
2006	O
  	O
.	O
    	O
9	O
.	O
       	O
x.	O
  	O
anguera	O
 	O
,	O
  	O
c.	O
  	O
wooters	O
 	O
,	O
  	O
b.	O
  	O
peskin	O
 	O
,	O
and	O
  	O
m.	O
  	O
aguilo	O
 	O
,	O
 	O
robust	B
speaker	I
segmentation	B
 	O
for	O
 	O
meetings	O
:	O
the	O
 	O
icsi	O
-	O
sri	O
 	O
spring	O
 	O
2005	O
 	O
diarization	B
 	O
system	O
,	O
 	O
in	O
  	O
proceeding	O
 	O
of	O
 	O
the	O
 	O
nist	O
mlmi	O
meeting	O
recognition	O
workshop	O
,	O
edinburgh	O
.	O
springer	O
,	O
 	O
2005	O
  	O
.	O
    	O
10	O
.	O
       	O
b.	O
 	O
h.	O
   	O
juang	O
   	O
and	O
   	O
l.	O
 	O
r.	O
   	O
rabiner	O
 	O
,	O
  	O
a	O
 	O
probabilistic	O
 	O
distance	B
 	O
measure	O
 	O
for	O
 	O
hidden	O
 	O
markov	O
models	B
,	O
 	O
at	O
&	O
t	O
tech	O
.	O
j.	O
,	O
 	O
64	O
(	O
2	O
):	O
391	O
 	O
–	O
 	O
408	O
,	O
 	O
1985	O
.	O
    	O
11	O
.	O
       	O
p.	O
   	O
delacourt	O
   	O
and	O
   	O
c.	O
  	O
wellekens	O
 	O
,	O
   	O
distbic	O
 	O
:	O
 	O
a	O
 	O
speaker	B
-	O
based	O
 	O
segmentation	B
 	O
for	O
 	O
audio	O
 	O
data	B
 	O
indexing	O
,	O
  	O
speech	O
 	O
communication	B
:	O
 	O
special	O
 	O
issue	O
 	O
in	O
accessing	O
 	O
information	B
 	O
in	O
 	O
spoken	O
audio	O
,	O
 	O
32	O
(	O
1	O
–	O
2	O
):	O
111	O
 	O
–	O
 	O
126	O
,	O
 	O
2000	O
.	O
    	O
12	O
.	O
       	O
h.	O
   	O
gish	O
   	O
and	O
   	O
m.	O
   	O
schmidt	O
 	O
,	O
  	O
text	O
-	O
independent	O
 	O
speaker	B
 	O
identiﬁ	O
cation	O
,	O
 	O
i	O
 	O
eee	O
 	O
signal	B
 	O
process	B
.	O
mag	O
.	O
,	O
 	O
11	O
:	O
18	O
 	O
–	O
 	O
32	O
,	O
 	O
1994	O
.	O
    	O
13	O
.	O
       	O
j.	O
  	O
campbell	O
 	O
,	O
 	O
speaker	B
recognition	O
:	O
a	O
tutorial	O
,	O
 	O
proc	O
.	O
ieee	O
,	O
 	O
85	O
(	O
9	O
):	O
1437	O
 	O
–	O
 	O
1462	O
,	O
 	O
1997	O
.	O
    	O
14	O
.	O
       	O
h.	O
  	O
kim	O
 	O
,	O
  	O
d.	O
  	O
ertelt	O
 	O
,	O
and	O
  	O
t.	O
  	O
sikora	O
 	O
,	O
 	O
hybrid	O
speaker	B
-	O
based	O
segmentation	B
system	O
using	O
 	O
model	B
-	O
level	B
 	O
clustering	B
,	O
 	O
p	O
 	O
roc	O
.	O
 	O
ieee	O
 	O
int	O
.	O
 	O
conf	O
.	O
 	O
acoust	O
.	O
 	O
speech	O
 	O
signal	B
 	O
process	B
.	O
,	O
  	O
1	O
:	O
745	O
 	O
–	O
 	O
748	O
,	O
 	O
2005	O
.	O
    	O
15	O
.	O
       	O
j.	O
  	O
ajmera	O
  	O
and	O
  	O
c.	O
  	O
wooters	O
 	O
,	O
 	O
a	O
robust	B
speaker	I
clustering	B
algorithm	O
,	O
paper	O
presented	O
 	O
at	O
 	O
ieee	O
 	O
workshop	O
 	O
on	O
 	O
automatic	O
 	O
speech	O
 	O
recognition	O
 	O
and	O
 	O
understanding	O
,	O
 	O
asru	O
’	O
03	O
,	O
 	O
2003	O
,	O
pp	O
.	O
 	O
411	O
 	O
–	O
 	O
416	O
  	O
.	O
 	O
references	B
   	O
129	O
  	O
16	O
.	O
       	O
c.	O
   	O
wooters	O
   	O
and	O
   	O
m.	O
   	O
huijbregts	O
 	O
,	O
  	O
the	O
 	O
icsi	O
 	O
rt07s	O
 	O
speaker	B
 	O
diarization	B
 	O
system	O
,	O
 	O
in	O
  	O
proceedings	O
 	O
of	O
 	O
the	O
 	O
rich	O
 	O
transcription	B
 	O
2007	O
 	O
meeting	O
 	O
recognition	O
 	O
evaluation	B
 	O
workshop	O
,	O
 	O
2007	O
  	O
.	O
    	O
17	O
.	O
       	O
h.	O
 	O
j.	O
   	O
nock	O
 	O
,	O
   	O
g.	O
   	O
iyengar	O
 	O
,	O
 	O
and	O
   	O
c.	O
   	O
neti	O
 	O
,	O
  	O
speaker	B
 	O
localisation	O
 	O
using	O
 	O
audio	O
-	O
visual	O
 	O
syn-	O
chrony	O
:	O
an	O
empirical	O
study	O
,	O
 	O
journal	O
of	O
vlsi	O
signal	B
processing	I
,	O
 	O
36	O
(	O
2	O
):	O
117	O
 	O
–	O
 	O
124	O
,	O
 	O
2004	O
.	O
    	O
18	O
.	O
       	O
s.	O
  	O
tamura	O
 	O
,	O
  	O
k.	O
  	O
iwano	O
 	O
,	O
  	O
k.	O
,	O
and	O
 	O
s.	O
  	O
furui	O
 	O
,	O
 	O
multi	O
-	O
modal	O
speech	B
recognition	I
using	O
optical	O
-	O
 	O
ﬂ	O
ow	O
analysis	B
for	O
lip	O
images	O
,	O
 	O
journal	O
of	O
vlsi	O
signal	B
processing	I
,	O
 	O
36	O
(	O
2	O
):	O
117	O
 	O
–	O
 	O
124	O
,	O
 	O
2004	O
.	O
    	O
19	O
.	O
       	O
h.	O
  	O
vajaria	O
 	O
,	O
  	O
t.	O
  	O
islam	O
 	O
,	O
  	O
s.	O
  	O
sarkar	O
 	O
,	O
  	O
r.	O
  	O
sankar	O
 	O
,	O
and	O
  	O
r.	O
  	O
kasturi	O
 	O
,	O
 	O
audio	O
segmentation	B
and	O
 	O
speaker	B
 	O
localization	O
 	O
in	O
 	O
meeting	O
 	O
videos	B
.	O
  	O
18th	O
 	O
international	O
 	O
conference	O
 	O
on	O
 	O
pattern	O
 	O
recognition	O
(	O
icpr	O
2006	O
)	O
,	O
 	O
2	O
:	O
1150	O
 	O
–	O
 	O
1153	O
,	O
 	O
2006	O
  	O
.	O
    	O
20	O
.	O
       	O
c.	O
  	O
zhang	O
 	O
,	O
  	O
p.	O
  	O
yin	O
 	O
,	O
  	O
y.	O
  	O
rui	O
 	O
,	O
  	O
r.	O
  	O
cutler	O
 	O
,	O
  	O
p.	O
  	O
viola	O
 	O
,	O
  	O
x.	O
  	O
sun	O
 	O
,	O
  	O
n.	O
  	O
pinto	O
 	O
,	O
and	O
  	O
z.	O
  	O
zhang	O
 	O
,	O
 	O
boosting	O
-	O
 	O
based	O
 	O
multimodal	O
 	O
speaker	B
 	O
detection	B
 	O
for	O
 	O
distributed	O
 	O
meeting	O
 	O
videos	B
,	O
 	O
i	O
 	O
eee	O
 	O
transactions	O
on	O
multimedia	O
,	O
 	O
10	O
(	O
8	O
):	O
1541	O
 	O
–	O
 	O
1552	O
,	O
 	O
2008	O
  	O
.	O
    	O
21	O
.	O
       	O
a.	O
  	O
noulas	O
  	O
and	O
  	O
b.	O
j.	O
a.	O
  	O
krose	O
 	O
,	O
 	O
on	O
-	O
line	O
multi	O
-	O
modal	O
speaker	B
diarization	I
,	O
in	O
i	O
 	O
cmi	O
 	O
’	O
07	O
:	O
 	O
proceedings	O
of	O
the	O
ninth	O
international	O
conference	O
on	O
multimodal	O
interfaces	O
,	O
  	O
acm	O
,	O
  	O
new	O
york	O
,	O
 	O
2007	O
,	O
pp	O
.	O
 	O
350	O
 	O
–	O
 	O
357	O
  	O
.	O
    	O
22	O
.	O
       	O
d.	O
a.	O
  	O
van	O
  	O
leeuwen	O
  	O
and	O
  	O
n.	O
  	O
br	O
ü	O
mmer	O
 	O
,	O
 	O
an	O
introduction	O
to	O
application	B
independent	O
 	O
evaluation	B
 	O
of	O
 	O
speaker	B
 	O
recognition	O
 	O
systems	O
,	O
 	O
in	O
  	O
speaker	B
 	O
classiﬁ	O
cation	O
,	O
   	O
c.	O
   	O
m	O
ü	O
ller	O
   	O
(	O
ed	O
.	O
)	O
,	O
 	O
vol	O
.	O
  	O
4343	O
  	O
of	O
 	O
l	O
 	O
ecture	O
 	O
notes	O
 	O
in	O
 	O
computer	B
 	O
science	O
 	O
/	O
 	O
artiﬁ	O
cial	O
 	O
intelligence	O
,	O
  	O
springer	O
,	O
 	O
heidelberg	O
,	O
 	O
2007	O
.	O
    	O
23	O
.	O
       	O
a.	O
  	O
martin	O
 	O
,	O
  	O
g.	O
  	O
doddington	O
 	O
,	O
  	O
t.	O
  	O
kamm	O
 	O
,	O
  	O
m.	O
o.	O
  	O
ki	O
 	O
,	O
and	O
  	O
m.	O
  	O
przybocki	O
 	O
,	O
 	O
the	O
det	O
curve	O
 	O
in	O
 	O
assessment	O
 	O
of	O
 	O
detection	B
 	O
task	O
 	O
performance	O
,	O
 	O
in	O
  	O
proc	O
.	O
 	O
eurospeech	O
 	O
1997	O
,	O
  	O
rhodes	O
,	O
 	O
greece	O
,	O
 	O
1997	O
,	O
pp	O
.	O
 	O
1895	O
 	O
–	O
 	O
1898	O
  	O
.	O
    	O
24	O
.	O
       	O
j.	O
-	O
l.	O
   	O
gauvain	O
   	O
and	O
   	O
c.	O
-	O
h.	O
   	O
lee	O
 	O
,	O
  	O
maximum	O
 	O
a	O
 	O
posteriori	O
 	O
esitimation	O
 	O
for	O
 	O
multivariate	O
 	O
gaussian	O
 	O
mixture	O
 	O
observations	O
 	O
of	O
 	O
markov	O
 	O
chains	O
,	O
  	O
ieee	O
 	O
trans	O
.	O
 	O
speech	O
 	O
audio	O
 	O
process	B
.	O
,	O
 	O
2	O
:	O
291	O
 	O
–	O
 	O
298	O
,	O
 	O
1994	O
.	O
    	O
25	O
.	O
       	O
w.	O
  	O
campbell	O
 	O
,	O
  	O
d.	O
  	O
sturim	O
 	O
,	O
and	O
  	O
d.	O
  	O
reynolds	O
 	O
,	O
 	O
support	O
vector	O
machines	O
using	O
gmm	O
 	O
supervectors	O
 	O
for	O
 	O
speaker	B
 	O
veriﬁ	O
cation	O
,	O
  	O
ieee	O
 	O
signal	B
 	O
process	B
.	O
 	O
lett	O
.	O
,	O
  	O
13	O
(	O
5	O
):	O
308	O
 	O
–	O
 	O
311	O
,	O
  	O
2006	O
.	O
    	O
26	O
.	O
       	O
r.	O
  	O
vogt	O
 	O
,	O
  	O
b.	O
  	O
baker	O
 	O
,	O
and	O
  	O
s.	O
  	O
sridharan	O
 	O
,	O
 	O
modelling	O
session	O
variability	O
in	O
text	O
indepen-	O
dent	O
speaker	B
veriﬁ	O
cation	O
,	O
in	O
 	O
proceedings	O
of	O
interspeech	O
,	O
 	O
2005	O
,	O
pp	O
.	O
 	O
3117	O
 	O
–	O
 	O
3120	O
  	O
.	O
    	O
27	O
.	O
       	O
p.	O
  	O
kenny	O
 	O
,	O
  	O
g.	O
  	O
boulianne	O
 	O
,	O
  	O
p.	O
  	O
ouellet	O
 	O
,	O
and	O
  	O
p.	O
  	O
dumouchel	O
 	O
,	O
 	O
joint	O
factor	B
analysis	I
versus	O
 	O
eigenchannels	O
in	O
speaker	B
recognition	O
,	O
 	O
ieee	O
trans	O
.	O
audio	O
,	O
speech	O
,	O
lang	O
.	O
process	B
.	O
,	O
  	O
15	O
(	O
4	O
):	O
1435	O
 	O
–	O
 	O
1448	O
,	O
 	O
2007	O
  	O
.	O
    	O
28	O
.	O
       	O
w.	O
   	O
campbell	O
 	O
,	O
   	O
d.	O
   	O
sturim	O
 	O
,	O
   	O
d.	O
   	O
reynolds	O
 	O
,	O
 	O
and	O
   	O
a.	O
   	O
solomonoff	O
 	O
,	O
  	O
svm	O
 	O
based	O
 	O
speaker	B
 	O
veriﬁ	O
cation	O
using	O
a	O
gmm	O
supervector	O
kernel	O
and	O
nap	O
variabilitycompensation	O
,	O
 	O
in	O
 	O
proc	O
.	O
icassp	O
,	O
toulouse	O
,	O
ieee	O
,	O
 	O
2006	O
,	O
pp	O
.	O
 	O
97	O
 	O
–	O
 	O
100	O
  	O

speaker	B
recognition	O
for	O
multi	O
-	O
speaker	B
conversations	O
using	O
x	O
-	O
vectors	O
david	O
snyder	O
,	O
daniel	O
garcia	O
-	O
romero	O
,	O
gregory	O
sell	O
,	O
alan	O
mccree	O
,	O
daniel	O
povey	O
,	O
sanjeev	O
khudanpur	O
center	O
for	O
language	O
and	O
speech	O
processing	B
&	O
human	O
language	O
technology	O
center	O
of	O
excellence	O
the	O
johns	O
hopkins	O
university	O
,	O
baltimore	O
,	O
md	O
21218	O
,	O
usa	O
abstract	O
early	O
work	O
using	O
discriminatively	O
trained	O
neural	B
networks	I
to	O
capture	O
speaker	B
characteristics	B
focused	O
on	O
extracting	O
frame	B
-	O
level	B
recently	O
,	O
deep	O
neural	B
networks	I
that	O
map	O
utterances	B
to	O
ﬁxed-	O
features	O
to	O
be	O
used	O
as	O
input	B
to	O
gaussian	O
speaker	B
models	B
[	O
6	O
,	O
7	O
]	O
.	O
dimensional	O
embeddings	O
have	O
emerged	O
as	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
in	O
heigold	O
et	O
al	O
.	O
,	O
introduced	O
an	O
end	O
-	O
to	O
-	O
end	O
system	O
,	O
trained	O
on	O
the	O
speaker	B
recognition	O
.	O
our	O
prior	O
work	O
introduced	O
x	O
-	O
vectors	O
,	O
an	O
em-	O
phrase	O
“	O
ok	O
google	O
,	O
”	O
that	O
jointly	O
learns	O
an	O
embedding	O
along	O
with	O
a	O
bedding	O
that	O
is	O
very	O
effective	O
for	O
both	O
speaker	B
recognition	O
and	O
similarity	B
metric	B
to	O
compare	O
pairs	O
of	O
embeddings	O
[	O
8	O
]	O
.	O
snyder	O
et	O
al	O
.	O
,	O
diarization	B
.	O
this	O
paper	O
combines	O
our	O
previous	O
work	O
and	O
applies	O
it	O
generalized	O
this	O
framework	O
to	O
text	O
-	O
independent	O
speaker	B
recognition	O
to	O
the	O
problem	O
of	O
speaker	B
recognition	O
on	O
multi	O
-	O
speaker	B
conversa-	O
and	O
inserted	O
a	O
temporal	O
pooling	O
layer	B
into	O
the	O
network	B
to	O
handle	O
tions	O
.	O
we	O
measure	O
performance	O
on	O
speakers	O
in	O
the	O
wild	O
and	O
report	O
variable	O
-	O
length	B
segments	O
[	O
9	O
]	O
.	O
the	O
work	O
in	O
[	O
1	O
,	O
10	O
]	O
split	O
the	O
end	O
-	O
to-	O
what	O
we	O
believe	O
are	O
the	O
best	O
published	O
error	B
rates	I
on	O
this	O
dataset	O
.	O
end	O
approach	O
into	O
two	O
parts	O
:	O
a	O
dnn	O
to	O
produce	O
embeddings	O
called	O
moreover	O
,	O
we	O
ﬁnd	O
that	O
diarization	B
substantially	O
reduces	O
error	B
rate	I
x	O
-	O
vectors	O
,	O
and	O
a	O
separately	O
trained	O
classiﬁer	O
to	O
compare	O
them	O
.	O
this	O
when	O
there	O
are	O
multiple	O
speakers	O
,	O
while	O
maintaining	O
excellent	O
per-	O
facilitates	O
use	O
of	O
all	O
the	O
accumulated	O
backend	O
technology	O
developed	O
formance	O
on	O
single	O
-	O
speaker	B
recordings	O
.	O
finally	O
,	O
we	O
introduce	O
an	O
over	O
the	O
years	O
for	O
i	O
-	O
vectors	O
,	O
such	O
as	O
length	B
-	O
normalization	O
and	O
plda	B
easily	O
implemented	O
method	B
to	O
remove	O
the	O
domain	B
-	O
sensitive	O
thresh-	O
scoring	O
.	O
the	O
x	O
-	O
vector	O
framework	O
is	O
described	O
in	O
section	O
3	O
.	O
old	O
typically	O
used	O
in	O
the	O
clustering	B
stage	B
of	O
a	O
diarization	B
system	O
.	O
the	O
proposed	O
method	B
is	O
more	O
robust	O
to	O
domain	B
shifts	O
,	O
and	O
achieves	O
similar	O
results	B
to	O
those	O
obtained	O
using	O
a	O
well	O
-	O
tuned	O
threshold	B
.	O
2.2	O
.	O
speaker	B
diarization	I
index	O
terms	B
—	O
speaker	B
recognition	O
,	O
speaker	B
diarization	I
,	O
deep	O
neural	B
networks	I
,	O
x	O
-	O
vectors	O
soon	O
after	O
their	O
development	O
for	O
speaker	B
recognition	O
,	O
shum	O
et	O
al	O
.	O
,	O
adapted	O
i	O
-	O
vectors	O
to	O
the	O
task	O
of	O
speaker	B
diarization	I
[	O
11	O
,	O
12	O
]	O
.	O
mir-	O
roring	O
progress	O
in	O
speaker	B
recognition	O
,	O
recent	O
systems	O
have	O
replaced	O
1	O
.	O
introduction	O
i	O
-	O
vectors	O
with	O
dnn	O
-	O
based	O
embeddings	O
for	O
capturing	O
speaker	B
char-	O
acteristics	O
[	O
13	O
,	O
14	O
,	O
15	O
]	O
.	O
most	O
research	B
in	O
speaker	B
recognition	O
assumes	O
that	O
there	O
is	O
only	O
one	O
speaker	B
per	O
recording	B
and	O
the	O
majority	O
of	O
standard	O
evaluation	B
a	O
popular	O
diarization	B
framework	O
involves	O
extracting	O
representa-	O
datasets	B
reﬂect	O
this	O
assumption	O
.	O
however	O
,	O
speech	O
data	B
collected	O
tions	O
(	O
i	O
-	O
vectors	O
or	O
dnn	O
embeddings	O
)	O
from	O
short	O
speech	B
segments	I
,	O
from	O
many	O
real	O
-	O
world	O
environments	O
violate	O
this	O
single	O
-	O
speaker	B
as-	O
and	O
clustering	B
them	O
,	O
to	O
discover	O
the	O
individual	O
speakers	O
in	O
a	O
record-	O
sumption	O
,	O
and	O
therefore	O
beneﬁt	O
from	O
speaker	B
diarization	I
as	O
a	O
prepro-	O
ing	O
.	O
early	O
work	O
used	O
k	O
-	O
means	O
or	O
spectral	O
clustering	B
[	O
11	O
,	O
12	O
]	O
.	O
al-	O
cessing	O
step	O
.	O
speaker	B
diarization	I
is	O
the	O
process	B
of	O
grouping	O
segments	O
ternatively	O
,	O
a	O
score	B
matrix	O
can	O
be	O
computed	O
between	O
pairs	O
of	O
rep-	O
of	O
speech	O
according	O
to	O
the	O
speaker	B
,	O
and	O
is	O
sometimes	O
referred	O
to	O
as	O
resentations	O
using	O
cosine	O
distance	B
[	O
16	O
]	O
or	O
plda	B
log	B
-	O
likelihood	B
ra-	O
the	O
“	O
who	O
spoke	O
when	O
”	O
task	O
.	O
recently	O
,	O
both	O
speaker	B
recognition	O
and	O
tios	O
[	O
17	O
]	O
,	O
and	O
clustered	O
using	O
agglomerative	O
hierarchical	O
clustering	B
diarization	B
have	O
advanced	O
signiﬁcantly	O
due	O
to	O
the	O
adoption	O
of	O
deep	O
(	O
ahc	O
)	O
[	O
18	O
]	O
.	O
clustering	B
provides	O
a	O
coarse	O
segmentation	B
,	O
which	O
is	O
neural	B
network	I
(	O
dnn	O
)	O
embeddings	O
to	O
capture	O
speaker	B
character-	O
often	O
reﬁned	O
at	O
the	O
frame	B
-	O
level	B
,	O
using	O
a	O
process	B
called	O
variational	O
istics	O
.	O
these	O
embeddings	O
are	O
now	O
replacing	O
i	O
-	O
vectors	O
,	O
which	O
have	O
bayes	O
resegmentation	B
[	O
19	O
]	O
.	O
been	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
in	O
both	O
tasks	O
for	O
almost	O
ten	O
years	O
.	O
our	O
work	O
is	O
based	O
on	O
x	O
-	O
vectors	O
,	O
a	O
type	O
of	O
dnn	O
embedding	O
we	O
developed	O
for	O
speaker	B
recognition	O
[	O
1	O
]	O
.	O
this	O
paper	O
studies	O
the	O
problem	O
of	O
speaker	B
2.3	O
.	O
multi	O
-	O
speaker	B
conversations	O
recognition	O
for	O
multi	O
-	O
speaker	B
conversations	O
using	O
a	O
modern	O
dnn	O
embedding	O
-	O
based	O
system	O
.	O
capturing	O
speaker	B
characteristics	B
in	O
ﬁxed	O
-	O
dimensional	O
embeddings	O
assumes	O
that	O
the	O
input	B
speech	O
was	O
generated	O
from	O
a	O
single	B
speaker	I
,	O
and	O
violating	O
this	O
assumption	O
reduces	O
the	O
effectiveness	O
of	O
the	O
rep-	O
2	O
.	O
background	O
resentation	O
[	O
18	O
,	O
20	O
]	O
.	O
interest	O
in	O
the	O
topic	O
of	O
speaker	B
recognition	O
on	O
multi	O
-	O
speaker	B
conversations	O
has	O
increased	O
with	O
the	O
2016	O
speakers	O
in	O
2.1	O
.	O
speaker	B
recognition	O
the	O
wild	O
(	O
sitw	O
)	O
challenge	B
[	O
21	O
]	O
and	O
the	O
recent	O
nist	O
2018	O
speaker	B
until	O
recently	O
,	O
most	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
speaker	B
recognition	O
systems	O
recognition	O
evaluation	B
[	O
22	O
]	O
due	O
to	O
the	O
presence	B
of	O
multi	O
-	O
speaker	B
en-	O
were	O
based	O
on	O
i	O
-	O
vectors	O
[	O
2	O
]	O
.	O
the	O
standard	O
approach	O
uses	O
gaussian	O
rollment	O
and	O
test	B
recordings	O
.	O
this	O
encourages	O
diarization	B
to	O
be	O
per-	O
mixture	O
models	B
(	O
gmms	O
)	O
and	O
factor	B
analysis	I
to	O
compress	O
multi-	O
formed	O
in	O
conjunction	O
with	O
speaker	B
recognition	O
.	O
participants	B
in	O
the	O
ple	O
sources	O
of	O
variability	O
into	O
a	O
low	O
-	O
dimensional	O
representation	O
,	O
sitw	O
challenge	B
showed	O
that	O
diarization	B
can	O
signiﬁcantly	O
improve	O
known	O
as	O
an	O
i	O
-	O
vector	O
.	O
a	O
probabilistic	O
linear	O
discriminant	O
analy-	O
speaker	B
recognition	O
rates	B
[	O
23	O
,	O
24	O
]	O
.	O
our	O
study	O
underscores	O
the	O
value	O
sis	O
(	O
plda	B
)	O
[	O
3	O
]	O
classiﬁer	O
is	O
used	O
to	O
compare	O
i	O
-	O
vectors	O
,	O
and	O
enable	O
of	O
diarization	B
for	O
speaker	B
recognition	O
in	O
the	O
multi	O
-	O
speaker	B
environ-	O
same	O
-	O
or	O
-	O
different	O
speaker	B
decisions	O
[	O
4	O
,	O
5	O
]	O
.	O
ment.dnn	O
for	O
6	O
epochs	O
(	O
instead	O
of	O
3	O
)	O
and	O
use	O
a	O
minibatch	O
size	B
of	O
128	O
table	O
1	O
.	O
x	O
-	O
vector	O
dnn	O
architecture	B
(	O
instead	O
of	O
64	O
)	O
.	O
layer	B
layer	B
type	O
context	O
size	B
1	O
tdnn	O
-	O
relu	O
t-2	O
:	O
t+2	O
512	O
3.4	O
.	O
embedding	O
extraction	B
2	O
dense	O
-	O
relu	O
t	O
512	O
3	O
tdnn	O
-	O
relu	O
t-2	O
,	O
t	O
,	O
t+2	O
512	O
once	O
the	O
network	B
is	O
trained	O
,	O
x	O
-	O
vectors	O
are	O
extracted	O
from	O
the	O
afﬁne	O
4	O
dense	O
-	O
relu	O
t	O
512	O
component	O
of	O
layer	B
12	O
.	O
the	O
x	O
-	O
vectors	O
are	O
used	O
as	O
features	O
for	O
two	O
5	O
tdnn	O
-	O
relu	O
t-3	O
,	O
t	O
,	O
t+3	O
512	O
different	O
plda	B
backends	O
(	O
one	O
for	O
the	O
diarization	B
system	O
described	O
6	O
dense	O
-	O
relu	O
t	O
512	O
in	O
section	O
4	O
and	O
one	O
for	O
the	O
speaker	B
recognition	O
system	O
described	O
in	O
7	O
tdnn	O
-	O
relu	O
t-4	O
,	O
t	O
,	O
t+4	O
512	O
section	O
5	O
)	O
.	O
8	O
dense	O
-	O
relu	O
t	O
512	O
9	O
dense	O
-	O
relu	O
t	O
512	O
4	O
.	O
speaker	B
diarization	I
10	O
dense	O
-	O
relu	O
t	O
1500	O
11	O
pooling	O
(	O
mean+stddev	O
)	O
full	O
-	O
seq	O
2x1500	O
the	O
diarization	B
system	O
is	O
based	O
on	O
a	O
system	O
we	O
devel-	O
12	O
dense(embedding)-relu	O
512	O
oped	O
for	O
the	O
2018	O
dihard	O
speaker	B
recognition	O
challenge	B
13	O
dense	O
-	O
relu	O
512	O
[	O
14	O
,	O
27	O
]	O
.	O
a	O
similar	O
recipe	O
(	O
for	O
narrowband	O
telephone	B
speech	I
)	O
14	O
dense	O
-	O
softmax	O
7185	O
(	O
#	O
spkrs	O
)	O
can	O
be	O
found	O
in	O
the	O
main	O
branch	O
of	O
the	O
kaldi	O
toolkit	O
:	O
https://github.com/kaldi-asr/kaldi/tree/	O
master	O
/	O
egs	O
/	O
callhome_diarization	O
/	O
v2	O
.	O
the	O
system	O
uses	O
x	O
-	O
vectors	O
extracted	O
from	O
the	O
dnn	O
in	O
section	O
3	O
with	O
plda	B
,	O
and	O
3	O
.	O
x	O
-	O
vector	O
dnn	O
agglomerative	O
hierarchical	O
clustering	B
(	O
ahc	O
)	O
.	O
the	O
plda	B
backend	O
this	O
section	O
describes	O
the	O
x	O
-	O
vector	O
dnn	O
.	O
the	O
architecture	B
is	O
consists	O
of	O
centering	O
,	O
whitening	O
and	O
length	B
normalization	O
,	O
followed	O
based	O
on	O
the	O
dnn	O
embedding	O
system	O
described	O
in	O
[	O
1	O
,	O
10	O
]	O
.	O
by	O
scoring	O
.	O
all	O
components	B
of	O
the	O
backend	O
are	O
trained	O
on	O
3	O
second	O
our	O
software	O
framework	O
has	O
been	O
made	O
available	O
in	O
the	O
kaldi	O
segments	O
extracted	O
from	O
the	O
augmented	O
voxceleb	O
data	B
described	O
in	O
toolkit	O
[	O
25	O
]	O
.	O
an	O
example	O
recipe	O
is	O
in	O
the	O
main	O
branch	O
section	O
6.1	O
.	O
of	O
kaldi	O
at	O
https://github.com/kaldi-asr/kaldi/	O
for	O
either	O
an	O
enrollment	O
recording	B
or	O
a	O
test	B
recording	B
,	O
x	O
-	O
vectors	O
tree	O
/	O
master	O
/	O
egs	O
/	O
sitw	O
/	O
v2	O
and	O
several	O
pretrained	O
x	O
-	O
vector	O
are	O
extracted	O
from	O
1.5	O
second	O
segments	O
with	O
a	O
0.75	O
second	O
overlap	O
.	O
systems	O
can	O
be	O
downloaded	O
from	O
http://kaldi-asr.org/	O
plda	B
scores	O
are	O
computed	O
between	O
all	O
pairs	O
of	O
x	O
-	O
vectors	O
.	O
this	O
is	O
models.html	O
.	O
we	O
plan	O
on	O
updating	O
the	O
recipe	O
and	O
pretrained	O
followed	O
by	O
ahc	O
with	O
average	B
linkage	O
clustering	B
.	O
in	O
our	O
primary	O
models	B
with	O
the	O
improved	O
system	O
described	O
in	O
this	O
work	O
.	O
system	O
,	O
the	O
number	O
of	O
clusters	O
is	O
controlled	O
by	O
a	O
stopping	O
threshold	B
which	O
was	O
tuned	O
on	O
the	O
held	O
-	O
out	O
sitw	O
dev	O
set	B
.	O
the	O
most	O
similar	O
clusters	O
are	O
repeatedly	O
merged	O
,	O
until	O
the	O
average	B
plda	B
scores	O
be-	O
3.1	O
.	O
architecture	B
tween	O
clusters	O
is	O
less	O
than	O
the	O
threshold	B
.	O
diarization	B
results	B
in	O
n	O
table	O
1	O
summarizes	O
the	O
architecture	B
used	O
in	O
this	O
work	O
.	O
the	O
ﬁrst	O
10	O
clusters	O
(	O
which	O
,	O
ideally	O
correspond	O
to	O
speakers	O
)	O
.	O
layers	O
of	O
the	O
x	O
-	O
vector	O
dnn	O
consists	O
of	O
layers	O
that	O
operate	O
on	O
speech	O
frames	O
,	O
with	O
a	O
small	O
temporal	O
context	O
centered	O
around	O
the	O
current	O
4.1	O
.	O
removing	O
the	O
ahc	O
threshold	B
frame	B
t.	O
the	O
pooling	O
layer	B
receives	O
the	O
output	B
of	O
layer	B
10	O
as	O
input	B
,	O
aggregates	O
over	O
the	O
input	B
segment	B
,	O
and	O
computes	O
its	O
mean	O
and	O
stan-	O
ahc	O
-	O
based	O
diarization	B
typically	O
requires	O
a	O
well	O
-	O
chosen	O
cluster	O
stop-	O
dard	O
deviation	O
.	O
these	O
segment	B
-	O
level	B
statistics	B
are	O
concatenated	O
to-	O
ping	O
threshold	B
to	O
achieve	O
good	O
performance	O
.	O
this	O
threshold	B
is	O
sen-	O
gether	O
and	O
passed	O
through	O
the	O
remaining	O
layers	O
of	O
the	O
network	B
.	O
the	O
sitive	O
to	O
the	O
domain	B
of	O
the	O
data	B
,	O
and	O
a	O
poorly	O
chosen	O
threshold	B
will	O
output	B
layer	B
computes	O
posterior	O
probabilities	O
for	O
the	O
training	O
speak-	O
result	O
in	O
bad	O
performance	O
.	O
this	O
is	O
a	O
particularly	O
concerning	O
possi-	O
ers	O
.	O
compared	O
to	O
the	O
architecture	B
described	O
in	O
[	O
1	O
]	O
,	O
we	O
use	O
a	O
slightly	O
bility	O
when	O
a	O
reliable	O
development	B
set	I
is	O
not	O
available	O
.	O
wider	O
temporal	O
context	O
in	O
the	O
tdnn	O
layers	O
,	O
and	O
interleave	O
dense	O
to	O
improve	O
robustness	O
,	O
we	O
propose	O
a	O
simple	O
alternative	O
to	O
elim-	O
layers	O
between	O
the	O
tdnn	O
layers	O
.	O
we	O
found	O
that	O
this	O
architecture	B
inate	O
the	O
need	O
for	O
the	O
ahc	O
threshold	B
.	O
instead	O
of	O
relying	O
on	O
a	O
tuned	O
greatly	O
outperforms	O
the	O
baseline	B
architecture	B
available	O
in	O
the	O
kaldi	O
ahc	O
threshold	B
,	O
we	O
begin	O
with	O
an	O
estimate	O
of	O
the	O
maximum	O
number	O
recipes	O
.	O
of	O
speakers	O
k	O
that	O
might	O
appear	O
in	O
the	O
recordings	O
.	O
we	O
assume	O
that	O
there	O
are	O
never	O
more	O
than	O
k	O
speakers	O
in	O
an	O
utterance	O
,	O
and	O
perform	O
clustering	B
k	O
times	O
,	O
with	O
exactly	O
k	O
∈	O
{	O
1	O
,	O
2	O
,	O
.	O
.	O
.	O
,	O
k	O
}	O
clusters	O
each	O
3.2	O
.	O
features	O
time	B
we	O
perform	O
clustering	B
.	O
taking	O
the	O
union	O
of	O
each	O
of	O
the	O
individ-	O
the	O
features	O
are	O
30	O
dimensional	O
mfccs	O
with	O
a	O
frame	B
-	O
length	B
of	O
25	O
ual	O
diarizations	O
results	B
in	O
a	O
set	B
of	O
n	O
=	O
k(k+1	O
)	O
ways	O
to	O
partition	O
2	O
ms	O
,	O
mean	O
-	O
normalized	O
over	O
a	O
sliding	O
window	O
of	O
up	O
to	O
3	O
seconds	B
.	O
au-	O
a	O
recording	B
that	O
has	O
at	O
most	O
k	O
speakers	O
.	O
the	O
n	O
potential	O
speak-	O
dio	O
ﬁles	O
are	O
sampled	O
at	O
16	O
khz	O
.	O
the	O
kaldi	O
energy	O
sad	O
is	O
used	O
to	O
ers	O
are	O
then	O
treated	O
exactly	O
the	O
same	O
as	O
the	O
speakers	O
discovered	O
by	O
ﬁlter	O
out	O
nonspeech	O
frames	O
.	O
clustering	B
with	O
an	O
ahc	O
threshold	B
,	O
as	O
described	O
in	O
section	O
5	O
.	O
looking	O
at	O
the	O
sitw	O
dev	O
set	B
,	O
we	O
found	O
that	O
the	O
performance	O
is	O
n’t	O
very	O
sensitive	O
to	O
different	O
values	B
of	O
k	O
≥	O
3	O
.	O
we	O
use	O
k	O
=	O
5	O
for	O
3.3	O
.	O
training	O
the	O
experiments	O
in	O
the	O
results	B
section	O
.	O
the	O
dnn	O
is	O
trained	O
to	O
classify	O
the	O
7,185	O
speakers	O
in	O
the	O
training	B
data	I
using	O
a	O
multi	O
-	O
class	O
cross	O
entropy	O
objective	O
function	O
.	O
a	O
training	O
4.2	O
.	O
diarizing	O
enrollment	O
recordings	O
example	O
consists	O
of	O
a	O
2–4	O
second	O
speech	B
segment	I
(	O
about	O
3	O
seconds	B
average	B
)	O
,	O
along	O
with	O
the	O
corresponding	O
speaker	B
label	O
.	O
following	O
a	O
if	O
we	O
are	O
processing	B
an	O
enrollment	O
recording	B
,	O
then	O
the	O
goal	O
is	O
to	O
use	O
study	O
by	O
mclaren	O
et	O
al	O
.	O
in	O
[	O
26	O
]	O
,	O
we	O
use	O
much	O
more	O
aggressive	O
data	B
an	O
assist	O
segment	B
to	O
identify	O
any	O
other	O
speech	O
in	O
the	O
recording	B
which	O
augmentation	B
than	O
in	O
previous	O
studies	O
(	O
see	O
section	O
6.1	O
)	O
,	O
train	O
the	O
belongs	O
to	O
the	O
speaker	B
we	O
wish	O
to	O
enroll	O
,	O
while	O
removing	O
any	O
speechbelonging	O
to	O
other	O
speakers	O
.	O
as	O
described	O
in	O
section	O
6.2	O
,	O
an	O
assist	O
dnn	O
was	O
trained	O
on	O
7.2	O
million	O
segments	O
,	O
comprised	O
of	O
the	O
1.2	O
segment	B
is	O
about	O
5	O
seconds	B
of	O
speech	O
in	O
a	O
longer	O
recording	B
,	O
which	O
is	O
million	O
“	O
raw	O
”	O
segments	O
extracted	O
directly	O
from	O
voxceleb	O
,	O
plus	O
an	O
known	O
to	O
contain	O
the	O
speaker	B
we	O
wish	O
to	O
enroll	O
.	O
additional	O
6	O
million	O
segments	O
obtained	O
by	O
data	B
augmentation	I
.	O
the	O
the	O
speech	O
corresponding	O
to	O
the	O
assist	O
segment	B
is	O
treated	O
as	O
an	O
plda	B
backend	O
for	O
speaker	B
recognition	O
(	O
section	O
5	O
)	O
was	O
trained	O
on	O
“	O
auxiliary	O
enrollment	O
”	O
and	O
the	O
entire	O
recording	B
is	O
treated	O
as	O
an	O
“	O
aux-	O
the	O
full	O
-	O
length	B
recordings	O
of	O
voxceleb	O
,	O
but	O
we	O
only	O
keep	O
the	O
speech	O
iliary	O
test	B
”	O
recording	B
.	O
after	O
clustering	B
,	O
we	O
obtain	O
n	O
speakers	O
in	O
the	O
belonging	O
to	O
the	O
speakers	O
of	O
interest	O
(	O
as	O
provided	O
by	O
the	O
segments	O
auxiliary	O
test	B
.	O
we	O
then	O
perform	O
the	O
procedure	O
described	O
in	O
section	O
5	O
,	O
that	O
are	O
distributed	O
with	O
the	O
corpora	B
)	O
.	O
we	O
apply	O
augmentation	B
to	O
which	O
involves	O
computing	O
plda	B
scores	O
between	O
the	O
auxiliary	O
en-	O
double	O
the	O
amount	B
of	O
training	B
data	I
,	O
which	O
increases	O
the	O
number	O
of	O
rollment	O
and	O
each	O
of	O
the	O
n	O
speakers	O
discovered	O
in	O
the	O
auxiliary	O
test	B
.	O
recordings	O
from	O
about	O
150,000	O
to	O
300,000	O
.	O
finally	O
,	O
the	O
diarization	B
all	O
the	O
speech	B
segments	I
belonging	O
to	O
the	O
speaker	B
in	O
the	O
auxiliary	O
backend	O
(	O
section	O
4	O
)	O
was	O
trained	O
on	O
256,000	O
three	O
second	O
segments	O
test	B
that	O
maximizes	O
the	O
plda	B
score	B
(	O
as	O
in	O
equation	O
1	O
)	O
are	O
identiﬁed	O
,	O
extracted	O
randomly	O
from	O
the	O
full	O
-	O
length	B
augmented	O
recordings	O
.	O
and	O
used	O
by	O
the	O
speaker	B
recognition	O
system	O
to	O
extract	O
an	O
enrollment	O
x	O
-	O
vector	O
.	O
6.2	O
.	O
speakers	O
in	O
the	O
wild	O
4.3	O
.	O
diarizing	O
test	B
recordings	O
we	O
perform	O
experiments	O
on	O
the	O
speakers	O
in	O
the	O
wild	O
(	O
sitw	O
)	O
dataset	O
developed	O
by	O
sri	O
international	O
[	O
21	O
]	O
.	O
the	O
dataset	O
consists	O
of	O
chal-	O
handling	O
the	O
test	B
recordings	O
is	O
straightforward	O
once	O
ahc	O
is	O
per-	O
lenging	O
audio	O
collected	O
from	O
diverse	O
conditions	O
in	O
the	O
video	O
audio	O
formed	O
.	O
the	O
speech	B
segments	I
are	O
grouped	O
according	O
to	O
the	O
n	O
speak-	O
domain	B
.	O
one	O
of	O
the	O
challenges	B
is	O
the	O
presence	B
of	O
multiple	O
speakers	O
ers	O
discovered	O
in	O
the	O
conversation	O
,	O
and	O
are	O
passed	O
directly	O
to	O
the	O
in	O
some	O
of	O
the	O
utterances	B
.	O
the	O
recordings	O
vary	O
in	O
length	B
,	O
from	O
6	O
to	O
speaker	B
recognition	O
system	O
,	O
where	O
they	O
are	O
used	O
to	O
perform	O
recog-	O
240	O
seconds	B
.	O
nition	O
as	O
described	O
in	O
the	O
next	O
section	O
.	O
the	O
dataset	O
is	O
divided	O
into	O
a	O
development	B
set	I
dev	O
(	O
which	O
we	O
use	O
only	O
for	O
tuning	O
)	O
and	O
an	O
evaluation	B
set	I
eval	O
.	O
the	O
eval	O
set	B
con-	O
5	O
.	O
speaker	B
recognition	O
tains	O
180	O
speakers	O
divided	O
into	O
4,170	O
models	B
and	O
a	O
total	O
of	O
2,883	O
audio	O
ﬁles	O
.	O
recognition	O
is	O
performed	O
using	O
x	O
-	O
vectors	O
extracted	O
from	O
the	O
dnn	O
in	O
enrollment	O
conditions	O
section	O
3	O
and	O
a	O
plda	B
backend	O
.	O
the	O
x	O
-	O
vectors	O
are	O
centered	O
,	O
dimen-	O
•	O
core	O
:	O
enrollment	O
recordings	O
contain	O
exactly	O
one	O
speaker	B
.	O
sionality	O
reduced	O
to	O
225	O
using	O
lda	O
,	O
and	O
are	O
length	B
-	O
normalized	O
.	O
all	O
•	O
assist	O
:	O
one	O
or	O
more	O
speakers	O
in	O
enroll	O
,	O
along	O
with	O
an	O
“	O
as-	O
parameters	O
in	O
the	O
backend	O
are	O
estimated	O
on	O
the	O
augmented	O
voxceleb	O
sist	O
”	O
mark	O
,	O
which	O
is	O
a	O
short	O
segment	B
(	O
typically	O
5	O
seconds	B
)	O
of	O
data	B
,	O
as	O
described	O
in	O
section	O
6.1	O
.	O
the	O
recording	B
that	O
is	O
known	O
to	O
contain	O
the	O
speaker	B
of	O
interest	O
.	O
if	O
diarization	B
was	O
performed	O
on	O
a	O
test	B
recording	B
,	O
then	O
,	O
instead	O
of	O
test	B
conditions	O
extracting	O
a	O
single	O
x	O
-	O
vector	O
for	O
the	O
entire	O
test	B
recording	B
,	O
we	O
extract	O
n	O
x	O
-	O
vectors	O
,	O
one	O
for	O
each	O
of	O
the	O
n	O
speakers	O
identiﬁed	O
in	O
the	O
recording	B
.	O
•	O
core	O
:	O
test	B
recordings	O
contain	O
exactly	O
one	O
speaker	B
.	O
suppose	O
r	O
(	O
,	O
)	O
is	O
the	O
plda	B
log	B
-	O
likelihood	B
ratio	I
score	B
,	O
u	O
is	O
the	O
x-	O
•	O
multi	O
:	O
one	O
or	O
more	O
speakers	O
in	O
the	O
test	B
recordings	O
.	O
vector	O
for	O
the	O
enrolled	O
speaker	B
and	O
v	O
,	O
v	O
,	O
.	O
.	O
.	O
,	O
v	O
are	O
the	O
x	O
-	O
vectors	O
1	O
2	O
n	O
for	O
each	O
of	O
the	O
n	O
speakers	O
in	O
the	O
test	B
recording	B
.	O
to	O
perform	O
speaker	B
7	O
.	O
experimental	O
results	B
recognition	O
,	O
we	O
compute	O
the	O
plda	B
score	B
as	O
in	O
equation	O
1	O
,	O
which	O
is	O
the	O
maximum	O
of	O
the	O
plda	B
scores	O
between	O
the	O
enrollment	O
x	O
-	O
vector	O
in	O
table	O
2	O
we	O
report	O
results	B
on	O
the	O
eval	O
portion	O
of	O
the	O
speakers	O
in	O
and	O
all	O
n	O
test	B
x	O
-	O
vectors	O
.	O
the	O
wild	O
(	O
sitw	O
)	O
dataset	O
.	O
the	O
four	O
evaluation	B
conditions	O
are	O
formed	O
by	O
pairing	O
an	O
enrollment	O
condition	B
with	O
a	O
test	B
condition	B
described	O
in	O
r(enroll	O
,	O
test	B
)	O
=	O
max{r(u	O
,	O
v	O
)	O
,	O
.	O
.	O
.	O
,	O
r(u	O
,	O
v	O
)	O
}	O
(	O
1	O
)	O
1	O
n	O
section	O
6.2	O
.	O
performance	O
on	O
these	O
conditions	O
is	O
examined	O
in	O
sec-	O
handling	O
a	O
diarized	O
enrollment	O
recording	B
is	O
simpler	O
,	O
since	O
there	O
tions	O
7.1–7.4	O
.	O
the	O
results	B
are	O
further	O
broken	O
down	O
by	O
whether	O
or	O
can	O
only	O
be	O
one	O
speaker	B
of	O
interest	O
at	O
a	O
time	B
.	O
we	O
simply	O
extract	O
the	O
not	O
the	O
enroll	O
or	O
test	B
recordings	O
are	O
diarized	O
.	O
the	O
diarization	B
system	O
enrollment	O
x	O
-	O
vector	O
from	O
all	O
speech	O
frames	O
identiﬁed	O
as	O
belonging	O
and	O
its	O
interaction	O
with	O
speaker	B
recognition	O
is	O
the	O
subject	O
of	O
sections	O
to	O
the	O
speaker	B
of	O
interest	O
(	O
as	O
described	O
in	O
section	O
4.2	O
)	O
,	O
and	O
ignore	O
4–5	O
.	O
we	O
report	O
results	B
in	O
terms	B
of	O
equal	O
error	B
rate	I
(	O
eer	B
)	O
and	O
the	O
the	O
remaining	O
frames	O
.	O
minimum	O
of	O
the	O
normalized	O
detection	B
cost	B
function	O
(	O
dcf	O
)	O
.	O
dcf1	O
uses	O
p	O
=	O
10−2	O
and	O
dcf2	O
uses	O
p	O
=	O
10−3	O
.	O
target	O
target	O
the	O
threshold	B
system	O
uses	O
an	O
ahc	O
threshold	B
tuned	O
on	O
the	O
dev	O
6	O
.	O
experimental	O
setup	B
set	B
to	O
control	O
the	O
number	O
of	O
speakers	O
,	O
whereas	O
no	O
threshold	B
uses	O
the	O
alternative	O
method	B
described	O
in	O
section	O
4.1	O
to	O
eliminate	O
the	O
thresh-	O
6.1	O
.	O
training	B
data	I
old	O
.	O
in	O
section	O
7.5	O
,	O
we	O
discuss	O
performance	O
using	O
the	O
proposed	O
al-	O
the	O
system	O
is	O
trained	O
on	O
a	O
large	O
subset	O
of	O
the	O
combined	O
voxceleb	O
1	O
ternative	O
system	O
that	O
eliminates	O
the	O
ahc	O
threshold	B
.	O
[	O
28	O
]	O
and	O
voxceleb	O
2	O
[	O
29	O
]	O
corpora	B
sampled	O
at	O
16	O
khz	O
.	O
the	O
test	B
por-	O
tion	O
of	O
voxceleb	O
2	O
as	O
well	O
as	O
60	O
speakers	O
from	O
voxceleb	O
1	O
over-	O
7.1	O
.	O
core	O
-	O
core	O
lap	O
with	O
the	O
evaluation	B
dataset	O
,	O
and	O
so	O
we	O
removed	O
them	O
before	O
training	O
.	O
see	O
http://www.openslr.org/resources/49/	O
in	O
the	O
simplest	O
sitw	O
evaluation	B
condition	B
,	O
there	O
is	O
exactly	O
one	O
voxceleb1_sitw_overlap.txt	O
for	O
a	O
list	O
of	O
speakers	O
from	O
speaker	B
present	O
in	O
both	O
the	O
test	B
and	O
enrollment	O
recordings	O
.	O
in	O
the	O
voxceleb	O
1	O
which	O
are	O
known	O
to	O
overlap	O
with	O
sitw	O
.	O
this	O
leaves	O
a	O
ﬁrst	O
row	O
of	O
results	B
in	O
table	O
2	O
(	O
no	O
diar	O
)	O
,	O
we	O
do	O
not	O
apply	O
any	O
total	O
of	O
over	O
150,000	O
recordings	O
from	O
7,185	O
speakers	O
.	O
using	O
the	O
tar-	O
diarization	B
and	O
achieve	O
very	O
low	O
error	B
rates	I
.	O
in	O
the	O
next	O
row	O
of	O
get	O
speaker	B
marks	O
provided	O
in	O
the	O
corpora	B
,	O
the	O
recordings	O
are	O
split	O
results	B
(	O
test	B
)	O
,	O
we	O
apply	O
diarization	B
to	O
the	O
test	B
recordings	O
.	O
using	O
into	O
over	O
1.2	O
million	O
segments	O
.	O
the	O
standard	O
approach	O
,	O
diarizing	O
single	O
-	O
speaker	B
recordings	O
degrades	O
we	O
apply	O
a	O
data	B
augmentation	I
strategy	O
based	O
on	O
[	O
1	O
]	O
that	O
consists	O
performance	O
by	O
a	O
very	O
small	O
amount	B
–	O
less	O
than	O
half	O
a	O
percent	O
relative	O
of	O
adding	O
noises	O
,	O
music	O
,	O
babble	O
,	O
and	O
reverberation	O
.	O
the	O
x	O
-	O
vector	O
on	O
all	O
performance	O
metrics.table	O
2	O
.	O
results	B
on	O
the	O
sitw	O
evaluation	B
set	I
.	O
eval	O
core	O
-	O
core	O
eval	O
core	O
-	O
multi	O
eval	O
assist	O
-	O
core	O
eval	O
assist	O
-	O
multi	O
diarization	B
eer	B
dcf1	O
dcf2	O
eer	B
dcf1	O
dcf2	O
eer	B
dcf1	O
dcf2	O
eer	B
dcf1	O
dcf2	O
no	O
diar	O
1.7	O
0.20	O
0.34	O
3.5	O
0.28	O
0.44	O
3.2	O
0.24	O
0.38	O
4.3	O
0.28	O
0.43	O
enroll	O
1.6	O
0.20	O
0.35	O
3.0	O
0.26	O
0.41	O
threshold	B
test	B
1.8	O
0.21	O
0.35	O
2.1	O
0.22	O
0.41	O
3.3	O
0.24	O
0.39	O
3.8	O
0.26	O
0.41	O
both	O
1.7	O
0.21	O
0.36	O
2.1	O
0.21	O
0.37	O
enroll	O
1.6	O
0.20	O
0.36	O
3.0	O
0.26	O
0.42	O
no	O
threshold	B
test	B
1.8	O
0.23	O
0.36	O
2.0	O
0.22	O
0.40	O
3.8	O
0.26	O
0.40	O
3.9	O
0.26	O
0.41	O
both	O
2.2	O
0.23	O
0.38	O
2.2	O
0.22	O
0.38	O
core	O
-	O
core	O
is	O
the	O
most	O
commonly	O
used	O
condition	B
from	O
sitw	O
.	O
diarizing	O
either	O
enroll	O
or	O
test	B
recordings	O
individually	O
(	O
but	O
not	O
our	O
best	O
performance	O
on	O
this	O
condition	B
is	O
eer=1.7	O
%	O
dcf1=0.20	O
,	O
together	O
)	O
results	B
in	O
moderate	O
improvements	B
in	O
eer	B
,	O
and	O
smaller	O
im-	O
which	O
comfortably	O
outperforms	O
the	O
best	O
previously	O
reported	O
num-	O
provements	O
in	O
dcf1	O
and	O
dcf2	O
.	O
fortunately	O
,	O
the	O
beneﬁt	O
of	O
com-	O
bers	O
in	O
[	O
30	O
]	O
,	O
which	O
are	O
eer=2.7	O
%	O
and	O
dcf1=0.33	O
.	O
the	O
x	O
-	O
vector	O
bining	O
enroll	O
and	O
test	B
diarization	B
results	B
in	O
much	O
more	O
dramatic	O
im-	O
dnn	O
architecture	B
in	O
this	O
paper	O
is	O
similar	O
to	O
that	O
of	O
the	O
previous	O
work	O
,	O
provements	O
.	O
looking	O
at	O
the	O
threshold	B
system	O
,	O
we	O
observe	O
a	O
50	O
%	O
so	O
the	O
improvements	B
are	O
mostly	O
due	O
to	O
a	O
better	O
training	O
recipe	O
,	O
which	O
eer	B
reduction	O
over	O
no	O
diarization	B
and	O
a	O
14–23	O
%	O
reduction	O
in	O
dcf	O
.	O
consists	O
of	O
more	O
aggressive	O
data	B
augmentation	I
than	O
previously	O
used	O
,	O
and	O
the	O
addition	O
of	O
a	O
substantial	O
amount	B
of	O
in	O
-	O
domain	B
data	B
from	O
the	O
7.5	O
.	O
removing	O
the	O
threshold	B
voxceleb	O
2	O
corpus	B
[	O
29	O
]	O
.	O
the	O
previous	O
sections	O
showed	O
that	O
the	O
threshold	B
system	O
achieves	O
excellent	O
results	B
.	O
it	O
relies	O
on	O
an	O
ahc	O
threshold	B
tuned	O
on	O
labeled	O
7.2	O
.	O
core	O
-	O
multi	O
in	O
-	O
domain	B
data	B
.	O
although	O
this	O
is	O
not	O
an	O
obstacle	O
for	O
this	O
paper	O
,	O
as	O
core	O
-	O
multi	O
extends	O
the	O
previous	O
condition	B
with	O
test	B
recordings	O
we	O
are	O
able	O
to	O
tune	O
on	O
the	O
well	O
-	O
matched	O
dev	O
set	B
,	O
it	O
can	O
not	O
be	O
as-	O
that	O
contain	O
one	O
or	O
more	O
speakers	O
.	O
we	O
still	O
use	O
single	O
-	O
speaker	B
en-	O
sumed	O
that	O
an	O
in	O
-	O
domain	B
development	B
set	I
is	O
always	O
available	O
.	O
the	O
rollment	O
recordings	O
in	O
this	O
condition	B
.	O
no	O
threshold	B
system	O
uses	O
the	O
method	B
described	O
in	O
section	O
4.1	O
to	O
ad-	O
diarizing	O
the	O
multi	O
-	O
speaker	B
test	B
conversations	O
(	O
test	B
)	O
results	B
in	O
dress	O
the	O
problem	O
of	O
performing	O
diarizing	O
when	O
no	O
development	B
set	I
a	O
clear	O
improvement	O
over	O
performing	O
no	O
diarization	B
(	O
no	O
diar	O
)	O
.	O
is	O
available	O
to	O
tune	O
on	O
.	O
using	O
a	O
tuned	O
ahc	O
threshold	B
,	O
diarization	B
reduces	O
eer	B
by	O
38	O
%	O
,	O
and	O
in	O
table	O
2	O
we	O
see	O
that	O
,	O
under	O
most	O
conditions	O
,	O
the	O
alternative	O
no	O
by	O
20	O
%	O
in	O
dcf1	O
and	O
8	O
%	O
in	O
dcf2	O
.	O
the	O
results	B
that	O
eliminate	O
the	O
threshold	B
system	O
performs	O
similarly	O
to	O
threshold	B
.	O
when	O
diarizing	O
ahc	O
threshold	B
are	O
even	O
slightly	O
better	O
.	O
note	O
that	O
we	O
do	O
not	O
consider	O
is	O
required	O
for	O
multi	O
-	O
speaker	B
conversations	O
,	O
the	O
results	B
of	O
this	O
sys-	O
the	O
effect	O
of	O
diarizing	O
the	O
enrollment	O
recordings	O
yet	O
,	O
as	O
we	O
do	O
not	O
tem	O
are	O
very	O
similar	O
to	O
the	O
standard	O
approach	O
.	O
the	O
system	O
performs	O
consider	O
that	O
meaningful	O
unless	O
the	O
assist	O
segments	O
are	O
provided	O
.	O
worst	O
on	O
assist	O
-	O
core	O
when	O
we	O
needlessly	O
diarize	O
the	O
test	B
record-	O
ings	O
.	O
however	O
,	O
the	O
both	O
results	B
are	O
nonetheless	O
better	O
than	O
the	O
results	B
without	O
diarization	B
.	O
7.3	O
.	O
assist	O
-	O
core	O
this	O
condition	B
introduces	O
our	O
systems	O
to	O
the	O
assist	O
segments	O
.	O
these	O
8	O
.	O
conclusions	O
segments	O
provide	O
a	O
few	O
seconds	B
of	O
speech	O
of	O
the	O
speaker	B
we	O
wish	O
to	O
enroll	O
.	O
as	O
described	O
in	O
section	O
4.2	O
,	O
we	O
use	O
the	O
assist	O
marks	O
to	O
this	O
paper	O
investigated	O
speaker	B
recognition	O
with	O
multi	O
-	O
speaker	B
discover	O
additional	O
speech	O
(	O
in	O
the	O
enrollment	O
recording	B
)	O
that	O
belongs	O
recordings	O
.	O
we	O
used	O
a	O
diarization	B
system	O
based	O
on	O
x	O
-	O
vectors	O
,	O
plda	B
,	O
to	O
the	O
speaker	B
of	O
interest	O
,	O
while	O
discarding	O
any	O
speech	O
from	O
other	O
and	O
agglomerative	O
hierarchical	O
clustering	B
(	O
ahc	O
)	O
as	O
a	O
front	O
-	O
end	O
for	O
speakers	O
.	O
although	O
the	O
enrollment	O
recordings	O
may	O
have	O
multiple	O
a	O
speaker	B
recognition	O
system	O
.	O
we	O
evaluated	O
performance	O
on	O
the	O
speakers	O
,	O
the	O
test	B
recordings	O
are	O
single	O
-	O
speaker	B
in	O
this	O
condition	B
.	O
speakers	O
in	O
the	O
wild	O
dataset	O
,	O
and	O
found	O
that	O
diarization	B
signiﬁ-	O
diarizing	O
the	O
enrollment	O
recordings	O
(	O
enroll	O
)	O
reduces	O
eer	B
cantly	O
improved	O
speaker	B
recognition	O
performance	O
on	O
multi	O
-	O
speaker	B
by	O
50	O
%	O
relative	O
to	O
no	O
diar	O
.	O
the	O
dcf	O
numbers	O
also	O
improve	O
,	O
but	O
conversations	O
,	O
and	O
retained	O
strong	O
performance	O
on	O
single	O
-	O
speaker	B
by	O
a	O
smaller	O
amount	B
.	O
as	O
expected	O
,	O
unnecessarily	O
diarizing	O
the	O
test	B
recordings	O
as	O
well	O
.	O
finally	O
,	O
we	O
showed	O
that	O
the	O
ahc	O
threshold	B
,	O
recordings	O
(	O
but	O
not	O
enrollment	O
)	O
results	B
in	O
the	O
worst	O
performance	O
.	O
which	O
controls	O
the	O
number	O
of	O
clusters	O
,	O
can	O
be	O
replaced	O
with	O
an	O
nonetheless	O
,	O
the	O
threshold	B
results	B
are	O
not	O
signiﬁcantly	O
worse	O
than	O
alternative	O
method	B
that	O
achieves	O
similar	O
performance	O
under	O
most	O
the	O
results	B
without	O
diarization	B
.	O
in	O
the	O
last	O
row	O
(	O
both	O
)	O
,	O
we	O
diarize	O
conditions	O
,	O
but	O
eliminates	O
the	O
need	O
for	O
a	O
in	O
-	O
domain	B
development	B
set	I
both	O
the	O
enrollment	O
and	O
the	O
test	B
recordings	O
.	O
for	O
the	O
threshold	B
sys-	O
for	O
tuning	O
.	O
tem	O
,	O
this	O
degrades	O
performance	O
by	O
2–8	O
%	O
relative	O
to	O
the	O
enroll	O
results	B
,	O
but	O
still	O
maintains	O
an	O
improvement	O
over	O
no	O
diar	O
.	O
9	O
.	O
acknowledgments	O
7.4	O
.	O
assist	O
-	O
multi	O
this	O
material	O
is	O
based	O
upon	O
work	O
supported	O
by	O
the	O
national	O
sci-	O
this	O
condition	B
combines	O
the	O
challenge	B
of	O
potential	O
multi	O
-	O
speaker	B
en-	O
ence	O
foundation	O
graduate	O
research	B
fellowship	O
under	O
grant	O
no	O
.	O
rollment	O
recordings	O
with	O
multi	O
-	O
speaker	B
test	B
recordings	O
.	O
as	O
in	O
the	O
1232825	O
.	O
any	O
opinion	O
,	O
ﬁndings	O
,	O
and	O
conclusions	O
or	O
recommenda-	O
previous	O
section	O
,	O
diarizing	O
the	O
enrollment	O
recordings	O
is	O
enabled	O
by	O
tions	O
expressed	O
in	O
this	O
material	O
are	O
those	O
of	O
the	O
authors(s	O
)	O
and	O
do	O
not	O
the	O
assist	O
segments	O
.	O
necessarily	O
reﬂect	O
the	O
views	O
of	O
the	O
national	O
science	O
foundation.10	O
.	O
references	B
[	O
15	O
]	O
q.	O
wang	O
,	O
c.	O
downey	O
,	O
l.	O
wan	O
,	O
p.	O
mansﬁeld	O
,	O
and	O
i.	O
lopez	O
moreno	O
,	O
“	O
speaker	B
diarization	I
with	O
lstm	O
,	O
”	O
in	O
2018	O
ieee	O
in-	O
[	O
1	O
]	O
d.	O
snyder	O
,	O
d.	O
garcia	O
-	O
romero	O
,	O
g.	O
sell	O
,	O
d.	O
povey	O
,	O
and	O
s.	O
khu-	O
ternational	O
conference	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
pro-	O
danpur	O
,	O
“	O
x	O
-	O
vectors	O
:	O
robust	O
dnn	O
embeddings	O
for	O
speaker	B
cessing	O
(	O
icassp	O
)	O
.	O
ieee	O
,	O
2018	O
,	O
pp	O
.	O
5239–5243	O
.	O
recognition	O
,	O
”	O
in	O
2018	O
ieee	O
international	O
conference	O
on	O
[	O
16	O
]	O
m.	O
senoussaoui	O
,	O
p.	O
kenny	O
,	O
t.	O
stafylakis	O
,	O
and	O
p.	O
dumouchel	O
,	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
(	O
icassp	O
)	O
.	O
ieee	O
,	O
“	O
a	O
study	O
of	O
the	O
cosine	O
distance	B
-	O
based	O
mean	O
shift	O
for	O
telephone	O
2018	O
.	O
speech	O
diarization	B
,	O
”	O
ieee	O
/	O
acm	O
transactions	O
on	O
audio	O
,	O
speech	O
[	O
2	O
]	O
n.	O
dehak	O
,	O
p.	O
kenny	O
,	O
r.	O
dehak	O
,	O
p.	O
dumouchel	O
,	O
and	O
p.	O
ouel-	O
and	O
language	B
processing	I
(	O
taslp	O
)	O
,	O
vol	O
.	O
22	O
,	O
no	O
.	O
1	O
,	O
pp	O
.	O
217	O
–	O
let	O
,	O
“	O
front	O
-	O
end	O
factor	B
analysis	I
for	O
speaker	B
veriﬁcation	O
,	O
”	O
ieee	O
227	O
,	O
2014	O
.	O
transactions	O
on	O
audio	O
,	O
speech	O
,	O
and	O
language	B
processing	I
,	O
vol	O
.	O
[	O
17	O
]	O
g.	O
sell	O
and	O
d.	O
garcia	O
-	O
romero	O
,	O
“	O
speaker	B
diarization	I
with	O
plda	B
19	O
,	O
no	O
.	O
4	O
,	O
pp	O
.	O
788–798	O
,	O
2011	O
.	O
i	O
-	O
vector	O
scoring	O
and	O
unsupervised	O
calibration	O
,	O
”	O
in	O
spoken	O
lan-	O
guage	O
technology	O
workshop	O
(	O
slt	O
)	O
,	O
2014	O
ieee	O
.	O
ieee	O
,	O
2014	O
,	O
[	O
3	O
]	O
s.	O
ioffe	O
,	O
“	O
probabilistic	O
linear	O
discriminant	B
analysis	I
,	O
”	O
computer	B
pp	O
.	O
413–417	O
.	O
vision	O
–	O
eccv	O
2006	O
,	O
pp	O
.	O
531–542	O
,	O
2006	O
.	O
[	O
18	O
]	O
p.	O
kenny	O
,	O
d.	O
reynolds	O
,	O
and	O
f.	O
castaldo	O
,	O
“	O
diarization	B
of	O
tele-	O
[	O
4	O
]	O
p.	O
kenny	O
,	O
“	O
bayesian	O
speaker	B
veriﬁcation	O
with	O
heavy	O
-	O
tailed	O
pri-	O
phone	O
conversations	O
using	O
factor	B
analysis	I
,	O
”	O
ieee	O
journal	O
of	O
ors	O
.	O
,	O
”	O
in	O
odyssey	O
,	O
2010	O
,	O
p.	O
14	O
.	O
selected	O
topics	O
in	O
signal	B
processing	I
,	O
vol	O
.	O
4	O
,	O
no	O
.	O
6	O
,	O
pp	O
.	O
1059	O
,	O
[	O
5	O
]	O
n.	O
bru¨mmer	O
and	O
e.	O
de	O
villiers	O
,	O
“	O
the	O
speaker	B
partitioning	O
2010	O
.	O
problem	O
.	O
,	O
”	O
in	O
odyssey	O
,	O
2010	O
,	O
p.	O
34	O
.	O
[	O
19	O
]	O
m.	O
diez	O
,	O
l.	O
burget	O
,	O
and	O
p.	O
matejka	O
,	O
“	O
speaker	B
diarization	I
based	O
on	O
bayesian	O
hmm	O
with	O
eigenvoice	O
priors	O
,	O
”	O
in	O
proc	O
.	O
odyssey	O
[	O
6	O
]	O
l.	O
heck	O
,	O
y.	O
konig	O
,	O
k.	O
sonmez	O
,	O
and	O
m.	O
weintraub	O
,	O
“	O
ro-	O
2018	O
the	O
speaker	B
and	O
language	O
recognition	O
workshop	O
,	O
2018	O
,	O
bustness	O
to	O
telephone	O
handset	O
distortion	O
in	O
speaker	B
recognition	O
pp	O
.	O
147–154	O
.	O
by	O
discriminative	O
feature	O
design	O
,	O
”	O
in	O
speech	B
communication	I
,	O
2000	O
,	O
vol	O
.	O
31	O
,	O
pp	O
.	O
181–192	O
.	O
[	O
20	O
]	O
a.	O
martin	O
and	O
m.	O
przybocki	O
,	O
“	O
speaker	B
recognition	O
in	O
a	O
multi-	O
speaker	B
environment	O
,	O
”	O
in	O
seventh	O
european	O
conference	O
on	O
[	O
7	O
]	O
a.	O
salman	O
,	O
learning	O
speaker	B
-	O
speciﬁc	O
characteristics	B
with	O
speech	B
communication	I
and	O
technology	O
,	O
2001	O
.	O
deep	O
neural	O
architecture	B
,	O
ph.d	O
.	O
thesis	O
,	O
university	O
of	O
manch-	O
[	O
21	O
]	O
m.	O
mclaren	O
,	O
l.	O
ferrer	O
,	O
d.	O
castan	O
,	O
and	O
a.	O
lawson	O
,	O
“	O
the	O
2016	O
ester	O
,	O
2012	O
.	O
speakers	O
in	O
the	O
wild	O
speaker	B
recognition	O
evaluation	B
.	O
,	O
”	O
in	O
inter-	O
[	O
8	O
]	O
g.	O
heigold	O
,	O
i.	O
moreno	O
,	O
s.	O
bengio	O
,	O
and	O
n.	O
shazeer	O
,	O
“	O
end	O
-	O
to	O
-	O
end	O
speech	O
,	O
2016	O
,	O
pp	O
.	O
823–827	O
.	O
text	O
-	O
dependent	O
speaker	B
veriﬁcation	O
,	O
”	O
in	O
2016	O
ieee	O
interna-	O
[	O
22	O
]	O
“	O
nist	O
speaker	B
recognition	O
evaluation	B
2018	O
,	O
”	O
https	O
:	O
tional	O
conference	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
//www.nist.gov	O
/	O
sites	O
/	O
default	O
/	O
files/	O
(	O
icassp	O
)	O
.	O
ieee	O
,	O
2016	O
,	O
pp	O
.	O
5115–5119	O
.	O
documents/2018/08/17	O
/	O
sre18_eval_plan	O
_	O
[	O
9	O
]	O
d.	O
snyder	O
,	O
p.	O
ghahremani	O
,	O
d.	O
povey	O
,	O
d.	O
garcia	O
-	O
romero	O
,	O
2018-05-31_v6.pdf	O
,	O
2018	O
.	O
y.	O
carmiel	O
,	O
and	O
s.	O
khudanpur	O
,	O
“	O
deep	O
neural	B
network	I
-	O
based	O
[	O
23	O
]	O
o.	O
novotny	O
`	O
,	O
p.	O
matejka	O
,	O
o.	O
plchot	O
,	O
o.	O
glembek	O
,	O
l.	O
burget	O
,	O
speaker	B
embeddings	I
for	O
end	O
-	O
to	O
-	O
end	O
speaker	B
veriﬁcation	O
,	O
”	O
in	O
and	O
j.	O
cernocky	O
`	O
,	O
“	O
analysis	B
of	O
speaker	B
recognition	O
systems	O
in	O
spoken	B
language	I
technology	O
workshop	O
(	O
slt	O
)	O
.	O
ieee	O
,	O
2016	O
.	O
realistic	O
scenarios	O
of	O
the	O
sitw	O
2016	O
challenge	B
.	O
,	O
”	O
in	O
interspeech	O
,	O
2016	O
,	O
pp	O
.	O
828–832	O
.	O
[	O
10	O
]	O
d.	O
snyder	O
,	O
d.	O
garcia	O
-	O
romero	O
,	O
d.	O
povey	O
,	O
and	O
s.	O
khudan-	O
pur	O
,	O
“	O
deep	O
neural	B
network	I
embeddings	O
for	O
text	O
-	O
independent	O
[	O
24	O
]	O
y.	O
liu	O
,	O
y.	O
tian	O
,	O
l.	O
he	O
,	O
and	O
j.	O
liu	O
,	O
“	O
investigating	O
various	O
speaker	B
veriﬁcation	O
,	O
”	O
proc	O
.	O
interspeech	O
,	O
pp	O
.	O
999–1003	O
,	O
2017	O
.	O
diarization	B
algorithms	O
for	O
speaker	B
in	O
the	O
wild	O
(	O
sitw	O
)	O
speaker	B
recognition	O
challenge	B
.	O
,	O
”	O
in	O
interspeech	O
,	O
2016	O
,	O
pp	O
.	O
853–857	O
.	O
[	O
11	O
]	O
s.	O
shum	O
,	O
n.	O
dehak	O
,	O
e.	O
chuangsuwanich	O
,	O
d.	O
reynolds	O
,	O
and	O
j.	O
glass	O
,	O
“	O
exploiting	O
intra	O
-	O
conversation	O
variability	O
for	O
speaker	B
[	O
25	O
]	O
d.	O
povey	O
,	O
a.	O
ghoshal	O
,	O
g.	O
boulianne	O
,	O
l.	O
burget	O
,	O
o.	O
glembek	O
,	O
diarization	B
,	O
”	O
in	O
twelfth	O
annual	B
conference	I
of	O
the	O
international	O
n.	O
goel	O
,	O
m.	O
hannemann	O
,	O
p.	O
motl´ıcˇek	O
,	O
y.	O
qian	O
,	O
p.	O
schwarz	O
,	O
speech	B
communication	I
association	O
,	O
2011	O
.	O
et	O
al	O
.	O
,	O
“	O
the	O
kaldi	O
speech	B
recognition	I
toolkit	O
,	O
”	O
in	O
proceedings	O
of	O
the	O
automatic	O
speech	B
recognition	I
&	O
understanding	O
(	O
asru	O
)	O
[	O
12	O
]	O
s.	O
shum	O
,	O
n.	O
dehak	O
,	O
and	O
j.	O
glass	O
,	O
“	O
on	O
the	O
use	O
of	O
spectral	O
and	O
workshop	O
,	O
2011	O
.	O
iterative	O
methods	O
for	O
speaker	B
diarization	I
,	O
”	O
in	O
thirteenth	O
an-	O
[	O
26	O
]	O
m.	O
mclaren	O
,	O
d.	O
castan	O
,	O
m.	O
nandwana	O
,	O
l.	O
ferrer	O
,	O
and	O
nual	O
conference	O
of	O
the	O
international	O
speech	B
communication	I
e.	O
yılmaz	O
,	O
“	O
how	O
to	O
train	O
your	O
speaker	B
embeddings	I
extrac-	O
association	O
,	O
2012	O
.	O
tor	O
,	O
”	O
in	O
odyssey	O
:	O
the	O
speaker	B
and	O
language	O
recognition	O
[	O
13	O
]	O
d.	O
garcia	O
-	O
romero	O
,	O
d.	O
snyder	O
,	O
g.	O
sell	O
,	O
d.	O
povey	O
,	O
and	O
a.	O
mc-	O
workshop	O
,	O
les	O
sables	O
dolonne	O
,	O
2018	O
.	O
cree	O
,	O
“	O
speaker	B
diarization	I
using	O
deep	O
neural	B
network	I
em-	O
[	O
27	O
]	O
n.	O
ryant	O
,	O
k.	O
church	O
,	O
c.	O
cieri	O
,	O
a.	O
cristia	O
,	O
j.	O
du	O
,	O
s.	O
ganapathy	O
,	O
beddings	O
,	O
”	O
in	O
2017	O
ieee	O
international	O
conference	O
on	O
acous-	O
and	O
m.	O
liberman	O
,	O
“	O
first	O
dihard	B
challenge	I
evaluation	B
plan	I
,	O
”	O
tics	O
,	O
speech	O
and	O
signal	B
processing	I
(	O
icassp	O
)	O
.	O
ieee	O
,	O
2017	O
,	O
pp	O
.	O
2018	O
.	O
4930–4934	O
.	O
[	O
28	O
]	O
a.	O
nagrani	O
,	O
j.	O
s.	O
chung	O
,	O
and	O
a.	O
zisserman	O
,	O
“	O
voxceleb	O
:	O
a	O
large-	O
[	O
14	O
]	O
g.	O
sell	O
,	O
d.	O
snyder	O
,	O
a.	O
mccree	O
,	O
d.	O
garcia	O
-	O
romero	O
,	O
j.	O
villalba	O
,	O
scale	O
speaker	B
identiﬁcation	O
dataset	O
,	O
”	O
in	O
interspeech	O
,	O
2017	O
.	O
m.	O
maciejewski	O
,	O
v.	O
manohar	O
,	O
n.	O
dehak	O
,	O
d.	O
povey	O
,	O
s.	O
watan-	O
[	O
29	O
]	O
j.	O
s.	O
chung	O
,	O
a.	O
nagrani	O
,	O
and	O
a.	O
zisserman	O
,	O
“	O
voxceleb2	O
:	O
deep	O
abe	O
,	O
and	O
s.	O
khudanpur	O
,	O
“	O
diarization	B
is	O
hard	O
:	O
some	O
experi-	O
speaker	B
recognition	O
,	O
”	O
in	O
interspeech	O
,	O
2018	O
.	O
ences	O
and	O
lessons	O
learned	O
for	O
the	O
jhu	O
team	O
in	O
the	O
inaugural	O
[	O
30	O
]	O
a.	O
silnova	O
,	O
n.	O
bru¨mmer	O
,	O
d.	O
garcia	O
-	O
romero	O
,	O
d.	O
snyder	O
,	O
and	O
dihard	B
challenge	I
,	O
”	O
in	O
proceedings	O
of	O
the	O
19th	O
annual	O
con-	O
l.	O
burget	O
,	O
“	O
fast	O
variational	O
bayes	O
for	O
heavy	O
-	O
tailed	O
plda	B
ap-	O
ference	O
of	O
the	O
international	O
speech	B
communication	I
associa-	O
plied	O
to	O
i	O
-	O
vectors	O
and	O
x	O
-	O
vectors	O
,	O
”	O
in	O
interspeech	O
2018	O
,	O
hyder-	O
tion	O
,	O
interspeech	O
2018	O
,	O
hyderabad	O
,	O
india	O
,	O
sep	O
2018	O
,	O
pp	O
.	O
abad	O
,	O
india	O
,	O
2018	O
,	O
pp	O
.	O
72–76	O
.	O

x	O
-	O
vectors	O
:	O
robust	O
dnn	O
embeddings	O
for	O
speaker	B
recognition	O
david	O
snyder	O
,	O
daniel	O
garcia	O
-	O
romero	O
,	O
gregory	O
sell	O
,	O
daniel	O
povey	O
,	O
sanjeev	O
khudanpur	O
center	O
for	O
language	O
and	O
speech	O
processing	B
&	O
human	O
language	O
technology	O
center	O
of	O
excellence	O
the	O
johns	O
hopkins	O
university	O
,	O
baltimore	O
,	O
md	O
21218	O
,	O
usa	O
abstract	O
alternatively	O
,	O
neural	B
networks	I
can	O
be	O
directly	O
optimized	O
to	O
dis-	O
criminate	O
between	O
speakers	O
.	O
this	O
has	O
potential	O
to	O
produce	O
power-	O
in	O
this	O
paper	O
,	O
we	O
use	O
data	B
augmentation	I
to	O
improve	O
performance	O
of	O
ful	O
,	O
compact	O
systems	O
[	O
13	O
]	O
,	O
that	O
only	O
require	O
speaker	B
labels	I
to	O
train	O
.	O
deep	O
neural	B
network	I
(	O
dnn	O
)	O
embeddings	O
for	O
speaker	B
recognition	O
.	O
in	O
early	O
systems	O
,	O
neural	B
networks	I
are	O
trained	O
to	O
separate	O
speakers	O
,	O
the	O
dnn	O
,	O
which	O
is	O
trained	O
to	O
discriminate	O
between	O
speakers	O
,	O
maps	O
and	O
frame	B
-	O
level	B
representations	O
are	O
extracted	O
from	O
the	O
network	B
and	O
variable	O
-	O
length	B
utterances	B
to	O
ﬁxed	O
-	O
dimensional	O
embeddings	O
that	O
we	O
used	O
as	O
features	O
for	O
gaussian	O
speaker	B
models	B
[	O
14	O
,	O
15	O
,	O
16	O
]	O
.	O
heigold	O
call	O
x	O
-	O
vectors	O
.	O
prior	O
studies	O
have	O
found	O
that	O
embeddings	O
leverage	O
et	O
al	O
.	O
,	O
introduced	O
an	O
end	O
-	O
to	O
-	O
end	O
system	O
,	O
trained	O
on	O
the	O
phrase	O
“	O
ok	O
large	O
-	O
scale	O
training	O
datasets	B
better	O
than	O
i	O
-	O
vectors	O
.	O
however	O
,	O
it	O
can	O
be	O
google	O
,	O
”	O
that	O
jointly	O
learns	O
an	O
embedding	O
along	O
with	O
a	O
similarity	B
challenging	O
to	O
collect	O
substantial	O
quantities	O
of	O
labeled	O
data	B
for	O
train-	O
metric	B
to	O
compare	O
pairs	O
of	O
embeddings	O
[	O
13	O
]	O
.	O
snyder	O
et	O
al	O
.	O
,	O
adapted	O
ing	O
.	O
we	O
use	O
data	B
augmentation	I
,	O
consisting	O
of	O
added	O
noise	O
and	O
rever-	O
this	O
approach	O
to	O
a	O
text	O
-	O
independent	O
application	B
and	O
inserted	O
a	O
tem-	O
beration	O
,	O
as	O
an	O
inexpensive	O
method	B
to	O
multiply	O
the	O
amount	B
of	O
train-	O
poral	O
pooling	O
layer	B
into	O
the	O
network	B
to	O
handle	O
variable	O
-	O
length	B
seg-	O
ing	O
data	B
and	O
improve	O
robustness	O
.	O
the	O
x	O
-	O
vectors	O
are	O
compared	O
with	O
ments	O
[	O
17	O
]	O
.	O
the	O
work	O
in	O
[	O
1	O
]	O
split	O
the	O
end	O
-	O
to	O
-	O
end	O
approach	O
into	O
two	O
i	O
-	O
vector	O
baselines	O
on	O
speakers	O
in	O
the	O
wild	O
and	O
nist	O
sre	O
2016	O
can-	O
parts	O
:	O
a	O
dnn	O
to	O
produce	O
embeddings	O
and	O
a	O
separately	O
trained	O
classi-	O
tonese	O
.	O
we	O
ﬁnd	O
that	O
while	O
augmentation	B
is	O
beneﬁcial	O
in	O
the	O
plda	B
ﬁer	O
to	O
compare	O
them	O
.	O
this	O
facilitates	O
the	O
use	O
of	O
all	O
the	O
accumulated	O
classiﬁer	O
,	O
it	O
is	O
not	O
helpful	O
in	O
the	O
i	O
-	O
vector	O
extractor	B
.	O
however	O
,	O
the	O
backend	O
technology	O
developed	O
over	O
the	O
years	O
for	O
i	O
-	O
vectors	O
,	O
such	O
as	O
x	O
-	O
vector	O
dnn	O
effectively	O
exploits	O
data	B
augmentation	I
,	O
due	O
to	O
its	O
su-	O
length	B
-	O
normalization	O
,	O
plda	B
scoring	O
,	O
and	O
domain	B
adaptation	O
tech-	O
pervised	O
training	O
.	O
as	O
a	O
result	O
,	O
the	O
x	O
-	O
vectors	O
achieve	O
superior	O
perfor-	O
niques	O
.	O
mance	O
on	O
the	O
evaluation	B
datasets	B
.	O
dnn	O
embedding	O
performance	O
appears	O
to	O
be	O
highly	O
scalable	O
with	O
index	O
terms	B
—	O
speaker	B
recognition	O
,	O
deep	O
neural	B
networks	I
,	O
data	B
the	O
amount	B
of	O
training	B
data	I
.	O
as	O
a	O
result	O
,	O
these	O
systems	O
have	O
found	O
augmentation	B
,	O
x	O
-	O
vectors	O
success	O
leveraging	O
large	O
proprietary	O
datasets	B
[	O
13	O
,	O
17	O
,	O
18	O
]	O
.	O
however	O
,	O
recent	O
systems	O
have	O
shown	O
promising	O
performance	O
trained	O
on	O
only	O
publicly	O
available	O
speaker	B
recognition	O
corpora	B
[	O
1	O
,	O
19	O
,	O
20	O
]	O
.	O
this	O
pa-	O
1	O
.	O
introduction	O
per	O
is	O
based	O
on	O
the	O
work	O
in	O
[	O
1	O
]	O
and	O
applies	O
data	B
augmentation	I
to	O
the	O
dnn	O
training	O
procedure	O
.	O
this	O
increases	O
the	O
amount	B
and	O
diversity	O
of	O
using	O
deep	O
neural	B
networks	I
(	O
dnn	O
)	O
to	O
capture	O
speaker	B
characteris-	O
the	O
existing	O
training	B
data	I
,	O
and	O
achieves	O
a	O
signiﬁcant	O
improvement	O
for	O
tics	O
is	O
currently	O
a	O
very	O
active	O
research	B
area	O
.	O
in	O
our	O
approach	O
,	O
repre-	O
the	O
x	O
-	O
vector	B
system	I
.	O
in	O
comparing	O
with	O
x	O
-	O
vectors	O
,	O
we	O
also	O
contribute	O
sentations	O
called	O
x	O
-	O
vectors	O
are	O
extracted	O
from	O
a	O
dnn	O
and	O
used	O
like	O
a	O
study	O
of	O
augmentation	B
in	O
i	O
-	O
vector	O
systems	O
.	O
i	O
-	O
vectors	O
.	O
this	O
paper	O
builds	O
on	O
our	O
recent	O
dnn	O
embedding	O
architec-	O
ture	O
[	O
1	O
]	O
.	O
we	O
show	O
that	O
artiﬁcially	O
augmenting	O
the	O
training	B
data	I
with	O
noises	O
and	O
reverberation	O
is	O
a	O
highly	O
effective	O
strategy	O
for	O
improving	O
performance	O
in	O
dnn	O
embedding	O
systems	O
.	O
2	O
.	O
speaker	B
recognition	O
systems	O
most	O
speaker	B
recognition	O
systems	O
are	O
based	O
on	O
i	O
-	O
vectors	O
[	O
2	O
]	O
.	O
the	O
standard	O
approach	O
consists	O
of	O
a	O
universal	O
background	O
model	B
this	O
section	O
describes	O
the	O
speaker	B
recognition	O
systems	O
developed	O
(	O
ubm	O
)	O
,	O
and	O
a	O
large	O
projection	O
matrix	O
t	O
that	O
are	O
learned	O
in	O
an	O
unsu-	O
for	O
this	O
study	O
,	O
which	O
consist	O
of	O
two	O
i	O
-	O
vector	O
baselines	O
and	O
the	O
dnn	O
pervised	O
way	O
to	O
maximize	O
the	O
data	B
likelihood	B
.	O
the	O
projection	O
maps	O
x	O
-	O
vector	B
system	I
.	O
all	O
systems	O
are	O
built	O
using	O
the	O
kaldi	O
speech	O
recog-	O
high	O
-	O
dimensional	O
statistics	B
from	O
the	O
ubm	O
into	O
a	O
low	O
-	O
dimensional	O
nition	O
toolkit	O
[	O
21	O
]	O
.	O
representation	O
,	O
known	O
as	O
an	O
i	O
-	O
vector	O
.	O
a	O
probabilistic	O
linear	O
discrimi-	O
nant	O
analysis	B
(	O
plda	B
)	O
[	O
3	O
]	O
classiﬁer	O
is	O
used	O
to	O
compare	O
i	O
-	O
vectors	O
,	O
and	O
enable	O
same	O
-	O
or	O
-	O
different	O
speaker	B
decisions	O
[	O
4	O
,	O
5	O
,	O
6	O
]	O
.	O
the	O
dnns	O
most	O
often	O
found	O
in	O
speaker	B
recognition	O
are	O
trained	O
2.1	O
.	O
acoustic	O
i	O
-	O
vector	O
as	O
acoustic	O
models	B
for	O
automatic	O
speech	B
recognition	I
(	O
asr	B
)	O
,	O
and	O
are	O
then	O
used	O
to	O
enhance	O
phonetic	O
modeling	O
in	O
the	O
i	O
-	O
vector	O
ubm	O
:	O
either	O
a	O
traditional	O
i	O
-	O
vector	B
system	I
based	O
on	O
the	O
gmm	O
-	O
ubm	O
recipe	O
de-	O
posteriors	O
from	O
the	O
asr	B
dnn	O
replace	O
those	O
from	O
a	O
gaussian	O
mix-	O
scribed	O
in	O
[	O
11	O
]	O
serves	O
as	O
our	O
acoustic	O
-	O
feature	O
baseline	B
system	I
.	O
the	O
ture	O
model	B
(	O
gmm	O
)	O
[	O
7	O
,	O
8	O
]	O
,	O
or	O
bottleneck	O
features	O
are	O
extracted	O
from	O
features	O
are	O
20	O
mfccs	O
with	O
a	O
frame	B
-	O
length	B
of	O
25ms	O
that	O
are	O
mean-	O
the	O
dnn	O
and	O
combined	O
with	O
acoustic	B
features	I
[	O
9	O
]	O
.	O
in	O
either	O
case	O
,	O
if	O
normalized	O
over	O
a	O
sliding	O
window	O
of	O
up	O
to	O
3	O
seconds	B
.	O
delta	O
and	O
the	O
asr	B
dnn	O
is	O
trained	O
on	O
in	O
-	O
domain	B
data	B
,	O
the	O
improvement	O
over	O
acceleration	O
are	O
appended	O
to	O
create	O
60	O
dimension	O
feature	O
vectors	O
.	O
traditional	O
acoustic	O
i	O
-	O
vectors	O
is	O
substantial	O
[	O
10	O
,	O
11	O
,	O
12	O
]	O
.	O
however	O
,	O
an	O
energy	O
-	O
based	O
speech	B
activity	I
detection	I
(	O
sad	O
)	O
system	O
selects	O
fea-	O
this	O
approach	O
introduces	O
the	O
need	O
for	O
transcribed	O
training	B
data	I
and	O
tures	O
corresponding	O
to	O
speech	O
frames	O
.	O
the	O
ubm	O
is	O
a	O
2048	O
com-	O
greatly	O
increases	O
computational	O
complexity	O
compared	O
to	O
traditional	O
ponent	O
full	O
-	O
covariance	O
gmm	O
.	O
the	O
system	O
uses	O
a	O
600	O
dimensional	O
i	O
-	O
vectors	O
.	O
i	O
-	O
vector	O
extractor	B
and	O
plda	B
for	O
scoring	O
(	O
see	O
section	O
2.4).2.2	O
.	O
phonetic	O
bottleneck	O
i	O
-	O
vector	O
gether	O
and	O
propagated	O
through	O
segment	B
-	O
level	B
layers	O
and	O
ﬁnally	O
the	O
softmax	O
output	B
layer	B
.	O
the	O
nonlinearities	O
are	O
all	O
rectiﬁed	O
linear	O
units	O
this	O
i	O
-	O
vector	B
system	I
incorporates	O
phonetic	O
bottleneck	O
features	O
(	O
relus	O
)	O
.	O
(	O
bnf	O
)	O
from	O
an	O
asr	B
dnn	O
acoustic	O
model	B
and	O
is	O
similar	O
to	O
[	O
9	O
]	O
.	O
the	O
dnn	O
is	O
trained	O
to	O
classify	O
the	O
n	O
speakers	O
in	O
the	O
training	O
the	O
dnn	O
is	O
a	O
time	B
-	O
delay	O
acoustic	O
model	B
with	O
p	O
-	O
norm	B
nonlineari-	O
data	B
.	O
a	O
training	O
example	O
consists	O
of	O
a	O
chunk	O
of	O
speech	O
features	O
ties	O
.	O
the	O
asr	B
dnn	O
is	O
trained	O
on	O
the	O
fisher	O
english	O
corpus	B
and	O
uses	O
(	O
about	O
3	O
seconds	B
average	B
)	O
,	O
and	O
the	O
corresponding	O
speaker	B
label	O
.	O
af-	O
the	O
same	O
recipe	O
and	O
architecture	B
as	O
the	O
system	O
described	O
in	O
section	O
ter	O
training	O
,	O
embeddings	O
are	O
extracted	O
from	O
the	O
afﬁne	O
component	O
of	O
2.2	O
of	O
[	O
11	O
]	O
,	O
except	O
that	O
the	O
penultimate	O
layer	B
is	O
replaced	O
with	O
a	O
60	O
layer	B
segment6	O
.	O
excluding	O
the	O
softmax	O
output	B
layer	B
and	O
segment7	O
dimensional	O
linear	O
bottleneck	O
layer	B
.	O
excluding	O
the	O
softmax	O
output	B
(	O
because	O
they	O
are	O
not	O
needed	O
after	O
training	O
)	O
there	O
is	O
a	O
total	O
of	O
4.2	O
layer	B
,	O
which	O
is	O
not	O
needed	O
to	O
compute	O
bnfs	O
,	O
the	O
dnn	O
has	O
9.2	O
million	O
parameters	O
.	O
million	O
parameters	O
.	O
the	O
bnfs	O
are	O
concatenated	O
with	O
the	O
same	O
20	O
dimensional	O
mfccs	O
described	O
in	O
section	O
2.1	O
plus	O
deltas	O
to	O
create	O
100	O
dimen-	O
2.4	O
.	O
plda	B
classiﬁer	O
sional	O
features	O
.	O
the	O
remaining	O
components	B
of	O
the	O
system	O
(	O
feature	O
the	O
same	O
type	O
of	O
plda	B
[	O
3	O
]	O
classiﬁer	O
is	O
used	O
for	O
the	O
x	O
-	O
vector	O
and	O
processing	B
,	O
ubm	O
,	O
i	O
-	O
vector	O
extractor	B
,	O
and	O
plda	B
classiﬁer	O
)	O
are	O
iden-	O
i	O
-	O
vector	O
systems	O
.	O
the	O
representations	O
(	O
x	O
-	O
vectors	O
or	O
i	O
-	O
vectors	O
)	O
are	O
tical	O
to	O
the	O
acoustic	O
system	O
in	O
section	O
2.1	O
.	O
centered	O
,	O
and	O
projected	O
using	O
lda	O
.	O
the	O
lda	O
dimension	O
was	O
tuned	O
on	O
the	O
sitw	O
development	B
set	I
to	O
200	O
for	O
i	O
-	O
vectors	O
and	O
150	O
for	O
2.3	O
.	O
the	O
x	O
-	O
vector	B
system	I
x	O
-	O
vectors	O
.	O
after	O
dimensionality	O
reduction	O
,	O
the	O
representations	O
are	O
length	B
-	O
normalized	O
and	O
modeled	O
by	O
plda	B
.	O
the	O
scores	O
are	O
normal-	O
this	O
section	O
describes	O
the	O
x	O
-	O
vector	B
system	I
.	O
it	O
is	O
based	O
on	O
the	O
dnn	O
ized	O
using	O
adaptive	O
s	O
-	O
norm	B
[	O
22	O
]	O
.	O
embeddings	O
in	O
[	O
1	O
]	O
and	O
described	O
in	O
greater	O
detail	O
there	O
.	O
our	O
software	O
framework	O
has	O
been	O
made	O
available	O
in	O
the	O
kaldi	O
toolkit	O
.	O
an	O
example	O
recipe	O
is	O
in	O
the	O
main	O
branch	O
of	O
kaldi	O
at	O
https	O
:	O
3	O
.	O
experimental	O
setup	B
//github.com	O
/	O
kaldi	O
-	O
asr	B
/	O
kaldi	O
/	O
tree	O
/	O
master	O
/	O
egs/	O
sre16	O
/	O
v2	O
and	O
a	O
pretrained	O
x	O
-	O
vector	B
system	I
can	O
be	O
downloaded	O
3.1	O
.	O
training	B
data	I
from	O
http://kaldi-asr.org/models.html	O
.	O
the	O
recipe	O
the	O
training	B
data	I
consists	O
of	O
both	O
telephone	O
and	O
microphone	O
speech	O
,	O
and	O
model	B
are	O
similar	O
to	O
the	O
x	O
-	O
vector	B
system	I
described	O
in	O
section	O
the	O
bulk	O
of	O
which	O
is	O
in	O
english	O
.	O
all	O
wideband	O
audio	O
is	O
downsampled	O
4.4	O
.	O
to	O
8khz	O
.	O
the	O
swbd	O
portion	O
consists	O
of	O
switchboard	O
2	O
phases	O
1	O
,	O
2	O
,	O
and	O
3	O
layer	B
layer	B
context	O
total	O
context	O
input	B
x	O
output	B
as	O
well	O
as	O
switchboard	O
cellular	O
.	O
in	O
total	O
,	O
the	O
swbd	O
dataset	O
contains	O
frame1	O
[	O
t	O
−	O
2	O
,	O
t	O
+	O
2	O
]	O
5	O
120x512	O
about	O
28k	O
recordings	O
from	O
2.6k	O
speakers	O
.	O
the	O
sre	O
portion	O
con-	O
frame2	O
{	O
t	O
−	O
2	O
,	O
t	O
,	O
t	O
+	O
2	O
}	O
9	O
1536x512	O
sists	O
of	O
nist	O
sres	O
from	O
2004	O
to	O
2010	O
along	O
with	O
mixer	O
6	O
and	O
con-	O
frame3	O
{	O
t	O
−	O
3	O
,	O
t	O
,	O
t	O
+	O
3	O
}	O
15	O
1536x512	O
tains	O
about	O
63k	O
recordings	O
from	O
4.4k	O
speakers	O
.	O
in	O
the	O
experiments	O
frame4	O
{	O
t	O
}	O
15	O
512x512	O
in	O
sections	O
4.1–4.4	O
the	O
extractors	O
(	O
ubm	O
/	O
t	O
or	O
embedding	O
dnn	O
)	O
are	O
frame5	O
{	O
t	O
}	O
15	O
512x1500	O
trained	O
on	O
swbd	O
and	O
sre	O
and	O
the	O
plda	B
classiﬁers	O
are	O
trained	O
on	O
stats	O
pooling	O
[	O
0	O
,	O
t	O
)	O
t	O
1500	O
t	O
x3000	O
just	O
sre	O
.	O
data	B
augmentation	I
is	O
described	O
in	O
section	O
3.3	O
and	O
is	O
ap-	O
segment6	O
{	O
0	O
}	O
t	O
3000x512	O
plied	O
to	O
these	O
datasets	B
as	O
explained	O
throughout	O
section	O
4	O
.	O
segment7	O
{	O
0	O
}	O
t	O
512x512	O
in	O
the	O
last	O
experiment	O
in	O
section	O
4.5	O
we	O
incorporate	O
audio	O
from	O
softmax	O
{	O
0	O
}	O
t	O
512xn	O
the	O
new	O
voxceleb	O
dataset	O
[	O
19	O
]	O
into	O
both	O
extractor	B
and	O
plda	B
train-	O
ing	O
lists	O
.	O
the	O
dataset	O
consists	O
of	O
videos	B
from	O
1,251	O
celebrity	O
speak-	O
ers	O
.	O
although	O
sitw	O
and	O
voxceleb	O
were	O
collected	O
independently	O
,	O
table	O
1	O
.	O
the	O
embedding	O
dnn	O
architecture	B
.	O
x	O
-	O
vectors	O
are	O
extracted	O
we	O
discovered	O
an	O
overlap	O
of	O
60	O
speakers	O
between	O
the	O
two	O
datasets	B
.	O
at	O
layer	B
segment6	O
,	O
before	O
the	O
nonlinearity	O
.	O
the	O
n	O
in	O
the	O
softmax	O
we	O
removed	O
the	O
overlapping	B
speakers	O
from	O
voxceleb	O
prior	O
to	O
using	O
layer	B
corresponds	O
to	O
the	O
number	O
of	O
training	O
speakers	O
.	O
it	O
for	O
training	O
.	O
this	O
reduces	O
the	O
size	B
of	O
the	O
dataset	O
to	O
1,191	O
speakers	O
and	O
about	O
20k	O
recordings	O
.	O
the	O
features	O
are	O
24	O
dimensional	O
ﬁlterbanks	O
with	O
a	O
frame	B
-	O
length	B
the	O
asr	B
dnn	O
used	O
in	O
the	O
i	O
-	O
vector	O
(	O
bnf	O
)	O
system	O
was	O
trained	O
of	O
25ms	O
,	O
mean	O
-	O
normalized	O
over	O
a	O
sliding	O
window	O
of	O
up	O
to	O
3	O
seconds	B
.	O
on	O
the	O
fisher	O
english	O
corpus	B
.	O
to	O
achieve	O
a	O
limited	O
form	O
of	O
domain	B
the	O
same	O
energy	O
sad	O
as	O
used	O
in	O
the	O
baseline	B
systems	O
ﬁlters	O
out	O
adaptation	O
,	O
the	O
development	B
data	I
from	O
sitw	O
and	O
sre16	O
is	O
pooled	O
nonspeech	O
frames	O
.	O
and	O
used	O
for	O
centering	O
and	O
score	B
normalization	O
.	O
no	O
augmentation	B
is	O
the	O
dnn	O
conﬁguration	O
is	O
outlined	O
in	O
table	O
1	O
.	O
suppose	O
an	O
input	B
applied	O
to	O
these	O
lists	O
.	O
segment	B
has	O
t	O
frames	O
.	O
the	O
ﬁrst	O
ﬁve	O
layers	O
operate	O
on	O
speech	O
frames	O
,	O
with	O
a	O
small	O
temporal	O
context	O
centered	O
at	O
the	O
current	O
frame	B
t.	O
for	O
3.2	O
.	O
evaluation	B
example	O
,	O
the	O
input	B
to	O
layer	B
frame3	O
is	O
the	O
spliced	O
output	B
of	O
frame2	O
,	O
at	O
frames	O
t	O
−	O
3	O
,	O
t	O
and	O
t	O
+	O
3	O
.	O
this	O
builds	O
on	O
the	O
temporal	O
context	O
of	O
the	O
our	O
evaluation	B
consists	O
of	O
two	O
distinct	O
datasets	B
:	O
speakers	O
in	O
the	O
wild	O
earlier	O
layers	O
,	O
so	O
that	O
frame3	O
sees	O
a	O
total	O
context	O
of	O
15	O
frames	O
.	O
(	O
sitw	O
)	O
core	O
[	O
23	O
]	O
and	O
the	O
cantonese	O
portion	O
of	O
the	O
nist	O
sre	O
2016	O
the	O
statistics	B
pooling	O
layer	B
aggregates	O
all	O
t	O
frame	B
-	O
level	B
outputs	O
evaluation	B
(	O
sre16	O
)	O
[	O
24	O
]	O
.	O
sitw	O
consists	O
of	O
unconstrained	O
video	O
au-	O
from	O
layer	B
frame5	O
and	O
computes	O
its	O
mean	O
and	O
standard	O
deviation	O
.	O
dio	O
of	O
english	O
speakers	O
,	O
with	O
naturally	O
occurring	O
noises	O
,	O
reverber-	O
the	O
statistics	B
are	O
1500	O
dimensional	O
vectors	O
,	O
computed	O
once	O
for	O
each	O
ation	O
,	O
as	O
well	O
as	O
device	O
and	O
codec	O
variability	O
.	O
the	O
sre16	O
portion	O
input	B
segment	B
.	O
this	O
process	B
aggregates	O
information	B
across	O
the	O
time	B
consists	O
of	O
cantonese	O
conversational	O
telephone	B
speech	I
.	O
both	O
en-	O
dimension	O
so	O
that	O
subsequent	O
layers	O
operate	O
on	O
the	O
entire	O
segment	B
.	O
roll	O
and	O
test	B
sitw	O
utterances	B
vary	O
in	O
length	B
form	O
6–240	O
seconds	B
.	O
in	O
table	O
1	O
,	O
this	O
is	O
denoted	O
by	O
a	O
layer	B
context	O
of	O
{	O
0	O
}	O
and	O
a	O
total	O
con-	O
for	O
sre16	O
,	O
the	O
enrollment	O
utterances	B
contain	O
about	O
60	O
seconds	B
of	O
text	O
of	O
t	O
.	O
the	O
mean	O
and	O
standard	O
deviation	O
are	O
concatenated	O
to-	O
speech	O
while	O
the	O
test	B
utterances	B
vary	O
from	O
10–60	O
seconds.sitw	O
core	O
sre16	O
cantonese	O
eer(%	O
)	O
dcf10−2	O
dcf10−3	O
eer(%	O
)	O
dcf10−2	O
dcf10−3	O
i	O
-	O
vector	O
(	O
acoustic	O
)	O
9.29	O
0.621	O
0.785	O
9.23	O
0.568	O
0.741	O
4.1	O
original	O
systems	O
i	O
-	O
vector	O
(	O
bnf	O
)	O
9.10	O
0.558	O
0.719	O
9.68	O
0.574	O
0.765	O
x	O
-	O
vector	O
9.40	O
0.632	O
0.790	O
8.00	O
0.491	O
0.697	O
i	O
-	O
vector	O
(	O
acoustic	O
)	O
8.64	O
0.588	O
0.755	O
8.92	O
0.544	O
0.717	O
4.2	O
plda	B
aug	O
.	O
i	O
-	O
vector	O
(	O
bnf	O
)	O
8.00	O
0.514	O
0.689	O
8.82	O
0.532	O
0.726	O
x	O
-	O
vector	O
7.56	O
0.586	O
0.746	O
7.45	O
0.463	O
0.669	O
i	O
-	O
vector	O
(	O
acoustic	O
)	O
8.89	O
0.626	O
0.790	O
9.20	O
0.575	O
0.748	O
4.3	O
extractor	B
aug	O
.	O
i	O
-	O
vector	O
(	O
bnf	O
)	O
7.27	O
0.533	O
0.730	O
8.89	O
0.569	O
0.777	O
x	O
-	O
vector	O
7.19	O
0.535	O
0.719	O
6.29	O
0.428	O
0.626	O
i	O
-	O
vector	O
(	O
acoustic	O
)	O
8.04	O
0.578	O
0.752	O
8.95	O
0.555	O
0.720	O
plda	B
and	O
4.4	O
i	O
-	O
vector	O
(	O
bnf	O
)	O
6.49	O
0.492	O
0.690	O
8.29	O
0.534	O
0.749	O
extractor	B
aug	O
.	O
x	O
-	O
vector	O
6.00	O
0.488	O
0.677	O
5.86	O
0.410	O
0.593	O
i	O
-	O
vector	O
(	O
acoustic	O
)	O
7.45	O
0.552	O
0.723	O
9.23	O
0.557	O
0.742	O
4.5	O
incl	O
.	O
voxceleb	O
i	O
-	O
vector	O
(	O
bnf	O
)	O
6.09	O
0.472	O
0.660	O
8.12	O
0.523	O
0.751	O
x	O
-	O
vector	O
4.16	O
0.393	O
0.606	O
5.71	O
0.399	O
0.569	O
table	O
2	O
.	O
results	B
using	O
data	B
augmentation	I
in	O
various	O
systems	O
.	O
“	O
extractor	B
”	O
refers	O
to	O
either	O
the	O
ubm	O
/	O
t	O
or	O
the	O
embedding	O
dnn	O
.	O
for	O
each	O
experiment	O
,	O
the	O
best	O
results	B
are	O
boldface	O
.	O
we	O
report	O
results	B
in	O
terms	B
of	O
equal	O
error	O
-	O
rate	O
(	O
eer	B
)	O
and	O
the	O
min-	O
4.1	O
.	O
original	O
systems	O
imum	O
of	O
the	O
normalized	O
detection	B
cost	B
function	O
(	O
dcf	O
)	O
at	O
p	O
=	O
target	O
10−2	O
and	O
p	O
=	O
10−3	O
.	O
note	O
that	O
the	O
sre16	O
results	B
have	O
not	O
in	O
this	O
section	O
,	O
we	O
evaluate	O
systems	O
without	O
data	B
augmentation	I
.	O
the	O
target	O
extractors	O
are	O
trained	O
on	O
the	O
swbd	O
and	O
sre	O
datasets	B
described	O
been	O
“	O
equalized	O
[	O
24	O
]	O
.	O
”	O
in	O
section	O
3.1	O
.	O
the	O
plda	B
classiﬁers	O
are	O
trained	O
on	O
just	O
the	O
sre	O
dataset	O
.	O
without	O
using	O
augmentation	B
,	O
the	O
best	O
results	B
on	O
sitw	O
are	O
3.3	O
.	O
data	B
augmentation	I
obtained	O
by	O
i	O
-	O
vector	O
(	O
bnf	O
)	O
,	O
which	O
is	O
12	O
%	O
better	O
than	O
the	O
x	O
-	O
vector	O
augmentation	B
increases	O
the	O
amount	B
and	O
diversity	O
of	O
the	O
existing	O
system	O
at	O
dcf10−2	O
.	O
the	O
acoustic	O
i	O
-	O
vector	B
system	I
also	O
achieves	O
training	B
data	I
.	O
our	O
strategy	O
employs	O
additive	O
noises	O
and	O
reverber-	O
slightly	O
lower	O
error	O
-	O
rates	B
than	O
the	O
x	O
-	O
vector	B
system	I
on	O
sitw	O
.	O
how-	O
ation	O
.	O
reverberation	O
involves	O
convolving	O
room	O
impulse	O
responses	O
ever	O
,	O
even	O
without	O
augmentation	B
,	O
the	O
best	O
results	B
for	O
sre16	O
can-	O
(	O
rir	O
)	O
with	O
audio	O
.	O
we	O
use	O
the	O
simulated	O
rirs	O
described	O
by	O
ko	O
et	O
tonese	O
are	O
obtained	O
by	O
the	O
x	O
-	O
vectors	O
.	O
in	O
terms	B
of	O
dcf10−2	O
,	O
these	O
al	O
.	O
in	O
[	O
25	O
]	O
,	O
and	O
the	O
reverberation	O
itself	O
is	O
performed	O
with	O
the	O
multi-	O
embeddings	O
are	O
about	O
14	O
%	O
better	O
than	O
either	O
i	O
-	O
vector	B
system	I
.	O
we	O
condition	B
training	O
tools	O
in	O
the	O
kaldi	O
aspire	O
recipe	O
[	O
21	O
]	O
.	O
for	O
addi-	O
observe	O
that	O
i	O
-	O
vector	O
(	O
bnf	O
)	O
has	O
no	O
advantage	O
over	O
i	O
-	O
vector	O
(	O
acous-	O
tive	O
noise	O
,	O
we	O
use	O
the	O
musan	O
dataset	O
,	O
which	O
consists	O
of	O
over	O
900	O
tic	O
)	O
for	O
this	O
cantonese	O
speech	O
.	O
this	O
echoes	O
recent	O
studies	O
that	O
have	O
noises	O
,	O
42	O
hours	B
of	O
music	O
from	O
various	O
genres	O
and	O
60	O
hours	B
of	O
speech	O
found	O
that	O
the	O
large	O
gains	O
achieved	O
by	O
bnfs	O
in	O
english	O
speech	O
are	O
from	O
twelve	O
languages	O
[	O
26	O
]	O
.	O
both	O
musan	O
and	O
the	O
rir	O
datasets	B
are	O
not	O
necessarily	O
transferable	O
to	O
non	O
-	O
english	O
data	B
[	O
27	O
]	O
.	O
freely	O
available	O
from	O
http://www.openslr.org	O
.	O
we	O
use	O
a	O
3-fold	O
augmentation	B
that	O
combines	O
the	O
original	O
“	O
clean	O
”	O
4.2	O
.	O
plda	B
augmentation	B
training	O
list	O
with	O
two	O
augmented	O
copies	O
.	O
to	O
augment	O
a	O
recording	B
,	O
we	O
choose	O
between	O
one	O
of	O
the	O
following	O
randomly	O
:	O
in	O
this	O
experiment	O
,	O
the	O
augmentation	B
strategy	O
described	O
in	O
section	O
•	O
babble	O
:	O
three	O
to	O
seven	O
speakers	O
are	O
randomly	O
picked	O
from	O
3.3	O
is	O
applied	O
to	O
only	O
the	O
plda	B
training	O
list	O
.	O
we	O
use	O
the	O
same	O
ex-	O
musan	O
speech	O
,	O
summed	O
together	O
,	O
then	O
added	O
to	O
the	O
original	O
tractors	O
as	O
the	O
previous	O
section	O
,	O
which	O
were	O
trained	O
on	O
the	O
original	O
signal	B
(	O
13	O
-	O
20db	O
snr	O
)	O
.	O
datasets	B
.	O
plda	B
augmentation	B
results	B
in	O
a	O
clear	O
improvement	O
for	O
all	O
three	O
systems	O
relative	O
to	O
section	O
4.1	O
.	O
however	O
,	O
it	O
appears	O
that	O
the	O
•	O
music	O
:	O
a	O
single	O
music	O
ﬁle	O
is	O
randomly	O
selected	O
from	O
mu-	O
x	O
-	O
vectors	O
may	O
beneﬁt	O
from	O
the	O
plda	B
augmentation	B
more	O
than	O
the	O
san	O
,	O
trimmed	O
or	O
repeated	O
as	O
necessary	O
to	O
match	O
duration	O
,	O
baseline	B
systems	O
.	O
on	O
sitw	O
,	O
the	O
x	O
-	O
vector	B
system	I
achieves	O
slightly	O
and	O
added	O
to	O
the	O
original	O
signal	B
(	O
5	O
-	O
15db	O
snr	O
)	O
.	O
lower	O
error	O
-	O
rates	B
than	O
i	O
-	O
vector	O
(	O
acoustic	O
)	O
,	O
but	O
continues	O
to	O
lag	O
behind	O
•	O
noise	O
:	O
musan	O
noises	O
are	O
added	O
at	O
one	O
second	O
intervals	O
i	O
-	O
vector	O
(	O
bnf	O
)	O
at	O
most	O
operating	O
points	O
.	O
on	O
sre16	O
,	O
the	O
x	O
-	O
vectors	O
throughout	O
the	O
recording	B
(	O
0	O
-	O
15db	O
snr	O
)	O
.	O
maintain	O
an	O
advantage	O
over	O
the	O
i	O
-	O
vectors	O
by	O
about	O
14	O
%	O
in	O
dcf10−2	O
.	O
•	O
reverb	O
:	O
the	O
training	O
recording	B
is	O
artiﬁcially	O
reverberated	O
via	O
convolution	O
with	O
simulated	O
rirs	O
.	O
4.3	O
.	O
extractor	B
augmentation	B
4	O
.	O
results	B
we	O
now	O
apply	O
data	B
augmentation	I
to	O
the	O
extractor	B
(	O
ubm	O
/	O
t	O
or	O
em-	O
bedding	O
dnn	O
)	O
training	O
lists	O
but	O
not	O
the	O
plda	B
list	O
.	O
the	O
effect	O
of	O
the	O
main	O
results	B
are	O
presented	O
in	O
table	O
2	O
and	O
are	O
referenced	O
through-	O
augmenting	O
the	O
ubm	O
/	O
t	O
is	O
inconsistent	O
in	O
the	O
i	O
-	O
vector	B
system	I
.	O
this	O
out	O
sections	O
4.1–4.5	O
.	O
we	O
compare	O
performance	O
of	O
two	O
i	O
-	O
vector	O
sys-	O
observation	O
is	O
supported	O
by	O
prior	O
studies	O
on	O
i	O
-	O
vectors	O
,	O
which	O
have	O
tems	O
,	O
labeled	O
i	O
-	O
vector	O
(	O
acoustic	O
)	O
and	O
i	O
-	O
vector	O
(	O
bnf	O
)	O
,	O
with	O
the	O
x-	O
found	O
that	O
augmentation	B
is	O
only	O
effective	O
in	O
the	O
plda	B
classiﬁer	O
vector	B
system	I
.	O
the	O
systems	O
are	O
described	O
in	O
sections	O
2.1	O
,	O
2.2	O
and	O
[	O
28	O
,	O
29	O
]	O
.	O
on	O
the	O
other	O
hand	O
,	O
augmenting	O
the	O
embedding	O
dnn	O
train-	O
2.3	O
,	O
respectively	O
.	O
throughout	O
the	O
following	O
sections	O
,	O
we	O
use	O
the	O
term	O
ing	O
list	O
results	B
in	O
a	O
large	O
improvement	O
.	O
in	O
contrast	O
to	O
the	O
i	O
-	O
vector	O
sys-	O
extractor	B
to	O
refer	O
to	O
either	O
the	O
ubm	O
/	O
t	O
or	O
the	O
embedding	O
dnn	O
.	O
tems	O
,	O
this	O
is	O
considerably	O
more	O
effective	O
than	O
augmenting	O
the	O
pldatraining	O
list	O
.	O
on	O
sitw	O
,	O
the	O
x	O
-	O
vector	B
system	I
achieves	O
lower	O
error-	O
  	O
60	O
  	O
i	O
-	O
vector	O
(	O
acoustic	O
)	O
rates	B
than	O
i	O
-	O
vector	O
(	O
acoustic	O
)	O
and	O
has	O
now	O
caught	O
up	O
to	O
the	O
i	O
-	O
vector	O
i	O
-	O
vector	O
(	O
bnf	O
)	O
(	O
bnf	O
)	O
system	O
.	O
on	O
sre16	O
,	O
the	O
x	O
-	O
vectors	O
are	O
now	O
25	O
%	O
better	O
than	O
the	O
  	O
40	O
  	O
x	O
-	O
vector	O
i	O
-	O
vectors	O
in	O
dcf10−2	O
,	O
which	O
is	O
almost	O
double	O
the	O
improvement	O
the	O
dnn	O
embeddings	O
had	O
with	O
plda	B
augmentation	B
alone	O
.	O
the	O
ﬁndings	O
in	O
this	O
section	O
indicate	O
that	O
data	B
augmentation	I
is	O
only	O
beneﬁcial	O
for	O
%	O
)	O
  	O
20	O
  	O
extractors	O
trained	O
with	O
supervision	O
.	O
y	O
(	O
in	O
 	O
bilit	O
  	O
10	O
  	O
a	O
4.4	O
.	O
plda	B
and	O
extractor	B
augmentation	B
b	O
  	O
5	O
   	O
o	O
pr	O
in	O
the	O
previous	O
sections	O
,	O
we	O
saw	O
that	O
plda	B
augmentation	B
was	O
help-	O
ss	O
   	O
2	O
   	O
ful	O
in	O
both	O
i	O
-	O
vector	O
and	O
dnn	O
embedding	O
systems	O
,	O
although	O
extractor	B
mi	O
  	O
1	O
   	O
augmentation	B
was	O
only	O
clearly	O
beneﬁcial	O
in	O
the	O
embedding	O
system	O
.	O
in	O
this	O
experiment	O
,	O
we	O
apply	O
data	B
augmentation	I
to	O
both	O
the	O
extractor	B
 	O
0.5	O
  	O
and	O
plda	B
training	O
lists	O
.	O
we	O
continue	O
to	O
use	O
swbd	O
and	O
sre	O
for	O
extractor	B
training	O
and	O
only	O
sre	O
for	O
plda	B
.	O
on	O
sitw	O
the	O
x	O
-	O
vectors	O
  	O
0.1	O
 	O
are	O
now	O
10	O
-	O
25	O
%	O
better	O
than	O
i	O
-	O
vector	O
(	O
acoustic	O
)	O
and	O
are	O
slightly	O
better	O
 	O
0.01	O
   	O
0.1	O
  	O
0.5	O
   	O
1	O
    	O
2	O
     	O
5	O
    	O
10	O
   	O
20	O
    	O
40	O
    	O
60	O
  	O
false	B
alarm	I
probability	B
(	O
in	O
%	O
)	O
than	O
i	O
-	O
vector	O
(	O
bnf	O
)	O
at	O
all	O
operating	O
points	O
.	O
on	O
sre16	O
cantonese	O
,	O
the	O
x	O
-	O
vectors	O
continue	O
to	O
maintain	O
the	O
large	O
lead	O
over	O
the	O
i	O
-	O
vector	O
systems	O
established	O
in	O
section	O
4.3	O
.	O
fig	O
.	O
2	O
.	O
det	O
curve	O
for	O
the	O
sitw	O
core	O
using	O
section	O
4.5	O
systems	O
.	O
4.5	O
.	O
including	O
voxceleb	O
these	O
results	B
are	O
illustrated	O
by	O
detection	B
error	O
tradeoff	O
(	O
det	O
)	O
plots	O
in	O
figures	O
1	O
and	O
2	O
.	O
  	O
60	O
  	O
i	O
-	O
vector	O
(	O
acoustic	O
)	O
5	O
.	O
conclusions	O
i	O
-	O
vector	O
(	O
bnf	O
)	O
  	O
40	O
  	O
x	O
-	O
vector	O
this	O
paper	O
studied	O
dnn	O
embeddings	O
for	O
speaker	B
recognition	O
.	O
we	O
found	O
that	O
data	B
augmentation	I
is	O
an	O
easily	O
implemented	O
and	O
effective	O
%	O
)	O
  	O
20	O
  	O
strategy	O
for	O
improving	O
their	O
performance	O
.	O
we	O
also	O
made	O
the	O
x	O
-	O
vector	O
n	O
 	O
system	O
–	O
our	O
implementation	O
of	O
dnn	O
embeddings	O
–	O
available	O
in	O
the	O
y	O
(	O
i	O
kaldi	O
toolkit	O
.	O
we	O
found	O
that	O
the	O
x	O
-	O
vector	B
system	I
signiﬁcantly	O
outper-	O
bilit	O
  	O
10	O
  	O
formed	O
two	O
standard	O
i	O
-	O
vector	O
baselines	O
on	O
sre16	O
cantonese	O
.	O
after	O
ba	O
  	O
5	O
   	O
including	O
a	O
large	O
amount	B
of	O
augmented	O
microphone	O
speech	O
,	O
the	O
x-	O
o	O
pr	O
vectors	O
achieved	O
much	O
lower	O
error	O
-	O
rates	B
than	O
our	O
best	O
baseline	B
on	O
ss	O
   	O
2	O
   	O
speakers	O
in	O
the	O
wild	O
.	O
bottleneck	O
features	O
from	O
an	O
asr	B
dnn	O
are	O
mi	O
used	O
in	O
our	O
best	O
i	O
-	O
vector	B
system	I
,	O
and	O
so	O
it	O
requires	O
transcribed	O
data	B
  	O
1	O
   	O
during	O
training	O
.	O
on	O
the	O
other	O
hand	O
,	O
the	O
x	O
-	O
vector	O
dnn	O
needs	O
only	O
 	O
0.5	O
  	O
speaker	B
labels	I
to	O
train	O
,	O
making	O
it	O
potentially	O
ideal	O
for	O
domains	O
with	O
little	O
transcribed	O
speech	O
.	O
more	O
generally	O
,	O
it	O
appears	O
that	O
x	O
-	O
vectors	O
  	O
0.1	O
 	O
are	O
now	O
a	O
strong	O
contender	O
for	O
next	O
-	O
generation	O
representations	O
for	O
 	O
0.01	O
   	O
0.1	O
  	O
0.5	O
   	O
1	O
    	O
2	O
     	O
5	O
    	O
10	O
   	O
20	O
    	O
40	O
    	O
60	O
  	O
speaker	B
recognition	O
.	O
false	B
alarm	I
probability	B
(	O
in	O
%	O
)	O
fig	O
.	O
1	O
.	O
det	O
curve	O
for	O
the	O
cantonese	O
portion	O
of	O
nist	O
sre16	O
using	O
6	O
.	O
acknowledgments	O
section	O
4.5	O
systems	O
.	O
this	O
material	O
is	O
based	O
upon	O
work	O
supported	O
by	O
the	O
national	O
sci-	O
ence	O
foundation	O
graduate	O
research	B
fellowship	O
under	O
grant	O
no	O
.	O
the	O
training	B
data	I
in	O
sections	O
4.1–4.4	O
is	O
dominated	O
by	O
telephone	O
1232825	O
.	O
this	O
work	O
was	O
partially	O
supported	O
by	O
nsf	O
grant	O
no	O
cri-	O
speech	O
.	O
in	O
this	O
experiment	O
,	O
we	O
explore	O
the	O
effect	O
of	O
adding	O
a	O
large	O
1513128	O
.	O
any	O
opinion	O
,	O
ﬁndings	O
,	O
and	O
conclusions	O
or	O
recommenda-	O
amount	B
of	O
microphone	O
speech	O
to	O
the	O
systems	O
in	O
section	O
4.4	O
.	O
the	O
tions	O
expressed	O
in	O
this	O
material	O
are	O
those	O
of	O
the	O
authors(s	O
)	O
and	O
do	O
not	O
voxceleb	O
dataset	O
[	O
19	O
]	O
is	O
augmented	O
,	O
and	O
added	O
to	O
both	O
the	O
extractor	B
necessarily	O
reﬂect	O
the	O
views	O
of	O
the	O
national	O
science	O
foundation	O
.	O
and	O
plda	B
lists	O
.	O
as	O
noted	O
in	O
section	O
3.1	O
,	O
we	O
found	O
60	O
speakers	O
which	O
overlap	O
with	O
sitw	O
;	O
all	O
speech	O
for	O
these	O
speakers	O
was	O
removed	O
from	O
the	O
training	O
lists	O
.	O
7	O
.	O
references	B
on	O
sitw	O
,	O
both	O
i	O
-	O
vector	O
and	O
x	O
-	O
vector	O
systems	O
improve	O
signif-	O
[	O
1	O
]	O
d.	O
snyder	O
,	O
d.	O
garcia	O
-	O
romero	O
,	O
d.	O
povey	O
,	O
and	O
s.	O
khudan-	O
icantly	O
.	O
however	O
,	O
the	O
x	O
-	O
vector	O
exploits	O
the	O
large	O
increase	O
in	O
the	O
pur	O
,	O
“	O
deep	O
neural	B
network	I
embeddings	O
for	O
text	O
-	O
independent	O
amount	B
of	O
in	O
-	O
domain	B
data	B
better	O
than	O
the	O
i	O
-	O
vector	O
systems	O
.	O
com-	O
speaker	B
veriﬁcation	O
,	O
”	O
proc	O
.	O
interspeech	O
,	O
pp	O
.	O
999–1003	O
,	O
2017	O
.	O
pared	O
to	O
i	O
-	O
vector	O
(	O
acoustic	O
)	O
,	O
the	O
x	O
-	O
vectors	O
are	O
better	O
by	O
44	O
%	O
in	O
eer	B
and	O
29	O
%	O
in	O
dcf10−2	O
.	O
compared	O
to	O
the	O
i	O
-	O
vector	O
(	O
bnf	O
)	O
system	O
,	O
it	O
is	O
[	O
2	O
]	O
n.	O
dehak	O
,	O
p.	O
kenny	O
,	O
r.	O
dehak	O
,	O
p.	O
dumouchel	O
,	O
and	O
p.	O
ouel-	O
now	O
better	O
by	O
32	O
%	O
in	O
eer	B
and	O
17	O
%	O
in	O
dcf10−2	O
.	O
on	O
sre16	O
,	O
the	O
let	O
,	O
“	O
front	O
-	O
end	O
factor	B
analysis	I
for	O
speaker	B
veriﬁcation	O
,	O
”	O
ieee	O
i	O
-	O
vector	O
systems	O
remain	O
roughly	O
the	O
same	O
compared	O
to	O
section	O
4.4	O
,	O
transactions	O
on	O
audio	O
,	O
speech	O
,	O
and	O
language	B
processing	I
,	O
vol	O
.	O
but	O
the	O
x	O
-	O
vectors	O
improve	O
on	O
all	O
operating	O
points	O
by	O
a	O
small	O
amount	B
.	O
19	O
,	O
no	O
.	O
4	O
,	O
pp	O
.	O
788–798	O
,	O
2011.[3	O
]	O
s.	O
ioffe	O
,	O
“	O
probabilistic	O
linear	O
discriminant	B
analysis	I
,	O
”	O
computer	B
[	O
19	O
]	O
a.	O
nagrani	O
,	O
j.	O
s.	O
chung	O
,	O
and	O
a.	O
zisserman	O
,	O
“	O
voxceleb	O
:	O
a	O
large-	O
vision	O
–	O
eccv	O
2006	O
,	O
pp	O
.	O
531–542	O
,	O
2006	O
.	O
scale	O
speaker	B
identiﬁcation	O
dataset	O
,	O
”	O
in	O
interspeech	O
,	O
2017	O
.	O
[	O
4	O
]	O
p.	O
kenny	O
,	O
“	O
bayesian	O
speaker	B
veriﬁcation	O
with	O
heavy	O
-	O
tailed	O
pri-	O
[	O
20	O
]	O
c.	O
zhang	O
and	O
k.	O
koishida	O
,	O
“	O
end	O
-	O
to	O
-	O
end	O
text	O
-	O
independent	O
ors	O
.	O
,	O
”	O
in	O
odyssey	O
,	O
2010	O
,	O
p.	O
14	O
.	O
speaker	B
veriﬁcation	O
with	O
triplet	O
loss	O
on	O
short	O
utterances	B
,	O
”	O
proc	O
.	O
[	O
5	O
]	O
n.	O
bru¨mmer	O
and	O
e.	O
de	O
villiers	O
,	O
“	O
the	O
speaker	B
partitioning	O
interspeech	O
,	O
pp	O
.	O
1487–1491	O
,	O
2017	O
.	O
problem	O
.	O
,	O
”	O
in	O
odyssey	O
,	O
2010	O
,	O
p.	O
34	O
.	O
[	O
21	O
]	O
d.	O
povey	O
,	O
a.	O
ghoshal	O
,	O
g.	O
boulianne	O
,	O
l.	O
burget	O
,	O
o.	O
glembek	O
,	O
[	O
6	O
]	O
d.	O
garcia	O
-	O
romero	O
and	O
c.	O
espy	O
-	O
wilson	O
,	O
“	O
analysis	B
of	O
i	O
-	O
vector	O
n.	O
goel	O
,	O
m.	O
hannemann	O
,	O
p.	O
motl´ıcˇek	O
,	O
y.	O
qian	O
,	O
p.	O
schwarz	O
,	O
length	B
normalization	O
in	O
speaker	B
recognition	O
systems	O
.	O
,	O
”	O
in	O
in-	O
et	O
al	O
.	O
,	O
“	O
the	O
kaldi	O
speech	B
recognition	I
toolkit	O
,	O
”	O
in	O
proceedings	O
terspeech	O
,	O
2011	O
,	O
pp	O
.	O
249–252	O
.	O
of	O
the	O
automatic	O
speech	B
recognition	I
&	O
understanding	O
(	O
asru	O
)	O
workshop	O
,	O
2011	O
.	O
[	O
7	O
]	O
y.	O
lei	O
,	O
n.	O
scheffer	O
,	O
l.	O
ferrer	O
,	O
and	O
m.	O
mclaren	O
,	O
“	O
a	O
novel	O
scheme	O
for	O
speaker	B
recognition	O
using	O
a	O
phonetically	O
-	O
aware	O
[	O
22	O
]	O
d.	O
sturim	O
and	O
d.	O
reynolds	O
,	O
“	O
speaker	B
adaptive	O
cohort	O
se-	O
deep	O
neural	B
network	I
,	O
”	O
in	O
2014	O
ieee	O
international	O
conference	O
lection	O
for	O
tnorm	O
in	O
text	O
-	O
independent	O
speaker	B
veriﬁcation	O
,	O
”	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
(	O
icassp	O
)	O
.	O
ieee	O
,	O
in	O
acoustics	B
,	O
speech	O
,	O
and	O
signal	B
processing	I
,	O
2005	O
.	O
proceed-	O
2014	O
,	O
pp	O
.	O
1695–1699	O
.	O
ings.(icassp’05	O
)	O
.	O
ieee	O
international	O
conference	O
on	O
.	O
ieee	O
,	O
2005	O
,	O
vol	O
.	O
1	O
,	O
pp	O
.	O
i–741	O
.	O
[	O
8	O
]	O
p.	O
kenny	O
,	O
v.	O
gupta	O
,	O
t.	O
stafylakis	O
,	O
p.	O
ouellet	O
,	O
and	O
j.	O
alam	O
,	O
“	O
deep	O
neural	B
networks	I
for	O
extracting	O
baum	O
-	O
welch	O
statistics	B
[	O
23	O
]	O
m.	O
mclaren	O
,	O
l.	O
ferrer	O
,	O
d.	O
castan	O
,	O
and	O
a.	O
lawson	O
,	O
“	O
the	O
2016	O
for	O
speaker	B
recognition	O
,	O
”	O
in	O
proc	O
.	O
odyssey	O
,	O
2014	O
.	O
speakers	O
in	O
the	O
wild	O
speaker	B
recognition	O
evaluation	B
.	O
,	O
”	O
in	O
inter-	O
[	O
9	O
]	O
m.	O
mclaren	O
,	O
y.	O
lei	O
,	O
and	O
l.	O
ferrer	O
,	O
“	O
advances	O
in	O
deep	O
neu-	O
speech	O
,	O
2016	O
,	O
pp	O
.	O
823–827	O
.	O
ral	O
network	B
approaches	O
to	O
speaker	B
recognition	O
,	O
”	O
in	O
acoustics	B
,	O
[	O
24	O
]	O
“	O
nist	O
speaker	B
recognition	O
evaluation	B
2016	O
,	O
”	O
speech	O
and	O
signal	B
processing	I
(	O
icassp	O
)	O
,	O
2015	O
ieee	O
interna-	O
https://www.nist.gov/itl/iad/mig/	O
tional	O
conference	O
on	O
.	O
ieee	O
,	O
2015	O
,	O
pp	O
.	O
4814–4818	O
.	O
speaker	B
-	O
recognition	O
-	O
evaluation-2016/	O
,	O
2016	O
.	O
[	O
10	O
]	O
d.	O
garcia	O
-	O
romero	O
,	O
x.	O
zhang	O
,	O
a.	O
mccree	O
,	O
and	O
d.	O
povey	O
,	O
“	O
im-	O
[	O
25	O
]	O
t.	O
ko	O
,	O
v.	O
peddinti	O
,	O
d.	O
povey	O
,	O
m.	O
seltzer	O
,	O
and	O
s.	O
khudanpur	O
,	O
“	O
a	O
proving	O
speaker	B
recognition	O
performance	O
in	O
the	O
domain	B
adap-	O
study	O
on	O
data	B
augmentation	I
of	O
reverberant	O
speech	O
for	O
robust	O
tation	O
challenge	B
using	O
deep	O
neural	B
networks	I
,	O
”	O
in	O
spoken	O
lan-	O
speech	B
recognition	I
,	O
”	O
in	O
acoustics	B
,	O
speech	O
and	O
signal	B
process-	O
guage	O
technology	O
workshop	O
(	O
slt	O
)	O
,	O
2014	O
ieee	O
.	O
ieee	O
,	O
2014	O
,	O
ing	O
(	O
icassp	O
)	O
,	O
2017	O
ieee	O
international	O
conference	O
on	O
.	O
ieee	O
,	O
pp	O
.	O
378–383	O
.	O
2017	O
,	O
pp	O
.	O
5220–5224	O
.	O
[	O
11	O
]	O
d.	O
snyder	O
,	O
d.	O
garcia	O
-	O
romero	O
,	O
and	O
d.	O
povey	O
,	O
“	O
time	B
delay	O
deep	O
[	O
26	O
]	O
d.	O
snyder	O
,	O
g	O
chen	O
,	O
and	O
d.	O
povey	O
,	O
“	O
musan	O
:	O
a	O
music	O
,	O
neural	B
network	I
-	O
based	O
universal	O
background	O
models	B
for	O
speaker	B
speech	O
,	O
and	O
noise	O
corpus	B
,	O
”	O
2015	O
,	O
arxiv:1510.08484v1	O
.	O
recognition	O
,	O
”	O
in	O
2015	O
ieee	O
workshop	O
on	O
automatic	O
speech	B
recognition	I
and	O
understanding	O
(	O
asru	O
)	O
.	O
ieee	O
,	O
2015	O
,	O
pp	O
.	O
92	O
–	O
[	O
27	O
]	O
o.	O
novotny	O
´	O
,	O
p.	O
mateˇjka	O
,	O
o.	O
glembeck	O
,	O
o	O
plchot	O
,	O
f.	O
gre´zl	O
,	O
97	O
.	O
l.	O
burget	O
,	O
and	O
j.	O
cˇ	O
ernocky	O
´	O
,	O
“	O
analysis	B
of	O
the	O
dnn	O
-	O
based	O
sre	O
systems	O
in	O
multi	O
-	O
language	O
conditions	O
,	O
”	O
in	O
spoken	B
language	I
[	O
12	O
]	O
s.	O
o.	O
sadjadi	O
,	O
j.	O
pelecanos	O
,	O
and	O
s.	O
ganapathy	O
,	O
“	O
the	O
ibm	O
technology	O
workshop	O
(	O
slt	O
)	O
.	O
ieee	O
,	O
2016	O
.	O
speaker	B
recognition	O
system	O
:	O
recent	O
advances	O
and	O
error	O
anal-	O
ysis	O
,	O
”	O
interspeech	O
,	O
pp	O
.	O
3633–3637	O
,	O
2016	O
.	O
[	O
28	O
]	O
y.	O
lei	O
,	O
l.	O
burget	O
,	O
l.	O
ferrer	O
,	O
m.	O
graciarena	O
,	O
and	O
n.	O
scheffer	O
,	O
“	O
towards	O
noise	O
-	O
robust	B
speaker	I
recognition	O
using	O
probabilistic	O
[	O
13	O
]	O
g.	O
heigold	O
,	O
i.	O
moreno	O
,	O
s.	O
bengio	O
,	O
and	O
n.	O
shazeer	O
,	O
“	O
end	O
-	O
to	O
-	O
end	O
linear	O
discriminant	B
analysis	I
,	O
”	O
in	O
acoustics	B
,	O
speech	O
and	O
signal	B
text	O
-	O
dependent	O
speaker	B
veriﬁcation	O
,	O
”	O
in	O
2016	O
ieee	O
interna-	O
processing	B
(	O
icassp	O
)	O
,	O
2012	O
ieee	O
international	O
conference	O
on	O
.	O
tional	O
conference	O
on	O
acoustics	B
,	O
speech	O
and	O
signal	B
processing	I
ieee	O
,	O
2012	O
,	O
pp	O
.	O
4253–4256	O
.	O
(	O
icassp	O
)	O
.	O
ieee	O
,	O
2016	O
,	O
pp	O
.	O
5115–5119	O
.	O
[	O
29	O
]	O
d.	O
garcia	O
-	O
romero	O
,	O
x.	O
zhou	O
,	O
and	O
c.	O
espy	O
-	O
wilson	O
,	O
“	O
multicon-	O
[	O
14	O
]	O
y.	O
konig	O
,	O
l.	O
heck	O
,	O
m.	O
weintraub	O
,	O
and	O
k.	O
sonmez	O
,	O
“	O
nonlin-	O
dition	O
training	O
of	O
gaussian	O
plda	B
models	B
in	O
i	O
-	O
vector	O
space	O
for	O
ear	O
discriminant	O
feature	O
extraction	B
for	O
robust	O
text	O
-	O
independent	O
noise	O
and	O
reverberation	O
robust	B
speaker	I
recognition	O
,	O
”	O
in	O
2012	O
speaker	B
recognition	O
,	O
”	O
in	O
proc	O
.	O
rla2c	O
,	O
esca	O
workshop	O
on	O
ieee	O
international	O
conference	O
on	O
acoustics	B
,	O
speech	O
and	O
sig-	O
speaker	B
recognition	O
and	O
its	O
commercial	O
and	O
forensic	O
appli-	O
nal	O
processing	B
(	O
icassp	O
)	O
.	O
ieee	O
,	O
2012	O
,	O
pp	O
.	O
4257–4260	O
.	O
cations	O
,	O
1998	O
.	O
[	O
15	O
]	O
l.	O
heck	O
,	O
y.	O
konig	O
,	O
k.	O
sonmez	O
,	O
and	O
m.	O
weintraub	O
,	O
“	O
ro-	O
bustness	O
to	O
telephone	O
handset	O
distortion	O
in	O
speaker	B
recognition	O
by	O
discriminative	O
feature	O
design	O
,	O
”	O
in	O
speech	B
communication	I
,	O
2000	O
,	O
vol	O
.	O
31	O
,	O
pp	O
.	O
181–192	O
.	O
[	O
16	O
]	O
a.	O
salman	O
,	O
learning	O
speaker	B
-	O
speciﬁc	O
characteristics	B
with	O
deep	O
neural	O
architecture	B
,	O
ph.d	O
.	O
thesis	O
,	O
university	O
of	O
manch-	O
ester	O
,	O
2012	O
.	O
[	O
17	O
]	O
d.	O
snyder	O
,	O
p.	O
ghahremani	O
,	O
d.	O
povey	O
,	O
d.	O
garcia	O
-	O
romero	O
,	O
y.	O
carmiel	O
,	O
and	O
s.	O
khudanpur	O
,	O
“	O
deep	O
neural	B
network	I
-	O
based	B
speaker	I
embeddings	O
for	O
end	O
-	O
to	O
-	O
end	O
speaker	B
veriﬁcation	O
,	O
”	O
in	O
spoken	B
language	I
technology	O
workshop	O
(	O
slt	O
)	O
.	O
ieee	O
,	O
2016	O
.	O
[	O
18	O
]	O
s.	O
zhang	O
,	O
z.	O
chen	O
,	O
y.	O
zhao	O
,	O
j.	O
li	O
,	O
and	O
y.	O
gong	O
,	O
“	O
end	O
-	O
to	O
-	O
end	O
attention	O
based	O
text	O
-	O
dependent	O
speaker	B
veriﬁcation	O
,	O
”	O
in	O
spo-	O
ken	O
language	O
technology	O
workshop	O
(	O
slt	O
)	O
,	O
2016	O
ieee	O
.	O
ieee	O
,	O
2016	O
,	O
pp	O
.	O

